#pragma once
// MIT License
// Copyright (c) 2025 Jan-Willem Krans (janwillem32 <at> hotmail <dot> com)
// Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
// The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

// # Radixsortbidi8
// This library implements an efficient stable sort on arrays using an 8-bit indexed, bidirectional, least significant bit first radix sort method.
// This is currently a single-file library, with some additional folders and files only used for its test suite.
// Sorting functionality is available for unsigned integer, signed integer, floating-point and enumeration types.
// All these sorting functions can sort ascending or descending, order forwards or reverse, and optionally filter by absolute value.
// Several filters are available, such as two types of absolute, and an inverse pattern for signed integer and floating point types.
// See "Modes of operation for the template functions" for more details on that.
// Implemented function optimisations include the ability to skip sorting steps, using multithreaded parallel (bidirectional) indexing and copying while sorting, and usage of platform-specific intrinsic functions.
// Radix sort in general can be used to sort all array sizes, but is more efficient when applied to somewhat larger arrays compared to other efficient (and stable) comparison-based methods, like introsort.
// See "Performance tests" for more details about array sizes, types and achievable improvements in speed when sorting large arrays with this library.

// ## Table of contents (searchable)
// ### Documentation block:
// - MIT License
// - Radixsortbidi8
// - Table of contents
// - Examples of using the 4 templates with simple arrays as input
// - Examples of using the 4 templates with input from indirection
// - Examples of using the 4 templates with input from modified indirection
// - Bonus example of the longest regular item, with complete decoration of the template
// - The 4 main sorting template functions that are implemented here
// - Modes of operation for the template functions
// - Miscellaneous notes
// - Naming and tooling conventions used in this library
// - Notes on ongoing research and development
// - Extended filtering information for each of the 8 main modes
// - Performance tests
// ### Compiler configuration block:
// - Per-compiler function attributes
// - Include statements and the last checks for compatibility
// ### Internal functions implementation block (rsbd8::helper namespace):
// - Helper constants and functions
// - Concurrency tools
// - General purpose register count constant
// - Utility structures to generate tests for the often padded 80-bit long double types
// - Endianess detection
// - Utility structures to generate tests for 64- or 128-bit types
// - Utility templates to call the getter function
// - Utility templates to split off the first parameter
// - Utility template to retrieve the data sources from classes
// - Utility templates to get either the member object type or the member function return type
// - Utility template to pick an unsigned type of the lowest rank with the same size
// - Utility templates to use bit carry operations for the operators less than, and less than or equal
// - Utility template of bit scan forward
// - Utility templates of rotate left or right by a compile-time constant amount
// - Helper functions to implement the 8 main modes
// - Helper functions to implement the offset transforms
// - Function implementation templates for multi-part types
// - Function implementation templates for single-part types
// - 1- to 16-way multithreading function reroutes
// - Reroutes to the 1- or 2-thread functions for single-part types
// - Reroutes to the 1- or 2-thread functions (variants without indirection)
// - Reroutes to the 1- or 2-thread functions (variants with indirection)
// - Functions to establish the initial treshold for beyond 2-way multithreading
// - Helper functions for converting inputs to perform unsigned comparisons in a final merging phase
// - Helper functions for merging the halves from multithreading inputs without indirection
// - Up to 4-way multithreading functions without indirection
// - Helper functions for merging the thirds from multithreading inputs without indirection
// - Up to 6-way multithreading functions without indirection
// - Up to 8-way multithreading functions without indirection
// - Up to 16-way multithreading functions without indirection
// - Helper functions for merging the halves from multithreading inputs with indirection
// - Up to 4-way multithreading functions with indirection
// - Helper functions for merging the thirds from multithreading inputs with indirection
// - Up to 6-way multithreading functions with indirection
// - Up to 8-way multithreading functions with indirection
// - Up to 16-way multithreading functions with indirection
// ### User-facing (inline) functions block (rsbd8 namespace):
// - Definition of the GetOffsetOf and getoffsetof templates
// - Generic large array allocation and deallocation functions
// - Wrapper template functions for the main sorting functions in this library
// ### Ending:
// - Library finalisation

// ## Examples of using the 4 templates with simple arrays as input (automatically deduced template parameters are omitted here):
// The rsbd8::radixsort() and rsbd8::radixsortcopy() template wrapper functions (typically) merely allocate memory prior to using the actual sorting functions.
// No intermediate buffer array is required when any variant of rsbd8::radixsortcopynoalloc() is used for sorting 8-bit types.
//
// - bool succeeded{rsbd8::radixsort(count, inputarr, pagesizeoptional)};
// - bool succeeded{rsbd8::radixsortcopy(count, inputarr, outputarr, pagesizeoptional)};
// - rsbd8::radixsortnoalloc(count, inputarr, bufferarr, false);
// - rsbd8::radixsortcopynoalloc(count, inputarr, outputarr, bufferarr);

// ## Examples of using the 4 templates with input from first-level indirection (automatically deduced template parameters are omitted here):
// This library includes common and much less common use scenarios to deal with input from first- and second-level indirection.
// The address offset template parameters (compile-time constants) displace the pointers as acting on a flat "std::byte const *" array, so not as some sort of array indices, to handle some cases with oddly formed structures.
// For the more advanced use cases, an extra argument (run-time, variadic function parameter) can be added to index the indirection when dealing with a (member) pointer/array.
// These index parameters are typically used in a more straightforward manner and use regular indexing.
// The variant with a getter function allows any number of extra arguments to pass on to the getter function.
// Using a getter function that can throw (meaning that it lacks "noexcept") will incur some extra processing overhead.
// Multithreading can be limited at compile-time by setting the macro RSBD8_THREAD_MAXIMUM to 1, 2, 4, 6, 8 or 16 simultaneous threads.
// There is no multithreading limit by default, but when multithreading is enabled, std::thread will be queried once per call to get the default available processor core count to the process.
// Limits for multithreading based on the input count can be disabled at compile-time by setting the macro RSBD8_THREAD_MINIMUM to force using at least 2, 4, 6, 8 or 16 simultaneous threads.
// This is again not enabled by default, and it only applies when processor cores are available at runtime. The much lower limits for allowing 2-way multithreading at runtime always apply.
//
// - bool succeeded{rsbd8::radixsort<&myclass::getterfunc>(count, inputarr, pagesizeoptional)};
// - bool succeeded{rsbd8::radixsort<&myclass::member>(count, inputarr, pagesizeoptional)};
// - bool succeeded{rsbd8::radixsort<std::uint64_t, addressoffset>(count, inputarr, pagesizeoptional)};
//
// - bool succeeded{rsbd8::radixsortcopy<&myclass::getterfunc>(count, inputarr, outputarr, pagesizeoptional, getterparameters...)};
// - bool succeeded{rsbd8::radixsortcopy<&myclass::member>(count, inputarr, outputarr, pagesizeoptional)};
// - bool succeeded{rsbd8::radixsortcopy<bool, addressoffset>(count, inputarr, outputarr, pagesizeoptional)};
//
// - rsbd8::radixsortnoalloc<&myclass::getterfunc>(count, inputarr, bufferarr, false, getterparameters...);
// - rsbd8::radixsortnoalloc<&myclass::member>(count, inputarr, bufferarr, false);
// - rsbd8::radixsortnoalloc<std::int16_t, addressoffset>(count, inputarr, bufferarr, false);
//
// - rsbd8::radixsortcopynoalloc<&myclass::getterfunc>(count, inputarr, outputarr, bufferarr, getterparameters...);
// - rsbd8::radixsortcopynoalloc<&myclass::member>(count, inputarr, outputarr, bufferarr);
// - rsbd8::radixsortcopynoalloc<float, addressoffset>(count, inputarr, outputarr, bufferarr);
//
// ### There are only a few template functions that almost directly implement sorting with indirection here:
// - rsbd8::radixsortcopynoalloc()
// - rsbd8::radixsortnoalloc()
// These both have 8-bit, 16/24/32/40/48/56/64-bit, (x87) 80-bit (plus padding) and 128-bit type template functions.
// These all have a version that handles straightforward arrays, and a version that handles arrays with indirection.
// All other items are compile-time, multithreading, or inlined wrapper helper tools for these.
// ### This base functionality can be expanded (like several wrapper functions do) by utilising the tools:
// - rsbd8::getoffsetof
// - rsbd8::allocatearray()
// - rsbd8::deallocatearray()
// - rsbd8::buffermemorywrapper

// ## Examples of using the 4 templates with input from second-level indirection (automatically deduced template parameters are omitted here):
// As the use case for these almost always involve multi-pass techniques, the user is advised to allocate the (reusable) buffers accordingly and avoid the use of radixsortcopy() and radixsort().
// The rsbd8::allocatearray() and rsbd8::deallocatearray() inline function templates are provided for handling an intermediate buffer.
// Again, no intermediate buffer is required when rsbd8::radixsortcopynoalloc() is used for sorting a single-part type.
// These will internally first retrieve a pointer to a "T" type array "T *myarray".
// After that it's dereferenced at the origin (first set of examples) or indexed (second set of examples) as "myarray[indirectionindex]" to retrieve the value used for sorting.
// Again, all "addressoffset" variants as template inputs displace like on a flat "std::byte const *", so not as some sort of array indices.
// The "addressoffset1" item here displaces the pointer in the input array to get the secondary pointer.
// The "addressoffset2" item here displaces the secondary pointer to get the (unfiltered) sorting value.
//
// ### Examples of using the 2 templates with no indexed second-level indirection:
//
// - rsbd8::radixsortcopynoalloc<&myclass::getterfunc, rsbd8::sortingdirection::ascfwdorder, rsbd8::sortingmode::native, addressoffset2>(count, inputarr, outputarr, bufferarr, getterparameters...);
// - rsbd8::radixsortcopynoalloc<&myclass::member, rsbd8::sortingdirection::ascfwdorder, rsbd8::sortingmode::native, addressoffset2>(count, inputarr, outputarr, bufferarr);
// - rsbd8::radixsortcopynoalloc<long *, addressoffset1, rsbd8::sortingdirection::ascfwdorder, rsbd8::sortingmode::native, addressoffset2>(count, inputarr, outputarr, bufferarr);
//
// - rsbd8::radixsortnoalloc<&myclass::getterfunc, rsbd8::sortingdirection::ascfwdorder, rsbd8::sortingmode::native, addressoffset2>(count, inputarr, bufferarr, false, getterparameters...);
// - rsbd8::radixsortnoalloc<&myclass::member, rsbd8::sortingdirection::ascfwdorder, rsbd8::sortingmode::native, addressoffset2>(count, inputarr, bufferarr, false);
// - rsbd8::radixsortnoalloc<wchar_t *, addressoffset1, rsbd8::sortingdirection::ascfwdorder, rsbd8::sortingmode::native, addressoffset2>(count, inputarr, bufferarr, false);
//
// ### Examples of using the 2 templates with indexed second-level indirection:
//
// - rsbd8::radixsortcopynoalloc<&myclass::getterfunc, rsbd8::sortingdirection::ascfwdorder, rsbd8::sortingmode::native, addressoffset2, true>(count, inputarr, outputarr, bufferarr, indirectionindex, getterparameters...);
// - rsbd8::radixsortcopynoalloc<&myclass::member, rsbd8::sortingdirection::ascfwdorder, rsbd8::sortingmode::native, addressoffset2, true>(count, inputarr, outputarr, bufferarr, indirectionindex);
// - rsbd8::radixsortcopynoalloc<double *, addressoffset1, rsbd8::sortingdirection::ascfwdorder, rsbd8::sortingmode::native, addressoffset2, true>(count, inputarr, outputarr, bufferarr, indirectionindex);
//
// - rsbd8::radixsortnoalloc<&myclass::getterfunc, rsbd8::sortingdirection::ascfwdorder, rsbd8::sortingmode::native, addressoffset2, true>(count, inputarr, bufferarr, false, indirectionindex, getterparameters...);
// - rsbd8::radixsortnoalloc<&myclass::member, rsbd8::sortingdirection::ascfwdorder, rsbd8::sortingmode::native, addressoffset2, true>(count, inputarr, bufferarr, false, indirectionindex);
// - rsbd8::radixsortnoalloc<unsigned long *, addressoffset1, rsbd8::sortingdirection::ascfwdorder, rsbd8::sortingmode::native, addressoffset2, true>(count, inputarr, bufferarr, false, indirectionindex);
//
// ### Examples of using the 2 templates with indexed first- and second-level indirection:
//
// - rsbd8::radixsortcopynoalloc<&myclass::member, rsbd8::sortingdirection::ascfwdorder, rsbd8::sortingmode::native, addressoffset2, true>(count, inputarr, outputarr, bufferarr, indirectionindex1, indirectionindex2);
// - rsbd8::radixsortcopynoalloc<long double *, addressoffset1, rsbd8::sortingdirection::ascfwdorder, rsbd8::sortingmode::native, addressoffset2, true>(count, inputarr, outputarr, bufferarr, indirectionindex1, indirectionindex2);
//
// - rsbd8::radixsortnoalloc<&myclass::member, rsbd8::sortingdirection::ascfwdorder, rsbd8::sortingmode::native, addressoffset2, true>(count, inputarr, bufferarr, false, indirectionindex1, indirectionindex2);
// - rsbd8::radixsortnoalloc<short *, addressoffset1, rsbd8::sortingdirection::ascfwdorder, rsbd8::sortingmode::native, addressoffset2, true>(count, inputarr, bufferarr, false, indirectionindex1, indirectionindex2);

// ## The 4 main sorting template functions that are implemented here
// ### radixsortnoalloc():
// - counted (first parameter "count", the end of arrays are no inputs to these functions unlike some sorting functions)
// - sorts an array (second parameter "input")
// - uses an array as a buffer of the same size and type (third parameter "buffer")
// - with a toggle to output to either the input array or the buffer array (optional fourth parameter "movetobuffer")
// - the array that is not selected for output contains garbage afterwards (typically the leftovers from an intermediate sorting stage)
// - both arrays need to be writable, but when using indirection the members can be const-qualified
// ### radixsortcopynoalloc():
// - counted (first parameter "count")
// - similar to radixsortnoalloc(), but will not write to the input array, which can be const-qualified (second parameter "input")
// - uses a dedicated output array of the same size (third parameter "output")
// - uses a memory buffer of the same size, which contains garbage afterwards (fourth parameter)
// ### radixsort():
// - wrapper template for radixsortnoalloc()
// - only allocates memory for the buffer parameter
// - (Windows-only) large page size for VirtualAlloc() can be used if enabled with the lock memory privilege for the application enabled (optional third parameter)
// - (POSIX implementing systems-only) flags for enabling pages with huge TLB functionality for mmap() can be used (optional third parameter)
// ### radixsortcopy():
// - wrapper template for radixsortcopynoalloc()
// - only allocates memory for the buffer parameter
// - (Windows-only) large page size for VirtualAlloc() can be used if enabled with the lock memory privilege for the application enabled (optional third parameter)
// - (POSIX implementing systems-only) flags for enabling pages with huge TLB functionality for mmap() can be used (optional third parameter)

// ## Modes of operation for the template functions
namespace rsbd8{
// All sorting functions here are templates with a compile-time constant sorting mode and direction.
enum struct sortingmode : unsigned char{// 5 bits as bitfields, bit 6 is used to select automatic modes (64 and greater)
// ### The three generic modes that can be activated are:
	native = 64,
// - automatic unsigned integer, signed integer or floating-point, depending on input type (default)
	nativeabs = 65,
// - automatic unsigned integer, absolute signed integer or absolute floating-point, depending on input type
// - (no distinct effect when used on an unsigned integer input type)
	nativetieredabs = 66,
// - automatic unsigned integer, absolute signed integer or absolute floating-point, depending on input type, but negative inputs will sort just below their positive counterparts
// - (no distinct effect when used on an unsigned integer input type)
//
// ### The five regular modes that can be activated are:
	forceunsigned = 0,
// - regular unsigned integer (default for unsigned input types)
	specialsigned = forceunsigned,
// - and also inside-out signed integer
// - (sorts ascending from 0, maximum value, minimum value, to -1)
	forcesigned = 1 << 1,
// - regular signed integer (default for signed input types)
	forceabssigned = 1 | 1 << 1,
// - absolute signed integer:
	forcefloatingp = 1 << 1 | 1 << 2,
// - regular floating-point (default for floating-point input types)
	forceabsfloatingp = 1 | 1 << 1 | 1 << 2,
// - absolute floating-point
	specialunsigned = forceabsfloatingp,
// - and also unsigned integer without using the top bit
//
// ### The three special modes that can be activated are:
	specialfloatingp = 1 << 2,
// - inside-out floating-point
// - (sorts ascending from +0., +infinity, +NaN, -NaN, -infinity, to -0.)
	forcetieredabsfloatingp = 1 | 1 << 2,
// - absolute floating-point, but negative inputs will sort just below their positive counterparts
// - (sorts ascending from -0., +0., -infinity, +infinity, to various -NaN or +NaN values at the end)
	forcetieredabssigned = 1
// - absolute signed integer, but negative inputs will sort just below their positive counterparts
// - (sorts ascending from 0, -1, 1, -2, 2, and so on, will work correctly for minimum values)
};
// ### The two reversing modes are:
enum struct sortingdirection : unsigned char{// 2 bits as bitfields
// - isdescsort (default false): reverse the sorting direction
// - isrevorder (default false): reverse the array direction when sorting items with the same value (only used when dealing with indirection)
// Enabling isdescsort costs next to nothing in terms of performance, isrevorder does initially take minor extra processing when handling multi-part types.
	ascfwdorder = 0,
// - isdescsort = false, isrevorder = false: stable sort, low to high (default)
	dscrevorder = 1 | 1 << 1,
// - isdescsort = true, isrevorder = true: stable sort, high to low, the complete opposite direction of the default functionality
	dscfwdorder = 1,
// - isdescsort = true, isrevorder = false: stable sort, high to low, but keeps items with the same value in the same order as in the source
	ascrevorder = 1 << 1
// - isdescsort = false, isrevorder = false: stable sort, low to high, but reverses items of the same value compared to the order in the source
// This last combination is very uncommon, but could be useful in some rare cases.
};
// ### To give an example of isdescsort = true, isrevorder = false, as it's a bit tricky to imagine without a reference:
// myclass collA[]{{1, "first"}, {1, "second"}, {-5, "third"}, {2, "fourth"}};// list construct
// myclass *pcollA[]{collA, collA + 1, collA + 2, collA + 3};// list pointers
// rsbd8::radixsortnoalloc<&myclass::keyorder, rsbd8::dscfwdorder>(4, pcollA, psomeunusedbuffer);
// Members of "pcollA" will then get sorted according to their value "keyorder", in reverse order, while keeping the same array order.
// Pointers will in this case point to: {2, "fourth"}, {1, "first"}, {1, "second"}, {-5, "third"}.
// That is different from fully reversing the order when using this line instead of the above:
// rsbd8::radixsortnoalloc<&myclass::keyorder, rsbd8::dscrevorder>(4, pcollA, psomeunusedbuffer);
// Pointers will in this case point to: {2, "fourth"}, {1, "second"}, {1, "first"}, {-5, "third"}.
// Notice the same reverse stable sorting here, but opposite placement when encountering the same value multiple times.
}// namespace rsbd8

// ## Miscellaneous notes
// Sorting unsigned values is the fastest, very closely followed up by signed values, followed up by floating-point values in this library.
// Unsigned 128-bit and larger integers can be sorted by sequential sorting from the bottom to the top parts as unsigned (64-bit) elements when using indirection.
// Signed 128-bit and larger integers are sorted the same, with only the topmost (64-bit) element sorted as signed because of the sign bit. This does not work when filtered by the absolute modes.
// Regular absolute 128-bit and larger floating-point values are sorted the same, with only the topmost (64-bit) element sorted as absolute floating-point because of the sign bit. This does not work when filtered by the default or tiered absolute modes.
// Re-use the same intermediate buffer combined with radixsortnoalloc() or radixsortcopynoalloc() when sorting 128-bit and larger integers like this.
// Inputs of type bool are reinterpreted as the unsigned integer type of the same size (usually the unsigned char type), but handling them is extremely efficient anyway.
// Anything but 0 or 1 in bool source data will impact sorting, but this only happens if the user deliberately overrides the compiler behaviour for bool data.
// The sign of type char is ambiguous, as by the original C standard, so cast inputs to char8_t * or unsigned char *, or force unsigned processing modes if unambiguously a binary sort of char characters is desired.
// Floating-point NaN values are sorted before negative infinity for the typical machine-generated "undefined" QNaN (0xFFF8'0000'0000'0000 on an IEEE double).
// Floating-point NaN positive values (implies not machine-generated) are sorted after positive infinity (0x7FF0'0000'0000'0001 and onward on an IEEE double).
// Floating-point SNaN (signalling) values do not trigger signals inside these functions. This is similar to many other non-arithmetic functions in namespace std.

// ## Naming and tooling conventions used in this library
// ### Textual:
// The base language for this library is modern British English (en-GB), but purely imported names may of course be sourced differently.
// All names are lowercase, with no separators, and any sort of length, based on convenience or frequency of local usage.
// Any sort of names on a global or namespace scope are longer, to provide some context.
// All user-facing functions have a general description in a comment in the line above them. This is generally what any IDE will display when giving a tooltip.
// The few macro definitions are all uppercase, separated by underscores, starting with "RSBD8_".
// There are most certainly no limitations on the lengths of functions, lines, comment blocks or other items. Everything is just kept sensible, in proper order, never spaghettified or obscured much, feature-rich (even if a little complicated sometimes), and very much optimised.
// This library undefines its macro definitions at the end of the file and does not need to expose any macro definitions externally.
// This library has three imported code sections that are clearly marked at the beginning and end. These are edited sparingly, unless they get replaced again with a newer version.
// ### Namespaces:
// rsbd8:: is radixsortbidi8, the enveloping namespace for this library
// rsbd8::helper:: is the underlying namespace for helper functions and constants. These are usually not directly invoked by the user of this library. No efforts are made to actually hide items from the user though.
// ### Templates:
// <typename T, typename U, typename V, typename W, typename X, typename M>
// These are the basic placeholders for types.
// T is used for the main input type, or the primary type being referred to.
// U is the deferred type, for example the unsigned variant of T, or an unsigned general utility type that is larger than T.
// V is always used as the class type of input and output arrays when dealing with indirection.
// W is the wildcard type, often an automatically deduced item in templated helper functions, but also often just a companion type to U.
// X is the index type, used for assigning unsigned integer indices of various sizes.
// M is the mask type, used in the merging phase of 4-way and greater multithreaded sorting.
// Some other template parts have defaults set up for them, especially for the longer lists of template parameters. This provides the user with often having less verbosity in their code.
// Template variable arguments as a C++ feature are used extensively by this library. Function-based variable arguments passing as inherited from original C isn't needed.
// All sorts of levels and configurations of template metaprogramming (C++17 and onward) are used in this library for optimisation, enhancing debugging or just making the code more concise.
// ### Functional:
// This is an optimal performance library. Of course, minor performance setbacks may arise from just compiler interpretation or functional issues. Keep the code close to the bare metal, in the right order to easily compile to instructions and use tons of optimisation features to overcome such issues.
// Even if many parts here just don't comply with most of the programming world's "clean" code rules, performance is key first, reducing the total count of functions but balanced with maintainability is second, and being descriptive of functionality in a combination of code and comments is third.
// Defensive programming here is mostly left to template metaprogramming and compile-time assertions, as compile-time items don't hurt performance.
// Parameter and environment checking is left to the absolute minimum outside of the debug mode. Of course, memory allocation failures are handled, and likewise the cases of potentially throwing functions.

// ## Notes on ongoing research and development
//
// ### TODO, add support for types larger than 128 bits
// - TODO, currently all functions here are guarded with an upper limit of 8-, 64-, 80, 96- or 128-bit (using std::enable_if sections). Future functionality will either require lifting the limits on current functions, or adding another set of functions for the larger data types. Given that radix sort variants excel at processing large data types compared to comparison-based sorting methods, do give this some priority in development.
//
// ### TODO, document computer system architecture-dependent code parts and add more options
// - TODO, investigate SIMD, in all of its shapes and sizes. Some experimentation has been done with x64+AVX-512 in an early version, but compared to other optimisations and strategies it never yielded much for these test functions.
// - TODO, the current version of this library does not provide much optimisation for processing any 64-bit (or larger) types on 32-bit systems at all. This can be documented, and later on optimised.
// - TODO, similarly, 16-bit systems still exist. (Even though these often do include a capable 32-bit capable data path line, see the history of x86 in this regard for example.) If this library can be optimised for use in a reasonably current 16-bit microcontroller, document and later on optimise for it.
// - TODO, add more platform-dependent, optimised code sequences here similar to the current collections in the rsbd8::helper namespace.
// - TODO, test and debug this library on more machines, platforms and such. Functionality and performance should both be guaranteed.
//
// ### TODO, this is a C++17 minimum library, but more modern features are welcome
// - TODO, bumping up the library to C++20 minimum isn't advised (yet), but could be in the near future.
// - TODO, C++23 features currently don't add much over some of the improvements seen in C++20, but for example indexed varargs from C++26 could certainly provide some simplification in a few functions here. Adding more modern C++ features (even if as optional items for now) is welcome.
//
// ### TODO, add support for non-array inputs
// - TODO, as the basic std::sort and std::stable_sort variants already support this functionality, it could be an advantage to add support for the other C++ iterable data sets.
// - TODO, performance testing and use case investigation is required for this subject, as radix sort types only really work well on somewhat larger arrays, and probably other larger iterable data sets, too.

// ## Extended filtering information for each of the 8 main modes
//
// ### Modes of operation for the template functions
// #### regular unsigned integer "forceunsigned" (default for unsigned input types)
// #### and also inside-out signed integer "specialsigned"
// - (sorts ascending from 0, maximum value, minimum value, to -1):
// - isabsvalue = false, issignmode = false, isfltpmode = false
// - lowest amount of filtering cost
// - straightforward process, no filter at all
// #### regular signed integer "forcesigned" (default for signed input types):
// - isabsvalue = false, issignmode = true, isfltpmode = false
// - lower amount of filtering cost
// - no filter in the processing phases
// - virtually flips the most significant bit when calculating offsets
// #### absolute signed integer "forceabssigned":
// - isabsvalue = true, issignmode = true, isfltpmode = false
// - medium amount of filtering cost
// - creates a sign bit mask, adds it to the input and uses it with xor on the input as a filter in the processing phases
// #### regular floating-point "forcefloatingp" (default for floating-point input types):
// - isabsvalue = false, issignmode = true, isfltpmode = true
// - higher amount of filtering cost
// - creates a sign bit mask and uses it with xor on the exponent and mantissa bits as a filter in the processing phases
// - virtually flips the most significant bit when calculating offsets
// #### absolute floating-point "forceabsfloatingp"
// #### and also unsigned integer without using the top bit "specialunsigned":
// - isabsvalue = true, issignmode = true, isfltpmode = true
// - low amount of filtering cost
// - masks out the sign bit in the processing phases
//
// The three special modes that can be activated are:
// #### inside-out floating-point "specialfloatingp"
// #### (sorts ascending from +0., +infinity, +NaN, -NaN, -infinity, to -0.):
// - isabsvalue = false, issignmode = false, isfltpmode = true
// - higher amount of filtering cost
// - creates a sign bit mask and uses it with xor on the exponent and mantissa bits as a filter in the processing phases
// #### absolute floating-point, but negative inputs will sort just below their positive counterparts "forcetieredabsfloatingp"
// #### (sorts ascending from -0., +0., -infinity, +infinity, to various -NaN or +NaN values at the end):
// - isabsvalue = true, issignmode = false, isfltpmode = true
// - medium amount of filtering cost
// - bit rotates left by one to move the sign bit to the least significant bit in the processing phases
// - virtually flips the least significant bit when calculating offsets
// #### absolute signed integer, but negative inputs will sort just below their positive counterparts "forcetieredabssigned"
// #### (sorts ascending from 0, -1, 1, -2, 2, and so on, will work correctly for minimum values):
// - isabsvalue = true, issignmode = false, isfltpmode = false
// - medium amount of filtering cost
// - creates a sign bit mask, shifts the input left by one and uses xor on the input with the sign bit mask as a filter in the processing phases
//
// ### Enabling reverse ordering on these modes will add slightly more to the initial filtering cost.
// For example, the highest amount of filtering cost would be on the floating-point full reverse mode.
// Take "highest amount" with a grain of salt though, as way more complicated filtering stages can be designed than what is used for this combination of filters.
//
// ### Absolute floating-point, but negative inputs will sort just below their positive counterparts operates differently.
// Bit rotate left by one is the first filtering step to make this possible.
// Sort as unsigned, just with the least significant bit flipped to complete the filter.
// #### As an example of this, the 8-bit sorting pattern in ascending mode:
// 0b1000'0000 -0.
// 0b0000'0000 +0.
// 0b1000'0001 -exp2(1 - mantissabitcount - exponentbias)
// 0b0000'0001 +exp2(1 - mantissabitcount - exponentbias)
// ...
// 0b1111'1111 -QNaN (maximum amount of ones)
// 0b0111'1111 +QNaN (maximum amount of ones)

// ## Performance tests
// ### This library has a performance test suite used for development.
// These performance test results are for sorting a block of 1 GiB, with fully random bits in integer and floating-point arrays (with no indirection or extra filtering).
// #### std::stable_sort() vs rsbd8::radixsort(), measured in 100 ns units:
// - float :_ 79341528806 vs 5068443726, a factor of 15.65 in speedup
// - double:_ 51521014035 vs 5284085860, a factor of 9.750 in speedup
// - uint64:_ 50518618540 vs 4882182872, a factor of 10.35 in speedup
// - int64 :_ 50963293135 vs 5159867120, a factor of 9.877 in speedup
// - uint32: 101573004007 vs 3701128500, a factor of 27.44 in speedup
// - int32 : 103658239227 vs 3801618261, a factor of 27.27 in speedup
// - uint16: 155841701982 vs 3233975799, a factor of 48.19 in speedup
// - int16 : 149563180451 vs 3191150398, a factor of 46.87 in speedup
// - uint8 : 213574532756 vs 3039381578, a factor of 70.27 in speedup
// - int8 _: 211616058503 vs 2946007896, a factor of 71.83 in speedup
// A radix sort with indirection, with its relatively fewer memory accesses compared to a comparison-based sort, will definitely often be one of the most optimal choices.
// However, sorting with indirection is slower than sorting without indirection, as expected.
// #### Simple tests of the first-level indirection rsbd8::radixsort() vs the direct variant above, measured in 100 ns units:
// - uint64: 20172428670 vs 4882182872, a factor of 4.132 in slowdown, purely because of indirection
// - double: 20779336651 vs 5284085860, a factor of 3.932 in slowdown, purely because of indirection
//
// ### The next tests were done on smaller blocks.
// There will be a minimum amount of array entries where rsbd8::radixsort() starts to get the upper hand in speed over std::stable_sort().
// #### These test results were obtained by performance testing on multiple sizes of blocks between .5 to 8 KB, with again fully random bits in unsigned integer and floating-point arrays (with no indirection):
// - float : 875 array entries
// - double: 600 array entries
// - uint64: 700 array entries
// - uint32: 400 array entries
// - uint16: 375 array entries
// - uint8 : 300 array entries
// Interpreting this means that radix sort variants will be faster for somewhat larger arrays when sorting data under the given conditions.
// In this case that's a sequence of just plain numbers in an array.
// When dealing with sorting while using indirection or filtering, test results will vary.
//
// ### System configuration data ofthe last performance tests:
// #### Performance testing was done on 2025-11-17 on development PC 1:
// - Intel Core i9 11900K, specification string: 11th Gen Intel Core i9-11900K @ 3.50GHz
// - Corsair CMK16GX4M2B3200C16 * 2, 32 GiB, 1600 MHz (XMP-3200 scheme), DDR4
// - ASRock Z590 PG Velocita, UEFI version L1.92
// - Windows 11 Home, 10.0.26100.6584
// - Microsoft Visual Studio 2026 (Community edition), using the default Visual C++ 2026 compiler
// - The CPU was locked to run at 3.5 GHz on all cores in the UEFI, without boosts or throttling during testing.
// - Some background programs were disabled, and the main testing was done by just running the test executable and letting DebugView x64 do the readout
// - DebugView is also useful at keeping a record on any outputs generated by other simultaneous processes to analyse some possible disturbances. If any such disturbances were detected, the test run was discarded and re-done.

// Per-compiler function attributes
// RSBD8_FUNC_INLINE is suitable to attempt force inlining of any function.
// RSBD8_FUNC_NORMAL is specifically for template functions in this header-only library, and doesn't include even a regular "inline" statement to prevent linking issues for non-template functions.
// These are the only two macros defined in this file, and #undef statements are used for them at the end.
#if defined(DEBUG) || defined(_DEBUG)// This part is debug-only. These are non-standard conforming macros, but note that the "NDEBUG" rule for detecting non-debug builds should only ever apply to runtime assert() statments in C++.
#ifdef _MSC_VER
#define RSBD8_FUNC_INLINE __declspec(noalias safebuffers) inline
#define RSBD8_FUNC_NORMAL __declspec(noalias safebuffers)
#else
#define RSBD8_FUNC_INLINE inline
#define RSBD8_FUNC_NORMAL
#endif
#else// release-only
#ifdef __clang__
#define RSBD8_FUNC_INLINE [[gnu::always_inline]] [[gnu::gnu_inline]] inline
#define RSBD8_FUNC_NORMAL
#elif defined(__GNUC__)
#define RSBD8_FUNC_INLINE [[gnu::always_inline]] inline
#define RSBD8_FUNC_NORMAL
#elif defined(__xlC__) || defined(__ghs__) || defined(__KEIL__) || defined(__CA__) || defined(__C166__) || defined(__C51__) || defined(__CX51__)
#define RSBD8_FUNC_INLINE inline __attribute__((always_inline))
#define RSBD8_FUNC_NORMAL
#elif defined(_MSC_VER)
#pragma warning(error: 4714)
#define RSBD8_FUNC_INLINE __declspec(noalias safebuffers) __forceinline
#define RSBD8_FUNC_NORMAL __declspec(noalias safebuffers)
#else
#define RSBD8_FUNC_INLINE inline
#define RSBD8_FUNC_NORMAL
#endif
#endif

// Include statements and the last checks for compatibility
// Compiler features minimum requirements are evaluated during compile-time if part of C++14 and newer.
// A more difficult test to implement here would be for example to detect mixed endianness between floating-point double and other data for on older ARM platforms.
// The C++20 "std::endian" parts in the "bit" header currently unfortunately don't indicate more than little, big and undefined mixed endianness.
namespace rsbd8::helper{// Avoid putting any include files into this library's namespace.
RSBD8_FUNC_INLINE void spinpause()noexcept;// simple forward declaration for the spinlocks used in multithreaded processing
}
//
// C++17 features detection
#if 201703L > __cplusplus
// Microsoft C/C++-compatible compilers don't set the __cplusplus predefined macro conforming to the standard by default for some very outdated legacy code reasons.
// /Zc:__cplusplus can correct it, but it's not part of the regular "Standards conformance" /permissive- compiler options.
// Use its internal macro here as a temporary fix.
#if !defined(_MSVC_LANG) || 201703L > _MSVC_LANG
#error Compiler does not conform to C++17 to compile this library.
#endif
#endif
// limited to C++17
#include <cassert>
#include <climits>
#include <cfloat>
#include <cstring>// for std::memcpy(), std::memset() and the like, this library doesn't use actual string functions
#include <future>
#include <atomic>
#include <functional>
#include <new>
#if !defined(_WIN32) && defined(_POSIX_C_SOURCE)// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
#include <sys/types.h>
#include <sys/mman.h>
#endif
#if CHAR_BIT & 8 - 1
#error This platform has an addressable unit that isn't divisible by 8. For these kinds of platforms it's better to re-write this library and not use an 8-bit indexed radix sort method.
#endif
#ifndef UINTPTR_MAX
#error This platform has no std::uintptr_t type, which should be near impossible. This library can be edited to get around that, however it might be more advantageous to edit the compiler.
#endif
#if 202002L <= __cplusplus || defined(_MSVC_LANG) && 202002L <= _MSVC_LANG
// limited to C++20
#include <bit>// (C++20)
// Library feature-test macros (C++20)
//
// Structured binding declaration (C++17)
#ifndef __cpp_structured_bindings
#error Compiler does not meet requirements for __cpp_structured_bindings for this library.
#endif
// std::byte (C++17)
#ifndef __cpp_lib_byte
#error Compiler does not meet requirements for __cpp_lib_byte for this library.
#endif
// std::is_nothrow_invocable_v (C++17)
// std::invoke_result_t (C++17)
#ifndef __cpp_lib_is_invocable
#error Compiler does not meet requirements for __cpp_lib_is_invocable for this library.
#endif
// std::is_same_v (C++17)
// std::is_integral_v (C++17)
// std::is_unsigned_v (C++17)
// std::is_signed_v (C++17)
// std::is_floating_point_v (C++17)
#ifndef __cpp_lib_type_trait_variable_templates
#error Compiler does not meet requirements for __cpp_lib_type_trait_variable_templates for this library.
#endif
// std::conditional_t (C++14)
// std::enable_if_t (C++14)
// std::make_unsigned_t (C++14)
// std::make_signed_t (C++14)
#ifndef __cpp_lib_transformation_trait_aliases
#error Compiler does not meet requirements for __cpp_lib_transformation_trait_aliases for this library.
#endif
//
// Compiler features under consideration for usage in a newer version of the library:
// std::endian (C++20)
// __cpp_lib_endian
//
// Compiler features that are not required, but will be used conditionally:
// std::bit_width (C++20)
// __cpp_lib_int_pow2
// std::countr_zero (C++20)
// __cpp_lib_bitops
// std::bit_cast (C++20)
// __cpp_lib_bit_cast
// [[likely]] (C++20)
// __has_cpp_attribute(likely)
// [[unlikely]] (C++20)
// __has_cpp_attribute(unlikely)
// [[nodiscard]] (C++17)
// __has_cpp_attribute(nodiscard)
// [[maybe_unused]] (C++17)
// __has_cpp_attribute(maybe_unused)
#endif
// Get compiler- and platform-specific intrinsic functions headers:
// (many items here are imported code, and this part also generates the spinpause() function)
#if defined(_MSC_VER)
// Microsoft C/C++-compatible compiler
#include <intrin.h>
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
RSBD8_FUNC_INLINE void rsbd8::helper::spinpause()noexcept{YieldProcessor();}
#elif (defined(_M_IX86) && !defined(_M_HYBRID_X86_ARM64)) || (defined(_M_X64) && !defined(_M_ARM64EC))
RSBD8_FUNC_INLINE void rsbd8::helper::spinpause()noexcept{_mm_pause();}
#elif defined(_M_ARM64) || defined(_M_ARM64EC) || defined(_M_HYBRID_X86_ARM64)
RSBD8_FUNC_INLINE void rsbd8::helper::spinpause()noexcept{__dmb(_ARM64_BARRIER_ISHST); __yield();}
#elif defined(_M_ARM)
RSBD8_FUNC_INLINE void rsbd8::helper::spinpause()noexcept{__dmb(_ARM_BARRIER_ISHST); __yield();}
#else
#error Unsupported system architecture for this compiler. Edit this library to add support for it.
#endif

#elif defined(__armel__) || defined(__ARMEL__)
// avoid using anything for this old ARM target
RSBD8_FUNC_INLINE void rsbd8::helper::spinpause()noexcept{}

#elif (defined(__GNUC__) || defined(__clang__)) && (defined(__x86_64__) || defined(__i386__))
// GCC/Clang-compatible compiler, targeting x86/x86-64
#include <x86intrin.h>
RSBD8_FUNC_INLINE void rsbd8::helper::spinpause()noexcept{_mm_pause();}

#elif (defined(__GNUC__) || defined(__clang__)) && (defined(__ARM_NEON__) || defined(__aarch64__))
// GCC/Clang-compatible compiler, targeting ARM with NEON
#include <arm_neon.h>
#if defined (MISSING_ARM_VLD1)
#include <ATen/cpu/vec256/missing_vld1_neon.h>
#elif defined (MISSING_ARM_VST1)
#include <ATen/cpu/vec256/missing_vst1_neon.h>
#endif
RSBD8_FUNC_INLINE void rsbd8::helper::spinpause()noexcept{
	__asm__ __volatile__ ("isb sy" ::: "memory");
	__asm__ __volatile__ ("yield" ::: "memory");
}

#elif (defined(__GNUC__) || defined(__clang__)) && defined(__IWMMXT__)
// GCC/Clang-compatible compiler, targeting ARM with WMMX
#include <mmintrin.h>
RSBD8_FUNC_INLINE void rsbd8::helper::spinpause()noexcept{
	__asm__ __volatile__ ("isb sy" ::: "memory");
	__asm__ __volatile__ ("yield" ::: "memory");
}

#elif (defined(__GNUC__) || defined(__clang__)) && (defined(__arm__) || (defined(__ARM_ARCH) && __ARM_ARCH >= 8) || defined(__ARM_ARCH_8A__))
// GCC/Clang-compatible compiler, targeting other ARM
RSBD8_FUNC_INLINE void rsbd8::helper::spinpause()noexcept{
	__asm__ __volatile__ ("isb sy" ::: "memory");
	__asm__ __volatile__ ("yield" ::: "memory");
}

#elif (defined(__GNUC__) || defined(__clang__) || defined(__xlC__)) && (defined(__VEC__) || defined(__ALTIVEC__))
// GCC/Clang/XLC-compatible compiler, targeting PowerPC with VMX/VSX
#include <altivec.h>
RSBD8_FUNC_INLINE void rsbd8::helper::spinpause()noexcept{
	__asm__ __volatile__ ("or 27,27,27" ::: "memory");
}

#elif (defined(__GNUC__) || defined(__clang__)) && defined(__SPE__)
// GCC/Clang-compatible compiler, targeting PowerPC with SPE
#include <spe.h>
RSBD8_FUNC_INLINE void rsbd8::helper::spinpause()noexcept{
	__asm__ __volatile__ ("or 27,27,27" ::: "memory");
}

#elif (defined(__GNUC__) || defined(__clang__) || defined(__xlC__)) && (defined(__powerpc__) || defined(__ppc__) || defined(__PPC__))
// GCC/Clang/XLC-compatible compiler, targeting other PowerPC
RSBD8_FUNC_INLINE void rsbd8::helper::spinpause()noexcept{
	__asm__ __volatile__ ("or 27,27,27" ::: "memory");
}

#elif (defined(__GNUC__) || defined(__clang__)) && defined(__ia64__)// IA64
// GCC/Clang-compatible compiler, targeting IA-64
RSBD8_FUNC_INLINE void rsbd8::helper::spinpause()noexcept{
	__asm__ __volatile__ ("hint @pause" ::: "memory");
}

#elif (defined(__GNUC__) || defined(__clang__)) && defined(__riscv) && __riscv_xlen == 64
// GCC/Clang-compatible compiler, targeting RISC-V 64
RSBD8_FUNC_INLINE void rsbd8::helper::spinpause()noexcept{
#ifdef __riscv_zihintpause
	__asm__ __volatile__ ("pause" ::: "memory");
#else
	__asm__ __volatile__ (".4byte 0x100000F" ::: "memory");// also just the encoding of "pause"
#endif
}

#else
// fallback, with warning
#pragma message("Compiler and system architecture not detected. Edit this library to add support for it.")
RSBD8_FUNC_INLINE void rsbd8::helper::spinpause()noexcept{}

#endif
namespace rsbd8{// Avoid putting any include files into this library's namespace.

// Helper constants and functions
namespace helper{// This libary defines a number of helper items, so categorise them as such.

// Concurrency tools

// Atomic light barrier for spinpause()-based loops (see above for that function)
// This assumes that the initial state of atomiclightbarrier is zero.
// This is not the variant that can also do exception-safe exit signalling, see atomicvarwrapper below for a part of that implementation.
template<std::size_t threadnumber, std::size_t threadcount, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	threadnumber < threadcount &&// 0-based threadnumber, make sure to give every thread a unique, sequential number
	1 < threadcount &&// at least 2 threads
	std::is_integral_v<T> &&
	std::numeric_limits<std::make_unsigned_t<T>>::max()	 >= threadcount - 1,
	void> simplebarrier(std::atomic<T> &atomiclightbarrier)noexcept{
	static T constexpr val{(threadnumber == threadcount - 1)? ~static_cast<T>(threadnumber) + 1 : static_cast<T>(1)};
	T old{atomiclightbarrier.fetch_add(val)};// the only modification here
	if(~val + 1 != old) do{// two's complement negation comparison
		spinpause();
	}while(atomiclightbarrier.load(std::memory_order_relaxed));
};

// This class is a simple RAII wrapper for the atomic variable when an exit state on destruction is needed.
// the barrier atomic variable must be able to signal exit, even if an exception occurs
struct atomicvarwrapper{
	std::atomic_uintptr_t &main;
	RSBD8_FUNC_INLINE atomicvarwrapper(std::atomic_uintptr_t &init)noexcept : main{init}{}
	RSBD8_FUNC_INLINE ~atomicvarwrapper()noexcept{
		std::uintptr_t old{};// this function assumes that the barrier atomic variable freed state is zero
		while(!main.compare_exchange_weak(old, reinterpret_cast<std::uintptr_t>(&main))){
			if(reinterpret_cast<std::uintptr_t>(&main) == old) break;// exit state by another thread
			old = 0;
			spinpause();
		}// set it to the pointer value of itself to signal exit, any other value is a busy state
	}
	atomicvarwrapper(atomicvarwrapper const &) = delete;
	atomicvarwrapper &operator=(atomicvarwrapper const &) = delete;
};

// General purpose register count constant

// This is a generalisation of the purpose register count per architecture.
enum struct gprfilesize : unsigned char{
	small,
// - architecture with less than 14 usable general-purpose registers
// - unused in this version of the library, but older x86 without extensions and ARM 32-bit Thumb mode will fit here
// - original 16/32-bit x86: 7 usable gprs, no real register renaming or store forwarding to use MMX or XMM registers as an advantage
// - ARM 32-bit Thumb mode: 7 usable gprs
	medium,
// - architecture with less than 30 usable general-purpose registers, used as a default for 32-bit architectures
// - 32-bit x86 with extensions: 7 usable gprs, can use 8 MMX and 8 XMM (with SSE2) registers with almost zero-cost store forwarding (compiler support for this optimisation is often pretty decent in this regard)
// - 32-bit ARM, not in Thumb mode (Thumb 2 mode is exempt): 14 usable gprs
// - RISC-V, 32-bit RV32E variant: 15 usable gprs
	large
// - used as a default for 64-bit architectures and beyond
// - x64: 15 (or 31 with APX) usable gprs, can use 8 MMX and 16 (or 32 with AVX-512) XMM registers with almost zero-cost store forwarding (compiler support for this optimisation is often pretty decent in this regard)
// - 64-bit ARM (AArch64/ARM64): 31 usable gprs
// - IA-64: many usable gprs, though some with specific purposes only
// - IBM POWER/PowerPC/Cell Broadband Engine: 31 usable gprs
// - DEC Alpha: 31 usable gprs
// - MIPS: 30 usable gprs
// - RISC-V, default 64-bit variant: 31 usable gprs
// - Epiphany: up to 64 usable gprs (configurable)
};
gprfilesize constexpr defaultgprfilesize{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX\
	|| defined(__VEC__) || defined(__ALTIVEC__)\
	|| defined(__SPE__)\
	|| defined(__powerpc__) || defined(__ppc__) || defined(__PPC__)
	// include the IBM POWER/PowerPC/Cell Broadband Engine macros from the previous section here as well, just to be sure
	gprfilesize::large
#else
	gprfilesize::medium
#endif
};

// Utility structures to generate tests for the often padded 80-bit long double types

// Platforms with a native 80-bit long double type are all little endian, hence that is the only implementation here.
struct alignas(alignof(std::uint_least64_t) * 2) longdoubletest128{
	std::uint_least64_t mantissa; std::uint_least64_t signexponent;// padded to 128 bits

	// warning: this comparison operator performs an unsigned comparison, not a signed or floating-point comparison
	RSBD8_FUNC_INLINE auto operator<(longdoubletest128 const &other)const noexcept{
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_subc)
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
		unsigned long long carrymid;
		__builtin_subcll(mantissa, other.mantissa, 0, &carrymid);
#else
		static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrymid;
		__builtin_subcl(mantissa, other.mantissa, 0, &carrymid);
#endif
#else
		static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrylo, carrymid;
		__builtin_subcl(reinterpret_cast<std::uint_least32_t const *>(&mantissa)[0], reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[0], 0, &carrylo);
		__builtin_subcl(reinterpret_cast<std::uint_least32_t const *>(&mantissa)[1], reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[1], carrylo, &carrymid);
#endif
		static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
		unsigned short carry;
		__builtin_subcs(static_cast<unsigned short>(signexponent), static_cast<unsigned short>(other.signexponent), static_cast<unsigned short>(carrymid), &carry);
		return carry;
#elif defined(_M_X64)
		return _subborrow_u16(_subborrow_u64(0, mantissa, other.mantissa, nullptr), static_cast<std::uint_least16_t>(signexponent), static_cast<std::uint_least16_t>(other.signexponent), nullptr);
#elif defined(_M_IX86)
		return _subborrow_u16(_subborrow_u32(_subborrow_u32(0, reinterpret_cast<std::uint_least32_t const *>(&mantissa)[0], reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[0], nullptr), reinterpret_cast<std::uint_least32_t const *>(&mantissa)[1], reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[1], nullptr), static_cast<std::uint_least16_t>(signexponent), static_cast<std::uint_least16_t>(other.signexponent), nullptr);
#else
		return std::tie(static_cast<std::uint_least16_t>(signexponent), mantissa) <
			std::tie(static_cast<std::uint_least16_t>(other.signexponent) other.mantissa);
#endif
	}
	RSBD8_FUNC_INLINE longdoubletest128 &operator&=(std::intptr_t const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa &= static_cast<std::uint_least64_t>(other);
		signexponent &= static_cast<std::uint_least64_t>(other);
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] &= static_cast<std::uint_least32_t>(other);
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] &= static_cast<std::uint_least32_t>(other);
		reinterpret_cast<std::uint_least32_t *>(&signexponent)[0] &= static_cast<std::uint_least32_t>(other);
		reinterpret_cast<std::uint_least32_t *>(&signexponent)[1] &= static_cast<std::uint_least32_t>(other);
#endif
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest128 operator&(std::intptr_t const &other)const noexcept{
		return{longdoubletest128{*this} &= other};
	}
	RSBD8_FUNC_INLINE longdoubletest128 &operator^=(std::intptr_t const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa ^= static_cast<std::uint_least64_t>(other);
		signexponent ^= static_cast<std::uint_least64_t>(other);
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] ^= static_cast<std::uint_least32_t>(other);
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] ^= static_cast<std::uint_least32_t>(other);
		reinterpret_cast<std::uint_least32_t *>(&signexponent)[0] ^= static_cast<std::uint_least32_t>(other);
		reinterpret_cast<std::uint_least32_t *>(&signexponent)[1] ^= static_cast<std::uint_least32_t>(other);
#endif
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest128 operator^(std::intptr_t const &other)const noexcept{
		return{longdoubletest128{*this} ^= other};
	}
	RSBD8_FUNC_INLINE longdoubletest128 &operator|=(std::intptr_t const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa |= static_cast<std::uint_least64_t>(other);
		signexponent |= static_cast<std::uint_least64_t>(other);
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] |= static_cast<std::uint_least32_t>(other);
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] |= static_cast<std::uint_least32_t>(other);
		reinterpret_cast<std::uint_least32_t *>(&signexponent)[0] |= static_cast<std::uint_least32_t>(other);
		reinterpret_cast<std::uint_least32_t *>(&signexponent)[1] |= static_cast<std::uint_least32_t>(other);
#endif
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest128 operator|(std::intptr_t const &other)const noexcept{
		return{longdoubletest128{*this} |= other};
	}
	RSBD8_FUNC_INLINE longdoubletest128 &operator&=(longdoubletest128 const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa &= other.mantissa;
		signexponent &= signexponent;
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] &= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[0];
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] &= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[1];
		reinterpret_cast<std::uint_least32_t *>(&signexponent)[0] &= reinterpret_cast<std::uint_least32_t const *>(&other.signexponent)[0];
		reinterpret_cast<std::uint_least32_t *>(&signexponent)[1] &= reinterpret_cast<std::uint_least32_t const *>(&other.signexponent)[1];
#endif
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest128 operator&(longdoubletest128 const &other)const noexcept{
		return{longdoubletest128{*this} &= other};
	}
	RSBD8_FUNC_INLINE longdoubletest128 &operator^=(longdoubletest128 const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa ^= other.mantissa;
		signexponent ^= signexponent;
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] ^= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[0];
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] ^= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[1];
		reinterpret_cast<std::uint_least32_t *>(&signexponent)[0] ^= reinterpret_cast<std::uint_least32_t const *>(&other.signexponent)[0];
		reinterpret_cast<std::uint_least32_t *>(&signexponent)[1] ^= reinterpret_cast<std::uint_least32_t const *>(&other.signexponent)[1];
#endif
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest128 operator^(longdoubletest128 const &other)const noexcept{
		return{longdoubletest128{*this} ^= other};
	}
	RSBD8_FUNC_INLINE longdoubletest128 &operator|=(longdoubletest128 const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa |= other.mantissa;
		signexponent |= signexponent;
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] |= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[0];
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] |= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[1];
		reinterpret_cast<std::uint_least32_t *>(&signexponent)[0] |= reinterpret_cast<std::uint_least32_t const *>(&other.signexponent)[0];
		reinterpret_cast<std::uint_least32_t *>(&signexponent)[1] |= reinterpret_cast<std::uint_least32_t const *>(&other.signexponent)[1];
#endif
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest128 operator|(longdoubletest128 const &other)const noexcept{
		return{longdoubletest128{*this} |= other};
	}
};
#pragma pack(push, 1)// longdoubletest96 and longdoubletest80 must be unpadded
struct longdoubletest96{
	// this class is x86-specific, and doesn't have natural alignment on the mantissa member
	std::uint_least64_t mantissa; std::uint_least32_t signexponent;// padded to 96 bits

	// warning: this comparison operator performs an unsigned comparison, not a signed or floating-point comparison
	RSBD8_FUNC_INLINE auto operator<(longdoubletest96 const &other)const noexcept{
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_subc)
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
		unsigned long long carrymid;
		__builtin_subcll(mantissa, other.mantissa, 0, &carrymid);
#else
		static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrymid;
		__builtin_subcl(mantissa, other.mantissa, 0, &carrymid);
#endif
#else
		static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrylo, carrymid;
		__builtin_subcl(reinterpret_cast<std::uint_least32_t const *>(&mantissa)[0], reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[0], 0, &carrylo);
		__builtin_subcl(reinterpret_cast<std::uint_least32_t const *>(&mantissa)[1], reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[1], carrylo, &carrymid);
#endif
		static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
		unsigned short carry;
		__builtin_subcs(static_cast<unsigned short>(signexponent), static_cast<unsigned short>(other.signexponent), static_cast<unsigned short>(carrymid), &carry);
		return carry;
#elif defined(_M_X64)
		return _subborrow_u16(_subborrow_u64(0, mantissa, other.mantissa, nullptr), static_cast<std::uint_least16_t>(signexponent), static_cast<std::uint_least16_t>(other.signexponent), nullptr);
#elif defined(_M_IX86)
		return _subborrow_u16(_subborrow_u32(_subborrow_u32(0, reinterpret_cast<std::uint_least32_t const *>(&mantissa)[0], reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[0], nullptr), reinterpret_cast<std::uint_least32_t const *>(&mantissa)[1], reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[1], nullptr), static_cast<std::uint_least16_t>(signexponent), static_cast<std::uint_least16_t>(other.signexponent), nullptr);
#else
		return std::tie(static_cast<std::uint_least16_t>(signexponent), mantissa) <
			std::tie(static_cast<std::uint_least16_t>(other.signexponent), other.mantissa);
#endif
	}
	RSBD8_FUNC_INLINE longdoubletest96 &operator&=(std::intptr_t const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa &= static_cast<std::uint_least64_t>(other);
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] &= static_cast<std::uint_least32_t>(other);
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] &= static_cast<std::uint_least32_t>(other);
#endif
		signexponent &= static_cast<std::uint_least32_t>(other);
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest96 operator&(std::intptr_t const &other)const noexcept{
		return{longdoubletest96{*this} &= other};
	}
	RSBD8_FUNC_INLINE longdoubletest96 &operator^=(std::intptr_t const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa ^= static_cast<std::uint_least64_t>(other);
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] ^= static_cast<std::uint_least32_t>(other);
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] ^= static_cast<std::uint_least32_t>(other);
#endif
		signexponent ^= static_cast<std::uint_least32_t>(other);
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest96 operator^(std::intptr_t const &other)const noexcept{
		return{longdoubletest96{*this} ^= other};
	}
	RSBD8_FUNC_INLINE longdoubletest96 &operator|=(std::intptr_t const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa |= static_cast<std::uint_least64_t>(other);
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] |= static_cast<std::uint_least32_t>(other);
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] |= static_cast<std::uint_least32_t>(other);
#endif
		signexponent |= static_cast<std::uint_least32_t>(other);
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest96 operator|(std::intptr_t const &other)const noexcept{
		return{longdoubletest96{*this} |= other};
	}
	RSBD8_FUNC_INLINE longdoubletest96 &operator&=(longdoubletest96 const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa &= other.mantissa;
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] &= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[0];
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] &= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[1];
#endif
		signexponent &= other.signexponent;
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest96 operator&(longdoubletest96 const &other)const noexcept{
		return{longdoubletest96{*this} &= other};
	}
	RSBD8_FUNC_INLINE longdoubletest96 &operator^=(longdoubletest96 const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa ^= other.mantissa;
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] ^= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[0];
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] ^= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[1];
#endif
		signexponent ^= other.signexponent;
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest96 operator^(longdoubletest96 const &other)const noexcept{
		return{longdoubletest96{*this} ^= other};
	}
	RSBD8_FUNC_INLINE longdoubletest96 &operator|=(longdoubletest96 const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa |= other.mantissa;
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] |= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[0];
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] |= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[1];
#endif
		signexponent |= other.signexponent;
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest96 operator|(longdoubletest96 const &other)const noexcept{
		return{longdoubletest96{*this} |= other};
	}
};
struct longdoubletest80{
	// this class is x86-specific, and doesn't have natural alignment on the mantissa member
	std::uint_least64_t mantissa; std::uint_least16_t signexponent;

	// warning: this comparison operator performs an unsigned comparison, not a signed or floating-point comparison
	RSBD8_FUNC_INLINE auto operator<(longdoubletest80 const &other)const noexcept{
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_subc)
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
		unsigned long long carrymid;
		__builtin_subcll(mantissa, other.mantissa, 0, &carrymid);
#else
		static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrymid;
		__builtin_subcl(mantissa, other.mantissa, 0, &carrymid);
#endif
#else
		static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrylo, carrymid;
		__builtin_subcl(reinterpret_cast<std::uint_least32_t const *>(&mantissa)[0], reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[0], 0, &carrylo);
		__builtin_subcl(reinterpret_cast<std::uint_least32_t const *>(&mantissa)[1], reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[1], carrylo, &carrymid);
#endif
		static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
		unsigned short carry;
		__builtin_subcs(signexponent, other.signexponent, static_cast<unsigned short>(carrymid), &carry);
		return carry;
#elif defined(_M_X64)
		return _subborrow_u16(_subborrow_u64(0, mantissa, other.mantissa, nullptr), signexponent, other.signexponent, nullptr);
#elif defined(_M_IX86)
		return _subborrow_u16(_subborrow_u32(_subborrow_u32(0, reinterpret_cast<std::uint_least32_t const *>(&mantissa)[0], reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[0], nullptr), reinterpret_cast<std::uint_least32_t const *>(&mantissa)[1], reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[1], nullptr), signexponent, other.signexponent, nullptr);
#else
		return std::tie(signexponent, mantissa) <
			std::tie(other.signexponent, other.mantissa);
#endif
	}
	RSBD8_FUNC_INLINE longdoubletest80 &operator&=(std::intptr_t const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa &= static_cast<std::uint_least64_t>(other);
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] &= static_cast<std::uint_least32_t>(other);
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] &= static_cast<std::uint_least32_t>(other);
#endif
		signexponent &= static_cast<std::uint_least16_t>(other);
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest80 operator&(std::intptr_t const &other)const noexcept{
		return{longdoubletest80{*this} &= other};
	}
	RSBD8_FUNC_INLINE longdoubletest80 &operator^=(std::intptr_t const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa ^= static_cast<std::uint_least64_t>(other);
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] ^= static_cast<std::uint_least32_t>(other);
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] ^= static_cast<std::uint_least32_t>(other);
#endif
		signexponent ^= static_cast<std::uint_least16_t>(other);
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest80 operator^(std::intptr_t const &other)const noexcept{
		return{longdoubletest80{*this} ^= other};
	}
	RSBD8_FUNC_INLINE longdoubletest80 &operator|=(std::intptr_t const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa |= static_cast<std::uint_least64_t>(other);
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] |= static_cast<std::uint_least32_t>(other);
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] |= static_cast<std::uint_least32_t>(other);
#endif
		signexponent |= static_cast<std::uint_least16_t>(other);
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest80 operator|(std::intptr_t const &other)const noexcept{
		return{longdoubletest80{*this} |= other};
	}
	RSBD8_FUNC_INLINE longdoubletest80 &operator&=(longdoubletest80 const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa &= other.mantissa;
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] &= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[0];
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] &= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[1];
#endif
		signexponent &= other.signexponent;
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest80 operator&(longdoubletest80 const &other)const noexcept{
		return{longdoubletest80{*this} &= other};
	}
	RSBD8_FUNC_INLINE longdoubletest80 &operator^=(longdoubletest80 const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa ^= other.mantissa;
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] ^= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[0];
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] ^= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[1];
#endif
		signexponent ^= other.signexponent;
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest80 operator^(longdoubletest80 const &other)const noexcept{
		return{longdoubletest80{*this} ^= other};
	}
	RSBD8_FUNC_INLINE longdoubletest80 &operator|=(longdoubletest80 const &other)noexcept{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// 64-bit and larger systems
		mantissa |= other.mantissa;
#else
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[0] |= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[0];
		reinterpret_cast<std::uint_least32_t *>(&mantissa)[1] |= reinterpret_cast<std::uint_least32_t const *>(&other.mantissa)[1];
#endif
		signexponent |= other.signexponent;
		return{*this};
	}
	RSBD8_FUNC_INLINE longdoubletest80 operator|(longdoubletest80 const &other)const noexcept{
		return{longdoubletest80{*this} |= other};
	}
};
#pragma pack(pop)// longdoubletest96 and longdoubletest80 must be unpadded

// Utility template to either pass through a type or allow std::underlying_type to do its work
template<typename T>
using stripenum = typename std::conditional_t<std::is_enum_v<T>, std::underlying_type<T>, std::enable_if<true, T>>::type;

// Endianess detection

// A dirty method that heavily relies on proper inlining and compiler optimisation of that, but it at least can detect the floating-point mixed endianness cases if used properly
template<typename T>
constexpr RSBD8_FUNC_INLINE std::enable_if_t<
	128 >= CHAR_BIT * sizeof(T) &&
	std::is_integral_v<stripenum<T>>,
	T> generatehighbit()noexcept{
	return{static_cast<T>(1) << (CHAR_BIT * sizeof(T) - 1)};
}
template<typename T>
constexpr RSBD8_FUNC_INLINE std::enable_if_t<
	128 >= CHAR_BIT * sizeof(T) &&
	std::is_floating_point_v<stripenum<T>>,
	T> generatehighbit()noexcept{
	// This will definately not work on some floating-point types from machines from the digial stone age.
	// However, this is a C++17 and onwards compatible library, and those devices have none of that.
	return{static_cast<T>(-0.)};
}
template<typename T>
constexpr RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>,
	T> generatehighbit()noexcept{
	return{{0, 0x8000u}};
}

// Utility structures to generate tests for 64- or 128-bit types

#if 0xFFFFFFFFFFFFFFFFu > UINTPTR_MAX// disable the 64-bit struct on 64-bit and larger systems
// This one can be big-, mixed- and little-endian.
template<bool isfltpmode>
struct alignas(alignof(std::uint_least32_t) * 2) test64{
	std::uint_least32_t data[2];
	// warning: this comparison operator performs an unsigned comparison, not a signed or floating-point comparison
	RSBD8_FUNC_INLINE auto operator<(test64 const &other)const noexcept{
		if constexpr(1 < sizeof(double)){
			// basic endianess detection, relies on proper inlining and compiler optimisation of that
			static auto constexpr highbit{generatehighbit<std::conditional_t<isfltpmode, double, std::uint_least64_t>>()};
			if(*reinterpret_cast<std::uint_least32_t const *>(&highbit)){// big and mixed-endian cases
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_subc)
				static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
				unsigned long carrymid, carry;
				__builtin_subcl(data[1], other.data[1], 0, &carrymid);
				__builtin_subcl(data[0], other.data[0], carrymid, &carry);
				return carry;
#elif defined(_M_IX86)
				return _subborrow_u32(_subborrow_u32(0, data[1], other.data[1], nullptr), data[0], other.data[0], nullptr);
#else
				return std::tie(data[0], data[1]) <
					std::tie(other.data[0], other.data[1]);
#endif
			}
		}
		// little-endian case
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_subc)
		static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrymid, carry;
		__builtin_subcl(data[0], other.data[0], 0, &carrymid);
		__builtin_subcl(data[1], other.data[1], carrymid, &carry);
		return carry;
#elif defined(_M_IX86)
		return _subborrow_u32(_subborrow_u32(0, data[0], other.data[0], nullptr), data[1], other.data[1], nullptr);
#else
		return std::tie(data[1], data[0]) <
			std::tie(other.data[1], other.data[0]);
#endif
	}
	RSBD8_FUNC_INLINE test64 &operator&=(std::intptr_t const &other)noexcept{
		data[0] &= static_cast<std::uint_least32_t>(other);
		data[1] &= static_cast<std::uint_least32_t>(other);
		return{*this};
	}
	RSBD8_FUNC_INLINE test64 operator&(std::intptr_t const &other)noexcept{
		return{{data[0] & static_cast<std::uint_least32_t>(other),
			data[1] & static_cast<std::uint_least32_t>(other)}};
	}
	RSBD8_FUNC_INLINE test64 &operator^=(std::intptr_t const &other)noexcept{
		data[0] ^= static_cast<std::uint_least32_t>(other);
		data[1] ^= static_cast<std::uint_least32_t>(other);
		return{*this};
	}
	RSBD8_FUNC_INLINE test64 operator^(std::intptr_t const &other)noexcept{
		return{{data[0] ^ static_cast<std::uint_least32_t>(other),
			data[1] ^ static_cast<std::uint_least32_t>(other)}};
	}
	RSBD8_FUNC_INLINE test64 &operator|=(std::intptr_t const &other)noexcept{
		data[0] |= static_cast<std::uint_least32_t>(other);
		data[1] |= static_cast<std::uint_least32_t>(other);
		return{*this};
	}
	RSBD8_FUNC_INLINE test64 operator|(std::intptr_t const &other)noexcept{
		return{{data[0] | static_cast<std::uint_least32_t>(other),
			data[1] | static_cast<std::uint_least32_t>(other)}};
	}
	RSBD8_FUNC_INLINE test64 &operator&=(test64 const &other)noexcept{
		data[0] &= other.data[0];
		data[1] &= other.data[1];
		return{*this};
	}
	RSBD8_FUNC_INLINE test64 operator&(test64 const &other)noexcept{
		return{{data[0] & other.data[0],
			data[1] & other.data[1]}};
	}
	RSBD8_FUNC_INLINE test64 &operator^=(test64 const &other)noexcept{
		data[0] ^= other.data[0];
		data[1] ^= other.data[1];
		return{*this};
	}
	RSBD8_FUNC_INLINE test64 operator^(test64 const &other)noexcept{
		return{{data[0] ^ other.data[0],
			data[1] ^ other.data[1]}};
	}
	RSBD8_FUNC_INLINE test64 &operator|=(test64 const &other)noexcept{
		data[0] |= other.data[0];
		data[1] |= other.data[1];
		return{*this};
	}
	RSBD8_FUNC_INLINE test64 operator|(test64 const &other)noexcept{
		return{{data[0] | other.data[0],
			data[1] | other.data[1]}};
	}
};
#else// only enable the 128-bit struct on 64-bit and larger systems
// This one can be big- and little-endian, but mixed-endian just doesn't occur on any 64-bit and onward system.
struct alignas(alignof(std::uint_least64_t) * 2) test128{
	std::uint_least64_t data[2];
	// warning: this comparison operator performs an unsigned comparison, not a signed or floating-point comparison
	RSBD8_FUNC_INLINE auto operator<(test128 const &other)const noexcept{
		if constexpr(1 < sizeof(std::uintmax_t)){
			// basic endianess detection, relies on proper inlining and compiler optimisation of that
			static std::uintmax_t constexpr highbit{generatehighbit<std::uintmax_t>()};
			if(*reinterpret_cast<unsigned char const *>(&highbit)){// big-endian case
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_subc)
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
				static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
				unsigned long long carrymid, carry;
				__builtin_subcll(data[1], other.data[1], 0, &carrymid);
				__builtin_subcll(data[0], other.data[0], carrymid, &carry);
#else
				static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
				unsigned long carrymid, carry;
				__builtin_subcl(data[1], other.data[1], 0, &carrymid);
				__builtin_subcl(data[0], other.data[0], carrymid, &carry);
#endif
				return carry;
#elif defined(_M_X64)
				return _subborrow_u64(_subborrow_u64(0, data[1], other.data[1], nullptr), data[0], other.data[0], nullptr);
#else
				return std::tie(data[0], data[1]) <
					std::tie(other.data[0], other.data[1]);
#endif
			}
		}
		// little-endian case
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_subc)
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
		unsigned long long carrymid, carry;
		__builtin_subcll(data[0], other.data[0], 0, &carrymid);
		__builtin_subcll(data[1], other.data[1], carrymid, &carry);
#else
		static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrymid, carry;
		__builtin_subcl(data[0], other.data[0], 0, &carrymid);
		__builtin_subcl(data[1], other.data[1], carrymid, &carry);
#endif
		return carry;
#elif defined(_M_X64)
		return _subborrow_u64(_subborrow_u64(0, data[0], other.data[0], nullptr), data[1], other.data[1], nullptr);
#else
		return std::tie(data[1], data[0]) <
			std::tie(other.data[1], other.data[0]);
#endif
	}
	RSBD8_FUNC_INLINE test128 &operator&=(std::intptr_t const &other)noexcept{
		data[0] &= static_cast<std::uint_least64_t>(other);
		data[1] &= static_cast<std::uint_least64_t>(other);
		return{*this};
	}
	RSBD8_FUNC_INLINE test128 operator&(std::intptr_t const &other)noexcept{
		return{{data[0] & static_cast<std::uint_least64_t>(other),
			data[1] & static_cast<std::uint_least64_t>(other)}};
	}
	RSBD8_FUNC_INLINE test128 &operator^=(std::intptr_t const &other)noexcept{
		data[0] ^= static_cast<std::uint_least64_t>(other);
		data[1] ^= static_cast<std::uint_least64_t>(other);
		return{*this};
	}
	RSBD8_FUNC_INLINE test128 operator^(std::intptr_t const &other)noexcept{
		return{{data[0] ^ static_cast<std::uint_least64_t>(other),
			data[1] ^ static_cast<std::uint_least64_t>(other)}};
	}
	RSBD8_FUNC_INLINE test128 &operator|=(std::intptr_t const &other)noexcept{
		data[0] |= static_cast<std::uint_least64_t>(other);
		data[1] |= static_cast<std::uint_least64_t>(other);
		return{*this};
	}
	RSBD8_FUNC_INLINE test128 operator|(std::intptr_t const &other)noexcept{
		return{{data[0] | static_cast<std::uint_least64_t>(other),
			data[1] | static_cast<std::uint_least64_t>(other)}};
	}
	RSBD8_FUNC_INLINE test128 &operator&=(test128 const &other)noexcept{
		data[0] &= other.data[0];
		data[1] &= other.data[1];
		return{*this};
	}
	RSBD8_FUNC_INLINE test128 operator&(test128 const &other)noexcept{
		return{{data[0] & other.data[0],
			data[1] & other.data[1]}};
	}
	RSBD8_FUNC_INLINE test128 &operator^=(test128 const &other)noexcept{
		data[0] ^= other.data[0];
		data[1] ^= other.data[1];
		return{*this};
	}
	RSBD8_FUNC_INLINE test128 operator^(test128 const &other)noexcept{
		return{{data[0] ^ other.data[0],
			data[1] ^ other.data[1]}};
	}
	RSBD8_FUNC_INLINE test128 &operator|=(test128 const &other)noexcept{
		data[0] |= other.data[0];
		data[1] |= other.data[1];
		return{*this};
	}
	RSBD8_FUNC_INLINE test128 operator|(test128 const &other)noexcept{
		return{{data[0] | other.data[0],
			data[1] | other.data[1]}};
	}
};
#endif

// Utility templates to create an immediate member object pointer for the type and offset indirection wrapper functions
#pragma pack(push, 1)
template<typename T, std::ptrdiff_t indirection1> struct memberobjectgenerator;
template<typename T>
struct memberobjectgenerator<T, 0>{
	T object;// no padding, as the object starts at the origin
};
template<typename T, std::ptrdiff_t indirection1>
struct memberobjectgenerator{
	std::byte padding[static_cast<std::size_t>(indirection1)];// this will work, but array counts are just required to be positive
	T object;// some amount of padding is used
};
#pragma pack(pop)

// Utility templates to call the getter function

// These can optionally split off the second-level indirection index parameter, or dereference the member object pointer.
// These will all reinterpret references as pointers.
template<auto indirection1, bool isindexed2, typename V, typename U, typename W>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_object_pointer_v<decltype(indirection1)> &&
	isindexed2 &&
	!std::is_lvalue_reference_v<decltype(std::declval<V *>()->*indirection1)>,
	std::remove_reference_t<decltype(std::declval<V *>()->*indirection1)>> splitget(V *p, U index1, W index2)noexcept{
	using T = std::remove_reference_t<decltype(std::declval<V *>()->*indirection1)>;
	// do not pass a nullptr here
	assert(p);
	return{reinterpret_cast<V *>(reinterpret_cast<T *>(p) + index1)->*indirection1};
}
template<auto indirection1, bool isindexed2, typename V, typename U, typename W>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_object_pointer_v<decltype(indirection1)> &&
	isindexed2 &&
	std::is_lvalue_reference_v<decltype(std::declval<V *>()->*indirection1)>,
	std::remove_reference_t<decltype(std::declval<V *>()->*indirection1)> *> splitget(V *p, U index1, W index2)noexcept{
	using T = std::remove_reference_t<decltype(std::declval<V *>()->*indirection1)>;
	// do not pass a nullptr here
	assert(p);
	return{reinterpret_cast<T *>(&(reinterpret_cast<V *>(reinterpret_cast<T *>(p) + index1)->*indirection1))};// always reinterpret references as pointers
}
template<auto indirection1, bool isindexed2, typename V, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_object_pointer_v<decltype(indirection1)> &&
	!std::is_lvalue_reference_v<decltype(std::declval<V *>()->*indirection1)>,
	std::remove_reference_t<decltype(std::declval<V *>()->*indirection1)>> splitget(V *p, U index)noexcept{
	using T = std::remove_reference_t<decltype(std::declval<V *>()->*indirection1)>;
	// do not pass a nullptr here
	assert(p);
	if constexpr(isindexed2){
		static_assert(std::is_pointer_v<T>, "invalid variable argument count for usage without second-level indirection");
		return{p->*indirection1};
	}else{
		return{reinterpret_cast<V *>(reinterpret_cast<T *>(p) + index)->*indirection1};
	}
}
template<auto indirection1, bool isindexed2, typename V, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_object_pointer_v<decltype(indirection1)> &&
	std::is_lvalue_reference_v<decltype(std::declval<V *>()->*indirection1)>,
	std::remove_reference_t<decltype(std::declval<V *>()->*indirection1)> *> splitget(V *p, U index)noexcept{
	using T = std::remove_reference_t<decltype(std::declval<V *>()->*indirection1)>;
	// do not pass a nullptr here
	assert(p);
	if constexpr(isindexed2){
		return{reinterpret_cast<T *>(&(p->*indirection1))};// always reinterpret references as pointers
	}else{
		return{reinterpret_cast<T *>(&(reinterpret_cast<V *>(reinterpret_cast<T *>(p) + index)->*indirection1))};// always reinterpret references as pointers
	}
}
template<auto indirection1, bool isindexed2, typename V>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_object_pointer_v<decltype(indirection1)> &&
	!isindexed2 &&
	!std::is_lvalue_reference_v<decltype(std::declval<V *>()->*indirection1)>,
	std::remove_reference_t<decltype(std::declval<V *>()->*indirection1)>> splitget(V *p)noexcept{
	// do not pass a nullptr here
	assert(p);
	return{p->*indirection1};
}
template<auto indirection1, bool isindexed2, typename V>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_object_pointer_v<decltype(indirection1)> &&
	!isindexed2 &&
	std::is_lvalue_reference_v<decltype(std::declval<V *>()->*indirection1)>,
	std::remove_reference_t<decltype(std::declval<V *>()->*indirection1)> *> splitget(V *p)noexcept{
	using T = std::remove_reference_t<decltype(std::declval<V *>()->*indirection1)>;
	// do not pass a nullptr here
	assert(p);
	return{reinterpret_cast<T *>(&(p->*indirection1))};// always reinterpret references as pointers
}
template<auto indirection1, bool isindexed2, typename V, typename W, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_function_pointer_v<decltype(indirection1)> &&
	isindexed2 &&
	!std::is_lvalue_reference_v<std::invoke_result_t<decltype(indirection1), V *, vararguments...>>,
	std::invoke_result_t<decltype(indirection1), V *, vararguments...>> splitget(V *p, W index2, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(indirection1), V *, vararguments...>){
	static_cast<void>(index2);
	// do not pass a nullptr here
	assert(p);
	return{(p->*indirection1)(varparameters...)};
}
template<auto indirection1, bool isindexed2, typename V, typename W, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_function_pointer_v<decltype(indirection1)> &&
	isindexed2 &&
	std::is_lvalue_reference_v<std::invoke_result_t<decltype(indirection1), V *, vararguments...>>,
	std::remove_reference_t<std::invoke_result_t<decltype(indirection1), V *, vararguments...>> *> splitget(V *p, W index2, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(indirection1), V *, vararguments...>){
	static_cast<void>(index2);
	using T = std::remove_reference_t<std::invoke_result_t<decltype(indirection1), V *, vararguments...>>;
	// do not pass a nullptr here
	assert(p);
	return{reinterpret_cast<T *>(&(p->*indirection1)(varparameters...))};// always reinterpret references as pointers
}
template<auto indirection1, bool isindexed2, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_function_pointer_v<decltype(indirection1)> &&
	!isindexed2 &&
	!std::is_lvalue_reference_v<std::invoke_result_t<decltype(indirection1), V *, vararguments...>>,
	std::invoke_result_t<decltype(indirection1), V *, vararguments...>> splitget(V *p, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(indirection1), V *, vararguments...>){
	// do not pass a nullptr here
	assert(p);
	return{(p->*indirection1)(varparameters...)};
}
template<auto indirection1, bool isindexed2, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_function_pointer_v<decltype(indirection1)> &&
	!isindexed2 &&
	std::is_lvalue_reference_v<std::invoke_result_t<decltype(indirection1), V *, vararguments...>>,
	std::remove_reference_t<std::invoke_result_t<decltype(indirection1), V *, vararguments...>>> splitget(V *p, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(indirection1), V *, vararguments...>){
	using T = std::remove_reference_t<std::invoke_result_t<decltype(indirection1), V *, vararguments...>>;
	// do not pass a nullptr here
	assert(p);
	return{reinterpret_cast<T *>(&(p->*indirection1)(varparameters...))};// always reinterpret references as pointers
}

// Utility templates to split off the first parameter

template<typename W, typename... vararguments>
RSBD8_FUNC_INLINE W splitparameter(W first, vararguments...)noexcept{
	return{first};
}
RSBD8_FUNC_INLINE void splitparameter()noexcept{
	// This function is a dummy, but it does allow the version without any extra arguments to exist.
}

// Utility template to retrieve the data sources from classes

// utility template to either retrieve the first-level source
template<auto indirection1, bool isindexed2, typename T, typename V, typename... vararguments>
RSBD8_FUNC_INLINE auto indirectinput1(V *p, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using U = std::invoke_result_t<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>;// splitget will convert references to pointers
	// do not pass a nullptr here
	assert(p);
	if constexpr(std::is_member_object_pointer_v<decltype(indirection1)>){
		if constexpr(!std::is_pointer_v<U>){// indirection directly to member, ignore isindexed2
			static_assert(sizeof(T) == sizeof(U), "misinterpreted indirection input type");
			if constexpr(1 == sizeof...(varparameters)){// indirection to member with an index
				return reinterpret_cast<V *>(reinterpret_cast<T const *>(p) + splitparameter(varparameters...))->*reinterpret_cast<T V:: *>(indirection1);
			}else if constexpr(0 == sizeof...(varparameters)){// indirection to member without an index
				return p->*reinterpret_cast<T V:: *>(indirection1);
			}else static_assert(false, "impossible first-level indirection indexing parameter count");
		}else{
			static_assert(!std::is_pointer_v<std::remove_pointer_t<U>> && !std::is_reference_v<std::remove_pointer_t<U>>, "third level indirection is not supported");
			static_assert(sizeof(T) == sizeof(std::remove_pointer_t<U>), "misinterpreted indirection input type");
			return reinterpret_cast<std::byte const *>(splitget<indirection1, isindexed2, V>(p, varparameters...));
		}
	}else if constexpr(std::is_member_function_pointer_v<decltype(indirection1)>){
		if constexpr(!std::is_pointer_v<U>){// indirection directly to item, ignore isindexed2
			static_assert(sizeof(T) == sizeof(U), "misinterpreted indirection input type");
			U val{(p->*indirection1)(varparameters...)};
#ifdef __cpp_lib_bit_cast
			return std::bit_cast<T>(val);
#else
			return *reinterpret_cast<T *>(&val);
#endif
		}else{// indirection to second level pointer
			static_assert(!std::is_pointer_v<std::remove_pointer_t<U>> && !std::is_reference_v<std::remove_pointer_t<U>>, "third level indirection is not supported");
			static_assert(sizeof(T) == sizeof(std::remove_pointer_t<U>), "misinterpreted indirection input type");
			return reinterpret_cast<std::byte const *>(splitget<indirection1, isindexed2, V>(p, varparameters...));
		}
	}else static_assert(false, "unsupported indirection input type");
}
// utility templates to either retrieve the second-level source or pass though results for full outputs
template<auto indirection1, std::ptrdiff_t indirection2, bool isindexed2, typename T, typename... vararguments>
RSBD8_FUNC_INLINE auto indirectinput2(std::byte const *pintermediate, vararguments... varparameters)noexcept{
	// do not pass a nullptr here
	assert(pintermediate);
	if constexpr(std::is_member_object_pointer_v<decltype(indirection1)>){
		if constexpr(0 == sizeof...(varparameters)){// indirection to member with no indices, ignore isindexed2
			return *reinterpret_cast<T const *>(pintermediate + indirection2);
		}else if constexpr(1 == sizeof...(varparameters)){// indirection to member with an index
			if constexpr(isindexed2){// second level extra index
				return reinterpret_cast<T const *>(pintermediate + indirection2)[splitparameter(varparameters...)];
			}else{// first level extra index
				return *reinterpret_cast<T const *>(pintermediate + indirection2);
			}
		}else if constexpr(2 == sizeof...(varparameters)){// indirection to member with two indices, ignore isindexed2
			std::pair indices{varparameters...};
			return reinterpret_cast<T const *>(pintermediate + indirection2)[indices.second];
		}else static_assert(false, "impossible second-level indirection indexing parameter count");
	}else if constexpr(std::is_member_function_pointer_v<decltype(indirection1)>){
		if constexpr(isindexed2){// second level extra index
			return reinterpret_cast<T const *>(pintermediate + indirection2)[splitparameter(varparameters...)];
		}else{// second level without an index
			return *reinterpret_cast<T const *>(pintermediate + indirection2);
		}
	}else static_assert(false, "unsupported indirection input type");
}
template<auto indirection1, std::ptrdiff_t indirection2, bool isindexed2, typename T, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	!std::is_pointer_v<T>,
	T> indirectinput2(T passthrough, vararguments...)noexcept{
	return{passthrough};
}

// Utility templates to get either the member object type or the member function return type

template<auto indirection1, bool isindexed2, typename V, typename dummy = void, typename... vararguments> struct memberpointerdeducebody;
// partial specialisation, by std::is_member_function_pointer_v
template<auto indirection1, bool isindexed2, typename V, typename... vararguments>
struct memberpointerdeducebody<indirection1, isindexed2, V, std::enable_if_t<std::is_member_function_pointer_v<decltype(indirection1)>>, vararguments...>{
	using type = std::invoke_result_t<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>;
};
// partial specialisation, by std::is_member_object_pointer_v
template<auto indirection1, bool isindexed2, typename V, typename... vararguments>
struct memberpointerdeducebody<indirection1, isindexed2, V, std::enable_if_t<std::is_member_object_pointer_v<decltype(indirection1)>>, vararguments...>{
	using type = std::remove_reference_t<decltype(std::declval<V>().*indirection1)>;
};
template<auto indirection1, bool isindexed2, typename V, typename... vararguments>
using memberpointerdeduce = typename memberpointerdeducebody<indirection1, isindexed2, V, void, vararguments...>::type;

// Utility template to pick an unsigned type of the lowest rank with the same size

// This can alternatively allow std::make_unsigned to do its work, too.
// This does not require using stripenum first to work.
// TODO: add support for 128-bit integers (test128) for 64-bit and onwards, else for 64-bit integers (test64)
template<typename T>
using tounifunsigned = std::conditional_t<1 == sizeof(T), unsigned char,
	std::conditional_t<sizeof(short) == sizeof(T), unsigned short,
	std::conditional_t<sizeof(signed) == sizeof(T), unsigned,
	std::conditional_t<sizeof(long) == sizeof(T), unsigned long,
	std::conditional_t<sizeof(long long) == sizeof(T), unsigned long long,
	std::conditional_t<std::is_class_v<T> || std::is_union_v<T>, T,// pass these through if oddly-sized
	std::conditional_t<std::is_same_v<long double, T> &&// convert long double
		64 == LDBL_MANT_DIG &&
		16384 == LDBL_MAX_EXP &&
		128 >= CHAR_BIT * sizeof(long double) &&
		64 < CHAR_BIT * sizeof(long double),
		std::conditional_t<80 == CHAR_BIT * sizeof(long double), longdoubletest80,
		std::conditional_t<96 == CHAR_BIT * sizeof(long double), longdoubletest96,
		std::conditional_t<128 == CHAR_BIT * sizeof(long double), longdoubletest128, void>>>,
	typename std::conditional_t<std::is_integral_v<T> || std::is_enum_v<T>, std::make_unsigned<T>, std::enable_if<true, void>>::type>>>>>>>;

// Utility templates to use bit carry operations for the operators less than, and less than or equal

template<typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	64 >= CHAR_BIT * sizeof(U) &&
	std::is_unsigned_v<U>,
	void> addcarryofless(unsigned &accumulator, U minuend, U subtrahend)noexcept{
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_subc) && __has_builtin(__builtin_addc)
	tounifunsigned<U> carry;
	if constexpr(1 == sizeof(U)) __builtin_subcb(minuend, subtrahend, 0, &carry);
	else if constexpr(sizeof(short) == sizeof(U)) __builtin_subcs(minuend, subtrahend, 0, &carry);
	else if constexpr(sizeof(signed) == sizeof(U)) __builtin_subc(minuend, subtrahend, 0, &carry);
	else if constexpr(sizeof(long) == sizeof(U)) __builtin_subcl(minuend, subtrahend, 0, &carry);
	else if constexpr(sizeof(long long) == sizeof(U))__builtin_subcll(minuend, subtrahend, 0, &carry);
	unsigned checkcarry;
	accumulator = __builtin_addc(accumulator, 0, static_cast<unsigned>(carry), &checkcarry);
	static_cast<void>(checkcarry);
	assert(!checkcarry);// the chosen accumulator should be big enough to never wrap-around
#elif defined(_M_X64)
	unsigned char carry;
	if constexpr(1 == sizeof(U)) carry = _subborrow_u8(0, minuend, subtrahend, nullptr);
	else if constexpr(2 == sizeof(U)) carry = _subborrow_u16(0, minuend, subtrahend, nullptr);
	else if constexpr(4 == sizeof(U)) carry = _subborrow_u32(0, minuend, subtrahend, nullptr);
	else if constexpr(8 == sizeof(U)) carry = _subborrow_u64(0, minuend, subtrahend, nullptr);
	unsigned char checkcarry{_addcarry_u32(carry, accumulator, 0, &accumulator)};// cmp r, r followed by adc r, 0
	static_cast<void>(checkcarry);
	assert(!checkcarry);// the chosen accumulator should be big enough to never wrap-around
#elif defined(_M_IX86)
	unsigned char carry;
	if constexpr(1 == sizeof(U)) carry = _subborrow_u8(0, minuend, subtrahend, nullptr);
	else if constexpr(2 == sizeof(U)) carry = _subborrow_u16(0, minuend, subtrahend, nullptr);
	else if constexpr(4 == sizeof(U)) carry = _subborrow_u32(0, minuend, subtrahend, nullptr);
	else if constexpr(8 == sizeof(U)) carry = _subborrow_u32(_subborrow_u32(0, static_cast<std::uint_least32_t>(minuend & 0xFFFFFFFFu), static_cast<std::uint_least32_t>(subtrahend & 0xFFFFFFFFu), nullptr), static_cast<std::uint_least32_t>(minuend >> 32), static_cast<std::uint_least32_t>(subtrahend >> 32), nullptr);// decompose; cmp r, r followed by sbb r, r
	unsigned char checkcarry{_addcarry_u32(carry, accumulator, 0, &accumulator)};// cmp r, r followed by adc r, 0
	static_cast<void>(checkcarry);
	assert(!checkcarry);// the chosen accumulator should be big enough to never wrap-around
#else
	accumulator += minuend < subtrahend;
#endif
}
template<typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	64 >= CHAR_BIT * sizeof(U) &&
	std::is_unsigned_v<U>,
	void> addcarryoflessorequal(unsigned &accumulator, U minuend, U subtrahend)noexcept{
	// The specialised versions actually calculate greater-than-or-equal, but with everything reversed.
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_subc)
	tounifunsigned<U> carry;// lowest rank with the same size as U
	if constexpr(1 == sizeof(U)) __builtin_subcb(minuend, subtrahend, 0, &carry);
	else if constexpr(sizeof(short) == sizeof(U)) __builtin_subcs(minuend, subtrahend, 0, &carry);
	else if constexpr(sizeof(signed) == sizeof(U)) __builtin_subc(minuend, subtrahend, 0, &carry);
	else if constexpr(sizeof(long) == sizeof(U)) __builtin_subcl(minuend, subtrahend, 0, &carry);
	else if constexpr(sizeof(long long) == sizeof(U))__builtin_subcll(minuend, subtrahend, 0, &carry);
	unsigned checkcarry;
	accumulator = __builtin_subc(accumulator, ~0u, static_cast<unsigned>(carry), &checkcarry);
	static_cast<void>(checkcarry);
	assert(checkcarry);// the chosen accumulator should be big enough to never wrap-around
#elif defined(_M_X64)
	unsigned char carry;
	if constexpr(1 == sizeof(U)) carry = _subborrow_u8(0, minuend, subtrahend, nullptr);
	else if constexpr(2 == sizeof(U)) carry = _subborrow_u16(0, minuend, subtrahend, nullptr);
	else if constexpr(4 == sizeof(U)) carry = _subborrow_u32(0, minuend, subtrahend, nullptr);
	else if constexpr(8 == sizeof(U)) carry = _subborrow_u64(0, minuend, subtrahend, nullptr);
	unsigned char checkcarry{_subborrow_u32(carry, accumulator, 0xFFFFFFFFu, &accumulator)};// cmp r, r followed by sbb r, -1
	static_cast<void>(checkcarry);
	assert(checkcarry);// the chosen accumulator should be big enough to never wrap-around
#elif defined(_M_IX86)
	unsigned char carry;
	if constexpr(1 == sizeof(U)) carry = _subborrow_u8(0, minuend, subtrahend, nullptr);
	else if constexpr(2 == sizeof(U)) carry = _subborrow_u16(0, minuend, subtrahend, nullptr);
	else if constexpr(4 == sizeof(U)) carry = _subborrow_u32(0, minuend, subtrahend, nullptr);
	else if constexpr(8 == sizeof(U)) carry = _subborrow_u32(_subborrow_u32(0, static_cast<std::uint_least32_t>(minuend & 0xFFFFFFFFu), static_cast<std::uint_least32_t>(subtrahend & 0xFFFFFFFFu), nullptr), static_cast<std::uint_least32_t>(minuend >> 32), static_cast<std::uint_least32_t>(subtrahend >> 32), nullptr);// decompose; cmp r, r followed by sbb r, r
	unsigned char checkcarry{_subborrow_u32(carry, accumulator, 0xFFFFFFFFu, &accumulator)};// cmp r, r followed by sbb r, -1
	static_cast<void>(checkcarry);
	assert(checkcarry);// the chosen accumulator should be big enough to never wrap-around
#else
	accumulator += minuend <= subtrahend;
#endif
}

// Utility template of bit scan forward

template<typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_integral_v<typename std::conditional_t<std::is_enum_v<T>,
		std::underlying_type<T>,
		std::enable_if<true, T>>::type>,
#if defined(_M_X64)
	std::conditional_t<32 >= CHAR_BIT * sizeof(T), unsigned, std::uint_least64_t>
#else
	unsigned
#endif
	> bitscanforwardportable(T input)noexcept{
	assert(input);// design decision: do not allow 0 as input as neither x86/x64 bsf nor using the de Bruijn sequence supports it
#ifdef _M_X64
	// will run bsf (bit scan forward) on older architectures, which is fine
	if constexpr(32 >= CHAR_BIT * sizeof(T)) return{_tzcnt_u32(input)};
	else return{_tzcnt_u64(input)};
#elif defined(_M_IX86)
	// will run bsf (bit scan forward) on older architectures, which is fine
	if constexpr(32 >= CHAR_BIT * sizeof(T)) return{_tzcnt_u32(input)};
	else{// The 32-bit x86 platform hardly has any 64-bit integer support, so just split the halves.
		// This is still easy to handle in assembly (2 general options, and some instructions can be interleaved in between):
		// tzcnt r, r; add r, 32; tzcnt r, r; cmovc r, r
		// tzcnt r, r; add r, 32; bsf r, r; cmovz r, r
		DWORD hi{32 + _tzcnt_u32(static_cast<DWORD>(input >> 32))}, lo;// will run bsf (bit scan forward) on older architectures, which is fine
		return{_BitScanForward(&lo, static_cast<DWORD>(input & 0xFFFFFFFFu))? lo : hi};
	}
#elif defined(_M_ARM) || defined(_M_ARM64) || defined(_M_HYBRID_X86_ARM64) || defined(_M_ARM64EC)
	if constexpr(32 >= CHAR_BIT * sizeof(T)) return{_CountTrailingZeros(input)};
	else return{_CountTrailingZeros64(input)};
#elif defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))
	if constexpr(sizeof(unsigned) >= sizeof(T)) return{static_cast<unsigned>(__builtin_ctz(input))};
	else if constexpr(sizeof(unsigned long) >= sizeof(T)) return{static_cast<unsigned>(__builtin_ctzl(input))};
	else return{static_cast<unsigned>(__builtin_ctzll(input))};
#elif defined(__cpp_lib_bitops)
	return{static_cast<unsigned>(std::countr_zero(input))};
#else// Count the consecutive zero bits (trailing) on the right with multiply and lookup.
	if constexpr(32 >= CHAR_BIT * sizeof(T)){
		static unsigned char constexpr MultiplyDeBruijnBitPosition[32]{
			0,
			1,
			28, 2,
			29, 14, 24, 3,
			30, 22, 20, 15, 25, 17, 4, 8,
			31, 27, 13, 23, 21, 19, 16, 7,
			26, 12, 18, 6,
			11, 5,
			10,
			9};
		return{MultiplyDeBruijnBitPosition[static_cast<std::make_unsigned_t<T>>(input & -static_cast<std::make_signed_t<T>>(input)) * 0x077CB531u >> 27]};
	}else{
		static unsigned char constexpr MultiplyDeBruijnBitPosition[64]{
			0,
			1,
			17, 2,
			18, 50, 3, 57,
			47, 19, 22, 51, 29, 4, 33, 58,
			15, 48, 20, 27, 25, 23, 52, 41, 54, 30, 38, 5, 43, 34, 59, 8,
			63, 16, 49, 56, 46, 21, 28, 32, 14, 26, 24, 40, 53, 37, 42, 7,
			62, 55, 45, 31, 13, 39, 36, 6,
			61, 44, 12, 35,
			60, 11,
			10,
			9};
		return{MultiplyDeBruijnBitPosition[static_cast<std::make_unsigned_t<T>>(input & -static_cast<std::make_signed_t<T>>(input)) * 0x37E84A99DAE458Fu >> 58]};
	}
#endif
}

// Utility templates of rotate left or right by a compile-time constant amount

template<unsigned char amount, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_integral_v<typename std::conditional_t<std::is_enum_v<T>,
		std::underlying_type<T>,
		std::enable_if<true, T>>::type>,
	T> rotateleftportable(T input)noexcept{
#if defined(_M_IX86) || defined(_M_X64) || defined(_M_ARM) || defined(_M_ARM64) || defined(_M_HYBRID_X86_ARM64) || defined(_M_ARM64EC)
	if constexpr(64 == CHAR_BIT * sizeof(T)) return{static_cast<T>(_rotl64(static_cast<unsigned long long>(input), amount))};
	else if constexpr(32 == CHAR_BIT * sizeof(T)) return{static_cast<T>(_rotl(static_cast<unsigned>(input), amount))};
	else if constexpr(16 == CHAR_BIT * sizeof(T)) return{static_cast<T>(_rotl16(static_cast<unsigned short>(input), amount))};
	else if constexpr(8 == CHAR_BIT * sizeof(T)) return{static_cast<T>(_rotl8(static_cast<unsigned char>(input), amount))};
	else static_assert(false, "Implementing larger types will require additional work and optimisation for this library.");
#elif defined(__cpp_lib_bitops)
	return{std::rotl(input, amount)};
#else// revert to shifting and combining
	// Given that T might be smaller than type "int", prevent the undesired integral promotion when following C/C++ rules here.
	// By far most compilers can optimise this to a single instruction.
	T copy{input};
	copy <<= amount;
	input >>= CHAR_BIT * sizeof(T) - amount;
	input |= copy;
	return{input};
#endif
}
template<unsigned char amount, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_integral_v<typename std::conditional_t<std::is_enum_v<T>,
		std::underlying_type<T>,
		std::enable_if<true, T>>::type>,
	T> rotaterightportable(T input)noexcept{
#if defined(_M_IX86) || defined(_M_X64) || defined(_M_ARM) || defined(_M_ARM64) || defined(_M_HYBRID_X86_ARM64) || defined(_M_ARM64EC)
	if constexpr(64 == CHAR_BIT * sizeof(T)) return{static_cast<T>(_rotr64(static_cast<unsigned long long>(input), amount))};
	else if constexpr(32 == CHAR_BIT * sizeof(T)) return{static_cast<T>(_rotr(static_cast<unsigned>(input), amount))};
	else if constexpr(16 == CHAR_BIT * sizeof(T)) return{static_cast<T>(_rotr16(static_cast<unsigned short>(input), amount))};
	else if constexpr(8 == CHAR_BIT * sizeof(T)) return{static_cast<T>(_rotr8(static_cast<unsigned char>(input), amount))};
	else static_assert(false, "Implementing larger types will require additional work and optimisation for this library.");
#elif defined(__cpp_lib_bitops)
	return{std::rotr(input, amount)};
#else// revert to shifting and combining
	// Given that T might be smaller than type "int", prevent the undesired integral promotion when following C/C++ rules here.
	// By far most compilers can optimise this to a single instruction.
	T copy{input};
	copy <<= CHAR_BIT * sizeof(T) - amount;
	input >>= amount;
	input |= copy;
	return{input};
#endif
}

// Helper functions to implement the 8 main modes

// The filtertop8() and filtershift8() template functions are customised for the sorting phase, and have no need for variants with pointers.
// These also only output std::size_t (or multiple) for direct use as indices.
// The filterinput() template functions modify their inputs and each has a variant that write their inputs to memory either once or twice.
// There are 5 of these, handling 1, 2, 3, 4 or 8 inputs.
// Each of these have two varians that take one or two pointers per input to store each input before modification.
// ### modes with no filtering here:
// - regular unsigned integer and also inside-out signed integer
// - regular signed integer
// ### modes with one-pass filtering here:
// - absolute floating-point and also unsigned integer without using the top bit
// - absolute floating-point, but negative inputs will sort just below their positive counterparts
// ### modes with two-pass filtering here:
// - regular floating point
// - inside-out floating-point
// - absolute signed integer
// - absolute signed integer, but negative inputs will sort just below their positive counterparts

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	std::size_t> filtertop8(U cur)noexcept{
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curp{static_cast<std::make_signed_t<T>>(cur)};
		if constexpr(!issignmode || isfltpmode){
			T curo{static_cast<T>(cur)};
			curo += curo;
			cur = curo;
		}
		curp >>= CHAR_BIT * sizeof(T) - 1;
		U curq{static_cast<T>(curp)};
		if constexpr(isfltpmode){
			cur >>= 1;
		}
		if constexpr(issignmode){
			T curo{static_cast<T>(cur)};
			curo += static_cast<T>(curq);
			cur = curo;
		}
		cur ^= curq;
		if constexpr(8 < CHAR_BIT * sizeof(T)) cur >>= CHAR_BIT * sizeof(T) - 8;
		assert(!(cur & ~0xFFu));
		return{static_cast<std::size_t>(cur)};
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		if constexpr(8 < CHAR_BIT * sizeof(T)){
			cur >>= CHAR_BIT * sizeof(T) - 8 - !issignmode;
			return{static_cast<std::size_t>(cur & 0xFFu >> static_cast<unsigned char>(issignmode))};
		}else if constexpr(issignmode){
			return{static_cast<std::size_t>(cur & 0x7Fu)};
		}else{
			cur = rotateleftportable<1>(static_cast<T>(cur));
			assert(!(cur & ~0xFFu));
			return{static_cast<std::size_t>(cur)};
		}
	}else if constexpr(8 < CHAR_BIT * sizeof(T)){
		cur >>= CHAR_BIT * sizeof(T) - 8;
		return{static_cast<std::size_t>(cur)};
	}else return{static_cast<std::size_t>(cur)};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	std::pair<std::size_t, std::size_t>> filtertop8(U cura, U curb)noexcept{
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		if constexpr(!issignmode || isfltpmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		if constexpr(!issignmode || isfltpmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		if constexpr(isfltpmode){
			cura >>= 1;
			curb >>= 1;
		}
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			cura = curoa;
			curb = curob;
		}
		cura ^= curqa;
		curb ^= curqb;
		if constexpr(8 < CHAR_BIT * sizeof(T)){
			cura >>= CHAR_BIT * sizeof(T) - 8;
			curb >>= CHAR_BIT * sizeof(T) - 8;
		}
		assert(!(cura & ~0xFFu));
		assert(!(curb & ~0xFFu));
		return{static_cast<std::size_t>(cura), static_cast<std::size_t>(curb)};
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		if constexpr(8 < CHAR_BIT * sizeof(T)){
			cura >>= CHAR_BIT * sizeof(T) - 8 - !issignmode;
			curb >>= CHAR_BIT * sizeof(T) - 8 - !issignmode;
			return{static_cast<std::size_t>(cura & 0xFFu >> static_cast<unsigned char>(issignmode)), static_cast<std::size_t>(curb & 0xFFu >> static_cast<unsigned char>(issignmode))};
		}else if constexpr(issignmode){
			return{static_cast<std::size_t>(cura & 0x7Fu), static_cast<std::size_t>(curb & 0x7Fu)};
		}else{
			cura = rotateleftportable<1>(static_cast<T>(cura));
			curb = rotateleftportable<1>(static_cast<T>(curb));
			assert(!(cura & ~0xFFu));
			assert(!(curb & ~0xFFu));
			return{static_cast<std::size_t>(cura), static_cast<std::size_t>(curb)};
		}
	}else if constexpr(8 < CHAR_BIT * sizeof(T)){
		cura >>= CHAR_BIT * sizeof(T) - 8;
		curb >>= CHAR_BIT * sizeof(T) - 8;
		return{static_cast<std::size_t>(cura), static_cast<std::size_t>(curb)};
	}else return{static_cast<std::size_t>(cura), static_cast<std::size_t>(curb)};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	std::tuple<std::size_t, std::size_t, std::size_t, std::size_t>> filtertop8(U cura, U curb, U curc, U curd)noexcept{
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		if constexpr(!issignmode || isfltpmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		if constexpr(!issignmode || isfltpmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		std::make_signed_t<T> curpc{static_cast<std::make_signed_t<T>>(curc)};
		if constexpr(!issignmode || isfltpmode){
			T curoc{static_cast<T>(curc)};
			curoc += curoc;
			curc = curoc;
		}
		curpc >>= CHAR_BIT * sizeof(T) - 1;
		U curqc{static_cast<T>(curpc)};
		std::make_signed_t<T> curpd{static_cast<std::make_signed_t<T>>(curd)};
		if constexpr(!issignmode || isfltpmode){
			T curod{static_cast<T>(curd)};
			curod += curod;
			curd = curod;
		}
		curpd >>= CHAR_BIT * sizeof(T) - 1;
		U curqd{static_cast<T>(curpd)};
		if constexpr(isfltpmode){
			cura >>= 1;
			curb >>= 1;
			curc >>= 1;
			curd >>= 1;
		}
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			T curoc{static_cast<T>(curc)};
			T curod{static_cast<T>(curd)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			curoc += static_cast<T>(curqc);
			curod += static_cast<T>(curqd);
			cura = curoa;
			curb = curob;
			curc = curoc;
			curd = curod;
		}
		cura ^= curqa;
		curb ^= curqb;
		curc ^= curqc;
		curd ^= curqd;
		if constexpr(8 < CHAR_BIT * sizeof(T)){
			cura >>= CHAR_BIT * sizeof(T) - 8;
			curb >>= CHAR_BIT * sizeof(T) - 8;
			curc >>= CHAR_BIT * sizeof(T) - 8;
			curd >>= CHAR_BIT * sizeof(T) - 8;
		}
		assert(!(cura & ~0xFFu));
		assert(!(curb & ~0xFFu));
		assert(!(curc & ~0xFFu));
		assert(!(curd & ~0xFFu));
		return{static_cast<std::size_t>(cura), static_cast<std::size_t>(curb), static_cast<std::size_t>(curc), static_cast<std::size_t>(curd)};
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		if constexpr(8 < CHAR_BIT * sizeof(T)){
			cura >>= CHAR_BIT * sizeof(T) - 8 - !issignmode;
			curb >>= CHAR_BIT * sizeof(T) - 8 - !issignmode;
			curc >>= CHAR_BIT * sizeof(T) - 8 - !issignmode;
			curd >>= CHAR_BIT * sizeof(T) - 8 - !issignmode;
			return{static_cast<std::size_t>(cura & 0xFFu >> static_cast<unsigned char>(issignmode)), static_cast<std::size_t>(curb & 0xFFu >> static_cast<unsigned char>(issignmode)), static_cast<std::size_t>(curc & 0xFFu >> static_cast<unsigned char>(issignmode)), static_cast<std::size_t>(curd & 0xFFu >> static_cast<unsigned char>(issignmode))};
		}else if constexpr(issignmode){
			return{static_cast<std::size_t>(cura & 0x7Fu), static_cast<std::size_t>(curb & 0x7Fu), static_cast<std::size_t>(curc & 0x7Fu), static_cast<std::size_t>(curd & 0x7Fu)};
		}else{
			cura = rotateleftportable<1>(static_cast<T>(cura));
			curb = rotateleftportable<1>(static_cast<T>(curb));
			curc = rotateleftportable<1>(static_cast<T>(curc));
			curd = rotateleftportable<1>(static_cast<T>(curd));
			assert(!(cura & ~0xFFu));
			assert(!(curb & ~0xFFu));
			assert(!(curc & ~0xFFu));
			assert(!(curd & ~0xFFu));
			return{static_cast<std::size_t>(cura), static_cast<std::size_t>(curb), static_cast<std::size_t>(curc), static_cast<std::size_t>(curd)};
		}
	}else if constexpr(8 < CHAR_BIT * sizeof(T)){
		cura >>= CHAR_BIT * sizeof(T) - 8;
		curb >>= CHAR_BIT * sizeof(T) - 8;
		curc >>= CHAR_BIT * sizeof(T) - 8;
		curd >>= CHAR_BIT * sizeof(T) - 8;
		return{static_cast<std::size_t>(cura), static_cast<std::size_t>(curb), static_cast<std::size_t>(curc), static_cast<std::size_t>(curd)};
	}else return{static_cast<std::size_t>(cura), static_cast<std::size_t>(curb), static_cast<std::size_t>(curc), static_cast<std::size_t>(curd)};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::size_t> filtertop8(std::uint_least64_t curm, U cure)noexcept{
	// Filtering is simplified if possible.
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curp{static_cast<std::int_least16_t>(cure)};
		if constexpr(!issignmode || isfltpmode){
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carry;
			__builtin_addcll(curm, curm, 0, &carry);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			__builtin_addcl(curm, curm, 0, &carry);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			std::uint_least32_t curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			__builtin_addcl(curmhi, curmhi, 0, &carry);
#endif
			unsigned short checkcarry;
			curo = __builtin_addcs(curo, curo, static_cast<unsigned short>(carry), &checkcarry);
			static_cast<void>(checkcarry);
#elif defined(_M_X64)
			unsigned char checkcarry{_addcarry_u16(_addcarry_u64(0, curm, curm, nullptr), curo, curo, &curo)};
			static_cast<void>(checkcarry);
#elif defined(_M_IX86)
			std::uint_least32_t curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			unsigned char checkcarry{_addcarry_u16(_addcarry_u32(0, curmhi, curmhi, nullptr), curo, curo, &curo)};
			static_cast<void>(checkcarry);
#else
			std::uint_least64_t curmtmp{curm};
			curm += curm;
			curo += curo;
			curo += curm < curmtmp;
#endif
			cure = curo;
		}
		curp >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curq{static_cast<std::uint_least64_t>(curp)};// sign-extend
#else
		std::uint_least32_t curq{static_cast<std::uint_least32_t>(curp)};// sign-extend
#endif
		if constexpr(isfltpmode) cure >>= 1;
		if constexpr(issignmode){
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carry;
			__builtin_addcll(curm, curq, 0, &carry);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			__builtin_addcl(curm, curq, 0, &carry);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			std::uint_least32_t curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			__builtin_addcl(curmhi, curq, 0, &carry);
#endif
			unsigned short checkcarry;
			curo = __builtin_addcs(curo, static_cast<unsigned short>(curq), static_cast<unsigned short>(carry), &checkcarry);
			static_cast<void>(checkcarry);
#elif defined(_M_X64)
			unsigned char checkcarry{_addcarry_u16(_addcarry_u64(0, curm, curq, nullptr), curo, static_cast<std::uint_least16_t>(curq), &curo)};
			static_cast<void>(checkcarry);
#elif defined(_M_IX86)
			std::uint_least32_t curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			unsigned char checkcarry{_addcarry_u16(_addcarry_u32(0, curmhi, curq, nullptr), curo, static_cast<std::uint_least16_t>(curq), &curo)};
			static_cast<void>(checkcarry);
#else
			curm += curq;
			curo += static_cast<std::uint_least16_t>(curq);
			curo += curm < curq;
#endif
			cure = curo;
		}
		cure ^= static_cast<U>(curq);
		return{static_cast<std::size_t>(cure >> 8 & 0xFFu)};
	}else if constexpr(isabsvalue && !issignmode && isfltpmode){// one-register filtering
		std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
		static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
		unsigned long long carry;
		__builtin_addcll(curm, curm, 0, &carry);
#else
		static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carry;
		__builtin_addcl(curm, curm, 0, &carry);
#endif
#else
		static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carry;
		std::uint_least32_t curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
		__builtin_addcl(curmhi, curmhi, 0, &carry);
#endif
		unsigned short checkcarry;
		curo = __builtin_addcs(curo, curo, static_cast<unsigned short>(carry), &checkcarry);
		static_cast<void>(checkcarry);
#elif defined(_M_X64)
		unsigned char checkcarry{_addcarry_u16(_addcarry_u64(0, curm, curm, nullptr), curo, curo, &curo)};
		static_cast<void>(checkcarry);
#elif defined(_M_IX86)
		std::uint_least32_t curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
		unsigned char checkcarry{_addcarry_u16(_addcarry_u32(0, curmhi, curmhi, nullptr), curo, curo, &curo)};
		static_cast<void>(checkcarry);
#else
		std::uint_least64_t curmtmp{curm};
		curm += curm;
		curo += curo;
		curo += curm < curmtmp;
#endif
		cure = curo;
		assert(!(cure & ~0xFFu));
		return{static_cast<std::size_t>(cure >> 8)};
	}else if constexpr(80 == CHAR_BIT * sizeof(T)){
		return{static_cast<std::size_t>(cure >> 8)};
	}else{
		// if unfiltered and cure isn't 16-bit, mask out the high bits
		return{static_cast<std::size_t>(cure >> 8 & 0xFFu)};
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::size_t> filtertop8(T cur)noexcept{
	// Use the function above.
	return{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(cur.mantissa, static_cast<U>(cur.signexponent))};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::pair<std::size_t, std::size_t>> filtertop8(std::uint_least64_t curma, U curea, std::uint_least64_t curmb, U cureb)noexcept{
	// Filtering is simplified if possible.
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curpa{static_cast<std::int_least16_t>(curea)};
		std::int_least16_t curpb{static_cast<std::int_least16_t>(cureb)};
		if constexpr(!issignmode || isfltpmode){
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			__builtin_addcll(curma, curma, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			__builtin_addcl(curma, curma, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			__builtin_addcl(curmhia, curmhia, 0, &carrya);
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, curoa, static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			__builtin_addcll(curmb, curmb, 0, &carryb);
#else
			unsigned long carryb;
			__builtin_addcl(curmb, curmb, 0, &carryb);
#endif
#else
			unsigned long carryb;
			std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			__builtin_addcl(curmhib, curmhib, 0, &carryb);
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, curob, static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curma, nullptr), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curmb, nullptr), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
			std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(0, curmhia, curmhia, nullptr), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(0, curmhib, curmhib, nullptr), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
#else
			std::uint_least64_t curmtmpa{curma}, curmtmpb{curmb};
			curma += curma;
			curoa += curoa;
			curoa += curma < curmtmpa;
			curmb += curmb;
			curob += curob;
			curob += curmb < curmtmpb;
#endif
			curea = curoa;
			cureb = curob;
		}
		curpa >>= 16 - 1;
		curpb >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curqa{static_cast<std::uint_least64_t>(curpa)};// sign-extend
		std::uint_least64_t curqb{static_cast<std::uint_least64_t>(curpb)};
#else
		std::uint_least32_t curqa{static_cast<std::uint_least32_t>(curpa)};// sign-extend
		std::uint_least32_t curqb{static_cast<std::uint_least32_t>(curpb)};
#endif
		if constexpr(isfltpmode){
			curea >>= 1;
			cureb >>= 1;
		}
		if constexpr(issignmode){
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			__builtin_addcll(curma, curqa, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			__builtin_addcl(curma, curqa, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			__builtin_addcl(curmhia, curqa, 0, &carrya);
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, static_cast<unsigned short>(curqa), static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			__builtin_addcll(curmb, curqb, 0, &carryb);
#else
			unsigned long carryb;
			__builtin_addcl(curmb, curqb, 0, &carryb);
#endif
#else
			unsigned long carryb;
			std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			__builtin_addcl(curmhib, curqb, 0, &carryb);
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, static_cast<unsigned short>(curqb), static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curqa, nullptr), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curqb, nullptr), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
			std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(0, curmhia, curqa, nullptr), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(0, curmhib, curqb, nullptr), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
#elif 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
			curma += curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curma < curqa;
			curmb += curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmb < curqb;
#else
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			std::uint_least32_t curmlotmpa{curmloa}, curmhitmpa{curmhia};
			std::uint_least32_t curmlotmpb{curmlob}, curmhitmpb{curmhib};
			curmloa += curqa;
			curmhia += curqa;
			curmhia += curmloa < curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curmhia < curqa;
			curmlob += curqb;
			curmhib += curqb;
			curmhib += curmlob < curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmhib < curqb;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			curea = curoa;
			cureb = curob;
		}
		curea ^= static_cast<U>(curqa);
		cureb ^= static_cast<U>(curqb);
		return{static_cast<std::size_t>(curea >> 8 & 0xFFu), static_cast<std::size_t>(cureb >> 8 & 0xFFu)};
	}else if constexpr(isabsvalue && !issignmode && isfltpmode){// one-register filtering
		std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
		std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
		static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
		unsigned long long carrya;
		__builtin_addcll(curma, curma, 0, &carrya);
#else
		static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrya;
		__builtin_addcl(curma, curma, 0, &carrya);
#endif
#else
		static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrya;
		std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		__builtin_addcl(curmhia, curmhia, 0, &carrya);
#endif
		unsigned short checkcarrya;
		curoa = __builtin_addcs(curoa, curoa, static_cast<unsigned short>(carrya), &checkcarrya);
		static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		unsigned long long carryb;
		__builtin_addcll(curmb, curmb, 0, &carryb);
#else
		unsigned long carryb;
		__builtin_addcl(curmb, curmb, 0, &carryb);
#endif
#else
		unsigned long carryb;
		std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		__builtin_addcl(curmhib, curmhib, 0, &carryb);
#endif
		unsigned short checkcarryb;
		curob = __builtin_addcs(curob, curob, static_cast<unsigned short>(carryb), &checkcarryb);
		static_cast<void>(checkcarryb);
#elif defined(_M_X64)
		unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curma, nullptr), curoa, curoa, &curoa)};
		static_cast<void>(checkcarrya);
		unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curmb, nullptr), curob, curob, &curob)};
		static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
		std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(0, curmhia, curmhia, nullptr), curoa, curoa, &curoa)};
		static_cast<void>(checkcarrya);
		std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(0, curmhib, curmhib, nullptr), curob, curob, &curob)};
		static_cast<void>(checkcarryb);
#else
		std::uint_least64_t curmtmpa{curma}, curmtmpb{curmb};
		curma += curma;
		curoa += curoa;
		curoa += curma < curmtmpa;
		curmb += curmb;
		curob += curob;
		curob += curmb < curmtmpb;
#endif
		curea = curoa;
		cureb = curob;
		assert(!(curea & ~0xFFu));
		assert(!(cureb & ~0xFFu));
		return{static_cast<std::size_t>(curea >> 8), static_cast<std::size_t>(cureb >> 8)};
	}else if constexpr(80 == CHAR_BIT * sizeof(T)){
		return{static_cast<std::size_t>(curea >> 8), static_cast<std::size_t>(cureb >> 8)};
	}else{
		// if unfiltered and cure isn't 16-bit, mask out the high bits
		return{static_cast<std::size_t>(curea >> 8 & 0xFFu), static_cast<std::size_t>(cureb >> 8 & 0xFFu)};
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::pair<std::size_t, std::size_t>> filtertop8(T cura, T curb)noexcept{
	// Use the function above.
	return{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(
		cura.mantissa, static_cast<U>(cura.signexponent),
		curb.mantissa, static_cast<U>(curb.signexponent))};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::tuple<std::size_t, std::size_t, std::size_t, std::size_t>> filtertop8(std::uint_least64_t curma, U curea, std::uint_least64_t curmb, U cureb, std::uint_least64_t curmc, U curec, std::uint_least64_t curmd, U cured)noexcept{
	// Filtering is simplified if possible.
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curpa{static_cast<std::int_least16_t>(curea)};
		std::int_least16_t curpb{static_cast<std::int_least16_t>(cureb)};
		std::int_least16_t curpc{static_cast<std::int_least16_t>(curec)};
		std::int_least16_t curpd{static_cast<std::int_least16_t>(cured)};
		if constexpr(!issignmode || isfltpmode){
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
			std::uint_least16_t curoc{static_cast<std::uint_least16_t>(curec)};
			std::uint_least16_t curod{static_cast<std::uint_least16_t>(cured)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			__builtin_addcll(curma, curma, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			__builtin_addcl(curma, curma, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			__builtin_addcl(curmhia, curmhia, 0, &carrya);
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, curoa, static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			__builtin_addcll(curmb, curmb, 0, &carryb);
#else
			unsigned long carryb;
			__builtin_addcl(curmb, curmb, 0, &carryb);
#endif
#else
			unsigned long carryb;
			std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			__builtin_addcl(curmhib, curmhib, 0, &carryb);
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, curob, static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryc;
			__builtin_addcll(curmc, curmc, 0, &carryc);
#else
			unsigned long carryc;
			__builtin_addcl(curmc, curmc, 0, &carryc);
#endif
#else
			unsigned long carryc;
			std::uint_least32_t curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			__builtin_addcl(curmhic, curmhic, 0, &carryc);
#endif
			unsigned short checkcarryc;
			curoc = __builtin_addcs(curoc, curoc, static_cast<unsigned short>(carryc), &checkcarryc);
			static_cast<void>(checkcarryc);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryd;
			__builtin_addcll(curmd, curmd, 0, &carryd);
#else
			unsigned long carryd;
			__builtin_addcl(curmd, curmd, 0, &carryd);
#endif
#else
			unsigned long carryd;
			std::uint_least32_t curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
			__builtin_addcl(curmhid, curmhid, 0, &carryd);
#endif
			unsigned short checkcarryd;
			curod = __builtin_addcs(curod, curod, static_cast<unsigned short>(carryd), &checkcarryd);
			static_cast<void>(checkcarryd);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curma, nullptr), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curmb, nullptr), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
			unsigned char checkcarryc{_addcarry_u16(_addcarry_u64(0, curmc, curmc, nullptr), curoc, curoc, &curoc)};
			static_cast<void>(checkcarryc);
			unsigned char checkcarryd{_addcarry_u16(_addcarry_u64(0, curmd, curmd, nullptr), curod, curod, &curod)};
			static_cast<void>(checkcarryd);
#elif defined(_M_IX86)
			std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(0, curmhia, curmhia, nullptr), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(0, curmhib, curmhib, nullptr), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
			std::uint_least32_t curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			unsigned char checkcarryc{_addcarry_u16(_addcarry_u32(0, curmhic, curmhic, nullptr), curoc, curoc, &curoc)};
			static_cast<void>(checkcarryc);
			std::uint_least32_t curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
			unsigned char checkcarryd{_addcarry_u16(_addcarry_u32(0, curmhid, curmhid, nullptr), curod, curod, &curod)};
			static_cast<void>(checkcarryd);
#else
			std::uint_least64_t curmtmpa{curma}, curmtmpb{curmb}, curmtmpc{curmc}, curmtmpd{curmd};
			curma += curma;
			curoa += curoa;
			curoa += curma < curmtmpa;
			curmb += curmb;
			curob += curob;
			curob += curmb < curmtmpb;
			curmc += curmc;
			curoc += curoc;
			curoc += curmc < curmtmpc;
			curmd += curmd;
			curod += curod;
			curod += curmd < curmtmpd;
#endif
			curea = curoa;
			cureb = curob;
			curec = curoc;
			cured = curod;
		}
		curpa >>= 16 - 1;
		curpb >>= 16 - 1;
		curpc >>= 16 - 1;
		curpd >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curqa{static_cast<std::uint_least64_t>(curpa)};// sign-extend
		std::uint_least64_t curqb{static_cast<std::uint_least64_t>(curpb)};
		std::uint_least64_t curqc{static_cast<std::uint_least64_t>(curpc)};
		std::uint_least64_t curqd{static_cast<std::uint_least64_t>(curpd)};
#else
		std::uint_least32_t curqa{static_cast<std::uint_least32_t>(curpa)};// sign-extend
		std::uint_least32_t curqb{static_cast<std::uint_least32_t>(curpb)};
		std::uint_least32_t curqc{static_cast<std::uint_least32_t>(curpc)};
		std::uint_least32_t curqd{static_cast<std::uint_least32_t>(curpd)};
#endif
		if constexpr(isfltpmode){
			curea >>= 1;
			cureb >>= 1;
			curec >>= 1;
			cured >>= 1;
		}
		if constexpr(issignmode){
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
			std::uint_least16_t curoc{static_cast<std::uint_least16_t>(curec)};
			std::uint_least16_t curod{static_cast<std::uint_least16_t>(cured)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			__builtin_addcll(curma, curqa, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			__builtin_addcl(curma, curqa, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			__builtin_addcl(curmhia, curqa, 0, &carrya);
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, static_cast<unsigned short>(curqa), static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			__builtin_addcll(curmb, curqb, 0, &carryb);
#else
			unsigned long carryb;
			__builtin_addcl(curmb, curqb, 0, &carryb);
#endif
#else
			unsigned long carryb;
			std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			__builtin_addcl(curmhib, curqb, 0, &carryb);
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, static_cast<unsigned short>(curqb), static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryc;
			__builtin_addcll(curmc, curqc, 0, &carryc);
#else
			unsigned long carryc;
			__builtin_addcl(curmc, curqc, 0, &carryc);
#endif
#else
			unsigned long carryc;
			std::uint_least32_t curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			__builtin_addcl(curmhic, curqc, 0, &carryc);
#endif
			unsigned short checkcarryc;
			curoc = __builtin_addcs(curoc, static_cast<unsigned short>(curqc), static_cast<unsigned short>(carryc), &checkcarryc);
			static_cast<void>(checkcarryc);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryd;
			__builtin_addcll(curmd, curqd, 0, &carryd);
#else
			unsigned long carryd;
			__builtin_addcl(curmd, curqd, 0, &carryd);
#endif
#else
			unsigned long carryd;
			std::uint_least32_t curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
			__builtin_addcl(curmhid, curqd, 0, &carryd);
#endif
			unsigned short checkcarryd;
			curod = __builtin_addcs(curod, static_cast<unsigned short>(curqd), static_cast<unsigned short>(carryd), &checkcarryd);
			static_cast<void>(checkcarryd);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curqa, nullptr), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curqb, nullptr), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
			unsigned char checkcarryc{_addcarry_u16(_addcarry_u64(0, curmc, curqc, nullptr), curoc, static_cast<std::uint_least16_t>(curqc), &curoc)};
			static_cast<void>(checkcarryc);
			unsigned char checkcarryd{_addcarry_u16(_addcarry_u64(0, curmd, curqd, nullptr), curod, static_cast<std::uint_least16_t>(curqd), &curod)};
			static_cast<void>(checkcarryd);
#elif defined(_M_IX86)
			std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(0, curmhia, curqa, nullptr), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(0, curmhib, curqb, nullptr), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
			std::uint_least32_t curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			unsigned char checkcarryc{_addcarry_u16(_addcarry_u32(0, curmhic, curqc, nullptr), curoc, static_cast<std::uint_least16_t>(curqc), &curoc)};
			static_cast<void>(checkcarryc);
			std::uint_least32_t curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
			unsigned char checkcarryd{_addcarry_u16(_addcarry_u32(0, curmhid, curqd, nullptr), curod, static_cast<std::uint_least16_t>(curqd), &curod)};
			static_cast<void>(checkcarryd);
#elif 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
			curma += curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curma < curqa;
			curmb += curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmb < curqb;
			curmc += curqc;
			curoc += static_cast<std::uint_least16_t>(curqc);
			curoc += curmc < curqc;
			curmd += curqd;
			curod += static_cast<std::uint_least16_t>(curqd);
			curod += curmd < curqd;
#else
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			std::uint_least32_t curmloc{static_cast<std::uint_least32_t>(curmc & 0xFFFFFFFFu)}, curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			std::uint_least32_t curmlod{static_cast<std::uint_least32_t>(curmd & 0xFFFFFFFFu)}, curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
			curmloa += curqa;
			curmhia += curqa;
			curmhia += curmloa < curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curmhia < curqa;
			curmlob += curqb;
			curmhib += curqb;
			curmhib += curmlob < curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmhib < curqb;
			curmloc += curqc;
			curmhic += curqc;
			curmhic += curmloc < curqc;
			curoc += static_cast<std::uint_least16_t>(curqc);
			curoc += curmhic < curqc;
			curmlod += curqd;
			curmhid += curqd;
			curmhid += curmlod < curqd;
			curod += static_cast<std::uint_least16_t>(curqd);
			curod += curmhid < curqd;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmc[2]{curmloc, curmhic};
			curmc = *reinterpret_cast<std::uint_least64_t *>(acurmc);// recompose
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmd[2]{curmlod, curmhid};
			curmd = *reinterpret_cast<std::uint_least64_t *>(acurmd);// recompose
#endif
			curea = curoa;
			cureb = curob;
			curec = curoc;
			cured = curod;
		}
		curea ^= static_cast<U>(curqa);
		cureb ^= static_cast<U>(curqb);
		curec ^= static_cast<U>(curqc);
		cured ^= static_cast<U>(curqd);
		return{static_cast<std::size_t>(curea >> 8 & 0xFFu), static_cast<std::size_t>(cureb >> 8 & 0xFFu), static_cast<std::size_t>(curec >> 8 & 0xFFu), static_cast<std::size_t>(cured >> 8 & 0xFFu)};
	}else if constexpr(isabsvalue && !issignmode && isfltpmode){// one-register filtering
		std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
		std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
		std::uint_least16_t curoc{static_cast<std::uint_least16_t>(curec)};
		std::uint_least16_t curod{static_cast<std::uint_least16_t>(cured)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
		static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
		unsigned long long carrya;
		__builtin_addcll(curma, curma, 0, &carrya);
#else
		static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrya;
		__builtin_addcl(curma, curma, 0, &carrya);
#endif
#else
		static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrya;
		std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		__builtin_addcl(curmhia, curmhia, 0, &carrya);
#endif
		unsigned short checkcarrya;
		curoa = __builtin_addcs(curoa, curoa, static_cast<unsigned short>(carrya), &checkcarrya);
		static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		unsigned long long carryb;
		__builtin_addcll(curmb, curmb, 0, &carryb);
#else
		unsigned long carryb;
		__builtin_addcl(curmb, curmb, 0, &carryb);
#endif
#else
		unsigned long carryb;
		std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		__builtin_addcl(curmhib, curmhib, 0, &carryb);
#endif
		unsigned short checkcarryb;
		curob = __builtin_addcs(curob, curob, static_cast<unsigned short>(carryb), &checkcarryb);
		static_cast<void>(checkcarryb);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		unsigned long long carryc;
		__builtin_addcll(curmc, curmc, 0, &carryc);
#else
		unsigned long carryc;
		__builtin_addcl(curmc, curmc, 0, &carryc);
#endif
#else
		unsigned long carryc;
		std::uint_least32_t curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
		__builtin_addcl(curmhic, curmhic, 0, &carryc);
#endif
		unsigned short checkcarryc;
		curoc = __builtin_addcs(curoc, curoc, static_cast<unsigned short>(carryc), &checkcarryc);
		static_cast<void>(checkcarryc);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		unsigned long long carryd;
		__builtin_addcll(curmd, curmd, 0, &carryd);
#else
		unsigned long carryd;
		__builtin_addcl(curmd, curmd, 0, &carryd);
#endif
#else
		unsigned long carryd;
		std::uint_least32_t curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
		__builtin_addcl(curmhid, curmhid, 0, &carryd);
#endif
		unsigned short checkcarryd;
		curod = __builtin_addcs(curod, curod, static_cast<unsigned short>(carryd), &checkcarryd);
		static_cast<void>(checkcarryd);
#elif defined(_M_X64)
		unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curma, nullptr), curoa, curoa, &curoa)};
		static_cast<void>(checkcarrya);
		unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curmb, nullptr), curob, curob, &curob)};
		static_cast<void>(checkcarryb);
		unsigned char checkcarryc{_addcarry_u16(_addcarry_u64(0, curmc, curmc, nullptr), curoc, curoc, &curoc)};
		static_cast<void>(checkcarryc);
		unsigned char checkcarryd{_addcarry_u16(_addcarry_u64(0, curmd, curmd, nullptr), curod, curod, &curod)};
		static_cast<void>(checkcarryd);
#elif defined(_M_IX86)
		std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(0, curmhia, curmhia, nullptr), curoa, curoa, &curoa)};
		static_cast<void>(checkcarrya);
		std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(0, curmhib, curmhib, nullptr), curob, curob, &curob)};
		static_cast<void>(checkcarryb);
		std::uint_least32_t curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
		unsigned char checkcarryc{_addcarry_u16(_addcarry_u32(0, curmhic, curmhic, nullptr), curoc, curoc, &curoc)};
		static_cast<void>(checkcarryc);
		std::uint_least32_t curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
		unsigned char checkcarryd{_addcarry_u16(_addcarry_u32(0, curmhid, curmhid, nullptr), curod, curod, &curod)};
		static_cast<void>(checkcarryd);
#else
		std::uint_least64_t curmtmpa{curma}, curmtmpb{curmb}, curmtmpc{curmc}, curmtmpd{curmd};
		curma += curma;
		curoa += curoa;
		curoa += curma < curmtmpa;
		curmb += curmb;
		curob += curob;
		curob += curmb < curmtmpb;
		curmc += curmc;
		curoc += curoc;
		curoc += curmc < curmtmpc;
		curmd += curmd;
		curod += curod;
		curod += curmd < curmtmpd;
#endif
		curea = curoa;
		cureb = curob;
		curec = curoc;
		cured = curod;
		assert(!(curea & ~0xFFu));
		assert(!(cureb & ~0xFFu));
		assert(!(curec & ~0xFFu));
		assert(!(cured & ~0xFFu));
		return{static_cast<std::size_t>(curea >> 8), static_cast<std::size_t>(cureb >> 8), static_cast<std::size_t>(curec >> 8), static_cast<std::size_t>(cured >> 8)};
	}else if constexpr(80 == CHAR_BIT * sizeof(T)){
		return{static_cast<std::size_t>(curea >> 8), static_cast<std::size_t>(cureb >> 8), static_cast<std::size_t>(curec >> 8), static_cast<std::size_t>(cured >> 8)};
	}else{
		// if unfiltered and cure isn't 16-bit, mask out the high bits
		return{static_cast<std::size_t>(curea >> 8 & 0xFFu), static_cast<std::size_t>(cureb >> 8 & 0xFFu), static_cast<std::size_t>(curec >> 8 & 0xFFu), static_cast<std::size_t>(cured >> 8 & 0xFFu)};
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::tuple<std::size_t, std::size_t, std::size_t, std::size_t>> filtertop8(T cura, T curb, T curc, T curd)noexcept{
	// Use the function above.
	return{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(
		cura.mantissa, static_cast<U>(cura.signexponent),
		curb.mantissa, static_cast<U>(curb.signexponent),
		curc.mantissa, static_cast<U>(curc.signexponent),
		curd.mantissa, static_cast<U>(curd.signexponent))};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::size_t> filterbelowtop8(std::uint_least64_t curm, U cure)noexcept{
	// Filtering is simplified if possible.
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curp{static_cast<std::int_least16_t>(cure)};
		if constexpr(isabsvalue && !issignmode){
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carry;
			__builtin_addcll(curm, curm, 0, &carry);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			__builtin_addcl(curm, curm, 0, &carry);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			std::uint_least32_t curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			__builtin_addcl(curmhi, curmhi, 0, &carry);
#endif
			unsigned short checkcarry;
			curo = __builtin_addcs(curo, curo, static_cast<unsigned short>(carry), &checkcarry);
			static_cast<void>(checkcarry);
#elif defined(_M_X64)
			unsigned char checkcarry{_addcarry_u16(_addcarry_u64(0, curm, curm, nullptr), curo, curo, &curo)};
			static_cast<void>(checkcarry);
#elif defined(_M_IX86)
			std::uint_least32_t curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			unsigned char checkcarry{_addcarry_u16(_addcarry_u32(0, curmhi, curmhi, nullptr), curo, curo, &curo)};
			static_cast<void>(checkcarry);
#else
			std::uint_least64_t curmtmp{curm};
			curm += curm;
			curo += curo;
			curo += curm < curmtmp;
#endif
			cure = curo;
		}
		curp >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curq{static_cast<std::uint_least64_t>(curp)};// sign-extend
#else
		std::uint_least32_t curq{static_cast<std::uint_least32_t>(curp)};// sign-extend
#endif
		if constexpr(issignmode){
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carry;
			__builtin_addcll(curm, curq, 0, &carry);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			__builtin_addcl(curm, curq, 0, &carry);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			std::uint_least32_t curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			__builtin_addcl(curmhi, curq, 0, &carry);
#endif
			unsigned short checkcarry;
			curo = __builtin_addcs(curo, static_cast<unsigned short>(curq), static_cast<unsigned short>(carry), &checkcarry);
			static_cast<void>(checkcarry);
#elif defined(_M_X64)
			unsigned char checkcarry{_addcarry_u16(_addcarry_u64(0, curm, curq, nullptr), curo, static_cast<std::uint_least16_t>(curq), &curo)};
			static_cast<void>(checkcarry);
#elif defined(_M_IX86)
			std::uint_least32_t curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			unsigned char checkcarry{_addcarry_u16(_addcarry_u32(0, curmhi, curq, nullptr), curo, static_cast<std::uint_least16_t>(curq), &curo)};
			static_cast<void>(checkcarry);
#else
			curm += curq;
			curo += static_cast<std::uint_least16_t>(curq);
			curo += curm < curq;
#endif
			cure = curo;
		}
		cure ^= static_cast<U>(curq);
	}else if constexpr(isabsvalue && !issignmode && isfltpmode){// one-register filtering
		std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
		static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
		unsigned long long carry;
		__builtin_addcll(curm, curm, 0, &carry);
#else
		static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carry;
		__builtin_addcl(curm, curm, 0, &carry);
#endif
#else
		static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carry;
		std::uint_least32_t curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
		__builtin_addcl(curmhi, curmhi, 0, &carry);
#endif
		unsigned short checkcarry;
		curo = __builtin_addcs(curo, curo, static_cast<unsigned short>(carry), &checkcarry);
		static_cast<void>(checkcarry);
#elif defined(_M_X64)
		unsigned char checkcarry{_addcarry_u16(_addcarry_u64(0, curm, curm, nullptr), curo, curo, &curo)};
		static_cast<void>(checkcarry);
#elif defined(_M_IX86)
		std::uint_least32_t curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
		unsigned char checkcarry{_addcarry_u16(_addcarry_u32(0, curmhi, curmhi, nullptr), curo, curo, &curo)};
		static_cast<void>(checkcarry);
#else
		std::uint_least64_t curmtmp{curm};
		curm += curm;
		curo += curo;
		curo += curm < curmtmp;
#endif
		cure = curo;
	}
	return{static_cast<std::size_t>(cure & 0xFFu)};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::size_t> filterbelowtop8(T cur)noexcept{
	// Use the function above.
	return{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(cur.mantissa, static_cast<U>(cur.signexponent))};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::pair<std::size_t, std::size_t>> filterbelowtop8(std::uint_least64_t curma, U curea, std::uint_least64_t curmb, U cureb)noexcept{
	// Filtering is simplified if possible.
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curpa{static_cast<std::int_least16_t>(curea)};
		std::int_least16_t curpb{static_cast<std::int_least16_t>(cureb)};
		if constexpr(isabsvalue && !issignmode){
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			__builtin_addcll(curma, curma, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			__builtin_addcl(curma, curma, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			__builtin_addcl(curmhia, curmhia, 0, &carrya);
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, curoa, static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			__builtin_addcll(curmb, curmb, 0, &carryb);
#else
			unsigned long carryb;
			__builtin_addcl(curmb, curmb, 0, &carryb);
#endif
#else
			unsigned long carryb;
			std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			__builtin_addcl(curmhib, curmhib, 0, &carryb);
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, curob, static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curma, nullptr), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curmb, nullptr), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
			std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(0, curmhia, curmhia, nullptr), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(0, curmhib, curmhib, nullptr), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
#else
			std::uint_least64_t curmtmpa{curma}, curmtmpb{curmb};
			curma += curma;
			curoa += curoa;
			curoa += curma < curmtmpa;
			curmb += curmb;
			curob += curob;
			curob += curmb < curmtmpb;
#endif
			curea = curoa;
			cureb = curob;
		}
		curpa >>= 16 - 1;
		curpb >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curqa{static_cast<std::uint_least64_t>(curpa)};// sign-extend
		std::uint_least64_t curqb{static_cast<std::uint_least64_t>(curpb)};
#else
		std::uint_least32_t curqa{static_cast<std::uint_least32_t>(curpa)};// sign-extend
		std::uint_least32_t curqb{static_cast<std::uint_least32_t>(curpb)};
#endif
		if constexpr(issignmode){
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			__builtin_addcll(curma, curqa, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			__builtin_addcl(curma, curqa, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			__builtin_addcl(curmhia, curqa, 0, &carrya);
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, static_cast<unsigned short>(curqa), static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			__builtin_addcll(curmb, curqb, 0, &carryb);
#else
			unsigned long carryb;
			__builtin_addcl(curmb, curqb, 0, &carryb);
#endif
#else
			unsigned long carryb;
			std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			__builtin_addcl(curmhib, curqb, 0, &carryb);
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, static_cast<unsigned short>(curqb), static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curqa, nullptr), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curqb, nullptr), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
			std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(0, curmhia, curqa, nullptr), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(0, curmhib, curqb, nullptr), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
#elif 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
			curma += curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curma < curqa;
			curmb += curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmb < curqb;
#else
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmloa += curqa;
			curmhia += curqa;
			curmhia += curmloa < curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curmhia < curqa;
			curmlob += curqb;
			curmhib += curqb;
			curmhib += curmlob < curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmhib < curqb;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			curea = curoa;
			cureb = curob;
		}
		curea ^= static_cast<U>(curqa);
		cureb ^= static_cast<U>(curqb);
	}else if constexpr(isabsvalue && !issignmode && isfltpmode){// one-register filtering
		std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
		std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
		static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
		unsigned long long carrya;
		__builtin_addcll(curma, curma, 0, &carrya);
#else
		static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrya;
		__builtin_addcl(curma, curma, 0, &carrya);
#endif
#else
		static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrya;
		std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		__builtin_addcl(curmhia, curmhia, 0, &carrya);
#endif
		unsigned short checkcarrya;
		curoa = __builtin_addcs(curoa, curoa, static_cast<unsigned short>(carrya), &checkcarrya);
		static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		unsigned long long carryb;
		__builtin_addcll(curmb, curmb, 0, &carryb);
#else
		unsigned long carryb;
		__builtin_addcl(curmb, curmb, 0, &carryb);
#endif
#else
		unsigned long carryb;
		std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		__builtin_addcl(curmhib, curmhib, 0, &carryb);
#endif
		unsigned short checkcarryb;
		curob = __builtin_addcs(curob, curob, static_cast<unsigned short>(carryb), &checkcarryb);
		static_cast<void>(checkcarryb);
#elif defined(_M_X64)
		unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curma, nullptr), curoa, curoa, &curoa)};
		static_cast<void>(checkcarrya);
		unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curmb, nullptr), curob, curob, &curob)};
		static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
		std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(0, curmhia, curmhia, nullptr), curoa, curoa, &curoa)};
		static_cast<void>(checkcarrya);
		std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(0, curmhib, curmhib, nullptr), curob, curob, &curob)};
		static_cast<void>(checkcarryb);
#else
		std::uint_least64_t curmtmpa{curma}, curmtmpb{curmb};
		curma += curma;
		curoa += curoa;
		curoa += curma < curmtmpa;
		curmb += curmb;
		curob += curob;
		curob += curmb < curmtmpb;
#endif
		curea = curoa;
		cureb = curob;
	}
	return{static_cast<std::size_t>(curea & 0xFFu), static_cast<std::size_t>(cureb & 0xFFu)};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::pair<std::size_t, std::size_t>> filterbelowtop8(T cura, T curb)noexcept{
	// Use the function above.
	return{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(
		cura.mantissa, static_cast<U>(cura.signexponent),
		curb.mantissa, static_cast<U>(curb.signexponent))};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::tuple<std::size_t, std::size_t, std::size_t, std::size_t>> filterbelowtop8(std::uint_least64_t curma, U curea, std::uint_least64_t curmb, U cureb, std::uint_least64_t curmc, U curec, std::uint_least64_t curmd, U cured)noexcept{
	// Filtering is simplified if possible.
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curpa{static_cast<std::int_least16_t>(curea)};
		std::int_least16_t curpb{static_cast<std::int_least16_t>(cureb)};
		std::int_least16_t curpc{static_cast<std::int_least16_t>(curec)};
		std::int_least16_t curpd{static_cast<std::int_least16_t>(cured)};
		if constexpr(isabsvalue && !issignmode){
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
			std::uint_least16_t curoc{static_cast<std::uint_least16_t>(curec)};
			std::uint_least16_t curod{static_cast<std::uint_least16_t>(cured)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			__builtin_addcll(curma, curma, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			__builtin_addcl(curma, curma, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			__builtin_addcl(curmhia, curmhia, 0, &carrya);
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, curoa, static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			__builtin_addcll(curmb, curmb, 0, &carryb);
#else
			unsigned long carryb;
			__builtin_addcl(curmb, curmb, 0, &carryb);
#endif
#else
			unsigned long carryb;
			std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			__builtin_addcl(curmhib, curmhib, 0, &carryb);
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, curob, static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryc;
			__builtin_addcll(curmc, curmc, 0, &carryc);
#else
			unsigned long carryc;
			__builtin_addcl(curmc, curmc, 0, &carryc);
#endif
#else
			unsigned long carryc;
			std::uint_least32_t curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			__builtin_addcl(curmhic, curmhic, 0, &carryc);
#endif
			unsigned short checkcarryc;
			curoc = __builtin_addcs(curoc, curoc, static_cast<unsigned short>(carryc), &checkcarryc);
			static_cast<void>(checkcarryc);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryd;
			__builtin_addcll(curmd, curmd, 0, &carryd);
#else
			unsigned long carryd;
			__builtin_addcl(curmd, curmd, 0, &carryd);
#endif
#else
			unsigned long carryd;
			std::uint_least32_t curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
			__builtin_addcl(curmhid, curmhid, 0, &carryd);
#endif
			unsigned short checkcarryd;
			curod = __builtin_addcs(curod, curod, static_cast<unsigned short>(carryd), &checkcarryd);
			static_cast<void>(checkcarryd);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curma, nullptr), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curmb, nullptr), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
			unsigned char checkcarryc{_addcarry_u16(_addcarry_u64(0, curmc, curmc, nullptr), curoc, curoc, &curoc)};
			static_cast<void>(checkcarryc);
			unsigned char checkcarryd{_addcarry_u16(_addcarry_u64(0, curmd, curmd, nullptr), curod, curod, &curod)};
			static_cast<void>(checkcarryd);
#elif defined(_M_IX86)
			std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(0, curmhia, curmhia, nullptr), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(0, curmhib, curmhib, nullptr), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
			std::uint_least32_t curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			unsigned char checkcarryc{_addcarry_u16(_addcarry_u32(0, curmhic, curmhic, nullptr), curoc, curoc, &curoc)};
			static_cast<void>(checkcarryc);
			std::uint_least32_t curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
			unsigned char checkcarryd{_addcarry_u16(_addcarry_u32(0, curmhid, curmhid, nullptr), curod, curod, &curod)};
			static_cast<void>(checkcarryd);
#else
			std::uint_least64_t curmtmpa{curma}, curmtmpb{curmb}, curmtmpc{curmc}, curmtmpd{curmd};
			curma += curma;
			curoa += curoa;
			curoa += curma < curmtmpa;
			curmb += curmb;
			curob += curob;
			curob += curmb < curmtmpb;
			curmc += curmc;
			curoc += curoc;
			curoc += curmc < curmtmpc;
			curmd += curmd;
			curod += curod;
			curod += curmd < curmtmpd;
#endif
			curea = curoa;
			cureb = curob;
			curec = curoc;
			cured = curod;
		}
		curpa >>= 16 - 1;
		curpb >>= 16 - 1;
		curpc >>= 16 - 1;
		curpd >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curqa{static_cast<std::uint_least64_t>(curpa)};// sign-extend
		std::uint_least64_t curqb{static_cast<std::uint_least64_t>(curpb)};
		std::uint_least64_t curqc{static_cast<std::uint_least64_t>(curpc)};
		std::uint_least64_t curqd{static_cast<std::uint_least64_t>(curpd)};
#else
		std::uint_least32_t curqa{static_cast<std::uint_least32_t>(curpa)};// sign-extend
		std::uint_least32_t curqb{static_cast<std::uint_least32_t>(curpb)};
		std::uint_least32_t curqc{static_cast<std::uint_least32_t>(curpc)};
		std::uint_least32_t curqd{static_cast<std::uint_least32_t>(curpd)};
#endif
		if constexpr(issignmode){
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
			std::uint_least16_t curoc{static_cast<std::uint_least16_t>(curec)};
			std::uint_least16_t curod{static_cast<std::uint_least16_t>(cured)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			__builtin_addcll(curma, curqa, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			__builtin_addcl(curma, curqa, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			__builtin_addcl(curmhia, curqa, 0, &carrya);
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, static_cast<unsigned short>(curqa), static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			__builtin_addcll(curmb, curqb, 0, &carryb);
#else
			unsigned long carryb;
			__builtin_addcl(curmb, curqb, 0, &carryb);
#endif
#else
			unsigned long carryb;
			std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			__builtin_addcl(curmhib, curqb, 0, &carryb);
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, static_cast<unsigned short>(curqb), static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryc;
			__builtin_addcll(curmc, curqc, 0, &carryc);
#else
			unsigned long carryc;
			__builtin_addcl(curmc, curqc, 0, &carryc);
#endif
#else
			unsigned long carryc;
			std::uint_least32_t curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			__builtin_addcl(curmhic, curqc, 0, &carryc);
#endif
			unsigned short checkcarryc;
			curoc = __builtin_addcs(curoc, static_cast<unsigned short>(curqc), static_cast<unsigned short>(carryc), &checkcarryc);
			static_cast<void>(checkcarryc);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryd;
			__builtin_addcll(curmd, curqd, 0, &carryd);
#else
			unsigned long carryd;
			__builtin_addcl(curmd, curqd, 0, &carryd);
#endif
#else
			unsigned long carryd;
			std::uint_least32_t curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
			__builtin_addcl(curmhid, curqd, 0, &carryd);
#endif
			unsigned short checkcarryd;
			curod = __builtin_addcs(curod, static_cast<unsigned short>(curqd), static_cast<unsigned short>(carryd), &checkcarryd);
			static_cast<void>(checkcarryd);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curqa, nullptr), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curqb, nullptr), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
			unsigned char checkcarryc{_addcarry_u16(_addcarry_u64(0, curmc, curqc, nullptr), curoc, static_cast<std::uint_least16_t>(curqc), &curoc)};
			static_cast<void>(checkcarryc);
			unsigned char checkcarryd{_addcarry_u16(_addcarry_u64(0, curmd, curqd, nullptr), curod, static_cast<std::uint_least16_t>(curqd), &curod)};
			static_cast<void>(checkcarryd);
#elif defined(_M_IX86)
			std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(0, curmhia, curqa, nullptr), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(0, curmhib, curqb, nullptr), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
			std::uint_least32_t curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			unsigned char checkcarryc{_addcarry_u16(_addcarry_u32(0, curmhic, curqc, nullptr), curoc, static_cast<std::uint_least16_t>(curqc), &curoc)};
			static_cast<void>(checkcarryc);
			std::uint_least32_t curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
			unsigned char checkcarryd{_addcarry_u16(_addcarry_u32(0, curmhid, curqd, nullptr), curod, static_cast<std::uint_least16_t>(curqd), &curod)};
			static_cast<void>(checkcarryd);
#elif 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
			curma += curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curma < curqa;
			curmb += curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmb < curqb;
			curmc += curqc;
			curoc += static_cast<std::uint_least16_t>(curqc);
			curoc += curmc < curqc;
			curmd += curqd;
			curod += static_cast<std::uint_least16_t>(curqd);
			curod += curmd < curqd;
#else
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			std::uint_least32_t curmloc{static_cast<std::uint_least32_t>(curmc & 0xFFFFFFFFu)}, curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			std::uint_least32_t curmlod{static_cast<std::uint_least32_t>(curmd & 0xFFFFFFFFu)}, curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
			curmloa += curqa;
			curmhia += curqa;
			curmhia += curmloa < curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curmhia < curqa;
			curmlob += curqb;
			curmhib += curqb;
			curmhib += curmlob < curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmhib < curqb;
			curmloc += curqc;
			curmhic += curqc;
			curmhic += curmloc < curqc;
			curoc += static_cast<std::uint_least16_t>(curqc);
			curoc += curmhic < curqc;
			curmlod += curqd;
			curmhid += curqd;
			curmhid += curmlod < curqd;
			curod += static_cast<std::uint_least16_t>(curqd);
			curod += curmhid < curqd;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmc[2]{curmloc, curmhic};
			curmc = *reinterpret_cast<std::uint_least64_t *>(acurmc);// recompose
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmd[2]{curmlod, curmhid};
			curmd = *reinterpret_cast<std::uint_least64_t *>(acurmd);// recompose
#endif
			curea = curoa;
			cureb = curob;
			curec = curoc;
			cured = curod;
		}
		curea ^= static_cast<U>(curqa);
		cureb ^= static_cast<U>(curqb);
		curec ^= static_cast<U>(curqc);
		cured ^= static_cast<U>(curqd);
	}else if constexpr(isabsvalue && !issignmode && isfltpmode){// one-register filtering
		std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
		std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
		std::uint_least16_t curoc{static_cast<std::uint_least16_t>(curec)};
		std::uint_least16_t curod{static_cast<std::uint_least16_t>(cured)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
		static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
		unsigned long long carrya;
		__builtin_addcll(curma, curma, 0, &carrya);
#else
		static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrya;
		__builtin_addcl(curma, curma, 0, &carrya);
#endif
#else
		static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrya;
		std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		__builtin_addcl(curmhia, curmhia, 0, &carrya);
#endif
		unsigned short checkcarrya;
		curoa = __builtin_addcs(curoa, curoa, static_cast<unsigned short>(carrya), &checkcarrya);
		static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		unsigned long long carryb;
		__builtin_addcll(curmb, curmb, 0, &carryb);
#else
		unsigned long carryb;
		__builtin_addcl(curmb, curmb, 0, &carryb);
#endif
#else
		unsigned long carryb;
		std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		__builtin_addcl(curmhib, curmhib, 0, &carryb);
#endif
		unsigned short checkcarryb;
		curob = __builtin_addcs(curob, curob, static_cast<unsigned short>(carryb), &checkcarryb);
		static_cast<void>(checkcarryb);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		unsigned long long carryc;
		__builtin_addcll(curmc, curmc, 0, &carryc);
#else
		unsigned long carryc;
		__builtin_addcl(curmc, curmc, 0, &carryc);
#endif
#else
		unsigned long carryc;
		std::uint_least32_t curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
		__builtin_addcl(curmhic, curmhic, 0, &carryc);
#endif
		unsigned short checkcarryc;
		curoc = __builtin_addcs(curoc, curoc, static_cast<unsigned short>(carryc), &checkcarryc);
		static_cast<void>(checkcarryc);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		unsigned long long carryd;
		__builtin_addcll(curmd, curmd, 0, &carryd);
#else
		unsigned long carryd;
		__builtin_addcl(curmd, curmd, 0, &carryd);
#endif
#else
		unsigned long carryd;
		std::uint_least32_t curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
		__builtin_addcl(curmhid, curmhid, 0, &carryd);
#endif
		unsigned short checkcarryd;
		curod = __builtin_addcs(curod, curod, static_cast<unsigned short>(carryd), &checkcarryd);
		static_cast<void>(checkcarryd);
#elif defined(_M_X64)
		unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curma, nullptr), curoa, curoa, &curoa)};
		static_cast<void>(checkcarrya);
		unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curmb, nullptr), curob, curob, &curob)};
		static_cast<void>(checkcarryb);
		unsigned char checkcarryc{_addcarry_u16(_addcarry_u64(0, curmc, curmc, nullptr), curoc, curoc, &curoc)};
		static_cast<void>(checkcarryc);
		unsigned char checkcarryd{_addcarry_u16(_addcarry_u64(0, curmd, curmd, nullptr), curod, curod, &curod)};
		static_cast<void>(checkcarryd);
#elif defined(_M_IX86)
		std::uint_least32_t curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(0, curmhia, curmhia, nullptr), curoa, curoa, &curoa)};
		static_cast<void>(checkcarrya);
		std::uint_least32_t curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(0, curmhib, curmhib, nullptr), curob, curob, &curob)};
		static_cast<void>(checkcarryb);
		std::uint_least32_t curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
		unsigned char checkcarryc{_addcarry_u16(_addcarry_u32(0, curmhic, curmhic, nullptr), curoc, curoc, &curoc)};
		static_cast<void>(checkcarryc);
		std::uint_least32_t curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
		unsigned char checkcarryd{_addcarry_u16(_addcarry_u32(0, curmhid, curmhid, nullptr), curod, curod, &curod)};
		static_cast<void>(checkcarryd);
#else
		std::uint_least64_t curmtmpa{curma}, curmtmpb{curmb}, curmtmpc{curmc}, curmtmpd{curmd};
		curma += curma;
		curoa += curoa;
		curoa += curma < curmtmpa;
		curmb += curmb;
		curob += curob;
		curob += curmb < curmtmpb;
		curmc += curmc;
		curoc += curoc;
		curoc += curmc < curmtmpc;
		curmd += curmd;
		curod += curod;
		curod += curmd < curmtmpd;
#endif
		curea = curoa;
		cureb = curob;
		curec = curoc;
		cured = curod;
	}
	return{static_cast<std::size_t>(curea & 0xFFu), static_cast<std::size_t>(cureb & 0xFFu), static_cast<std::size_t>(curec & 0xFFu), static_cast<std::size_t>(cured & 0xFFu)};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::tuple<std::size_t, std::size_t, std::size_t, std::size_t>> filterbelowtop8(T cura, T curb, T curc, T curd)noexcept{
	// Use the function above.
	return{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(
		cura.mantissa, static_cast<U>(cura.signexponent),
		curb.mantissa, static_cast<U>(curb.signexponent),
		curc.mantissa, static_cast<U>(curc.signexponent),
		curd.mantissa, static_cast<U>(curd.signexponent))};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::size_t> filtershift8(U cur, unsigned shift)noexcept{
	// Filtering is simplified if possible.
	// This should never filter the top part for non-absolute floating-point inputs.
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curp{static_cast<std::make_signed_t<T>>(cur)};
		if constexpr(isabsvalue && !issignmode){
			T curo{static_cast<T>(cur)};
			curo += curo;
			cur = curo;
		}
		curp >>= CHAR_BIT * sizeof(T) - 1;
		U curq{static_cast<T>(curp)};
		if constexpr(issignmode){
			T curo{static_cast<T>(cur)};
			curo += static_cast<T>(curq);
			cur = curo;
		}
		cur ^= curq;
	}else if constexpr(isabsvalue && !issignmode && isfltpmode){// one-register filtering
		cur = rotateleftportable<1>(static_cast<T>(cur));
	}
	cur >>= shift;
	return{static_cast<std::size_t>(cur & 0xFFu)};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::size_t> filtershift8(std::uint_least64_t curm, U cure, unsigned shift)noexcept{
	// Filtering is simplified if possible.
	// This should never filter the top 16 bits.
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curp{static_cast<std::int_least16_t>(cure)};
		if constexpr(isabsvalue && !issignmode) curm += curm;
		curp >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curq{static_cast<std::uint_least64_t>(curp)};// sign-extend
#else
		std::uint_least32_t curq{static_cast<std::uint_least32_t>(curp)};// sign-extend
#endif
		if constexpr(issignmode){
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
			curm += curq;
#elif (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymid, checkcarry;
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo = __builtin_addcl(curmlo, curq, 0, &carrymid);
			curmhi = __builtin_addcl(curmhi, curq, carrymid, &checkcarry);
			static_cast<void>(checkcarry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#elif defined(_M_IX86)
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			unsigned char checkcarry{_addcarry_u32(_addcarry_u32(0, curmlo, curq, &curmlo), curmhi, curq, &curmhi)};
			static_cast<void>(checkcarry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#else
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo += curq;
			curmhi += curq;
			curmhi += curmlo < curq;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
		}
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		curm ^= curq;
#else
		std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
		curmlo ^= curq;
		curmhi ^= curq;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
		curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
	}else if constexpr(isabsvalue && !issignmode && isfltpmode){// one-register filtering
		std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
		static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
		unsigned short carrysign;
		curo = __builtin_addcs(curo, curo, 0, &carrysign);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
		unsigned long long checkcarry;
		curm = __builtin_addcll(curm, curm, static_cast<unsigned long long>(carrysign), &checkcarry);
#else
		static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long checkcarry;
		curm = __builtin_addcl(curm, curm, static_cast<unsigned long>(carrysign), &checkcarry);
#endif
		static_cast<void>(checkcarry);
#else
		static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrymid, checkcarry;
		std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
		curmlo = __builtin_addcl(curmlo, curmlo, static_cast<unsigned long>(carrysign), &carrymid);
		curmhi = __builtin_addcl(curmhi, curmhi, carrymid, &checkcarry);
		static_cast<void>(checkcarry);
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
		curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
#elif defined(_M_X64)
		unsigned char checkcarry{_addcarry_u64(_addcarry_u16(0, curo, curo, &curo), curm, curm, &curm)};
		static_cast<void>(checkcarry);
#elif defined(_M_IX86)
		std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
		unsigned char checkcarry{_addcarry_u32(_addcarry_u32(_addcarry_u16(0, curo, curo, &curo), curmlo, curmlo, &curmlo), curmhi, curmhi, &curmhi)};
		static_cast<void>(checkcarry);
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
		curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#else
		std::uint_least16_t curotmp{curo};
		curo += curo;
		curm += curm;
		curm += curo < curotmp;
#endif
	}
	curm >>= shift;
	return{static_cast<std::size_t>(curm & 0xFFu)};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::size_t> filtershift8(T cur, unsigned shift)noexcept{
	// Use the function above.
	return{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(
		cur.mantissa, static_cast<U>(cur.signexponent),
		shift)};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::pair<std::size_t, std::size_t>> filtershift8(U cura, U curb, unsigned shift)noexcept{
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		if constexpr(isabsvalue && !issignmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		if constexpr(isabsvalue && !issignmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			cura = curoa;
			curb = curob;
		}
		cura ^= curqa;
		curb ^= curqb;
	}else if constexpr(isabsvalue && !issignmode && isfltpmode){// one-register filtering
		cura = rotateleftportable<1>(static_cast<T>(cura));
		curb = rotateleftportable<1>(static_cast<T>(curb));
	}
	cura >>= shift;
	curb >>= shift;
	return{static_cast<std::size_t>(cura & 0xFFu), static_cast<std::size_t>(curb & 0xFFu)};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
		std::is_same_v<longdoubletest96, T> ||
		std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::pair<std::size_t, std::size_t>> filtershift8(std::uint_least64_t curma, U curea, std::uint_least64_t curmb, U cureb, unsigned shift)noexcept{
	// Filtering is simplified if possible.
	// This should never filter the top 16 bits.
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curpa{static_cast<std::int_least16_t>(curea)};
		std::int_least16_t curpb{static_cast<std::int_least16_t>(cureb)};
		if constexpr(isabsvalue && !issignmode){
			curma += curma;
			curmb += curmb;
		}
		curpa >>= 16 - 1;
		curpb >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curqa{static_cast<std::uint_least64_t>(curpa)};// sign-extend
		std::uint_least64_t curqb{static_cast<std::uint_least64_t>(curpb)};
#else
		std::uint_least32_t curqa{static_cast<std::uint_least32_t>(curpa)};// sign-extend
		std::uint_least32_t curqb{static_cast<std::uint_least32_t>(curpb)};
#endif
		if constexpr(issignmode){
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
			curma += curqa;
			curmb += curqb;
#elif (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymida, checkcarrya;
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa = __builtin_addcl(curmloa, curqa, 0, &carrymida);
			curmhia = __builtin_addcl(curmhia, curqa, carrymida, &checkcarrya);
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			unsigned long carrymidb, checkcarryb;
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob = __builtin_addcl(curmlob, curqb, 0, &carrymidb);
			curmhib = __builtin_addcl(curmhib, curqb, carrymidb, &checkcarryb);
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#elif defined(_M_IX86)
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u32(_addcarry_u32(0, curmloa, curqa, &curmloa), curmhia, curqa, &curmhia)};
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u32(_addcarry_u32(0, curmlob, curqb, &curmlob), curmhib, curqb, &curmhib)};
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#else
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmloa += curqa;
			curmhia += curqa;
			curmhia += curmloa < curqa;
			curmlob += curqb;
			curmhib += curqb;
			curmhib += curmlob < curqb;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
		}
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		curma ^= curqa;
		curmb ^= curqb;
#else
		std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		curmloa ^= curqa;
		curmhia ^= curqa;
		curmlob ^= curqb;
		curmhib ^= curqb;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
		curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
		curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
	}else if constexpr(isabsvalue && !issignmode && isfltpmode){// one-register filtering
		std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
		std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
		static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
		unsigned short carrysigna;
		curoa = __builtin_addcs(curoa, curoa, 0, &carrysigna);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
		unsigned long long checkcarrya;
		curma = __builtin_addcll(curma, curma, static_cast<unsigned long long>(carrysigna), &checkcarrya);
#else
		static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long checkcarrya;
		curma = __builtin_addcl(curma, curma, static_cast<unsigned long>(carrysigna), &checkcarrya);
#endif
		static_cast<void>(checkcarrya);
#else
		static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrymida, checkcarrya;
		std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		curmloa = __builtin_addcl(curmloa, curmloa, static_cast<unsigned long>(carrysigna), &carrymida);
		curmhia = __builtin_addcl(curmhia, curmhia, carrymida, &checkcarrya);
		static_cast<void>(checkcarrya);
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
		curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
#endif
		unsigned short carrysignb;
		curob = __builtin_addcs(curob, curob, 0, &carrysignb);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		unsigned long long checkcarryb;
		curmb = __builtin_addcll(curmb, curmb, static_cast<unsigned long long>(carrysignb), &checkcarryb);
#else
		unsigned long checkcarryb;
		curmb = __builtin_addcl(curmb, curmb, static_cast<unsigned long>(carrysignb), &checkcarryb);
#endif
		static_cast<void>(checkcarryb);
#else
		unsigned long carrymidb, checkcarryb;
		std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		curmlob = __builtin_addcl(curmlob, curmlob, static_cast<unsigned long>(carrysignb), &carrymidb);
		curmhib = __builtin_addcl(curmhib, curmhib, carrymidb, &checkcarryb);
		static_cast<void>(checkcarryb);
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
		curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
#elif defined(_M_X64)
		unsigned char checkcarrya{_addcarry_u64(_addcarry_u16(0, curoa, curoa, &curoa), curma, curma, &curma)};
		static_cast<void>(checkcarrya);
		unsigned char checkcarryb{_addcarry_u64(_addcarry_u16(0, curob, curob, &curob), curmb, curmb, &curmb)};
		static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
		std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		unsigned char checkcarrya{_addcarry_u32(_addcarry_u32(_addcarry_u16(0, curoa, curoa, &curoa), curmloa, curmloa, &curmloa), curmhia, curmhia, &curmhia)};
		static_cast<void>(checkcarrya);
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
		curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
		std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		unsigned char checkcarryb{_addcarry_u32(_addcarry_u32(_addcarry_u16(0, curob, curob, &curob), curmlob, curmlob, &curmlob), curmhib, curmhib, &curmhib)};
		static_cast<void>(checkcarryb);
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
		curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#else
		std::uint_least16_t curotmpa{curoa}, curotmpb{curob};
		curoa += curoa;
		curma += curma;
		curma += curoa < curotmpa;
		curob += curob;
		curmb += curmb;
		curmb += curob < curotmpb;
#endif
	}
	curma >>= shift;
	curmb >>= shift;
	return{static_cast<std::size_t>(curma & 0xFFu), static_cast<std::size_t>(curmb & 0xFFu)};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::pair<std::size_t, std::size_t>> filtershift8(T cura, T curb, unsigned shift)noexcept{
	// Use the function above.
	return{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(
		cura.mantissa, static_cast<U>(cura.signexponent),
		curb.mantissa, static_cast<U>(curb.signexponent),
		shift)};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::tuple<std::size_t, std::size_t, std::size_t, std::size_t>> filtershift8(U cura, U curb, U curc, U curd, unsigned shift)noexcept{
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		if constexpr(isabsvalue && !issignmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		if constexpr(isabsvalue && !issignmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		std::make_signed_t<T> curpc{static_cast<std::make_signed_t<T>>(curc)};
		if constexpr(isabsvalue && !issignmode){
			T curoc{static_cast<T>(curc)};
			curoc += curoc;
			curc = curoc;
		}
		curpc >>= CHAR_BIT * sizeof(T) - 1;
		U curqc{static_cast<T>(curpc)};
		std::make_signed_t<T> curpd{static_cast<std::make_signed_t<T>>(curd)};
		if constexpr(isabsvalue && !issignmode){
			T curod{static_cast<T>(curd)};
			curod += curod;
			curd = curod;
		}
		curpd >>= CHAR_BIT * sizeof(T) - 1;
		U curqd{static_cast<T>(curpd)};
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			T curoc{static_cast<T>(curc)};
			T curod{static_cast<T>(curd)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			curoc += static_cast<T>(curqc);
			curod += static_cast<T>(curqd);
			cura = curoa;
			curb = curob;
			curc = curoc;
			curd = curod;
		}
		cura ^= curqa;
		curb ^= curqb;
		curc ^= curqc;
		curd ^= curqd;
	}else if constexpr(isabsvalue && !issignmode && isfltpmode){// one-register filtering
		cura = rotateleftportable<1>(static_cast<T>(cura));
		curb = rotateleftportable<1>(static_cast<T>(curb));
		curc = rotateleftportable<1>(static_cast<T>(curc));
		curd = rotateleftportable<1>(static_cast<T>(curd));
	}
	cura >>= shift;
	curb >>= shift;
	curc >>= shift;
	curd >>= shift;
	return{static_cast<std::size_t>(cura & 0xFFu), static_cast<std::size_t>(curb & 0xFFu), static_cast<std::size_t>(curc & 0xFFu), static_cast<std::size_t>(curd & 0xFFu)};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::tuple<std::size_t, std::size_t, std::size_t, std::size_t>> filtershift8(std::uint_least64_t curma, U curea, std::uint_least64_t curmb, U cureb, std::uint_least64_t curmc, U curec, std::uint_least64_t curmd, U cured, unsigned shift)noexcept{
	// Filtering is simplified if possible.
	// This should never filter the top 16 bits.
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curpa{static_cast<std::int_least16_t>(curea)};
		std::int_least16_t curpb{static_cast<std::int_least16_t>(cureb)};
		std::int_least16_t curpc{static_cast<std::int_least16_t>(curec)};
		std::int_least16_t curpd{static_cast<std::int_least16_t>(cured)};
		if constexpr(isabsvalue && !issignmode){
			curma += curma;
			curmb += curmb;
			curmc += curmc;
			curmd += curmd;
		}
		curpa >>= 16 - 1;
		curpb >>= 16 - 1;
		curpc >>= 16 - 1;
		curpd >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curqa{static_cast<std::uint_least64_t>(curpa)};// sign-extend
		std::uint_least64_t curqb{static_cast<std::uint_least64_t>(curpb)};
		std::uint_least64_t curqc{static_cast<std::uint_least64_t>(curpc)};
		std::uint_least64_t curqd{static_cast<std::uint_least64_t>(curpd)};
#else
		std::uint_least32_t curqa{static_cast<std::uint_least32_t>(curpa)};// sign-extend
		std::uint_least32_t curqb{static_cast<std::uint_least32_t>(curpb)};
		std::uint_least32_t curqc{static_cast<std::uint_least32_t>(curpc)};
		std::uint_least32_t curqd{static_cast<std::uint_least32_t>(curpd)};
#endif
		if constexpr(issignmode){
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
			curma += curqa;
			curmb += curqb;
			curmc += curqc;
			curmd += curqd;
#elif (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymida, checkcarrya;
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa = __builtin_addcl(curmloa, curqa, 0, &carrymida);
			curmhia = __builtin_addcl(curmhia, curqa, carrymida, &checkcarrya);
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			unsigned long carrymidb, checkcarryb;
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob = __builtin_addcl(curmlob, curqb, 0, &carrymidb);
			curmhib = __builtin_addcl(curmhib, curqb, carrymidb, &checkcarryb);
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymidc, checkcarryc;
			std::uint_least32_t curmloc{static_cast<std::uint_least32_t>(curmc & 0xFFFFFFFFu)}, curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			curmloc = __builtin_addcl(curmloc, curqc, 0, &carrymidc);
			curmhic = __builtin_addcl(curmhic, curqc, carrymidc, &checkcarryc);
			static_cast<void>(checkcarryc);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmc[2]{curmloc, curmhic};
			curmc = *reinterpret_cast<std::uint_least64_t *>(acurmc);// recompose
			unsigned long carrymidd, checkcarryd;
			std::uint_least32_t curmlod{static_cast<std::uint_least32_t>(curmd & 0xFFFFFFFFu)}, curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
			curmlod = __builtin_addcl(curmlod, curqd, 0, &carrymidd);
			curmhid = __builtin_addcl(curmhid, curqd, carrymidd, &checkcarryd);
			static_cast<void>(checkcarryd);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmd[2]{curmlod, curmhid};
			curmd = *reinterpret_cast<std::uint_least64_t *>(acurmd);// recompose
#elif defined(_M_IX86)
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u32(_addcarry_u32(0, curmloa, curqa, &curmloa), curmhia, curqa, &curmhia)};
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u32(_addcarry_u32(0, curmlob, curqb, &curmlob), curmhib, curqb, &curmhib)};
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
			std::uint_least32_t curmloc{static_cast<std::uint_least32_t>(curmc & 0xFFFFFFFFu)}, curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			unsigned char checkcarryc{_addcarry_u32(_addcarry_u32(0, curmloc, curqc, &curmloc), curmhic, curqc, &curmhic)};
			static_cast<void>(checkcarryc);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmc[2]{curmloc, curmhic};
			curmc = *reinterpret_cast<std::uint_least64_t *>(acurmc);// recompose
			std::uint_least32_t curmlod{static_cast<std::uint_least32_t>(curmd & 0xFFFFFFFFu)}, curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
			unsigned char checkcarryd{_addcarry_u32(_addcarry_u32(0, curmlod, curqd, &curmlod), curmhid, curqd, &curmhid)};
			static_cast<void>(checkcarryd);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmd[2]{curmlod, curmhid};
			curmd = *reinterpret_cast<std::uint_least64_t *>(acurmd);// recompose
#else
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			std::uint_least32_t curmloc{static_cast<std::uint_least32_t>(curmc & 0xFFFFFFFFu)}, curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			std::uint_least32_t curmlod{static_cast<std::uint_least32_t>(curmd & 0xFFFFFFFFu)}, curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
			curmloa += curqa;
			curmhia += curqa;
			curmhia += curmloa < curqa;
			curmlob += curqb;
			curmhib += curqb;
			curmhib += curmlob < curqb;
			curmloc += curqc;
			curmhic += curqc;
			curmhic += curmloc < curqc;
			curmlod += curqd;
			curmhid += curqd;
			curmhid += curmlod < curqd;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmc[2]{curmloc, curmhic};
			curmc = *reinterpret_cast<std::uint_least64_t *>(acurmc);// recompose
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmd[2]{curmlod, curmhid};
			curmd = *reinterpret_cast<std::uint_least64_t *>(acurmd);// recompose
#endif
		}
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		curma ^= curqa;
		curmb ^= curqb;
		curmc ^= curqc;
		curmd ^= curqd;
#else
		std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		std::uint_least32_t curmloc{static_cast<std::uint_least32_t>(curmc & 0xFFFFFFFFu)}, curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
		std::uint_least32_t curmlod{static_cast<std::uint_least32_t>(curmd & 0xFFFFFFFFu)}, curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
		curmloa ^= curqa;
		curmhia ^= curqa;
		curmlob ^= curqb;
		curmhib ^= curqb;
		curmloc ^= curqc;
		curmhic ^= curqc;
		curmlod ^= curqd;
		curmhid ^= curqd;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
		curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
		curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmc[2]{curmloc, curmhic};
		curmc = *reinterpret_cast<std::uint_least64_t *>(acurmc);// recompose
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmd[2]{curmlod, curmhid};
		curmd = *reinterpret_cast<std::uint_least64_t *>(acurmd);// recompose
#endif
	}else if constexpr(isabsvalue && !issignmode && isfltpmode){// one-register filtering
		std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
		std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
		std::uint_least16_t curoc{static_cast<std::uint_least16_t>(curec)};
		std::uint_least16_t curod{static_cast<std::uint_least16_t>(cured)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
		static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
		unsigned short carrysigna;
		curoa = __builtin_addcs(curoa, curoa, 0, &carrysigna);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
		unsigned long long checkcarrya;
		curma = __builtin_addcll(curma, curma, static_cast<unsigned long long>(carrysigna), &checkcarrya);
#else
		static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long checkcarrya;
		curma = __builtin_addcl(curma, curma, static_cast<unsigned long>(carrysigna), &checkcarrya);
#endif
		static_cast<void>(checkcarrya);
#else
		static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
		unsigned long carrymida, checkcarrya;
		std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		curmloa = __builtin_addcl(curmloa, curmloa, static_cast<unsigned long>(carrysigna), &carrymida);
		curmhia = __builtin_addcl(curmhia, curmhia, carrymida, &checkcarrya);
		static_cast<void>(checkcarrya);
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
		curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
#endif
		unsigned short carrysignb;
		curob = __builtin_addcs(curob, curob, 0, &carrysignb);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		unsigned long long checkcarryb;
		curmb = __builtin_addcll(curmb, curmb, static_cast<unsigned long long>(carrysignb), &checkcarryb);
#else
		unsigned long checkcarryb;
		curmb = __builtin_addcl(curmb, curmb, static_cast<unsigned long>(carrysignb), &checkcarryb);
#endif
		static_cast<void>(checkcarryb);
#else
		unsigned long carrymidb, checkcarryb;
		std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		curmlob = __builtin_addcl(curmlob, curmlob, static_cast<unsigned long>(carrysignb), &carrymidb);
		curmhib = __builtin_addcl(curmhib, curmhib, carrymidb, &checkcarryb);
		static_cast<void>(checkcarryb);
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
		curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
		unsigned short carrysignc;
		curoc = __builtin_addcs(curoc, curoc, 0, &carrysignc);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		unsigned long long checkcarryc;
		curmc = __builtin_addcll(curmc, curmc, static_cast<unsigned long long>(carrysignc), &checkcarryc);
#else
		unsigned long checkcarryc;
		curmc = __builtin_addcl(curmc, curmc, static_cast<unsigned long>(carrysignc), &checkcarryc);
#endif
		static_cast<void>(checkcarryc);
#else
		unsigned long carrymidc, checkcarryc;
		std::uint_least32_t curmloc{static_cast<std::uint_least32_t>(curmc & 0xFFFFFFFFu)}, curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
		curmloc = __builtin_addcl(curmloc, curmloc, static_cast<unsigned long>(carrysignc), &carrymidc);
		curmhic = __builtin_addcl(curmhic, curmhic, carrymidc, &checkcarryc);
		static_cast<void>(checkcarryc);
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmc[2]{curmloc, curmhic};
		curmc = *reinterpret_cast<std::uint_least64_t *>(acurmc);// recompose
#endif
		unsigned short carrysignd;
		curod = __builtin_addcs(curod, curod, 0, &carrysignd);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		unsigned long long checkcarryd;
		curmd = __builtin_addcll(curmd, curmd, static_cast<unsigned long long>(carrysignd), &checkcarryd);
#else
		unsigned long checkcarryd;
		curmd = __builtin_addcl(curmd, curmd, static_cast<unsigned long>(carrysignd), &checkcarryd);
#endif
		static_cast<void>(checkcarryd);
#else
		unsigned long carrymidd, checkcarryd;
		std::uint_least32_t curmlod{static_cast<std::uint_least32_t>(curmd & 0xFFFFFFFFu)}, curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
		curmlod = __builtin_addcl(curmlod, curmlod, static_cast<unsigned long>(carrysignd), &carrymidd);
		curmhid = __builtin_addcl(curmhid, curmhid, carrymidd, &checkcarryd);
		static_cast<void>(checkcarryd);
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmd[2]{curmlod, curmhid};
		curmd = *reinterpret_cast<std::uint_least64_t *>(acurmd);// recompose
#endif
#elif defined(_M_X64)
		unsigned char checkcarrya{_addcarry_u64(_addcarry_u16(0, curoa, curoa, &curoa), curma, curma, &curma)};
		static_cast<void>(checkcarrya);
		unsigned char checkcarryb{_addcarry_u64(_addcarry_u16(0, curob, curob, &curob), curmb, curmb, &curmb)};
		static_cast<void>(checkcarryb);
		unsigned char checkcarryc{_addcarry_u64(_addcarry_u16(0, curoc, curoc, &curoc), curmc, curmc, &curmc)};
		static_cast<void>(checkcarryc);
		unsigned char checkcarryd{_addcarry_u64(_addcarry_u16(0, curod, curod, &curod), curmd, curmd, &curmd)};
		static_cast<void>(checkcarryd);
#elif defined(_M_IX86)
		std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		unsigned char checkcarrya{_addcarry_u32(_addcarry_u32(_addcarry_u16(0, curoa, curoa, &curoa), curmloa, curmloa, &curmloa), curmhia, curmhia, &curmhia)};
		static_cast<void>(checkcarrya);
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
		curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
		std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		unsigned char checkcarryb{_addcarry_u32(_addcarry_u32(_addcarry_u16(0, curob, curob, &curob), curmlob, curmlob, &curmlob), curmhib, curmhib, &curmhib)};
		static_cast<void>(checkcarryb);
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
		curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
		std::uint_least32_t curmloc{static_cast<std::uint_least32_t>(curmc & 0xFFFFFFFFu)}, curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
		unsigned char checkcarryc{_addcarry_u32(_addcarry_u32(_addcarry_u16(0, curoc, curoc, &curoc), curmloc, curmloc, &curmloc), curmhic, curmhic, &curmhic)};
		static_cast<void>(checkcarryc);
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmc[2]{curmloc, curmhic};
		curmc = *reinterpret_cast<std::uint_least64_t *>(acurmc);// recompose
		std::uint_least32_t curmlod{static_cast<std::uint_least32_t>(curmd & 0xFFFFFFFFu)}, curmhid{static_cast<std::uint_least32_t>(curmd >> 32)};// decompose
		unsigned char checkcarryd{_addcarry_u32(_addcarry_u32(_addcarry_u16(0, curod, curod, &curod), curmlod, curmlod, &curmlod), curmhid, curmhid, &curmhid)};
		static_cast<void>(checkcarryd);
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmd[2]{curmlod, curmhid};
		curmd = *reinterpret_cast<std::uint_least64_t *>(acurmd);// recompose
#else
		std::uint_least16_t curotmpa{curoa}, curotmpb{curob}, curotmpc{curoc}, curotmpd{curod};
		curoa += curoa;
		curma += curma;
		curma += curoa < curotmpa;
		curob += curob;
		curmb += curmb;
		curmb += curob < curotmpb;
		curoc += curoc;
		curmc += curmc;
		curmc += curoc < curotmpc;
		curod += curod;
		curmd += curmd;
		curmd += curod < curotmpd;
#endif
	}
	curma >>= shift;
	curmb >>= shift;
	curmc >>= shift;
	curmd >>= shift;
	return{static_cast<std::size_t>(curma & 0xFFu), static_cast<std::size_t>(curmb & 0xFFu),static_cast<std::size_t>(curmc & 0xFFu), static_cast<std::size_t>(curmd & 0xFFu)};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U) &&
	8 < CHAR_BIT * sizeof(U),
	std::tuple<std::size_t, std::size_t, std::size_t, std::size_t>> filtershift8(T cura, T curb, T curc, T curd, unsigned shift)noexcept{
	// Use the function above.
	return{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(
		cura.mantissa, static_cast<U>(cura.signexponent),
		curb.mantissa, static_cast<U>(curb.signexponent),
		curc.mantissa, static_cast<U>(curc.signexponent),
		curd.mantissa, static_cast<U>(curd.signexponent),
		shift)};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(std::uint_least64_t &curm, U &cure)noexcept{
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curp{static_cast<std::int_least16_t>(cure)};
		if constexpr(isfltpmode){
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
			curo += curo;
			cure = curo;
		}else if constexpr(!issignmode){
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carry;
			curm = __builtin_addcll(curm, curm, 0, &carry);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			curm = __builtin_addcl(curm, curm, 0, &carry);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymid, carry;
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo = __builtin_addcl(curmlo, curmlo, 0, &carrymid);
			curmhi = __builtin_addcl(curmhi, curmhi, carrymid, &carry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
			unsigned short checkcarry;
			curo = __builtin_addcs(curo, curo, static_cast<unsigned short>(carry), &checkcarry);
			static_cast<void>(checkcarry);
#elif defined(_M_X64)
			unsigned char checkcarry{_addcarry_u16(_addcarry_u64(0, curm, curm, &curm), curo, curo, &curo)};
			static_cast<void>(checkcarry);
#elif defined(_M_IX86)
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			unsigned char checkcarry{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlo, curmlo, &curmlo), curmhi, curmhi, &curmhi), curo, curo, &curo)};
			static_cast<void>(checkcarry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#else
			std::uint_least64_t curmtmp{curm};
			curm += curm;
			curo += static_cast<std::uint_least16_t>(curo);
			curo += curm < curmtmp;
#endif
			cure = curo;
		}
		curp >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curq{static_cast<std::uint_least64_t>(curp)};// sign-extend
#else
		std::uint_least32_t curq{static_cast<std::uint_least32_t>(curp)};// sign-extend
#endif
		if constexpr(isfltpmode) cure >>= 1;
		if constexpr(issignmode){
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carry;
			curm = __builtin_addcll(curm, curq, 0, &carry);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			curm = __builtin_addcl(curm, curq, 0, &carry);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymid, carry;
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo = __builtin_addcl(curmlo, curq, 0, &carrymid);
			curmhi = __builtin_addcl(curmhi, curq, carrymid, &carry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
			unsigned short checkcarry;
			curo = __builtin_addcs(curo, static_cast<unsigned short>(curq), static_cast<unsigned short>(carry), &checkcarry);
			static_cast<void>(checkcarry);
#elif defined(_M_X64)
			unsigned char checkcarry{_addcarry_u16(_addcarry_u64(0, curm, curq, &curm), curo, static_cast<std::uint_least16_t>(curq), &curo)};
			static_cast<void>(checkcarry);
#elif defined(_M_IX86)
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			unsigned char checkcarry{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlo, curq, &curmlo), curmhi, curq, &curmhi), curo, static_cast<std::uint_least16_t>(curq), &curo)};
			static_cast<void>(checkcarry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#elif 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
			curm += curq;
			curo += static_cast<std::uint_least16_t>(curq);
			curo += curm < curq;
#else
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo += curq;
			curmhi += curq;
			curmhi += curmlo < curq;
			curo += static_cast<std::uint_least16_t>(curq);
			curo += curmhi < curq;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
			cure = curo;
		}
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		curm ^= curq;
#else
		std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
		curmlo ^= curq;
		curmhi ^= curq;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
		curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
		cure ^= static_cast<U>(curq);
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		if constexpr(issignmode) cure &= 0xFFFFu >> 1;
		else{
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
			unsigned short carrysign;
			curo = __builtin_addcs(curo, curo, 0, &carrysign);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carry;
			curm = __builtin_addcll(curm, curm, static_cast<unsigned long long>(carrysign), &carry);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			curm = __builtin_addcl(curm, curm, static_cast<unsigned long>(carrysign), &carry);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymid, carry;
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo = __builtin_addcl(curmlo, curmlo, static_cast<unsigned long>(carrysign), &carrymid);
			curmhi = __builtin_addcl(curmhi, curmhi, carrymid, &carry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
			unsigned short checkcarry;
			curo = __builtin_addcs(curo, 0, static_cast<unsigned short>(carry), &checkcarry);
			static_cast<void>(checkcarry);
#elif defined(_M_X64)
			unsigned char checkcarry{_addcarry_u16(_addcarry_u64(_addcarry_u16(0, curo, curo, &curo), curm, curm, &curm), curo, 0, &curo)};
			static_cast<void>(checkcarry);
#elif defined(_M_IX86)
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			unsigned char checkcarry{_addcarry_u16(_addcarry_u32(_addcarry_u32(_addcarry_u16(0, curo, curo, &curo), curmlo, curmlo, &curmlo), curmhi, curmhi, &curmhi), curo, 0, &curo)};
			static_cast<void>(checkcarry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#else
			std::uint_least16_t curotmp{curo};
			curo += curo;
			std::uint_least64_t curmtmp{curm};
			curm += curm;
			curm += curo < curotmp;
			curo += curm < curmtmp;
#endif
			cure = curo;
		}
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(std::uint_least64_t &curm, U &cure, T *out)noexcept{
	// do not pass a nullptr here
	assert(out);
	using W = decltype(T::signexponent);
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curp{static_cast<std::int_least16_t>(cure)};
		if constexpr(isfltpmode){
			out[0].signexponent = static_cast<W>(cure);
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
			curo += curo;
			cure = curo;
		}else if constexpr(!issignmode){
			out[0].signexponent = static_cast<W>(cure);
			out[0].mantissa = curm;
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carry;
			curm = __builtin_addcll(curm, curm, 0, &carry);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			curm = __builtin_addcl(curm, curm, 0, &carry);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymid, carry;
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo = __builtin_addcl(curmlo, curmlo, 0, &carrymid);
			curmhi = __builtin_addcl(curmhi, curmhi, carrymid, &carry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
			unsigned short checkcarry;
			curo = __builtin_addcs(curo, curo, static_cast<unsigned short>(carry), &checkcarry);
			static_cast<void>(checkcarry);
#elif defined(_M_X64)
			unsigned char checkcarry{_addcarry_u16(_addcarry_u64(0, curm, curm, &curm), curo, curo, &curo)};
			static_cast<void>(checkcarry);
#elif defined(_M_IX86)
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			unsigned char checkcarry{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlo, curmlo, &curmlo), curmhi, curmhi, &curmhi), curo, curo, &curo)};
			static_cast<void>(checkcarry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#else
			std::uint_least64_t curmtmp{curm};
			curm += curm;
			curo += static_cast<std::uint_least16_t>(curo);
			curo += curm < curmtmp;
#endif
			cure = curo;
		}
		curp >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curq{static_cast<std::uint_least64_t>(curp)};// sign-extend
#else
		std::uint_least32_t curq{static_cast<std::uint_least32_t>(curp)};// sign-extend
#endif
		if constexpr(isfltpmode){
			cure >>= 1;
			out[0].mantissa = curm;
		}
		if constexpr(issignmode){
			if constexpr(!isfltpmode){
				out[0].signexponent = static_cast<W>(cure);
				out[0].mantissa = curm;
			}
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carry;
			curm = __builtin_addcll(curm, curq, 0, &carry);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			curm = __builtin_addcl(curm, curq, 0, &carry);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymid, carry;
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo = __builtin_addcl(curmlo, curq, 0, &carrymid);
			curmhi = __builtin_addcl(curmhi, curq, carrymid, &carry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
			unsigned short checkcarry;
			curo = __builtin_addcs(curo, static_cast<unsigned short>(curq), static_cast<unsigned short>(carry), &checkcarry);
			static_cast<void>(checkcarry);
#elif defined(_M_X64)
			unsigned char checkcarry{_addcarry_u16(_addcarry_u64(0, curm, curq, &curm), curo, static_cast<std::uint_least16_t>(curq), &curo)};
			static_cast<void>(checkcarry);
#elif defined(_M_IX86)
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			unsigned char checkcarry{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlo, curq, &curmlo), curmhi, curq, &curmhi), curo, static_cast<std::uint_least16_t>(curq), &curo)};
			static_cast<void>(checkcarry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#elif 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
			curm += curq;
			curo += static_cast<std::uint_least16_t>(curq);
			curo += curm < curq;
#else
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo += curq;
			curmhi += curq;
			curmhi += curmlo < curq;
			curo += static_cast<std::uint_least16_t>(curq);
			curo += curmhi < curq;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
			cure = curo;
		}
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		curm ^= curq;
#else
		std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
		curmlo ^= curq;
		curmhi ^= curq;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
		curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
		cure ^= static_cast<U>(curq);
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		out[0].signexponent = static_cast<W>(cure);
		if constexpr(issignmode){
			cure &= 0xFFFFu >> 1;
			out[0].mantissa = curm;
		}else{
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
			unsigned short carrysign;
			curo = __builtin_addcs(curo, curo, 0, &carrysign);
			out[0].mantissa = curm;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carry;
			curm = __builtin_addcll(curm, curm, static_cast<unsigned long long>(carrysign), &carry);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			curm = __builtin_addcl(curm, curm, static_cast<unsigned long>(carrysign), &carry);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymid, carry;
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo = __builtin_addcl(curmlo, curmlo, static_cast<unsigned long>(carrysign), &carrymid);
			curmhi = __builtin_addcl(curmhi, curmhi, carrymid, &carry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
			unsigned short checkcarry;
			curo = __builtin_addcs(curo, 0, static_cast<unsigned short>(carry), &checkcarry);
			static_cast<void>(checkcarry);
#elif defined(_M_X64)
			unsigned char carrysign{_addcarry_u16(0, curo, curo, &curo)};
			out[0].mantissa = curm;
			unsigned char checkcarry{_addcarry_u16(_addcarry_u64(carrysign, curm, curm, &curm), curo, 0, &curo)};
			static_cast<void>(checkcarry);
#elif defined(_M_IX86)
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			unsigned char carrysign{_addcarry_u16(0, curo, curo, &curo)};
			out[0].mantissa = curm;
			unsigned char checkcarry{_addcarry_u16(_addcarry_u32(_addcarry_u32(carrysign, curmlo, curmlo, &curmlo), curmhi, curmhi, &curmhi), curo, 0, &curo)};
			static_cast<void>(checkcarry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#else
			std::uint_least16_t curotmp{curo};
			curo += curo;
			out[0].mantissa = curm;
			std::uint_least64_t curmtmp{curm};
			curm += curm;
			curm += curo < curotmp;
			curo += curm < curmtmp;
#endif
			cure = curo;
		}
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(std::uint_least64_t &curm, U &cure, T *out, T *dst)noexcept{
	// do not pass a nullptr here
	assert(out);
	assert(dst);
	using W = decltype(T::signexponent);
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curp{static_cast<std::int_least16_t>(cure)};
		if constexpr(isfltpmode){
			out[0].signexponent = static_cast<W>(cure);
			dst[0].signexponent = static_cast<W>(cure);
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
			curo += curo;
			cure = curo;
		}else if constexpr(!issignmode){
			out[0].signexponent = static_cast<W>(cure);
			dst[0].signexponent = static_cast<W>(cure);
			out[0].mantissa = curm;
			dst[0].mantissa = curm;
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carry;
			curm = __builtin_addcll(curm, curm, 0, &carry);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			curm = __builtin_addcl(curm, curm, 0, &carry);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymid, carry;
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo = __builtin_addcl(curmlo, curmlo, 0, &carrymid);
			curmhi = __builtin_addcl(curmhi, curmhi, carrymid, &carry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
			unsigned short checkcarry;
			curo = __builtin_addcs(curo, curo, static_cast<unsigned short>(carry), &checkcarry);
			static_cast<void>(checkcarry);
#elif defined(_M_X64)
			unsigned char checkcarry{_addcarry_u16(_addcarry_u64(0, curm, curm, &curm), curo, curo, &curo)};
			static_cast<void>(checkcarry);
#elif defined(_M_IX86)
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			unsigned char checkcarry{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlo, curmlo, &curmlo), curmhi, curmhi, &curmhi), curo, curo, &curo)};
			static_cast<void>(checkcarry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#else
			std::uint_least64_t curmtmp{curm};
			curm += curm;
			curo += static_cast<std::uint_least16_t>(curo);
			curo += curm < curmtmp;
#endif
			cure = curo;
		}
		curp >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curq{static_cast<std::uint_least64_t>(curp)};// sign-extend
#else
		std::uint_least32_t curq{static_cast<std::uint_least32_t>(curp)};// sign-extend
#endif
		if constexpr(isfltpmode){
			cure >>= 1;
			out[0].mantissa = curm;
			dst[0].mantissa = curm;
		}
		if constexpr(issignmode){
			if constexpr(!isfltpmode){
				out[0].signexponent = static_cast<W>(cure);
				dst[0].signexponent = static_cast<W>(cure);
				out[0].mantissa = curm;
				dst[0].mantissa = curm;
			}
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carry;
			curm = __builtin_addcll(curm, curq, 0, &carry);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			curm = __builtin_addcl(curm, curq, 0, &carry);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymid, carry;
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo = __builtin_addcl(curmlo, curq, 0, &carrymid);
			curmhi = __builtin_addcl(curmhi, curq, carrymid, &carry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
			unsigned short checkcarry;
			curo = __builtin_addcs(curo, static_cast<unsigned short>(curq), static_cast<unsigned short>(carry), &checkcarry);
			static_cast<void>(checkcarry);
#elif defined(_M_X64)
			unsigned char checkcarry{_addcarry_u16(_addcarry_u64(0, curm, curq, &curm), curo, static_cast<std::uint_least16_t>(curq), &curo)};
			static_cast<void>(checkcarry);
#elif defined(_M_IX86)
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			unsigned char checkcarry{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlo, curq, &curmlo), curmhi, curq, &curmhi), curo, static_cast<std::uint_least16_t>(curq), &curo)};
			static_cast<void>(checkcarry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#elif 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
			curm += curq;
			curo += static_cast<std::uint_least16_t>(curq);
			curo += curm < curq;
#else
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo += curq;
			curmhi += curq;
			curmhi += curmlo < curq;
			curo += static_cast<std::uint_least16_t>(curq);
			curo += curmhi < curq;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
			cure = curo;
		}
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		curm ^= curq;
#else
		std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
		curmlo ^= curq;
		curmhi ^= curq;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
		curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
		cure ^= static_cast<U>(curq);
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		out[0].signexponent = static_cast<W>(cure);
		dst[0].signexponent = static_cast<W>(cure);
		if constexpr(issignmode){
			cure &= 0xFFFFu >> 1;
			out[0].mantissa = curm;
			dst[0].mantissa = curm;
		}else{
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
			unsigned short carrysign;
			curo = __builtin_addcs(curo, curo, 0, &carrysign);
			out[0].mantissa = curm;
			dst[0].mantissa = curm;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carry;
			curm = __builtin_addcll(curm, curm, static_cast<unsigned long long>(carrysign), &carry);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			curm = __builtin_addcl(curm, curm, static_cast<unsigned long>(carrysign), &carry);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymid, carry;
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo = __builtin_addcl(curmlo, curmlo, static_cast<unsigned long>(carrysign), &carrymid);
			curmhi = __builtin_addcl(curmhi, curmhi, carrymid, &carry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
			unsigned short checkcarry;
			curo = __builtin_addcs(curo, 0, static_cast<unsigned short>(carry), &checkcarry);
			static_cast<void>(checkcarry);
#elif defined(_M_X64)
			unsigned char carrysign{_addcarry_u16(0, curo, curo, &curo)};
			out[0].mantissa = curm;
			dst[0].mantissa = curm;
			unsigned char checkcarry{_addcarry_u16(_addcarry_u64(carrysign, curm, curm, &curm), curo, 0, &curo)};
			static_cast<void>(checkcarry);
#elif defined(_M_IX86)
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			unsigned char carrysign{_addcarry_u16(0, curo, curo, &curo)};
			out[0].mantissa = curm;
			dst[0].mantissa = curm;
			unsigned char checkcarry{_addcarry_u16(_addcarry_u32(_addcarry_u32(carrysign, curmlo, curmlo, &curmlo), curmhi, curmhi, &curmhi), curo, 0, &curo)};
			static_cast<void>(checkcarry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#else
			std::uint_least16_t curotmp{curo};
			curo += curo;
			out[0].mantissa = curm;
			dst[0].mantissa = curm;
			std::uint_least64_t curmtmp{curm};
			curm += curm;
			curm += curo < curotmp;
			curo += curm < curmtmp;
#endif
			cure = curo;
		}
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(std::uint_least64_t &curma, U &curea, std::uint_least64_t &curmb, U &cureb)noexcept{
	using W = decltype(T::signexponent);
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curpa{static_cast<std::int_least16_t>(curea)};
		std::int_least16_t curpb{static_cast<std::int_least16_t>(cureb)};
		if constexpr(isfltpmode){
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			curoa += curoa;
			curea = curoa;
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
			curob += curob;
			cureb = curob;
		}else if constexpr(!issignmode){
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			curma = __builtin_addcll(curma, curma, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			curma = __builtin_addcl(curma, curma, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymida, carrya;
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa = __builtin_addcl(curmloa, curmloa, 0, &carrymida);
			curmhia = __builtin_addcl(curmhia, curmhia, carrymida, &carrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, curoa, static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			curmb = __builtin_addcll(curmb, curmb, 0, &carryb);
#else
			unsigned long carryb;
			curmb = __builtin_addcl(curmb, curmb, 0, &carryb);
#endif
#else
			unsigned long carrymidb, carryb;
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob = __builtin_addcl(curmlob, curmlob, 0, &carrymidb);
			curmhib = __builtin_addcl(curmhib, curmhib, carrymidb, &carryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, curob, static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curma, &curma), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curmb, &curmb), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmloa, curmloa, &curmloa), curmhia, curmhia, &curmhia), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlob, curmlob, &curmlob), curmhib, curmhib, &curmhib), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#else
			std::uint_least64_t curmtmpa{curma};
			curma += curma;
			curoa += static_cast<std::uint_least16_t>(curoa);
			curoa += curma < curmtmpa;
			std::uint_least64_t curmtmpb{curmb};
			curmb += curmb;
			curob += static_cast<std::uint_least16_t>(curob);
			curob += curmb < curmtmpb;
#endif
			curea = curoa;
			cureb = curob;
		}
		curpa >>= 16 - 1;
		curpb >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curqa{static_cast<std::uint_least64_t>(curpa)};// sign-extend
		std::uint_least64_t curqb{static_cast<std::uint_least64_t>(curpb)};
#else
		std::uint_least32_t curqa{static_cast<std::uint_least32_t>(curpa)};// sign-extend
		std::uint_least32_t curqb{static_cast<std::uint_least32_t>(curpb)};
#endif
		if constexpr(isfltpmode){
			curea >>= 1;
			cureb >>= 1;
		}
		if constexpr(issignmode){
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			curma = __builtin_addcll(curma, curqa, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			curma = __builtin_addcl(curma, curqa, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymida, carrya;
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa = __builtin_addcl(curmloa, curqa, 0, &carrymida);
			curmhia = __builtin_addcl(curmhia, curqa, carrymida, &carrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, static_cast<unsigned short>(curqa), static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			curmb = __builtin_addcll(curmb, curqb, 0, &carryb);
#else
			unsigned long carryb;
			curmb = __builtin_addcl(curmb, curqb, 0, &carryb);
#endif
#else
			unsigned long carrymidb, carryb;
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob = __builtin_addcl(curmlob, curqb, 0, &carrymidb);
			curmhib = __builtin_addcl(curmhib, curqb, carrymidb, &carryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, static_cast<unsigned short>(curqb), static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curqa, &curma), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curqb, &curmb), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmloa, curqa, &curmloa), curmhia, curqa, &curmhia), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlob, curqb, &curmlob), curmhib, curqb, &curmhib), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#elif 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
			curma += curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curma < curqa;
			curmb += curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmb < curqb;
#else
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa += curqa;
			curmhia += curqa;
			curmhia += curmloa < curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curmhia < curqa;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob += curqb;
			curmhib += curqb;
			curmhib += curmlob < curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmhib < curqb;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			curea = curoa;
			cureb = curob;
		}
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		curma ^= curqa;
		curmb ^= curqb;
#else
		std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		curmloa ^= curqa;
		curmhia ^= curqa;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
		curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
		std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		curmlob ^= curqb;
		curmhib ^= curqb;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
		curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
		curea ^= static_cast<U>(curqa);
		cureb ^= static_cast<U>(curqb);
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		if constexpr(issignmode){
			curea &= 0xFFFFu >> 1;
			cureb &= 0xFFFFu >> 1;
		}else{
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
			unsigned short carrysigna;
			curoa = __builtin_addcs(curoa, curoa, 0, &carrysigna);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			curma = __builtin_addcll(curma, curma, static_cast<unsigned long long>(carrysigna), &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			curma = __builtin_addcl(curma, curma, static_cast<unsigned long>(carrysigna), &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymida, carrya;
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa = __builtin_addcl(curmloa, curmloa, static_cast<unsigned long>(carrysigna), &carrymida);
			curmhia = __builtin_addcl(curmhia, curmhia, carrymida, &carrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, 0, static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
			unsigned short carrysignb;
			curob = __builtin_addcs(curob, curob, 0, &carrysignb);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			curmb = __builtin_addcll(curmb, curmb, static_cast<unsigned long long>(carrysignb), &carryb);
#else
			unsigned long carryb;
			curmb = __builtin_addcl(curmb, curmb, static_cast<unsigned long>(carrysignb), &carryb);
#endif
#else
			unsigned long carrymidb, carryb;
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob = __builtin_addcl(curmlob, curmlob, static_cast<unsigned long>(carrysignb), &carrymidb);
			curmhib = __builtin_addcl(curmhib, curmhib, carrymidb, &carryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, 0, static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#elif defined(_M_X64)
			unsigned char carrysigna{_addcarry_u16(0, curoa, curoa, &curoa)};
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(carrysigna, curma, curma, &curma), curoa, 0, &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char carrysignb{_addcarry_u16(0, curob, curob, &curob)};
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(carrysignb, curmb, curmb, &curmb), curob, 0, &curob)};
			static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char carrysigna{_addcarry_u16(0, curoa, curoa, &curoa)};
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(_addcarry_u32(carrysigna, curmloa, curmloa, &curmloa), curmhia, curmhia, &curmhia), curoa, 0, &curoa)};
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char carrysignb{_addcarry_u16(0, curob, curob, &curob)};
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(_addcarry_u32(carrysignb, curmlob, curmlob, &curmlob), curmhib, curmhib, &curmhib), curob, 0, &curob)};
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#else
			std::uint_least16_t curotmpa{curoa};
			curoa += curoa;
			std::uint_least64_t curmtmpa{curma};
			curma += curma;
			curma += curoa < curotmpa;
			curoa += curma < curmtmpa;
			std::uint_least16_t curotmpb{curob};
			curob += curob;
			std::uint_least64_t curmtmpb{curmb};
			curmb += curmb;
			curmb += curob < curotmpb;
			curob += curmb < curmtmpb;
#endif
			curea = curoa;
			cureb = curob;
		}
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(std::uint_least64_t &curma, U &curea, T *outa, std::uint_least64_t &curmb, U &cureb, T *outb)noexcept{
	// do not pass a nullptr here
	assert(outa);
	assert(outb);
	using W = decltype(T::signexponent);
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curpa{static_cast<std::int_least16_t>(curea)};
		std::int_least16_t curpb{static_cast<std::int_least16_t>(cureb)};
		if constexpr(isfltpmode){
			outa[0].signexponent = static_cast<W>(curea);
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			curoa += curoa;
			curea = curoa;
			outb[0].signexponent = static_cast<W>(cureb);
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
			curob += curob;
			cureb = curob;
		}else if constexpr(!issignmode){
			outa[0].signexponent = static_cast<W>(curea);
			outa[0].mantissa = curma;
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			outb[0].signexponent = static_cast<W>(cureb);
			outb[0].mantissa = curmb;
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			curma = __builtin_addcll(curma, curma, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			curma = __builtin_addcl(curma, curma, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymida, carrya;
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa = __builtin_addcl(curmloa, curmloa, 0, &carrymida);
			curmhia = __builtin_addcl(curmhia, curmhia, carrymida, &carrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, curoa, static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			curmb = __builtin_addcll(curmb, curmb, 0, &carryb);
#else
			unsigned long carryb;
			curmb = __builtin_addcl(curmb, curmb, 0, &carryb);
#endif
#else
			unsigned long carrymidb, carryb;
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob = __builtin_addcl(curmlob, curmlob, 0, &carrymidb);
			curmhib = __builtin_addcl(curmhib, curmhib, carrymidb, &carryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, curob, static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curma, &curma), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curmb, &curmb), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmloa, curmloa, &curmloa), curmhia, curmhia, &curmhia), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlob, curmlob, &curmlob), curmhib, curmhib, &curmhib), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#else
			std::uint_least64_t curmtmpa{curma};
			curma += curma;
			curoa += static_cast<std::uint_least16_t>(curoa);
			curoa += curma < curmtmpa;
			std::uint_least64_t curmtmpb{curmb};
			curmb += curmb;
			curob += static_cast<std::uint_least16_t>(curob);
			curob += curmb < curmtmpb;
#endif
			curea = curoa;
			cureb = curob;
		}
		curpa >>= 16 - 1;
		curpb >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curqa{static_cast<std::uint_least64_t>(curpa)};// sign-extend
		std::uint_least64_t curqb{static_cast<std::uint_least64_t>(curpb)};
#else
		std::uint_least32_t curqa{static_cast<std::uint_least32_t>(curpa)};// sign-extend
		std::uint_least32_t curqb{static_cast<std::uint_least32_t>(curpb)};
#endif
		if constexpr(isfltpmode){
			curea >>= 1;
			cureb >>= 1;
			outa[0].mantissa = curma;
			outb[0].mantissa = curmb;
		}
		if constexpr(issignmode){
			if constexpr(!isfltpmode){
				outa[0].signexponent = static_cast<W>(curea);
				outb[0].signexponent = static_cast<W>(cureb);
				outa[0].mantissa = curma;
				outb[0].mantissa = curmb;
			}
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			curma = __builtin_addcll(curma, curqa, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			curma = __builtin_addcl(curma, curqa, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymida, carrya;
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa = __builtin_addcl(curmloa, curqa, 0, &carrymida);
			curmhia = __builtin_addcl(curmhia, curqa, carrymida, &carrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, static_cast<unsigned short>(curqa), static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			curmb = __builtin_addcll(curmb, curqb, 0, &carryb);
#else
			unsigned long carryb;
			curmb = __builtin_addcl(curmb, curqb, 0, &carryb);
#endif
#else
			unsigned long carrymidb, carryb;
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob = __builtin_addcl(curmlob, curqb, 0, &carrymidb);
			curmhib = __builtin_addcl(curmhib, curqb, carrymidb, &carryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, static_cast<unsigned short>(curqb), static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curqa, &curma), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curqb, &curmb), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmloa, curqa, &curmloa), curmhia, curqa, &curmhia), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlob, curqb, &curmlob), curmhib, curqb, &curmhib), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#elif 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
			curma += curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curma < curqa;
			curmb += curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmb < curqb;
#else
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			std::uint_least32_t curmlotmpa{curmloa}, curmhitmpa{curmhia};
			curmloa += curqa;
			curmhia += curqa;
			curmhia += curmloa < curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curmhia < curqa;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob += curqb;
			curmhib += curqb;
			curmhib += curmlob < curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmhib < curqb;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			curea = curoa;
			cureb = curob;
		}
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		curma ^= curqa;
		curmb ^= curqb;
#else
		std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		curmloa ^= curqa;
		curmhia ^= curqa;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
		curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
		std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		curmlob ^= curqb;
		curmhib ^= curqb;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
		curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
		curea ^= static_cast<U>(curqa);
		cureb ^= static_cast<U>(curqb);
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		outa[0].signexponent = static_cast<W>(curea);
		outb[0].signexponent = static_cast<W>(cureb);
		if constexpr(issignmode){
			curea &= 0xFFFFu >> 1;
			cureb &= 0xFFFFu >> 1;
			outa[0].mantissa = curma;
			outb[0].mantissa = curmb;
		}else{
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
			unsigned short carrysigna;
			curoa = __builtin_addcs(curoa, curoa, 0, &carrysigna);
			outa[0].mantissa = curma;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			curma = __builtin_addcll(curma, curma, static_cast<unsigned long long>(carrysigna), &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			curma = __builtin_addcl(curma, curma, static_cast<unsigned long>(carrysigna), &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymida, carrya;
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa = __builtin_addcl(curmloa, curmloa, static_cast<unsigned long>(carrysigna), &carrymida);
			curmhia = __builtin_addcl(curmhia, curmhia, carrymida, &carrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, 0, static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
			unsigned short carrysignb;
			curob = __builtin_addcs(curob, curob, 0, &carrysignb);
			outb[0].mantissa = curmb;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			curmb = __builtin_addcll(curmb, curmb, static_cast<unsigned long long>(carrysignb), &carryb);
#else
			unsigned long carryb;
			curmb = __builtin_addcl(curmb, curmb, static_cast<unsigned long>(carrysignb), &carryb);
#endif
#else
			unsigned long carrymidb, carryb;
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob = __builtin_addcl(curmlob, curmlob, static_cast<unsigned long>(carrysignb), &carrymidb);
			curmhib = __builtin_addcl(curmhib, curmhib, carrymidb, &carryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, 0, static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#elif defined(_M_X64)
			unsigned char carrysigna{_addcarry_u16(0, curoa, curoa, &curoa)};
			outa[0].mantissa = curma;
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(carrysigna, curma, curma, &curma), curoa, 0, &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char carrysignb{_addcarry_u16(0, curob, curob, &curob)};
			outb[0].mantissa = curmb;
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(carrysignb, curmb, curmb, &curmb), curob, 0, &curob)};
			static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char carrysigna{_addcarry_u16(0, curoa, curoa, &curoa)};
			outa[0].mantissa = curma;
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(_addcarry_u32(carrysigna, curmloa, curmloa, &curmloa), curmhia, curmhia, &curmhia), curoa, 0, &curoa)};
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char carrysignb{_addcarry_u16(0, curob, curob, &curob)};
			outb[0].mantissa = curmb;
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(_addcarry_u32(carrysignb, curmlob, curmlob, &curmlob), curmhib, curmhib, &curmhib), curob, 0, &curob)};
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#else
			std::uint_least16_t curotmpa{curoa};
			curoa += curoa;
			outa[0].mantissa = curma;
			std::uint_least64_t curmtmpa{curma};
			curma += curma;
			curma += curoa < curotmpa;
			curoa += curma < curmtmpa;
			std::uint_least16_t curotmpb{curob};
			curob += curob;
			outb[0].mantissa = curmb;
			std::uint_least64_t curmtmpb{curmb};
			curmb += curmb;
			curmb += curob < curotmpb;
			curob += curmb < curmtmpb;
#endif
			curea = curoa;
			cureb = curob;
		}
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(std::uint_least64_t &curma, U &curea, T *outa, T *dsta, std::uint_least64_t &curmb, U &cureb, T *outb, T *dstb)noexcept{
	// do not pass a nullptr here
	assert(outa);
	assert(dsta);
	assert(outb);
	assert(dstb);
	using W = decltype(T::signexponent);
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curpa{static_cast<std::int_least16_t>(curea)};
		std::int_least16_t curpb{static_cast<std::int_least16_t>(cureb)};
		if constexpr(isfltpmode){
			outa[0].signexponent = static_cast<W>(curea);
			dsta[0].signexponent = static_cast<W>(curea);
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			curoa += curoa;
			curea = curoa;
			outb[0].signexponent = static_cast<W>(cureb);
			dstb[0].signexponent = static_cast<W>(cureb);
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
			curob += curob;
			cureb = curob;
		}else if constexpr(!issignmode){
			outa[0].signexponent = static_cast<W>(curea);
			dsta[0].signexponent = static_cast<W>(curea);
			outa[0].mantissa = curma;
			dsta[0].mantissa = curma;
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			outb[0].signexponent = static_cast<W>(cureb);
			dstb[0].signexponent = static_cast<W>(cureb);
			outb[0].mantissa = curmb;
			dstb[0].mantissa = curmb;
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			curma = __builtin_addcll(curma, curma, 0, &carrya);
#else
			unsigned long carrya;
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			curma = __builtin_addcl(curma, curma, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymida, carrya;
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa = __builtin_addcl(curmloa, curmloa, 0, &carrymida);
			curmhia = __builtin_addcl(curmhia, curmhia, carrymida, &carrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, curoa, static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			curmb = __builtin_addcll(curmb, curmb, 0, &carryb);
#else
			unsigned long carryb;
			curmb = __builtin_addcl(curmb, curmb, 0, &carryb);
#endif
#else
			unsigned long carrymidb, carryb;
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob = __builtin_addcl(curmlob, curmlob, 0, &carrymidb);
			curmhib = __builtin_addcl(curmhib, curmhib, carrymidb, &carryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, curob, static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curma, &curma), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curmb, &curmb), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmloa, curmloa, &curmloa), curmhia, curmhia, &curmhia), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlob, curmlob, &curmlob), curmhib, curmhib, &curmhib), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#else
			std::uint_least64_t curmtmpa{curma};
			curma += curma;
			curoa += static_cast<std::uint_least16_t>(curoa);
			curoa += curma < curmtmpa;
			std::uint_least64_t curmtmpb{curmb};
			curmb += curmb;
			curob += static_cast<std::uint_least16_t>(curob);
			curob += curmb < curmtmpb;
#endif
			curea = curoa;
			cureb = curob;
		}
		curpa >>= 16 - 1;
		curpb >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curqa{static_cast<std::uint_least64_t>(curpa)};// sign-extend
		std::uint_least64_t curqb{static_cast<std::uint_least64_t>(curpb)};
#else
		std::uint_least32_t curqa{static_cast<std::uint_least32_t>(curpa)};// sign-extend
		std::uint_least32_t curqb{static_cast<std::uint_least32_t>(curpb)};
#endif
		if constexpr(isfltpmode){
			curea >>= 1;
			cureb >>= 1;
			outa[0].mantissa = curma;
			dsta[0].mantissa = curma;
			outb[0].mantissa = curmb;
			dstb[0].mantissa = curmb;
		}
		if constexpr(issignmode){
			if constexpr(!isfltpmode){
				outa[0].signexponent = static_cast<W>(curea);
				dsta[0].signexponent = static_cast<W>(curea);
				outb[0].signexponent = static_cast<W>(cureb);
				dstb[0].signexponent = static_cast<W>(cureb);
				outa[0].mantissa = curma;
				dsta[0].mantissa = curma;
				outb[0].mantissa = curmb;
				dstb[0].mantissa = curmb;
			}
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			curma = __builtin_addcll(curma, curqa, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			curma = __builtin_addcl(curma, curqa, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymida, carrya;
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa = __builtin_addcl(curmloa, curqa, 0, &carrymida);
			curmhia = __builtin_addcl(curmhia, curqa, carrymida, &carrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, static_cast<unsigned short>(curqa), static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			curmb = __builtin_addcll(curmb, curqb, 0, &carryb);
#else
			unsigned long carryb;
			curmb = __builtin_addcl(curmb, curqb, 0, &carryb);
#endif
#else
			unsigned long carrymidb, carryb;
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob = __builtin_addcl(curmlob, curqb, 0, &carrymidb);
			curmhib = __builtin_addcl(curmhib, curqb, carrymidb, &carryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, static_cast<unsigned short>(curqb), static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curqa, &curma), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curqb, &curmb), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmloa, curqa, &curmloa), curmhia, curqa, &curmhia), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlob, curqb, &curmlob), curmhib, curqb, &curmhib), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#elif 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
			curma += curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curma < curqa;
			curmb += curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmb < curqb;
#else
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa += curqa;
			curmhia += curqa;
			curmhia += curmloa < curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curmhia < curqa;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob += curqb;
			curmhib += curqb;
			curmhib += curmlob < curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmhib < curqb;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			curea = curoa;
			cureb = curob;
		}
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		curma ^= curqa;
		curmb ^= curqb;
#else
		std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		curmloa ^= curqa;
		curmhia ^= curqa;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
		curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
		std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		curmlob ^= curqb;
		curmhib ^= curqb;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
		curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
		curea ^= static_cast<U>(curqa);
		cureb ^= static_cast<U>(curqb);
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		outa[0].signexponent = static_cast<W>(curea);
		dsta[0].signexponent = static_cast<W>(curea);
		outb[0].signexponent = static_cast<W>(cureb);
		dstb[0].signexponent = static_cast<W>(cureb);
		if constexpr(issignmode){
			curea &= 0xFFFFu >> 1;
			cureb &= 0xFFFFu >> 1;
			outa[0].mantissa = curma;
			dsta[0].mantissa = curma;
			outb[0].mantissa = curmb;
			dstb[0].mantissa = curmb;
		}else{
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
			unsigned short carrysigna;
			curoa = __builtin_addcs(curoa, curoa, 0, &carrysigna);
			outa[0].mantissa = curma;
			dsta[0].mantissa = curma;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			curma = __builtin_addcll(curma, curma, static_cast<unsigned long long>(carrysigna), &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			curma = __builtin_addcl(curma, curma, static_cast<unsigned long>(carrysigna), &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymida, carrya;
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa = __builtin_addcl(curmloa, curmloa, static_cast<unsigned long>(carrysigna), &carrymida);
			curmhia = __builtin_addcl(curmhia, curmhia, carrymida, &carrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, 0, static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
			unsigned short carrysignb;
			curob = __builtin_addcs(curob, curob, 0, &carrysignb);
			outb[0].mantissa = curmb;
			dstb[0].mantissa = curmb;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			curmb = __builtin_addcll(curmb, curmb, static_cast<unsigned long long>(carrysignb), &carryb);
#else
			unsigned long carryb;
			curmb = __builtin_addcl(curmb, curmb, static_cast<unsigned long>(carrysignb), &carryb);
#endif
#else
			unsigned long carrymidb, carryb;
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob = __builtin_addcl(curmlob, curmlob, static_cast<unsigned long>(carrysignb), &carrymidb);
			curmhib = __builtin_addcl(curmhib, curmhib, carrymidb, &carryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, 0, static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#elif defined(_M_X64)
			unsigned char carrysigna{_addcarry_u16(0, curoa, curoa, &curoa)};
			outa[0].mantissa = curma;
			dsta[0].mantissa = curma;
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(carrysigna, curma, curma, &curma), curoa, 0, &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char carrysignb{_addcarry_u16(0, curob, curob, &curob)};
			outb[0].mantissa = curmb;
			dstb[0].mantissa = curmb;
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(carrysignb, curmb, curmb, &curmb), curob, 0, &curob)};
			static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char carrysigna{_addcarry_u16(0, curoa, curoa, &curoa)};
			outa[0].mantissa = curma;
			dsta[0].mantissa = curma;
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(_addcarry_u32(carrysigna, curmloa, curmloa, &curmloa), curmhia, curmhia, &curmhia), curoa, 0, &curoa)};
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char carrysignb{_addcarry_u16(0, curob, curob, &curob)};
			outb[0].mantissa = curmb;
			dstb[0].mantissa = curmb;
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(_addcarry_u32(carrysignb, curmlob, curmlob, &curmlob), curmhib, curmhib, &curmhib), curob, 0, &curob)};
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#else
			std::uint_least16_t curotmpa{curoa};
			curoa += curoa;
			outa[0].mantissa = curma;
			dsta[0].mantissa = curma;
			std::uint_least64_t curmtmpa{curma};
			curma += curma;
			curma += curoa < curotmpa;
			curoa += curma < curmtmpa;
			std::uint_least16_t curotmpb{curob};
			curob += curob;
			outb[0].mantissa = curmb;
			dstb[0].mantissa = curmb;
			std::uint_least64_t curmtmpb{curmb};
			curmb += curmb;
			curmb += curob < curotmpb;
			curob += curmb < curmtmpb;
#endif
			curea = curoa;
			cureb = curob;
		}
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(U &cur)noexcept{
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curp{static_cast<std::make_signed_t<T>>(cur)};
		if constexpr(!issignmode || isfltpmode){
			T curo{static_cast<T>(cur)};
			curo += curo;
			cur = curo;
		}
		curp >>= CHAR_BIT * sizeof(T) - 1;
		U curq{static_cast<T>(curp)};
		if constexpr(isfltpmode) cur >>= 1;
		if constexpr(issignmode){
			T curo{static_cast<T>(cur)};
			curo += static_cast<T>(curq);
			cur = curo;
		}
		cur ^= curq;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		if constexpr(issignmode) cur &= ~static_cast<T>(0) >> 1;
		else cur = rotateleftportable<1>(static_cast<T>(cur));
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(U &cur, T *out)noexcept{
	// do not pass a nullptr here
	assert(out);
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curp{static_cast<std::make_signed_t<T>>(cur)};
		*out = static_cast<T>(cur);
		if constexpr(!issignmode || isfltpmode){
			T curo{static_cast<T>(cur)};
			curo += curo;
			cur = curo;
		}
		curp >>= CHAR_BIT * sizeof(T) - 1;
		U curq{static_cast<T>(curp)};
		if constexpr(isfltpmode) cur >>= 1;
		if constexpr(issignmode){
			T curo{static_cast<T>(cur)};
			curo += static_cast<T>(curq);
			cur = curo;
		}
		cur ^= curq;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		*out = static_cast<T>(cur);
		if constexpr(issignmode) cur &= ~static_cast<T>(0) >> 1;
		else cur = rotateleftportable<1>(static_cast<T>(cur));
	}else *out = static_cast<T>(cur);
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(U &cur, T *out, T *dst)noexcept{
	// do not pass a nullptr here
	assert(out);
	assert(dst);
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curp{static_cast<std::make_signed_t<T>>(cur)};
		*out = static_cast<T>(cur);
		*dst = static_cast<T>(cur);
		if constexpr(!issignmode || isfltpmode){
			T curo{static_cast<T>(cur)};
			curo += curo;
			cur = curo;
		}
		curp >>= CHAR_BIT * sizeof(T) - 1;
		U curq{static_cast<T>(curp)};
		if constexpr(isfltpmode) cur >>= 1;
		if constexpr(issignmode){
			T curo{static_cast<T>(cur)};
			curo += static_cast<T>(curq);
			cur = curo;
		}
		cur ^= curq;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		*out = static_cast<T>(cur);
		*dst = static_cast<T>(cur);
		if constexpr(issignmode) cur &= ~static_cast<T>(0) >> 1;
		else cur = rotateleftportable<1>(static_cast<T>(cur));
	}else{
		*out = static_cast<T>(cur);
		*dst = static_cast<T>(cur);
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(U &cura, U &curb)noexcept{
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		if constexpr(!issignmode || isfltpmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		if constexpr(!issignmode || isfltpmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		if constexpr(isfltpmode){
			cura >>= 1;
			curb >>= 1;
		}
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			cura = curoa;
			curb = curob;
		}
		cura ^= curqa;
		curb ^= curqb;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		if constexpr(issignmode){
			cura &= ~static_cast<T>(0) >> 1;
			curb &= ~static_cast<T>(0) >> 1;
		}else{
			cura = rotateleftportable<1>(static_cast<T>(cura));
			curb = rotateleftportable<1>(static_cast<T>(curb));
		}
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(U &cura, T *outa, U &curb, T *outb)noexcept{
	// do not pass a nullptr here
	assert(outa);
	assert(outb);
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		*outa = static_cast<T>(cura);
		if constexpr(!issignmode || isfltpmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		*outb = static_cast<T>(curb);
		if constexpr(!issignmode || isfltpmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		if constexpr(isfltpmode){
			cura >>= 1;
			curb >>= 1;
		}
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			cura = curoa;
			curb = curob;
		}
		cura ^= curqa;
		curb ^= curqb;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		*outa = static_cast<T>(cura);
		if constexpr(issignmode) cura &= ~static_cast<T>(0) >> 1;
		else cura = rotateleftportable<1>(static_cast<T>(cura));
		*outb = static_cast<T>(curb);
		if constexpr(issignmode) curb &= ~static_cast<T>(0) >> 1;
		else curb = rotateleftportable<1>(static_cast<T>(curb));
	}else{
		*outa = static_cast<T>(cura);
		*outb = static_cast<T>(curb);
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(U &cura, T *outa, T *dsta, U &curb, T *outb, T *dstb)noexcept{
	// do not pass a nullptr here
	assert(outa);
	assert(dsta);
	assert(outb);
	assert(dstb);
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		*outa = static_cast<T>(cura);
		*dsta = static_cast<T>(cura);
		if constexpr(!issignmode || isfltpmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		*outb = static_cast<T>(curb);
		*dstb = static_cast<T>(curb);
		if constexpr(!issignmode || isfltpmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		if constexpr(isfltpmode){
			cura >>= 1;
			curb >>= 1;
		}
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			cura = curoa;
			curb = curob;
		}
		cura ^= curqa;
		curb ^= curqb;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		*outa = static_cast<T>(cura);
		*dsta = static_cast<T>(cura);
		if constexpr(issignmode) cura &= ~static_cast<T>(0) >> 1;
		else cura = rotateleftportable<1>(static_cast<T>(cura));
		*outb = static_cast<T>(curb);
		*dstb = static_cast<T>(curb);
		if constexpr(issignmode) curb &= ~static_cast<T>(0) >> 1;
		else curb = rotateleftportable<1>(static_cast<T>(curb));
	}else{
		*outa = static_cast<T>(cura);
		*dsta = static_cast<T>(cura);
		*outb = static_cast<T>(curb);
		*dstb = static_cast<T>(curb);
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(U &cura, U &curb, U &curc)noexcept{
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		if constexpr(!issignmode || isfltpmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		if constexpr(!issignmode || isfltpmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		std::make_signed_t<T> curpc{static_cast<std::make_signed_t<T>>(curc)};
		if constexpr(!issignmode || isfltpmode){
			T curoc{static_cast<T>(curc)};
			curoc += curoc;
			curc = curoc;
		}
		curpc >>= CHAR_BIT * sizeof(T) - 1;
		U curqc{static_cast<T>(curpc)};
		if constexpr(isfltpmode){
			cura >>= 1;
			curb >>= 1;
			curc >>= 1;
		}
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			T curoc{static_cast<T>(curc)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			curoc += static_cast<T>(curqc);
			cura = curoa;
			curb = curob;
			curc = curoc;
		}
		cura ^= curqa;
		curb ^= curqb;
		curc ^= curqc;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		if constexpr(issignmode){
			cura &= ~static_cast<T>(0) >> 1;
			curb &= ~static_cast<T>(0) >> 1;
			curc &= ~static_cast<T>(0) >> 1;
		}else{
			cura = rotateleftportable<1>(static_cast<T>(cura));
			curb = rotateleftportable<1>(static_cast<T>(curb));
			curc = rotateleftportable<1>(static_cast<T>(curc));
		}
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(U &cura, T *outa, U &curb, T *outb, U &curc, T *outc)noexcept{
	// do not pass a nullptr here
	assert(outa);
	assert(outb);
	assert(outc);
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		*outa = static_cast<T>(cura);
		if constexpr(!issignmode || isfltpmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		*outb = static_cast<T>(curb);
		if constexpr(!issignmode || isfltpmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		std::make_signed_t<T> curpc{static_cast<std::make_signed_t<T>>(curc)};
		*outc = static_cast<T>(curc);
		if constexpr(!issignmode || isfltpmode){
			T curoc{static_cast<T>(curc)};
			curoc += curoc;
			curc = curoc;
		}
		curpc >>= CHAR_BIT * sizeof(T) - 1;
		U curqc{static_cast<T>(curpc)};
		if constexpr(isfltpmode){
			cura >>= 1;
			curb >>= 1;
			curc >>= 1;
		}
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			T curoc{static_cast<T>(curc)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			curoc += static_cast<T>(curqc);
			cura = curoa;
			curb = curob;
			curc = curoc;
		}
		cura ^= curqa;
		curb ^= curqb;
		curc ^= curqc;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		*outa = static_cast<T>(cura);
		if constexpr(issignmode) cura &= ~static_cast<T>(0) >> 1;
		else cura = rotateleftportable<1>(static_cast<T>(cura));
		*outb = static_cast<T>(curb);
		if constexpr(issignmode) curb &= ~static_cast<T>(0) >> 1;
		else curb = rotateleftportable<1>(static_cast<T>(curb));
		*outc = static_cast<T>(curc);
		if constexpr(issignmode) curb &= ~static_cast<T>(0) >> 1;
		else curc = rotateleftportable<1>(static_cast<T>(curc));
	}else{
		*outa = static_cast<T>(cura);
		*outb = static_cast<T>(curb);
		*outc = static_cast<T>(curc);
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(U &cura, T *outa, T *dsta, U &curb, T *outb, T *dstb, U &curc, T *outc, T *dstc)noexcept{
	// do not pass a nullptr here
	assert(outa);
	assert(dsta);
	assert(outb);
	assert(dstb);
	assert(outc);
	assert(dstc);
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		*outa = static_cast<T>(cura);
		*dsta = static_cast<T>(cura);
		if constexpr(!issignmode || isfltpmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		*outb = static_cast<T>(curb);
		*dstb = static_cast<T>(curb);
		if constexpr(!issignmode || isfltpmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		std::make_signed_t<T> curpc{static_cast<std::make_signed_t<T>>(curc)};
		*outc = static_cast<T>(curc);
		*dstc = static_cast<T>(curc);
		if constexpr(!issignmode || isfltpmode){
			T curoc{static_cast<T>(curc)};
			curoc += curoc;
			curc = curoc;
		}
		curpc >>= CHAR_BIT * sizeof(T) - 1;
		U curqc{static_cast<T>(curpc)};
		if constexpr(isfltpmode){
			cura >>= 1;
			curb >>= 1;
			curc >>= 1;
		}
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			T curoc{static_cast<T>(curc)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			curoc += static_cast<T>(curqc);
			cura = curoa;
			curb = curob;
			curc = curoc;
		}
		cura ^= curqa;
		curb ^= curqb;
		curc ^= curqc;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		*outa = static_cast<T>(cura);
		*dsta = static_cast<T>(cura);
		if constexpr(issignmode) cura &= ~static_cast<T>(0) >> 1;
		else cura = rotateleftportable<1>(static_cast<T>(cura));
		*outb = static_cast<T>(curb);
		*dstb = static_cast<T>(curb);
		if constexpr(issignmode) curb &= ~static_cast<T>(0) >> 1;
		else curb = rotateleftportable<1>(static_cast<T>(curb));
		*outc = static_cast<T>(curc);
		*dstc = static_cast<T>(curc);
		if constexpr(issignmode) curc &= ~static_cast<T>(0) >> 1;
		else curc = rotateleftportable<1>(static_cast<T>(curc));
	}else{
		*outa = static_cast<T>(cura);
		*dsta = static_cast<T>(cura);
		*outb = static_cast<T>(curb);
		*dstb = static_cast<T>(curb);
		*outc = static_cast<T>(curc);
		*dstc = static_cast<T>(curc);
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(U &cura, U &curb, U &curc, U &curd)noexcept{
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		if constexpr(!issignmode || isfltpmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		if constexpr(!issignmode || isfltpmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		std::make_signed_t<T> curpc{static_cast<std::make_signed_t<T>>(curc)};
		if constexpr(!issignmode || isfltpmode){
			T curoc{static_cast<T>(curc)};
			curoc += curoc;
			curc = curoc;
		}
		curpc >>= CHAR_BIT * sizeof(T) - 1;
		U curqc{static_cast<T>(curpc)};
		std::make_signed_t<T> curpd{static_cast<std::make_signed_t<T>>(curd)};
		if constexpr(!issignmode || isfltpmode){
			T curod{static_cast<T>(curd)};
			curod += curod;
			curd = curod;
		}
		curpd >>= CHAR_BIT * sizeof(T) - 1;
		U curqd{static_cast<T>(curpd)};
		if constexpr(isfltpmode){
			cura >>= 1;
			curb >>= 1;
			curc >>= 1;
			curd >>= 1;
		}
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			T curoc{static_cast<T>(curc)};
			T curod{static_cast<T>(curd)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			curoc += static_cast<T>(curqc);
			curod += static_cast<T>(curqd);
			cura = curoa;
			curb = curob;
			curc = curoc;
			curd = curod;
		}
		cura ^= curqa;
		curb ^= curqb;
		curc ^= curqc;
		curd ^= curqd;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		if constexpr(issignmode){
			cura &= ~static_cast<T>(0) >> 1;
			curb &= ~static_cast<T>(0) >> 1;
			curc &= ~static_cast<T>(0) >> 1;
			curd &= ~static_cast<T>(0) >> 1;
		}else{
			cura = rotateleftportable<1>(static_cast<T>(cura));
			curb = rotateleftportable<1>(static_cast<T>(curb));
			curc = rotateleftportable<1>(static_cast<T>(curc));
			curd = rotateleftportable<1>(static_cast<T>(curd));
		}
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(U &cura, T *outa, U &curb, T *outb, U &curc, T *outc, U &curd, T *outd)noexcept{
	// do not pass a nullptr here
	assert(outa);
	assert(outb);
	assert(outc);
	assert(outd);
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		*outa = static_cast<T>(cura);
		if constexpr(!issignmode || isfltpmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		*outb = static_cast<T>(curb);
		if constexpr(!issignmode || isfltpmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		std::make_signed_t<T> curpc{static_cast<std::make_signed_t<T>>(curc)};
		*outc = static_cast<T>(curc);
		if constexpr(!issignmode || isfltpmode){
			T curoc{static_cast<T>(curc)};
			curoc += curoc;
			curc = curoc;
		}
		curpc >>= CHAR_BIT * sizeof(T) - 1;
		U curqc{static_cast<T>(curpc)};
		std::make_signed_t<T> curpd{static_cast<std::make_signed_t<T>>(curd)};
		*outd = static_cast<T>(curd);
		if constexpr(!issignmode || isfltpmode){
			T curod{static_cast<T>(curd)};
			curod += curod;
			curd = curod;
		}
		curpd >>= CHAR_BIT * sizeof(T) - 1;
		U curqd{static_cast<T>(curpd)};
		if constexpr(isfltpmode){
			cura >>= 1;
			curb >>= 1;
			curc >>= 1;
			curd >>= 1;
		}
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			T curoc{static_cast<T>(curc)};
			T curod{static_cast<T>(curd)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			curoc += static_cast<T>(curqc);
			curod += static_cast<T>(curqd);
			cura = curoa;
			curb = curob;
			curc = curoc;
			curd = curod;
		}
		cura ^= curqa;
		curb ^= curqb;
		curc ^= curqc;
		curd ^= curqd;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		*outa = static_cast<T>(cura);
		if constexpr(issignmode) cura &= ~static_cast<T>(0) >> 1;
		else cura = rotateleftportable<1>(static_cast<T>(cura));
		*outb = static_cast<T>(curb);
		if constexpr(issignmode) curb &= ~static_cast<T>(0) >> 1;
		else curb = rotateleftportable<1>(static_cast<T>(curb));
		*outc = static_cast<T>(curc);
		if constexpr(issignmode) curc &= ~static_cast<T>(0) >> 1;
		else curc = rotateleftportable<1>(static_cast<T>(curc));
		*outd = static_cast<T>(curd);
		if constexpr(issignmode) curd &= ~static_cast<T>(0) >> 1;
		else curd = rotateleftportable<1>(static_cast<T>(curd));
	}else{
		*outa = static_cast<T>(cura);
		*outb = static_cast<T>(curb);
		*outc = static_cast<T>(curc);
		*outd = static_cast<T>(curd);
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(U &cura, T *outa, T *dsta, U &curb, T *outb, T *dstb, U &curc, T *outc, T *dstc, U &curd, T *outd, T *dstd)noexcept{
	// do not pass a nullptr here
	assert(outa);
	assert(dsta);
	assert(outb);
	assert(dstb);
	assert(outc);
	assert(dstc);
	assert(outd);
	assert(dstd);
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		*outa = static_cast<T>(cura);
		*dsta = static_cast<T>(cura);
		if constexpr(!issignmode || isfltpmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		*outb = static_cast<T>(curb);
		*dstb = static_cast<T>(curb);
		if constexpr(!issignmode || isfltpmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		std::make_signed_t<T> curpc{static_cast<std::make_signed_t<T>>(curc)};
		*outc = static_cast<T>(curc);
		*dstc = static_cast<T>(curc);
		if constexpr(!issignmode || isfltpmode){
			T curoc{static_cast<T>(curc)};
			curoc += curoc;
			curc = curoc;
		}
		curpc >>= CHAR_BIT * sizeof(T) - 1;
		U curqc{static_cast<T>(curpc)};
		std::make_signed_t<T> curpd{static_cast<std::make_signed_t<T>>(curd)};
		*outd = static_cast<T>(curd);
		*dstd = static_cast<T>(curd);
		if constexpr(!issignmode || isfltpmode){
			T curod{static_cast<T>(curd)};
			curod += curod;
			curd = curod;
		}
		curpd >>= CHAR_BIT * sizeof(T) - 1;
		U curqd{static_cast<T>(curpd)};
		if constexpr(isfltpmode){
			cura >>= 1;
			curb >>= 1;
			curc >>= 1;
			curd >>= 1;
		}
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			T curoc{static_cast<T>(curc)};
			T curod{static_cast<T>(curd)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			curoc += static_cast<T>(curqc);
			curod += static_cast<T>(curqd);
			cura = curoa;
			curb = curob;
			curc = curoc;
			curd = curod;
		}
		cura ^= curqa;
		curb ^= curqb;
		curc ^= curqc;
		curd ^= curqd;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		*outa = static_cast<T>(cura);
		*dsta = static_cast<T>(cura);
		if constexpr(issignmode) cura &= ~static_cast<T>(0) >> 1;
		else cura = rotateleftportable<1>(static_cast<T>(cura));
		*outb = static_cast<T>(curb);
		*dstb = static_cast<T>(curb);
		if constexpr(issignmode) curb &= ~static_cast<T>(0) >> 1;
		else curb = rotateleftportable<1>(static_cast<T>(curb));
		*outc = static_cast<T>(curc);
		*dstc = static_cast<T>(curc);
		if constexpr(issignmode) curc &= ~static_cast<T>(0) >> 1;
		else curc = rotateleftportable<1>(static_cast<T>(curc));
		*outd = static_cast<T>(curd);
		*dstd = static_cast<T>(curd);
		if constexpr(issignmode) curd &= ~static_cast<T>(0) >> 1;
		else curd = rotateleftportable<1>(static_cast<T>(curd));
	}else{
		*outa = static_cast<T>(cura);
		*dsta = static_cast<T>(cura);
		*outb = static_cast<T>(curb);
		*dstb = static_cast<T>(curb);
		*outc = static_cast<T>(curc);
		*dstc = static_cast<T>(curc);
		*outd = static_cast<T>(curd);
		*dstd = static_cast<T>(curd);
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(U &cura, U &curb, U &curc, U &curd, U &cure, U &curf, U &curg, U &curh)noexcept{
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		if constexpr(!issignmode || isfltpmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		if constexpr(!issignmode || isfltpmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		std::make_signed_t<T> curpc{static_cast<std::make_signed_t<T>>(curc)};
		if constexpr(!issignmode || isfltpmode){
			T curoc{static_cast<T>(curc)};
			curoc += curoc;
			curc = curoc;
		}
		curpc >>= CHAR_BIT * sizeof(T) - 1;
		U curqc{static_cast<T>(curpc)};
		std::make_signed_t<T> curpd{static_cast<std::make_signed_t<T>>(curd)};
		if constexpr(!issignmode || isfltpmode){
			T curod{static_cast<T>(curd)};
			curod += curod;
			curd = curod;
		}
		curpd >>= CHAR_BIT * sizeof(T) - 1;
		U curqd{static_cast<T>(curpd)};
		std::make_signed_t<T> curpe{static_cast<std::make_signed_t<T>>(cure)};
		if constexpr(!issignmode || isfltpmode){
			T curoe{static_cast<T>(cure)};
			curoe += curoe;
			cure = curoe;
		}
		curpe >>= CHAR_BIT * sizeof(T) - 1;
		U curqe{static_cast<T>(curpe)};
		std::make_signed_t<T> curpf{static_cast<std::make_signed_t<T>>(curf)};
		if constexpr(!issignmode || isfltpmode){
			T curof{static_cast<T>(curf)};
			curof += curof;
			curf = curof;
		}
		curpf >>= CHAR_BIT * sizeof(T) - 1;
		U curqf{static_cast<T>(curpf)};
		std::make_signed_t<T> curpg{static_cast<std::make_signed_t<T>>(curg)};
		if constexpr(!issignmode || isfltpmode){
			T curog{static_cast<T>(curg)};
			curog += curog;
			curg = curog;
		}
		curpg >>= CHAR_BIT * sizeof(T) - 1;
		U curqg{static_cast<T>(curpg)};
		std::make_signed_t<T> curph{static_cast<std::make_signed_t<T>>(curh)};
		if constexpr(!issignmode || isfltpmode){
			T curoh{static_cast<T>(curh)};
			curoh += curoh;
			curh = curoh;
		}
		curph >>= CHAR_BIT * sizeof(T) - 1;
		U curqh{static_cast<T>(curph)};
		if constexpr(isfltpmode){
			cura >>= 1;
			curb >>= 1;
			curc >>= 1;
			curd >>= 1;
			cure >>= 1;
			curf >>= 1;
			curg >>= 1;
			curh >>= 1;
		}
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			T curoc{static_cast<T>(curc)};
			T curod{static_cast<T>(curd)};
			T curoe{static_cast<T>(cure)};
			T curof{static_cast<T>(curf)};
			T curog{static_cast<T>(curg)};
			T curoh{static_cast<T>(curh)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			curoc += static_cast<T>(curqc);
			curod += static_cast<T>(curqd);
			curoe += static_cast<T>(curqe);
			curof += static_cast<T>(curqf);
			curog += static_cast<T>(curqg);
			curoh += static_cast<T>(curqh);
			cura = curoa;
			curb = curob;
			curc = curoc;
			curd = curod;
			cure = curoe;
			curf = curof;
			curg = curog;
			curh = curoh;
		}
		cura ^= curqa;
		curb ^= curqb;
		curc ^= curqc;
		curd ^= curqd;
		cure ^= curqe;
		curf ^= curqf;
		curg ^= curqg;
		curh ^= curqh;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		if constexpr(issignmode){
			cura &= ~static_cast<T>(0) >> 1;
			curb &= ~static_cast<T>(0) >> 1;
			curc &= ~static_cast<T>(0) >> 1;
			curd &= ~static_cast<T>(0) >> 1;
			cure &= ~static_cast<T>(0) >> 1;
			curf &= ~static_cast<T>(0) >> 1;
			curg &= ~static_cast<T>(0) >> 1;
			curh &= ~static_cast<T>(0) >> 1;
		}else{
			cura = rotateleftportable<1>(static_cast<T>(cura));
			curb = rotateleftportable<1>(static_cast<T>(curb));
			curc = rotateleftportable<1>(static_cast<T>(curc));
			curd = rotateleftportable<1>(static_cast<T>(curd));
			cure = rotateleftportable<1>(static_cast<T>(cure));
			curf = rotateleftportable<1>(static_cast<T>(curf));
			curg = rotateleftportable<1>(static_cast<T>(curg));
			curh = rotateleftportable<1>(static_cast<T>(curh));
		}
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(U &cura, T *outa, U &curb, T *outb, U &curc, T *outc, U &curd, T *outd, U &cure, T *oute, U &curf, T *outf, U &curg, T *outg, U &curh, T *outh)noexcept{
	// do not pass a nullptr here
	assert(outa);
	assert(outb);
	assert(outc);
	assert(outd);
	assert(oute);
	assert(outf);
	assert(outg);
	assert(outh);
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		*outa = static_cast<T>(cura);
		if constexpr(!issignmode || isfltpmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		*outb = static_cast<T>(curb);
		if constexpr(!issignmode || isfltpmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		std::make_signed_t<T> curpc{static_cast<std::make_signed_t<T>>(curc)};
		*outc = static_cast<T>(curc);
		if constexpr(!issignmode || isfltpmode){
			T curoc{static_cast<T>(curc)};
			curoc += curoc;
			curc = curoc;
		}
		curpc >>= CHAR_BIT * sizeof(T) - 1;
		U curqc{static_cast<T>(curpc)};
		std::make_signed_t<T> curpd{static_cast<std::make_signed_t<T>>(curd)};
		*outd = static_cast<T>(curd);
		if constexpr(!issignmode || isfltpmode){
			T curod{static_cast<T>(curd)};
			curod += curod;
			curd = curod;
		}
		curpd >>= CHAR_BIT * sizeof(T) - 1;
		U curqd{static_cast<T>(curpd)};
		std::make_signed_t<T> curpe{static_cast<std::make_signed_t<T>>(cure)};
		*oute = static_cast<T>(cure);
		if constexpr(!issignmode || isfltpmode){
			T curoe{static_cast<T>(cure)};
			curoe += curoe;
			cure = curoe;
		}
		curpe >>= CHAR_BIT * sizeof(T) - 1;
		U curqe{static_cast<T>(curpe)};
		std::make_signed_t<T> curpf{static_cast<std::make_signed_t<T>>(curf)};
		*outf = static_cast<T>(curf);
		if constexpr(!issignmode || isfltpmode){
			T curof{static_cast<T>(curf)};
			curof += curof;
			curf = curof;
		}
		curpf >>= CHAR_BIT * sizeof(T) - 1;
		U curqf{static_cast<T>(curpf)};
		std::make_signed_t<T> curpg{static_cast<std::make_signed_t<T>>(curg)};
		*outg = static_cast<T>(curg);
		if constexpr(!issignmode || isfltpmode){
			T curog{static_cast<T>(curg)};
			curog += curog;
			curg = curog;
		}
		curpg >>= CHAR_BIT * sizeof(T) - 1;
		U curqg{static_cast<T>(curpg)};
		std::make_signed_t<T> curph{static_cast<std::make_signed_t<T>>(curh)};
		*outh = static_cast<T>(curh);
		if constexpr(!issignmode || isfltpmode){
			T curoh{static_cast<T>(curh)};
			curoh += curoh;
			curh = curoh;
		}
		curph >>= CHAR_BIT * sizeof(T) - 1;
		U curqh{static_cast<T>(curph)};
		if constexpr(isfltpmode){
			cura >>= 1;
			curb >>= 1;
			curc >>= 1;
			curd >>= 1;
			cure >>= 1;
			curf >>= 1;
			curg >>= 1;
			curh >>= 1;
		}
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			T curoc{static_cast<T>(curc)};
			T curod{static_cast<T>(curd)};
			T curoe{static_cast<T>(cure)};
			T curof{static_cast<T>(curf)};
			T curog{static_cast<T>(curg)};
			T curoh{static_cast<T>(curh)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			curoc += static_cast<T>(curqc);
			curod += static_cast<T>(curqd);
			curoe += static_cast<T>(curqe);
			curof += static_cast<T>(curqf);
			curog += static_cast<T>(curqg);
			curoh += static_cast<T>(curqh);
			cura = curoa;
			curb = curob;
			curc = curoc;
			curd = curod;
			cure = curoe;
			curf = curof;
			curg = curog;
			curh = curoh;
		}
		cura ^= curqa;
		curb ^= curqb;
		curc ^= curqc;
		curd ^= curqd;
		cure ^= curqe;
		curf ^= curqf;
		curg ^= curqg;
		curh ^= curqh;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		*outa = static_cast<T>(cura);
		if constexpr(issignmode) cura &= ~static_cast<T>(0) >> 1;
		else cura = rotateleftportable<1>(static_cast<T>(cura));
		*outb = static_cast<T>(curb);
		if constexpr(issignmode) curb &= ~static_cast<T>(0) >> 1;
		else curb = rotateleftportable<1>(static_cast<T>(curb));
		*outc = static_cast<T>(curc);
		if constexpr(issignmode) curc &= ~static_cast<T>(0) >> 1;
		else curc = rotateleftportable<1>(static_cast<T>(curc));
		*outd = static_cast<T>(curd);
		if constexpr(issignmode) curd &= ~static_cast<T>(0) >> 1;
		else curd = rotateleftportable<1>(static_cast<T>(curd));
		*oute = static_cast<T>(cure);
		if constexpr(issignmode) cure &= ~static_cast<T>(0) >> 1;
		else cure = rotateleftportable<1>(static_cast<T>(cure));
		*outf = static_cast<T>(curf);
		if constexpr(issignmode) curf &= ~static_cast<T>(0) >> 1;
		else curf = rotateleftportable<1>(static_cast<T>(curf));
		*outg = static_cast<T>(curg);
		if constexpr(issignmode) curg &= ~static_cast<T>(0) >> 1;
		else curg = rotateleftportable<1>(static_cast<T>(curg));
		*outh = static_cast<T>(curh);
		if constexpr(issignmode) curh &= ~static_cast<T>(0) >> 1;
		else curh = rotateleftportable<1>(static_cast<T>(curh));
	}else{
		*outa = static_cast<T>(cura);
		*outb = static_cast<T>(curb);
		*outc = static_cast<T>(curc);
		*outd = static_cast<T>(curd);
		*oute = static_cast<T>(cure);
		*outf = static_cast<T>(curf);
		*outg = static_cast<T>(curg);
		*outh = static_cast<T>(curh);
	}
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
	void> filterinput(U &cura, T *outa, T *dsta, U &curb, T *outb, T *dstb, U &curc, T *outc, T *dstc, U &curd, T *outd, T *dstd, U &cure, T *oute, T *dste, U &curf, T *outf, T *dstf, U &curg, T *outg, T *dstg, U &curh, T *outh, T *dsth)noexcept{
	// do not pass a nullptr here
	assert(outa);
	assert(dsta);
	assert(outb);
	assert(dstb);
	assert(outc);
	assert(dstc);
	assert(outd);
	assert(dstd);
	assert(oute);
	assert(dste);
	assert(outf);
	assert(dstf);
	assert(outg);
	assert(dstg);
	assert(outh);
	assert(dsth);
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		*outa = static_cast<T>(cura);
		*dsta = static_cast<T>(cura);
		if constexpr(!issignmode || isfltpmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		*outb = static_cast<T>(curb);
		*dstb = static_cast<T>(curb);
		if constexpr(!issignmode || isfltpmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		std::make_signed_t<T> curpc{static_cast<std::make_signed_t<T>>(curc)};
		*outc = static_cast<T>(curc);
		*dstc = static_cast<T>(curc);
		if constexpr(!issignmode || isfltpmode){
			T curoc{static_cast<T>(curc)};
			curoc += curoc;
			curc = curoc;
		}
		curpc >>= CHAR_BIT * sizeof(T) - 1;
		U curqc{static_cast<T>(curpc)};
		std::make_signed_t<T> curpd{static_cast<std::make_signed_t<T>>(curd)};
		*outd = static_cast<T>(curd);
		*dstd = static_cast<T>(curd);
		if constexpr(!issignmode || isfltpmode){
			T curod{static_cast<T>(curd)};
			curod += curod;
			curd = curod;
		}
		curpd >>= CHAR_BIT * sizeof(T) - 1;
		U curqd{static_cast<T>(curpd)};
		std::make_signed_t<T> curpe{static_cast<std::make_signed_t<T>>(cure)};
		*oute = static_cast<T>(cure);
		*dste = static_cast<T>(cure);
		if constexpr(!issignmode || isfltpmode){
			T curoe{static_cast<T>(cure)};
			curoe += curoe;
			cure = curoe;
		}
		curpe >>= CHAR_BIT * sizeof(T) - 1;
		U curqe{static_cast<T>(curpe)};
		std::make_signed_t<T> curpf{static_cast<std::make_signed_t<T>>(curf)};
		*outf = static_cast<T>(curf);
		*dstf = static_cast<T>(curf);
		if constexpr(!issignmode || isfltpmode){
			T curof{static_cast<T>(curf)};
			curof += curof;
			curf = curof;
		}
		curpf >>= CHAR_BIT * sizeof(T) - 1;
		U curqf{static_cast<T>(curpf)};
		std::make_signed_t<T> curpg{static_cast<std::make_signed_t<T>>(curg)};
		*outg = static_cast<T>(curg);
		*dstg = static_cast<T>(curg);
		if constexpr(!issignmode || isfltpmode){
			T curog{static_cast<T>(curg)};
			curog += curog;
			curg = curog;
		}
		curpg >>= CHAR_BIT * sizeof(T) - 1;
		U curqg{static_cast<T>(curpg)};
		std::make_signed_t<T> curph{static_cast<std::make_signed_t<T>>(curh)};
		*outh = static_cast<T>(curh);
		*dsth = static_cast<T>(curh);
		if constexpr(!issignmode || isfltpmode){
			T curoh{static_cast<T>(curh)};
			curoh += curoh;
			curh = curoh;
		}
		curph >>= CHAR_BIT * sizeof(T) - 1;
		U curqh{static_cast<T>(curph)};
		if constexpr(isfltpmode){
			cura >>= 1;
			curb >>= 1;
			curc >>= 1;
			curd >>= 1;
			cure >>= 1;
			curf >>= 1;
			curg >>= 1;
			curh >>= 1;
		}
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			T curoc{static_cast<T>(curc)};
			T curod{static_cast<T>(curd)};
			T curoe{static_cast<T>(cure)};
			T curof{static_cast<T>(curf)};
			T curog{static_cast<T>(curg)};
			T curoh{static_cast<T>(curh)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			curoc += static_cast<T>(curqc);
			curod += static_cast<T>(curqd);
			curoe += static_cast<T>(curqe);
			curof += static_cast<T>(curqf);
			curog += static_cast<T>(curqg);
			curoh += static_cast<T>(curqh);
			cura = curoa;
			curb = curob;
			curc = curoc;
			curd = curod;
			cure = curoe;
			curf = curof;
			curg = curog;
			curh = curoh;
		}
		cura ^= curqa;
		curb ^= curqb;
		curc ^= curqc;
		curd ^= curqd;
		cure ^= curqe;
		curf ^= curqf;
		curg ^= curqg;
		curh ^= curqh;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		*outa = static_cast<T>(cura);
		*dsta = static_cast<T>(cura);
		if constexpr(issignmode) cura &= ~static_cast<T>(0) >> 1;
		else cura = rotateleftportable<1>(static_cast<T>(cura));
		*outb = static_cast<T>(curb);
		*dstb = static_cast<T>(curb);
		if constexpr(issignmode) curb &= ~static_cast<T>(0) >> 1;
		else curb = rotateleftportable<1>(static_cast<T>(curb));
		*outc = static_cast<T>(curc);
		*dstc = static_cast<T>(curc);
		if constexpr(issignmode) curc &= ~static_cast<T>(0) >> 1;
		else curc = rotateleftportable<1>(static_cast<T>(curc));
		*outd = static_cast<T>(curd);
		*dstd = static_cast<T>(curd);
		if constexpr(issignmode) curd &= ~static_cast<T>(0) >> 1;
		else curd = rotateleftportable<1>(static_cast<T>(curd));
		*oute = static_cast<T>(cure);
		*dste = static_cast<T>(cure);
		if constexpr(issignmode) cure &= ~static_cast<T>(0) >> 1;
		else cure = rotateleftportable<1>(static_cast<T>(cure));
		*outf = static_cast<T>(curf);
		*dstf = static_cast<T>(curf);
		if constexpr(issignmode) curf &= ~static_cast<T>(0) >> 1;
		else curf = rotateleftportable<1>(static_cast<T>(curf));
		*outg = static_cast<T>(curg);
		*dstg = static_cast<T>(curg);
		if constexpr(issignmode) curg &= ~static_cast<T>(0) >> 1;
		else curg = rotateleftportable<1>(static_cast<T>(curg));
		*outh = static_cast<T>(curh);
		*dsth = static_cast<T>(curh);
		if constexpr(issignmode) curh &= ~static_cast<T>(0) >> 1;
		else curh = rotateleftportable<1>(static_cast<T>(curh));
	}else{
		*outa = static_cast<T>(cura);
		*dsta = static_cast<T>(cura);
		*outb = static_cast<T>(curb);
		*dstb = static_cast<T>(curb);
		*outc = static_cast<T>(curc);
		*dstc = static_cast<T>(curc);
		*outd = static_cast<T>(curd);
		*dstd = static_cast<T>(curd);
		*oute = static_cast<T>(cure);
		*dste = static_cast<T>(cure);
		*outf = static_cast<T>(curf);
		*dstf = static_cast<T>(curf);
		*outg = static_cast<T>(curg);
		*dstg = static_cast<T>(curg);
		*outh = static_cast<T>(curh);
		*dsth = static_cast<T>(curh);
	}
}

// Helper functions to implement the offset transforms

// version for both threads when multithreading is used at run time (writes a full set of offsets in this case)
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X>,
	unsigned> generateoffsetsshared(std::size_t count, X offsets[], X offsetscompanion[])noexcept{
	using U = std::conditional_t<sizeof(X) < sizeof(unsigned), unsigned, X>;// assume zero-extension to be basically free for U on basically all modern machines
	// do not pass a nullptr here
	assert(offsets);
	// isdescsort is frequently optimised away in this part, e.g.: isdescsort * 2 - 1 generates 1 or -1
	static_assert(!isabsvalue || !issignmode, "this function variant is not entirely intended for usage on the top part in absolute signed modes");
	// Determining the starting point depends on several factors here.
	static std::size_t constexpr offsetsstride{8 * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	X *t{isrevorder? offsetscompanion : offsets// low-to-high or high-to-low
		+ (!isabsvalue && issignmode) * (offsetsstride / 2 - isdescsort)
		+ (isdescsort && (isabsvalue || !issignmode)) * (offsetsstride - 1)
		+ (isabsvalue && !issignmode && isfltpmode) * (1 - isdescsort * 2)};
	X *u{isrevorder? offsets : offsetscompanion// low-to-high or high-to-low
		+ (!isabsvalue && issignmode) * (offsetsstride / 2 - isdescsort)
		+ (isdescsort && (isabsvalue || !issignmode)) * (offsetsstride - 1)
		+ (isabsvalue && !issignmode && isfltpmode) * (1 - isdescsort * 2)};
	unsigned b;// return value, indicates if a carry-out has occurred and all inputs are valued the same
	U offset{static_cast<U>(*t) + static_cast<U>(*u)};
	*t = 0;// the first offset always starts at zero
	if constexpr(!isabsvalue && issignmode){// handle the sign bit, virtually offset the top part by half the range here
		t += 1 - isdescsort * 2;
		u += 1 - isdescsort * 2;
		unsigned j{256 / 2 - 1};
		b = count < offset;// carry-out can only happen once per cycle here, so optimise that
		do{
			U difference{static_cast<U>(*t) + static_cast<U>(*u)};
			*t = static_cast<X>(offset);
			u[isdescsort * 2 - 1] = static_cast<X>(offset - 1);// high half
			t += 1 - isdescsort * 2;
			u += 1 - isdescsort * 2;
			offset += difference;
			addcarryofless(b, static_cast<U>(count), difference);
		}while(--j);
		U differencemid{static_cast<U>(t[256 * (isdescsort * 2 - 1)]) + static_cast<U>(u[256 * (isdescsort * 2 - 1)])};
		t[256 * (isdescsort * 2 - 1)] = static_cast<X>(offset);
		u[isdescsort * 2 - 1] = static_cast<X>(offset - 1);// high half
		t += (256 - 1) * (isdescsort * 2 - 1);// offset to the start/end of the range
		u += (256 - 1) * (isdescsort * 2 - 1);
		j = 256 / 2 - 2;
		offset += differencemid;
		addcarryofless(b, static_cast<U>(count), differencemid);
		do{
			U difference{static_cast<U>(*t) + static_cast<U>(*u)};
			*t = static_cast<X>(offset);
			u[isdescsort * 2 - 1] = static_cast<X>(offset - 1);// high half
			t += 1 - isdescsort * 2;
			u += 1 - isdescsort * 2;
			offset -= difference * (isdescsort * 2 - 1);
			addcarryofless(b, static_cast<U>(count), difference);
		}while(--j);
	}else{// unsigned or signed absolute
		// custom loop for the special mode: absolute floating-point, but negative inputs will sort just below their positive counterparts
		if constexpr(isabsvalue && !issignmode && isfltpmode){// starts at one removed from the initial index
			t += isdescsort * 2 - 1;// step back
			u += isdescsort * 2 - 1;
			unsigned j{256 / 2 - 1};// double the number of items per loop
			b = count < offset;// carry-out can only happen once per cycle here, so optimise that
			do{
				U difference{static_cast<U>(*t) + static_cast<U>(*u)};// even
				*t = static_cast<X>(offset);
				u[1 - isdescsort * 2] = static_cast<X>(offset - 1);// odd, high half
				offset += difference;
				addcarryofless(b, static_cast<U>(count), difference);
				difference = static_cast<U>(t[3 - isdescsort * 6]) + static_cast<U>(u[3 - isdescsort * 6]);// odd
				t[3 - isdescsort * 6] = static_cast<X>(offset);
				*u = static_cast<X>(offset - 1);// even, high half
				t += 2 - isdescsort * 4;// step forward twice
				u += 2 - isdescsort * 4;
				offset += difference;
				addcarryofless(b, static_cast<U>(count), difference);
			}while(--j);
		}else{// all other modes
			t += 1 - isdescsort * 2;
			u += 1 - isdescsort * 2;
			unsigned j{256 - 2};
			b = count < offset;// carry-out can only happen once per cycle here, so optimise that
			do{
				U difference{static_cast<U>(*t) + static_cast<U>(*u)};
				*t = static_cast<X>(offset);
				u[isdescsort * 2 - 1] = static_cast<X>(offset - 1);// high half
				t += 1 - isdescsort * 2;
				u += 1 - isdescsort * 2;
				offset += difference;
				addcarryofless(b, static_cast<U>(count), difference);
			}while(--j);
		}
	}
	addcarryofless(b, static_cast<U>(count), static_cast<U>(*t) + static_cast<U>(*u));
	*t = static_cast<X>(offset);
	*u = static_cast<X>(count);// high half, the last offset always starts at the end
	// again, adjust for the special mode
	u[((isabsvalue && !issignmode && isfltpmode) != isdescsort) * 2 - 1] = static_cast<X>(offset - 1);// high half
	return{b};
}

// version for the companion thread
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X>,
	unsigned> generateoffsetssinglemtc(std::size_t count, X offsets[], X offsetscompanion[])noexcept{
	using U = std::conditional_t<sizeof(X) < sizeof(unsigned), unsigned, X>;// assume zero-extension to be basically free for U on basically all modern machines
	// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
	// isdescsort is frequently optimised away in this part, e.g.: isdescsort * 2 - 1 generates 1 or -1
	// Determining the starting point depends on several factors here.
	static std::size_t constexpr offsetsstride{8 * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	// do not pass a nullptr here
	assert(offsets);
	assert(offsetscompanion);
	X *t{isrevorder? offsetscompanion : offsets + (offsetsstride - 1)// high-to-low or low-to-high
		- (!isabsvalue && issignmode) * (offsetsstride / 2 - isdescsort)
		- (isdescsort && (isabsvalue || !issignmode)) * (offsetsstride - 1)
		- (isabsvalue && !issignmode && isfltpmode) * (1 - isdescsort * 2)};
	X *u{isrevorder? offsets : offsetscompanion + (offsetsstride - 1)// high-to-low or low-to-high
		- (!isabsvalue && issignmode) * (offsetsstride / 2 - isdescsort)
		- (isdescsort && (isabsvalue || !issignmode)) * (offsetsstride - 1)
		- (isabsvalue && !issignmode && isfltpmode) * (1 - isdescsort * 2)};
	unsigned b;// return value, indicates if a carry-out has occurred and all inputs are valued the same
	U initdifference{static_cast<U>(*u) + static_cast<U>(*t)};
	*u = static_cast<X>(count);// high half, the last offset always starts at the end
	if constexpr(!isabsvalue && issignmode){// handle the sign bit, virtually offset the top part by half the range here
		u += isdescsort * 2 - 1;
		t += isdescsort * 2 - 1;
		unsigned j{256 / 2 - 1};
		U offset{static_cast<U>(count) - initdifference};
		b = count < initdifference;// carry-out can only happen once per cycle here, so optimise that
		do{
			U difference{static_cast<U>(*u) + static_cast<U>(*t)};
			*u = static_cast<X>(offset);// high half
			t[1 - isdescsort * 2] = static_cast<X>(offset + 1);// low half
			u += isdescsort * 2 - 1;
			t += isdescsort * 2 - 1;
			offset -= difference;
			addcarryofless(b, static_cast<U>(count), difference);
		}while(--j);
		t[1 - isdescsort * 2] = static_cast<X>(offset + 1);// low half
	}else{// unsigned or signed absolute
		if constexpr(isabsvalue && !issignmode && isfltpmode){// starts at one removed from the initial index
			// custom loop for the special mode: absolute floating-point, but negative inputs will sort just below their positive counterparts
			u += 1 - isdescsort * 2;// step back
			t += 1 - isdescsort * 2;
			unsigned j{256 / 4 - 1};// double the number of items per loop
			U offset{static_cast<U>(count) - initdifference};
			b = count < initdifference;// carry-out can only happen once per cycle here, so optimise that
			do{
				U difference{static_cast<U>(*u) + static_cast<U>(*t)};// even
				*u = static_cast<X>(offset);// even, high half
				t[isdescsort * 2 - 1] = static_cast<X>(offset + 1);// odd, low half
				offset -= difference;
				addcarryofless(b, static_cast<U>(count), difference);
				difference = static_cast<U>(u[isdescsort * 6 - 3]) + static_cast<U>(t[isdescsort * 6 - 3]);// odd
				u[isdescsort * 6 - 3] = static_cast<X>(offset);// odd, high half
				*t = static_cast<X>(offset + 1);// even, low half
				u += isdescsort * 4 - 2;// step forward twice
				t += isdescsort * 4 - 2;
				offset -= difference;
				addcarryofless(b, static_cast<U>(count), difference);
			}while(--j);
			U difference{static_cast<U>(*u) + static_cast<U>(*t)};// even
			*u = static_cast<X>(offset);// even, high half
			t[isdescsort * 2 - 1] = static_cast<X>(offset + 1);// odd, low half
			offset -= difference;
			addcarryofless(b, static_cast<U>(count), difference);
			*t = static_cast<X>(offset + 1);// even, low half
		}else{// all other modes
			u += isdescsort * 2 - 1;
			t += isdescsort * 2 - 1;
			// 127 / 2 is only rounded down in the companion thread
			// the floating-point case (-1 item) is for the companion thread
			unsigned j{256 / 2 - 1 - 127 / 2 * (isabsvalue && issignmode) - isfltpmode};
			U offset{static_cast<U>(count) - initdifference};
			b = count < initdifference;// carry-out can only happen once per cycle here, so optimise that
			do{
				U difference{static_cast<U>(*u) + static_cast<U>(*t)};
				*u = static_cast<X>(offset);// even, high half
				t[1 - isdescsort * 2] = static_cast<X>(offset + 1);// odd, low half
				u += isdescsort * 2 - 1;
				t += isdescsort * 2 - 1;
				offset -= difference;
				addcarryofless(b, static_cast<U>(count), difference);
			}while(--j);
			t[1 - isdescsort * 2] = static_cast<X>(offset + 1);// odd, low half
		}
	}
	return{b};
}

// version for the companion thread
template<bool isdescsort, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X>,
	std::pair<unsigned, unsigned>> generateoffsetsmultimtc(std::size_t count, X offsets[], X offsetscompanion[])noexcept{
	// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
	static std::size_t constexpr typebitsize{
		(std::is_same_v<longdoubletest128, T> ||
		std::is_same_v<longdoubletest96, T> ||
		std::is_same_v<longdoubletest80, T>)? 80 : CHAR_BIT * sizeof(T)};
	// do not pass a nullptr here
	assert(offsets);
	assert(offsetscompanion);
	// transform the top set of offsets first and work downwards to keep the cache hot for the first few stages
	// the companion thread mostly handles the top sets
	X *tbase{offsets + (typebitsize / 8 - 1) * 256};
	X *ubase{offsetscompanion + (typebitsize / 8 - 1) * 256};
	unsigned skipsteps, paritybool;// only the main thread may initialise at 0 or 1 for the parity
	if constexpr(issignmode){// start off with signed handling on the top, split it up if absolute mode is used
		if constexpr(!isabsvalue) paritybool = generateoffsetsshared<isdescsort, false, isabsvalue, issignmode, isfltpmode, X>(count, tbase, ubase);
		else paritybool = generateoffsetssinglemtc<isdescsort, false, isabsvalue, issignmode, isfltpmode, X>(count, tbase, ubase);
		tbase -= 256;
		ubase -= 256;
		skipsteps = paritybool << (typebitsize / 8 - 1);
	}else{
		paritybool = 0;
		skipsteps = 0;
	}
	static std::size_t constexpr fullsets{typebitsize / 8 - (isabsvalue && issignmode)};
	static std::size_t constexpr halfsets{fullsets >> 1};
	if constexpr(1 < halfsets - (!isabsvalue && issignmode)){
		signed k{static_cast<signed>(typebitsize / 8 - 1 - issignmode)};
		do{// handle these sets like regular unsigned
			unsigned b{generateoffsetsshared<isdescsort, false, false, false, false, X>(count, tbase, ubase)};
			tbase -= 256;
			ubase -= 256;
			paritybool ^= b;
			skipsteps |= b << k;
			--k;
		}while(static_cast<unsigned>(halfsets - 1) < k);
	}else if constexpr(1 == halfsets - (!isabsvalue && issignmode)){// handle this set like regular unsigned
		unsigned b{generateoffsetsshared<isdescsort, false, false, false, false, X>(count, tbase, ubase)};
		paritybool ^= b;
		skipsteps += b * (1u << (typebitsize / 8 - 1 - issignmode));// this will usually optimise out
	}
	if constexpr(1 & fullsets){// handle the last split up set (for odd counts)
		unsigned b{generateoffsetssinglemtc<isdescsort, false, isabsvalue, issignmode, isfltpmode, X>(count, offsets, offsetscompanion)};
		paritybool ^= b;
		skipsteps |= b;
	}
	return{skipsteps, paritybool};// paritybool will be 1 for when the swap count is odd
}

// version for the main thread when multithreading is used
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X>,
	unsigned> generateoffsetssinglemain(std::size_t count, X offsets[], X offsetscompanion[])noexcept{
	using U = std::conditional_t<sizeof(X) < sizeof(unsigned), unsigned, X>;// assume zero-extension to be basically free for U on basically all modern machines
	// do not pass a nullptr here
	assert(offsets);
	assert(offsetscompanion);
	// isdescsort is frequently optimised away in this part, e.g.: isdescsort * 2 - 1 generates 1 or -1
	// Determining the starting point depends on several factors here.
	static std::size_t constexpr offsetsstride{8 * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	X *t{isrevorder? offsetscompanion : offsets// low-to-high or high-to-low
		+ (!isabsvalue && issignmode) * (offsetsstride / 2 - isdescsort)
		+ (isdescsort && (isabsvalue || !issignmode)) * (offsetsstride - 1)
		+ (isabsvalue && !issignmode && isfltpmode) * (1 - isdescsort * 2)};
	X *u{isrevorder? offsets : offsetscompanion// low-to-high or high-to-low
		+ (!isabsvalue && issignmode) * (offsetsstride / 2 - isdescsort)
		+ (isdescsort && (isabsvalue || !issignmode)) * (offsetsstride - 1)
		+ (isabsvalue && !issignmode && isfltpmode) * (1 - isdescsort * 2)};
	U offset{static_cast<U>(*t) + static_cast<U>(*u)};
	*t = 0;// low half, the first offset always starts at zero
	unsigned b;// return value, indicates if a carry-out has occurred and all inputs are valued the same
	if constexpr(!isabsvalue && issignmode){// handle the sign bit, virtually offset the top part by half the range here
		t += 1 - isdescsort * 2;
		u += 1 - isdescsort * 2;
		unsigned j{256 / 2 - 1};
		b = count < offset;// carry-out can only happen once per cycle here, so optimise that
		do{
			U difference{static_cast<U>(*t) + static_cast<U>(*u)};
			*t = static_cast<X>(offset);// low half
			u[isdescsort * 2 - 1] = static_cast<X>(offset - 1);// high half
			t += 1 - isdescsort * 2;
			u += 1 - isdescsort * 2;
			offset += difference;
			addcarryofless(b, static_cast<U>(count), difference);
		}while(--j);
		u[isdescsort * 2 - 1] = static_cast<X>(offset - 1);// high half
	}else{// unsigned or signed absolute
		if constexpr(isabsvalue && !issignmode && isfltpmode){// starts at one removed from the initial index
			// custom loop for the special mode: absolute floating-point, but negative inputs will sort just below their positive counterparts
			t += isdescsort * 2 - 1;// step back
			u += isdescsort * 2 - 1;
			unsigned j{256 / 4 - 1};// double the number of items per loop
			b = count < offset;// carry-out can only happen once per cycle here, so optimise that
			do{
				U difference{static_cast<U>(*t) + static_cast<U>(*u)};// even
				*t = static_cast<X>(offset);// even, low half
				u[1 - isdescsort * 2] = static_cast<X>(offset - 1);// odd, high half
				offset += difference;
				addcarryofless(b, static_cast<U>(count), difference);
				difference = static_cast<U>(t[3 - isdescsort * 6]) + static_cast<U>(u[3 - isdescsort * 6]);// odd
				t[3 - isdescsort * 6] = static_cast<X>(offset);// odd, low half
				*u = static_cast<X>(offset - 1);// even, high half
				t += 2 - isdescsort * 4;// step forward twice
				u += 2 - isdescsort * 4;
				offset += difference;
				addcarryofless(b, static_cast<U>(count), difference);
			}while(--j);
			U difference{static_cast<U>(*t) + static_cast<U>(*u)};// even
			*t = static_cast<X>(offset);// even, low half
			u[1 - isdescsort * 2] = static_cast<X>(offset - 1);// odd, high half
			offset += difference;
			addcarryofless(b, static_cast<U>(count), difference);
			*u = static_cast<X>(offset - 1);// even, high half
		}else{// all other modes
			t += 1 - isdescsort * 2;
			u += 1 - isdescsort * 2;
			// 127 / 2 is only rounded down in the companion thread
			// the floating-point case (-1 item) is for the companion thread
			unsigned j{256 / 2 - 1 - (127 + 1) / 2 * (isabsvalue && issignmode)};
			b = count < offset;// carry-out can only happen once per cycle here, so optimise that
			do{
				U difference{static_cast<U>(*t) + static_cast<U>(*u)};
				*t = static_cast<X>(offset);// even, low half
				u[isdescsort * 2 - 1] = static_cast<X>(offset - 1);// odd, high half
				t += 1 - isdescsort * 2;
				u += 1 - isdescsort * 2;
				offset += difference;
				addcarryofless(b, static_cast<U>(count), difference);
			}while(--j);
			u[isdescsort * 2 - 1] = static_cast<X>(offset - 1);// odd, high half
		}
	}
	return{b};
}

// version for the main thread when no multithreading is used at run time
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X>,
	unsigned> generateoffsetssinglemain(std::size_t count, X offsets[])noexcept{
	using U = std::conditional_t<sizeof(X) < sizeof(unsigned), unsigned, X>;// assume zero-extension to be basically free for U on basically all modern machines
	// do not pass a nullptr here
	assert(offsets);
	// isdescsort is frequently optimised away in this part, e.g.: isdescsort * 2 - 1 generates 1 or -1
	// Determining the starting point depends on several factors here.
	static std::size_t constexpr offsetsstride{8 * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	X *t{offsets// low-to-high or high-to-low
		+ (!isabsvalue && issignmode) * ((offsetsstride + isfltpmode) / 2 - isdescsort)
		+ (isdescsort && (isabsvalue || !issignmode)) * (offsetsstride - 1)
		+ (isabsvalue && !issignmode && isfltpmode) * (1 - isdescsort * 2)};
	U offset{*t};
	unsigned b;// return value, indicates if a carry-out has occurred and all inputs are valued the same
	if constexpr(isrevorder){
		if constexpr(!isabsvalue && issignmode){// handle the sign bit, virtually offset the top part by half the range here
			U difference{t[1 - isdescsort * 2]};
			b = count < offset;// carry-out can only happen once per cycle here, so optimise that
			--offset;
			unsigned j{256 / 2 - 1};
			*t = static_cast<X>(offset);
			t += 1 - isdescsort * 2;
			do{
				offset += difference;
				addcarryofless(b, static_cast<U>(count), difference);
				U difference{t[1 - isdescsort * 2]};
				*t = static_cast<X>(offset);
				t += 1 - isdescsort * 2;
			}while(--j);
			offset += difference;
			addcarryofless(b, static_cast<U>(count), difference);
			difference = t[256 * (isdescsort * 2 - 1)];
			j = 256 / 2 - 3;
			*t = static_cast<X>(offset);
			t += (256 - 1) * (isdescsort * 2 - 1);// offset to the start/end of the range
			do{
				offset += difference;
				addcarryofless(b, static_cast<U>(count), difference);
				difference = *t;
				*t = static_cast<X>(offset);
				t += 1 - isdescsort * 2;
			}while(--j);
			offset += difference;
			addcarryofless(b, static_cast<U>(count), difference);
			*t = static_cast<X>(offset);
			addcarryofless(b, static_cast<U>(count), t[1 - isdescsort * 2]);
			t[1 - isdescsort * 2] = static_cast<X>(count);// the last offset always starts at the end
		}else{// unsigned or signed absolute
			if constexpr(isabsvalue && !issignmode && isfltpmode){// starts at one removed from the initial index
				// custom loop for the special mode: absolute floating-point, but negative inputs will sort just below their positive counterparts
				U difference{t[isdescsort * 2 - 1]};// even
				t += isdescsort * 2 - 1;// step back
				b = count < offset;// carry-out can only happen once per cycle here, so optimise that
				--offset;
				unsigned j{256 / 2 - 1};// double the number of items per loop
				do{
					t[1 - isdescsort * 2] = static_cast<X>(offset);
					offset += difference;
					addcarryofless(b, static_cast<U>(count), difference);
					difference = t[3 - isdescsort * 6];// odd
					*t = static_cast<X>(offset);
					offset += difference;
					addcarryofless(b, static_cast<U>(count), difference);
					difference = t[isdescsort * 2 - 1];// even
					t += 2 - isdescsort * 4;// step forward twice
				}while(--j);
				offset += difference;
				addcarryofless(b, static_cast<U>(count), difference);
				t[1 - isdescsort * 2] = static_cast<X>(offset);
				addcarryofless(b, static_cast<U>(count), *t);
				*t = static_cast<X>(count);// the last offset always starts at the end
			}else{// all other modes
				U difference{t[1 - isdescsort * 2]};
				b = count < offset;// carry-out can only happen once per cycle here, so optimise that
				--offset;
				unsigned j{256 - 2 - 127 * (isabsvalue && issignmode) - isfltpmode};
				do{
					offset += difference;
					addcarryofless(b, static_cast<U>(count), difference);
					difference = t[2 - isdescsort * 4];
					*t = static_cast<X>(offset);
					t += 1 - isdescsort * 2;
				}while(--j);
				offset += difference;
				addcarryofless(b, static_cast<U>(count), difference);
				*t = static_cast<X>(offset);
				addcarryofless(b, static_cast<U>(count), t[1 - isdescsort * 2]);
				t[1 - isdescsort * 2] = static_cast<X>(count);// the last offset always starts at the end
			}
		}
	}else{// not reverse ordered
		*t = 0;// the first offset always starts at zero
		if constexpr(!isabsvalue && issignmode){// handle the sign bit, virtually offset the top part by half the range here
			t += 1 - isdescsort * 2;
			unsigned j{256 / 2 - 1};
			b = count < offset;// carry-out can only happen once per cycle here, so optimise that
			do{
				U difference{*t};
				*t = static_cast<X>(offset);
				t += 1 - isdescsort * 2;
				offset += difference;
				addcarryofless(b, static_cast<U>(count), difference);
			}while(--j);
			U differencemid{t[256 * (isdescsort * 2 - 1)]};
			t[256 * (isdescsort * 2 - 1)] = static_cast<X>(offset);
			t += (256 - 1) * (isdescsort * 2 - 1);// offset to the start/end of the range
			j = 256 / 2 - 2;
			offset += differencemid;
			addcarryofless(b, static_cast<U>(count), differencemid);
			do{
				U difference{*t};
				*t = static_cast<X>(offset);
				t += 1 - isdescsort * 2;
				offset += difference;
				addcarryofless(b, static_cast<U>(count), difference);
			}while(--j);
		}else{// unsigned or signed absolute
			if constexpr(isabsvalue && !issignmode && isfltpmode){// starts at one removed from the initial index
				// custom loop for the special mode: absolute floating-point, but negative inputs will sort just below their positive counterparts
				t += isdescsort * 2 - 1;// step back
				unsigned j{256 / 2 - 1};// double the number of items per loop
				b = count < offset;// carry-out can only happen once per cycle here, so optimise that
				do{
					U difference{*t};// even
					*t = static_cast<X>(offset);
					offset += difference;
					addcarryofless(b, static_cast<U>(count), difference);
					difference = t[3 - isdescsort * 6];// odd
					t[3 - isdescsort * 6] = static_cast<X>(offset);
					t += 2 - isdescsort * 4;// step forward twice
					offset += difference;
					addcarryofless(b, static_cast<U>(count), difference);
				}while(--j);
			}else{// all other modes
				t += 1 - isdescsort * 2;
				unsigned j{256 - 2 - 127 * (isabsvalue && issignmode) - isfltpmode};
				b = count < offset;// carry-out can only happen once per cycle here, so optimise that
				do{
					U difference{*t};
					*t = static_cast<X>(offset);
					t += 1 - isdescsort * 2;
					offset += difference;
					addcarryofless(b, static_cast<U>(count), difference);
				}while(--j);
			}
		}
		addcarryofless(b, static_cast<U>(count), static_cast<U>(*t));
		*t = static_cast<X>(offset);
	}
	return{b};
}

// version for the main thread when no multithreading is used at compile time
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X>,
	unsigned> generateoffsetssingle(std::size_t count, X offsets[], std::nullptr_t = nullptr, unsigned = 0)noexcept{
	using U = std::conditional_t<sizeof(X) < sizeof(unsigned), unsigned, X>;// assume zero-extension to be basically free for U on basically all modern machines
	// do not pass a nullptr here
	assert(offsets);
	// isdescsort is frequently optimised away in this part, e.g.: isdescsort * 2 - 1 generates 1 or -1
	// Determining the starting point depends on several factors here.
	static std::size_t constexpr offsetsstride{8 * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	static std::size_t constexpr typebitsize{
		(std::is_same_v<longdoubletest128, T> ||
		std::is_same_v<longdoubletest96, T> ||
		std::is_same_v<longdoubletest80, T>)? 80 :
		std::is_same_v<std::nullptr_t, T>? 8 : CHAR_BIT * sizeof(T)};
	static std::size_t constexpr stride{offsetsstride + (typebitsize / 8 - 1) * 256};// offsetsstride, adapted for the multi-part types
	X *t{offsets// low-to-high or high-to-low
		+ (!isabsvalue && issignmode) * ((offsetsstride + isfltpmode) / 2 - isdescsort)
		+ (isdescsort && (isabsvalue || !issignmode)) * (offsetsstride - 1)
		+ (isabsvalue && !issignmode && isfltpmode) * (1 - isdescsort * 2)};
	unsigned b;// return value, indicates if a carry-out has occurred and all inputs are valued the same
	U offset{*t};
	if constexpr(isrevorder){
		t[stride] = 0;// high half, the first offset always starts at zero
		if constexpr(!isabsvalue && issignmode){// handle the sign bit, virtually offset the top part by half the range here
			t += 1 - isdescsort * 2;
			unsigned j{256 / 2 - 1};
			b = count < offset;// carry-out can only happen once per cycle here, so optimise that
			do{
				U difference{*t};
				t[stride] = static_cast<X>(offset);// high half
				t[isdescsort * 2 - 1] = static_cast<X>(offset - 1);
				t += 1 - isdescsort * 2;
				offset += difference;
				addcarryofless(b, static_cast<U>(count), difference);
			}while(--j);
			U differencemid{t[256 * (isdescsort * 2 - 1)]};
			t[stride + 256 * (isdescsort * 2 - 1)] = static_cast<X>(offset);// high half
			t[isdescsort * 2 - 1] = static_cast<X>(offset - 1);
			t += (256 - 1) * (isdescsort * 2 - 1);// offset to the start/end of the range
			j = 256 / 2 - 2;
			offset += differencemid;
			addcarryofless(b, static_cast<U>(count), differencemid);
			do{
				U difference{*t};
				t[stride] = static_cast<X>(offset);// high half
				t[isdescsort * 2 - 1] = static_cast<X>(offset - 1);
				t += 1 - isdescsort * 2;
				offset -= difference * (isdescsort * 2 - 1);
				addcarryofless(b, static_cast<U>(count), difference);
			}while(--j);
		}else{// unsigned or signed absolute
			// custom loop for the special mode: absolute floating-point, but negative inputs will sort just below their positive counterparts
			if constexpr(isabsvalue && !issignmode && isfltpmode){// starts at one removed from the initial index
				t += isdescsort * 2 - 1;// step back
				unsigned j{256 / 2 - 1};// double the number of items per loop
				b = count < offset;// carry-out can only happen once per cycle here, so optimise that
				do{
					U difference{*t};// even
					t[stride] = static_cast<X>(offset);// high half
					t[1 - isdescsort * 2] = static_cast<X>(offset - 1);// odd
					offset += difference;
					addcarryofless(b, static_cast<U>(count), difference);
					difference = t[3 - isdescsort * 6];// odd
					t[stride + 3 - isdescsort * 6] = static_cast<X>(offset);// high half
					*t = static_cast<X>(offset - 1);// even
					t += 2 - isdescsort * 4;// step forward twice
					offset += difference;
					addcarryofless(b, static_cast<U>(count), difference);
				}while(--j);
			}else{// all other modes
				t += 1 - isdescsort * 2;
				unsigned j{256 - 2};
				b = count < offset;// carry-out can only happen once per cycle here, so optimise that
				do{
					U difference{*t};
					t[stride] = static_cast<X>(static_cast<X>(offset));// high half
					t[isdescsort * 2 - 1] = static_cast<X>(offset - 1);
					t += 1 - isdescsort * 2;
					offset += difference;
					addcarryofless(b, static_cast<U>(count), difference);
				}while(--j);
			}
		}
		addcarryofless(b, static_cast<U>(count), *t);
		t[stride] = static_cast<X>(offset);// high half
		*t = static_cast<X>(count);// the last offset always starts at the end
		// again, adjust for the special mode
		t[((isabsvalue && !issignmode && isfltpmode) != isdescsort) * 2 - 1] = static_cast<X>(offset - 1);
	}else{// not reversed order
		*t = 0;// the first offset always starts at zero
		if constexpr(!isabsvalue && issignmode){// handle the sign bit, virtually offset the top part by half the range here
			t += 1 - isdescsort * 2;
			unsigned j{256 / 2 - 1};
			b = count < offset;// carry-out can only happen once per cycle here, so optimise that
			do{
				U difference{*t};
				*t = static_cast<X>(offset);
				t[stride + isdescsort * 2 - 1] = static_cast<X>(offset - 1);// high half
				t += 1 - isdescsort * 2;
				offset += difference;
				addcarryofless(b, static_cast<U>(count), difference);
			}while(--j);
			U differencemid{t[256 * (isdescsort * 2 - 1)]};
			t[256 * (isdescsort * 2 - 1)] = static_cast<X>(offset);
			t[stride + isdescsort * 2 - 1] = static_cast<X>(offset - 1);// high half
			t += (256 - 1) * (isdescsort * 2 - 1);// offset to the start/end of the range
			j = 256 / 2 - 2;
			offset += differencemid;
			addcarryofless(b, static_cast<U>(count), differencemid);
			do{
				U difference{*t};
				*t = static_cast<X>(offset);
				t[stride + isdescsort * 2 - 1] = static_cast<X>(offset - 1);// high half
				t += 1 - isdescsort * 2;
				offset -= difference * (isdescsort * 2 - 1);
				addcarryofless(b, static_cast<U>(count), difference);
			}while(--j);
		}else{// unsigned or signed absolute
			// custom loop for the special mode: absolute floating-point, but negative inputs will sort just below their positive counterparts
			if constexpr(isabsvalue && !issignmode && isfltpmode){// starts at one removed from the initial index
				t += isdescsort * 2 - 1;// step back
				unsigned j{256 / 2 - 1};// double the number of items per loop
				b = count < offset;// carry-out can only happen once per cycle here, so optimise that
				do{
					U difference{*t};// even
					*t = static_cast<X>(offset);
					t[stride + 1 - isdescsort * 2] = static_cast<X>(offset - 1);// odd, high half
					offset += difference;
					addcarryofless(b, static_cast<U>(count), difference);
					difference = t[3 - isdescsort * 6];// odd
					t[3 - isdescsort * 6] = static_cast<X>(offset);
					t[stride] = static_cast<X>(offset - 1);// even, high half
					t += 2 - isdescsort * 4;// step forward twice
					offset += difference;
					addcarryofless(b, static_cast<U>(count), difference);
				}while(--j);
			}else{// all other modes
				t += 1 - isdescsort * 2;
				unsigned j{256 - 2};
				b = count < offset;// carry-out can only happen once per cycle here, so optimise that
				do{
					U difference{*t};
					*t = static_cast<X>(offset);
					t[stride + isdescsort * 2 - 1] = static_cast<X>(offset - 1);// high half
					t += 1 - isdescsort * 2;
					offset += difference;
					addcarryofless(b, static_cast<U>(count), difference);
				}while(--j);
			}
		}
		addcarryofless(b, static_cast<U>(count), static_cast<U>(*t));
		*t = static_cast<X>(offset);
		t[stride] = static_cast<X>(count);// high half, the last offset always starts at the end
		// again, adjust for the special mode
		t[stride + ((isabsvalue && !issignmode && isfltpmode) != isdescsort) * 2 - 1] = static_cast<X>(offset - 1);// high half
	}
	return{b};
}

// version for the main thread when multithreading is used at compile time
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X>,
	unsigned> generateoffsetssingle(std::size_t count, X offsets[], X offsetscompanion[], unsigned usemultithread)noexcept{
	// do not pass a nullptr here
	assert(offsets);
	if(usemultithread) assert(offsetscompanion);
	unsigned b;// return value, indicates if a carry-out has occurred and all inputs are valued the same
	if(usemultithread) b = generateoffsetssinglemain<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, X>(count, offsets, offsetscompanion);
	else b = generateoffsetssinglemain<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, X>(count, offsets);
	return{b};
}

// version for the main thread when no multithreading is used at compile time
template<bool isdescsort, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	std::pair<unsigned, unsigned>> generateoffsetsmulti(std::size_t count, X offsets[], std::nullptr_t = nullptr, unsigned = 0, unsigned paritybool = 0)noexcept{
	static std::size_t constexpr typebitsize{
		(std::is_same_v<longdoubletest128, T> ||
		std::is_same_v<longdoubletest96, T> ||
		std::is_same_v<longdoubletest80, T>)? 80 : CHAR_BIT * sizeof(T)};
	// do not pass a nullptr here
	assert(offsets);
	// transform the top set of offsets first and work downwards to keep the cache hot for the first few stages
	if constexpr (1 & typebitsize / 8) paritybool ^= 1;// when the maximum amount of steps is odd, the parity starts off flipped
	X *tbase{offsets + (typebitsize / 8 - 1) * 256};
	unsigned skipsteps;
	if constexpr(issignmode){// start off with signed handling on the top
		unsigned b{generateoffsetssingle<isdescsort, false, isabsvalue, issignmode, isfltpmode, T, X>(count, tbase)};
		tbase -= 256;
		paritybool ^= b;
		skipsteps = b << (typebitsize / 8 - 1);
	}else skipsteps = 0;
	if constexpr(16 < typebitsize || !issignmode && !(isabsvalue && !issignmode && isfltpmode)){
		signed k{static_cast<signed>(typebitsize / 8 - 1 - issignmode)};
		do{// handle these sets like regular unsigned
			unsigned b{generateoffsetssingle<isdescsort, false, false, false, false, T, X>(count, tbase)};
			tbase -= 256;
			paritybool ^= b;
			skipsteps |= b << k;
			--k;
		}while((isabsvalue && !issignmode && isfltpmode)? 0 < k : 0 <= k);
	}else{// handle this set like regular unsigned
		unsigned b{generateoffsetssingle<isdescsort, false, false, false, false, T, X>(count, tbase)};
		paritybool ^= b;
		if constexpr(isabsvalue && !issignmode && isfltpmode) skipsteps = b << 1;
		else skipsteps |= b;
	}
	if constexpr(isabsvalue && !issignmode && isfltpmode){	// handle the least significant bit
		unsigned b{generateoffsetssingle<isdescsort, false, isabsvalue, issignmode, isfltpmode, T, X>(count, offsets)};
		paritybool ^= b;
		skipsteps |= b;
	}
	return{skipsteps, paritybool};// paritybool will be 1 for when the swap count is odd
}

// version for the main thread when multithreading is used at compile time
template<bool isdescsort, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	std::pair<unsigned, unsigned>> generateoffsetsmulti(std::size_t count, X offsets[], X offsetscompanion[], unsigned usemultithread, unsigned paritybool = 0)noexcept{
	static std::size_t constexpr typebitsize{
		(std::is_same_v<longdoubletest128, T> ||
		std::is_same_v<longdoubletest96, T> ||
		std::is_same_v<longdoubletest80, T>)? 80 : CHAR_BIT * sizeof(T)};
	// do not pass a nullptr here
	assert(offsets);
	if(usemultithread) assert(offsetscompanion);
	// transform the top set of offsets first and work downwards to keep the cache hot for the first few stages
	if constexpr (1 & typebitsize / 8) paritybool ^= 1;// when the maximum amount of steps is odd, the parity starts off flipped
	X *tbase{offsets + (typebitsize / 8 - 1) * 256};
	unsigned skipsteps;
	if(usemultithread){
		// the main thread mostly handles the bottom sets
		X *ubase{offsetscompanion + (typebitsize / 8 - 1) * 256};
		if constexpr(isabsvalue && issignmode){// start off with signed absolute handling on the top, split it up if absolute mode is used
			unsigned b{generateoffsetssinglemain<isdescsort, false, isabsvalue, issignmode, isfltpmode>(count, tbase, ubase)};
			paritybool ^= b;
			skipsteps = b << (typebitsize / 8 - 1);
		}else skipsteps = 0;
		static std::size_t constexpr fullsets{typebitsize / 8 - (isabsvalue && issignmode)};
		static std::size_t constexpr halfsets{fullsets >> 1};
		tbase -= 256 * halfsets;
		ubase -= 256 * halfsets;
		if constexpr(1 + (isabsvalue && !issignmode && isfltpmode) < halfsets){
			signed k{static_cast<signed>(halfsets - 1)};
			do{// handle these sets like regular unsigned
				unsigned b{generateoffsetsshared<isdescsort, false, false, false, false>(count, tbase, ubase)};
				tbase -= 256;
				ubase -= 256;
				paritybool ^= b;
				skipsteps |= b << k;
				--k;
			}while((isabsvalue && !issignmode && isfltpmode)? 0 < k : 0 <= k);
		}else if constexpr(1 + (isabsvalue && !issignmode && isfltpmode) == halfsets){// handle this set like regular unsigned
			unsigned b{generateoffsetsshared<isdescsort, false, false, false, false>(count, tbase, ubase)};
			paritybool ^= b;
			if constexpr(isabsvalue && !issignmode && isfltpmode) skipsteps = b << 1;
			else skipsteps |= b;
		}
		if constexpr((1 & fullsets) || isabsvalue && !issignmode && isfltpmode){	// handle the last split up set (for odd counts) and the least significant bit
			unsigned b;
			if constexpr(1 & fullsets) b = generateoffsetssinglemain<isdescsort, false, isabsvalue, issignmode, isfltpmode>(count, offsets, offsetscompanion);
			else b = generateoffsetsshared<isdescsort, false, isabsvalue, issignmode, isfltpmode>(count, offsets, offsetscompanion);
			paritybool ^= b;
			skipsteps |= b;
		}
	}else{// single-threaded case
		if constexpr(issignmode){// start off with signed handling on the top
			unsigned b{generateoffsetssinglemain<isdescsort, false, isabsvalue, issignmode, isfltpmode>(count, tbase)};
			tbase -= 256;
			paritybool ^= b;
			skipsteps = b << (typebitsize / 8 - 1);
		}else skipsteps = 0;
		if constexpr(16 < typebitsize || !issignmode && !(isabsvalue && !issignmode && isfltpmode)){
			signed k{typebitsize / 8 - 1 - issignmode};
			do{// handle these sets like regular unsigned
				unsigned b{generateoffsetssinglemain<isdescsort, false, false, false, false>(count, tbase)};
				tbase -= 256;
				paritybool ^= b;
				skipsteps |= b << k;
				--k;
			}while((isabsvalue && !issignmode && isfltpmode)? 0 < k : 0 <= k);
		}else{// handle this set like regular unsigned
			unsigned b{generateoffsetssinglemain<isdescsort, false, false, false, false>(count, tbase)};
			paritybool ^= b;
			if constexpr(isabsvalue && !issignmode && isfltpmode) skipsteps = b << 1;
			else skipsteps |= b;
		}
		if constexpr(isabsvalue && !issignmode && isfltpmode){	// handle the least significant bit
			unsigned b{generateoffsetssinglemain<isdescsort, false, isabsvalue, issignmode, isfltpmode>(count, offsets)};
			paritybool ^= b;
			skipsteps |= b;
		}
	}
	return{skipsteps, paritybool};// paritybool will be 1 for when the swap count is odd
}

// Function implementation templates for multi-part types

// initialisation part, multi-threading companion for the radixsortnoallocmulti2thread() function implementation template for 80-bit-based long double types without indirection
// Platforms with a native 80-bit long double type are all little endian, hence that is the only implementation here.
// Do not use this function directly.
template<bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, bool isinputconst, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>),
	void> radixsortnoallocmulti2threadinitmtc(std::size_t count, std::conditional_t<isinputconst, T const *, T *> input, T pout[], std::conditional_t<isinputconst, T *, std::nullptr_t> pdst, X offsetscompanion[])noexcept{
	using W = decltype(T::signexponent);
	using U = std::conditional_t<128 == CHAR_BIT * sizeof(T), std::uint_least64_t, unsigned>;// assume zero-extension to be basically free for U on basically all modern machines, but do not remove padding
	assert(3 <= count);// this function is not for small arrays, 4 is the minimum original array count
	// do not pass a nullptr here
	assert(input);
	assert(pout);
	if(isinputconst) assert(pdst);
	assert(offsetscompanion);
	if constexpr(isrevorder && 80 < CHAR_BIT * sizeof(T)){// also reverse the array at the same time
		// reverse ordering is applied here because the padding bytes could matter, hence the check above
		if constexpr(isinputconst){
			pout += count;
			pdst += count;
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
				do{
					U cure{static_cast<U>(input[0].signexponent)};
					std::uint_least64_t curm{input[0].mantissa};
					++input;
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curm, cure, pout, pdst);
						--pout;
						--pdst;
					}
					unsigned cure0{static_cast<unsigned>(cure & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pout[0].signexponent = static_cast<W>(cure);
						pdst[0].signexponent = static_cast<W>(cure);
					}
					cure >>= 8;
					unsigned curm0{static_cast<unsigned>(curm & 0xFFu)};
					unsigned curm1{static_cast<unsigned>(curm >> 8)};
					unsigned curm2{static_cast<unsigned>(curm >> 16)};
					unsigned curm3{static_cast<unsigned>(curm >> 24)};
					unsigned curm4{static_cast<unsigned>(curm >> 32)};
					unsigned curm5{static_cast<unsigned>(curm >> 40)};
					unsigned curm6{static_cast<unsigned>(curm >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pout[0].mantissa = curm;
						pdst[0].mantissa = curm;
					}
					curm >>= 56;
					++offsetscompanion[8 * 256 + static_cast<std::size_t>(cure0)];
					cure &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsetscompanion[curm0];
					curm1 &= 0xFFu;
					curm2 &= 0xFFu;
					curm3 &= 0xFFu;
					curm4 &= 0xFFu;
					curm5 &= 0xFFu;
					curm6 &= 0xFFu;
					++offsetscompanion[9 * 256 + static_cast<std::size_t>(cure)];
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curm)];
					++offsetscompanion[256 + static_cast<std::size_t>(curm1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curm2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curm3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curm4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curm5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curm6)];
				}while(0 <= --i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
				do{
					U curelo{static_cast<U>(input[0].signexponent)};
					std::uint_least64_t curmlo{input[0].mantissa};
					U curehi{static_cast<U>(input[1].signexponent)};
					std::uint_least64_t curmhi{input[1].mantissa};
					input += 2;
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(
							curmlo, curelo, pout, pdst,
							curmhi, curehi, pout - 1, pdst - 1);
						pout -= 2;
						pdst -= 2;
					}
					// register pressure performance issue on several platforms: first do the low half here
					unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pout[0].signexponent = static_cast<W>(curelo);
						pdst[0].signexponent = static_cast<W>(curelo);
					}
					curelo >>= 8;
					unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
					unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
					unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
					unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
					unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
					unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
					unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pout[0].mantissa = curmlo;
						pdst[0].mantissa = curmlo;
					}
					curmlo >>= 56;
					++offsetscompanion[8 * 256 + static_cast<std::size_t>(curelo0)];
					curelo &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsetscompanion[curmlo0];
					curmlo1 &= 0xFFu;
					curmlo2 &= 0xFFu;
					curmlo3 &= 0xFFu;
					curmlo4 &= 0xFFu;
					curmlo5 &= 0xFFu;
					curmlo6 &= 0xFFu;
					++offsetscompanion[9 * 256 + static_cast<std::size_t>(curelo)];
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curmlo)];
					++offsetscompanion[256 + static_cast<std::size_t>(curmlo1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curmlo2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curmlo3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curmlo4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curmlo5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curmlo6)];
					// register pressure performance issue on several platforms: do the high half here second
					unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pout[-1].signexponent = static_cast<W>(curehi);
						pdst[-1].signexponent = static_cast<W>(curehi);
					}
					curehi >>= 8;
					unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
					unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
					unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
					unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
					unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
					unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
					unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pout[-1].mantissa = curmhi;
						pout -= 2;
						pdst[-1].mantissa = curmhi;
						pdst -= 2;
					}
					curmhi >>= 56;
					++offsetscompanion[8 * 256 + static_cast<std::size_t>(curehi0)];
					curehi &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsetscompanion[curmhi0];
					curmhi1 &= 0xFFu;
					curmhi2 &= 0xFFu;
					curmhi3 &= 0xFFu;
					curmhi4 &= 0xFFu;
					curmhi5 &= 0xFFu;
					curmhi6 &= 0xFFu;
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curmhi)];
					++offsetscompanion[9 * 256 + static_cast<std::size_t>(curehi)];
					++offsetscompanion[256 + static_cast<std::size_t>(curmhi1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curmhi2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curmhi3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curmhi4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curmhi5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curmhi6)];
					i -= 2;
				}while(0 <= i);
			}
		}else{// !isinputconst
			T *pinputlo{input}, *pinputhi{input + count};
			T *poutputlo{pout}, *poutputhi{pout + count};
			std::size_t i{(count + 1 + 2) >> 2};// rounded up in the companion thread
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				do{
					U curelo{static_cast<U>(pinputlo[0].signexponent)};
					std::uint_least64_t curmlo{pinputlo[0].mantissa};
					U curehi{static_cast<U>(pinputhi[0].signexponent)};
					std::uint_least64_t curmhi{pinputhi[0].mantissa};
					// register pressure performance issue on several platforms: first do the low half here
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curmlo, curelo, pinputhi, poutputhi);
						--pinputhi;
						--poutputhi;
					}
					unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pinputhi[0].signexponent = static_cast<W>(curelo);
						poutputhi[0].signexponent = static_cast<W>(curelo);
					}
					curelo >>= 8;
					unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
					unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
					unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
					unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
					unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
					unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
					unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pinputhi[0].mantissa = curmlo;
						--pinputhi;
						poutputhi[0].mantissa = curmlo;
						--poutputhi;
					}
					curmlo >>= 56;
					++offsetscompanion[8 * 256 + static_cast<std::size_t>(curelo0)];
					curelo &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsetscompanion[curmlo0];
					curmlo1 &= 0xFFu;
					curmlo2 &= 0xFFu;
					curmlo3 &= 0xFFu;
					curmlo4 &= 0xFFu;
					curmlo5 &= 0xFFu;
					curmlo6 &= 0xFFu;
					++offsetscompanion[9 * 256 + static_cast<std::size_t>(curelo)];
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curmlo)];
					++offsetscompanion[256 + static_cast<std::size_t>(curmlo1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curmlo2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curmlo3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curmlo4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curmlo5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curmlo6)];
					// register pressure performance issue on several platforms: do the low half here second
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curmhi, curehi, pinputlo, poutputlo);
						++pinputlo;
						++poutputlo;
					}
					unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pinputlo[0].signexponent = static_cast<W>(curehi);
						poutputlo[0].signexponent = static_cast<W>(curehi);
					}
					curehi >>= 8;
					unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
					unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
					unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
					unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
					unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
					unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
					unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pinputlo[0].mantissa = curmhi;
						++pinputlo;
						poutputlo[0].mantissa = curmhi;
						++poutputlo;
					}
					curmhi >>= 56;
					++offsetscompanion[8 * 256 + static_cast<std::size_t>(curehi0)];
					curehi &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsetscompanion[curmhi0];
					curmhi1 &= 0xFFu;
					curmhi2 &= 0xFFu;
					curmhi3 &= 0xFFu;
					curmhi4 &= 0xFFu;
					curmhi5 &= 0xFFu;
					curmhi6 &= 0xFFu;
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curmhi)];
					++offsetscompanion[9 * 256 + static_cast<std::size_t>(curehi)];
					++offsetscompanion[256 + static_cast<std::size_t>(curmhi1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curmhi2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curmhi3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curmhi4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curmhi5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curmhi6)];
				}while(--i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				do{
					U curelo{static_cast<U>(pinputlo[0].signexponent)};
					std::uint_least64_t curmlo{pinputlo[0].mantissa};
					U curehi{static_cast<U>(pinputhi[0].signexponent)};
					std::uint_least64_t curmhi{pinputhi[0].mantissa};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(
							curmlo, curelo, pinputhi, poutputhi,
							curmhi, curehi, pinputlo, poutputlo);
						--pinputhi;
						--poutputhi;
						++pinputlo;
						++poutputlo;
					}
					// register pressure performance issue on several platforms: first do the low half here
					unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pinputhi[0].signexponent = static_cast<W>(curelo);
						poutputhi[0].signexponent = static_cast<W>(curelo);
					}
					curelo >>= 8;
					unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
					unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
					unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
					unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
					unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
					unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
					unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pinputhi[0].mantissa = curmlo;
						--pinputhi;
						poutputhi[0].mantissa = curmlo;
						--poutputhi;
					}
					curmlo >>= 56;
					++offsetscompanion[8 * 256 + static_cast<std::size_t>(curelo0)];
					curelo &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsetscompanion[curmlo0];
					curmlo1 &= 0xFFu;
					curmlo2 &= 0xFFu;
					curmlo3 &= 0xFFu;
					curmlo4 &= 0xFFu;
					curmlo5 &= 0xFFu;
					curmlo6 &= 0xFFu;
					++offsetscompanion[9 * 256 + static_cast<std::size_t>(curelo)];
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curmlo)];
					++offsetscompanion[256 + static_cast<std::size_t>(curmlo1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curmlo2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curmlo3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curmlo4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curmlo5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curmlo6)];
					// register pressure performance issue on several platforms: do the low half here second
					unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pinputlo[0].signexponent = static_cast<W>(curehi);
						poutputlo[0].signexponent = static_cast<W>(curehi);
					}
					curehi >>= 8;
					unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
					unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
					unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
					unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
					unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
					unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
					unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pinputlo[0].mantissa = curmhi;
						++pinputlo;
						poutputlo[0].mantissa = curmhi;
						++poutputlo;
					}
					curmhi >>= 56;
					++offsetscompanion[8 * 256 + static_cast<std::size_t>(curehi0)];
					curehi &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsetscompanion[curmhi0];
					curmhi1 &= 0xFFu;
					curmhi2 &= 0xFFu;
					curmhi3 &= 0xFFu;
					curmhi4 &= 0xFFu;
					curmhi5 &= 0xFFu;
					curmhi6 &= 0xFFu;
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curmhi)];
					++offsetscompanion[9 * 256 + static_cast<std::size_t>(curehi)];
					++offsetscompanion[256 + static_cast<std::size_t>(curmhi1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curmhi2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curmhi3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curmhi4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curmhi5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curmhi6)];
				}while(--i);
			}
		}
	}else{// not in reverse order
		input += count;
		pout += count;
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
			std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
			do{
				U cure{static_cast<U>(input[0].signexponent)};
				std::uint_least64_t curm{input[0].mantissa};
				--input;
				if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(curm, cure, pout);
					--pout;
				}
				unsigned cure0{static_cast<unsigned>(cure & 0xFFu)};
				if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
					pout[0].signexponent = static_cast<W>(cure);
				}
				cure >>= 8;
				unsigned curm0{static_cast<unsigned>(curm & 0xFFu)};
				unsigned curm1{static_cast<unsigned>(curm >> 8)};
				unsigned curm2{static_cast<unsigned>(curm >> 16)};
				unsigned curm3{static_cast<unsigned>(curm >> 24)};
				unsigned curm4{static_cast<unsigned>(curm >> 32)};
				unsigned curm5{static_cast<unsigned>(curm >> 40)};
				unsigned curm6{static_cast<unsigned>(curm >> 48)};
				if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
					pout[0].mantissa = curm;
				}
				curm >>= 56;
				++offsetscompanion[8 * 256 + static_cast<std::size_t>(cure0)];
				cure &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
				++offsetscompanion[curm0];
				curm1 &= 0xFFu;
				curm2 &= 0xFFu;
				curm3 &= 0xFFu;
				curm4 &= 0xFFu;
				curm5 &= 0xFFu;
				curm6 &= 0xFFu;
				++offsetscompanion[9 * 256 + static_cast<std::size_t>(cure)];
				++offsetscompanion[7 * 256 + static_cast<std::size_t>(curm)];
				++offsetscompanion[256 + static_cast<std::size_t>(curm1)];
				++offsetscompanion[2 * 256 + static_cast<std::size_t>(curm2)];
				++offsetscompanion[3 * 256 + static_cast<std::size_t>(curm3)];
				++offsetscompanion[4 * 256 + static_cast<std::size_t>(curm4)];
				++offsetscompanion[5 * 256 + static_cast<std::size_t>(curm5)];
				++offsetscompanion[6 * 256 + static_cast<std::size_t>(curm6)];
			}while(--i);
		}else{// architecture: do not limit as much when there's a reasonable amount of registers
			std::size_t i{(count + 1 + 2) >> 2};// rounded up in the companion thread
			do{
				U curehi{static_cast<U>(input[0].signexponent)};
				std::uint_least64_t curmhi{input[0].mantissa};
				U curelo{static_cast<U>(input[-1].signexponent)};
				std::uint_least64_t curmlo{input[-1].mantissa};
				input -= 2;
				if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(
						curmhi, curehi, pout,
						curmlo, curelo, pout - 1);
					pout -= 2;
				}
				// register pressure performance issue on several platforms: do the high half here first
				unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
				if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
					pout[0].signexponent = static_cast<W>(curehi);
				}
				curehi >>= 8;
				unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
				unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
				unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
				unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
				unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
				unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
				unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
				if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
					pout[0].mantissa = curmhi;
				}
				curmhi >>= 56;
				++offsetscompanion[8 * 256 + static_cast<std::size_t>(curehi0)];
				curehi &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
				++offsetscompanion[curmhi0];
				curmhi1 &= 0xFFu;
				curmhi2 &= 0xFFu;
				curmhi3 &= 0xFFu;
				curmhi4 &= 0xFFu;
				curmhi5 &= 0xFFu;
				curmhi6 &= 0xFFu;
				++offsetscompanion[9 * 256 + static_cast<std::size_t>(curehi)];
				++offsetscompanion[7 * 256 + static_cast<std::size_t>(curmhi)];
				++offsetscompanion[256 + static_cast<std::size_t>(curmhi1)];
				++offsetscompanion[2 * 256 + static_cast<std::size_t>(curmhi2)];
				++offsetscompanion[3 * 256 + static_cast<std::size_t>(curmhi3)];
				++offsetscompanion[4 * 256 + static_cast<std::size_t>(curmhi4)];
				++offsetscompanion[5 * 256 + static_cast<std::size_t>(curmhi5)];
				++offsetscompanion[6 * 256 + static_cast<std::size_t>(curmhi6)];
				// register pressure performance issue on several platforms: do the low half here second
				unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
				if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
					pout[-1].signexponent = static_cast<W>(curelo);
				}
				curelo >>= 8;
				unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
				unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
				unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
				unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
				unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
				unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
				unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
				if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
					pout[-1].mantissa = curmlo;
					pout -= 2;
				}
				curmlo >>= 56;
				++offsetscompanion[8 * 256 + static_cast<std::size_t>(curelo0)];
				curelo &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
				++offsetscompanion[curmlo0];
				curmlo1 &= 0xFFu;
				curmlo2 &= 0xFFu;
				curmlo3 &= 0xFFu;
				curmlo4 &= 0xFFu;
				curmlo5 &= 0xFFu;
				curmlo6 &= 0xFFu;
				++offsetscompanion[9 * 256 + static_cast<std::size_t>(curelo)];
				++offsetscompanion[7 * 256 + static_cast<std::size_t>(curmlo)];
				++offsetscompanion[256 + static_cast<std::size_t>(curmlo1)];
				++offsetscompanion[2 * 256 + static_cast<std::size_t>(curmlo2)];
				++offsetscompanion[3 * 256 + static_cast<std::size_t>(curmlo3)];
				++offsetscompanion[4 * 256 + static_cast<std::size_t>(curmlo4)];
				++offsetscompanion[5 * 256 + static_cast<std::size_t>(curmlo5)];
				++offsetscompanion[6 * 256 + static_cast<std::size_t>(curmlo6)];
			}while(--i);
		}
	}
}

// main part, multi-threading companion for the radixsortnoallocmulti2thread() function implementation template for 80-bit-based long double types without indirection
// Platforms with a native 80-bit long double type are all little endian, hence that is the only implementation here.
// Do not use this function directly.
template<bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>),
	void> radixsortnoallocmulti2threadmainmtc(std::size_t count, T const input[], T pdst[], T pdstnext[], X offsetscompanion[], unsigned runsteps, std::atomic_uintptr_t &atomiclightbarrier)noexcept{
	using W = decltype(T::signexponent);
	using U = std::conditional_t<128 == CHAR_BIT * sizeof(T), std::uint_least64_t, unsigned>;// assume zero-extension to be basically free for U on basically all modern machines, but do not remove padding
	assert(3 <= count);// this function is not for small arrays, 4 is the minimum original array count
	// do not pass a nullptr here
	assert(input);
	assert(pdst);
	assert(pdstnext);
	assert(offsetscompanion);
	assert(runsteps);
	unsigned shifter{bitscanforwardportable(runsteps)};// at least 1 bit is set inside runsteps as by previous check
	T *psrchi;
	if constexpr(isrevorder && 80 < CHAR_BIT * sizeof(T)){
		psrchi = pdstnext + count;// reverse ordering is applied here because the padding bytes could matter
	}else{// no reverse ordering applied
		psrchi = const_cast<T *>(input) + count;// psrchi will never be written to
	}
	// skip a step if possible
	runsteps >>= shifter;
	X *poffset{offsetscompanion + static_cast<std::size_t>(shifter) * 256};
	while(1 < atomiclightbarrier.load(std::memory_order_relaxed)){// continue if it's 0 or 1
		spinpause();// catch up until the other thread releases the barrier
	}// do not place this inside the main loop, as the barrier is released there by cancelling 1 and -1 in interlocked add-fetch operations
	if(80 / 8 - 2 == shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
		[[unlikely]]
#endif
		goto handletop16;// rare, but possible
	if(80 / 8 - 2 < shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
		[[unlikely]]
#endif
		goto handletop8;// rare, but possible
	shifter *= 8;
	for(;;){
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
			std::size_t j{(count + 1 + 2) >> 2};// rounded up in the top part
			do{// fill the array, two at a time
				U outea{static_cast<U>(psrchi[0].signexponent)};
				std::uint_least64_t outma{psrchi[0].mantissa};
				U outeb{static_cast<U>(psrchi[-1].signexponent)};
				std::uint_least64_t outmb{psrchi[-1].mantissa};
				psrchi -= 2;
				auto[cura, curb]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outma, outea, outmb, outeb, shifter)};
				std::size_t offseta{poffset[cura]--};// the next item will be placed one lower
				std::size_t offsetb{poffset[curb]--};
				T *pwa = pdst + offseta;
				T *pwb = pdst + offsetb;
				pwa[0].signexponent = static_cast<W>(outea);
				pwa[0].mantissa = outma;
				pwb[0].signexponent = static_cast<W>(outeb);
				pwb[0].mantissa = outmb;
			}while(--j);
		}else{// architecture: limit to four at a time when there's a decent amount of registers
			std::size_t j{(count + 1 + 4) >> 3};// rounded up in the top part
			do{// fill the array, four at a time
				U outea{static_cast<U>(psrchi[0].signexponent)};
				std::uint_least64_t outma{psrchi[0].mantissa};
				U outeb{static_cast<U>(psrchi[-1].signexponent)};
				std::uint_least64_t outmb{psrchi[-1].mantissa};
				U outec{static_cast<U>(psrchi[-2].signexponent)};
				std::uint_least64_t outmc{psrchi[-2].mantissa};
				U outed{static_cast<U>(psrchi[-3].signexponent)};
				std::uint_least64_t outmd{psrchi[-3].mantissa};
				psrchi -= 4;
				auto[cura, curb, curc, curd]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outma, outea, outmb, outeb, outmc, outec, outmd, outed, shifter)};
				std::size_t offseta{poffset[cura]--};// the next item will be placed one lower
				std::size_t offsetb{poffset[curb]--};
				std::size_t offsetc{poffset[curc]--};
				std::size_t offsetd{poffset[curd]--};
				T *pwa = pdst + offseta;
				T *pwb = pdst + offsetb;
				T *pwc = pdst + offsetc;
				T *pwd = pdst + offsetd;
				pwa[0].signexponent = static_cast<W>(outea);
				pwa[0].mantissa = outma;
				pwb[0].signexponent = static_cast<W>(outeb);
				pwb[0].mantissa = outmb;
				pwc[0].signexponent = static_cast<W>(outec);
				pwc[0].mantissa = outmc;
				pwd[0].signexponent = static_cast<W>(outed);
				pwd[0].mantissa = outmd;
			}while(--j);
		}
		runsteps >>= 1;
		if(!runsteps)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
			[[unlikely]]
#endif
			break;
		{
			unsigned index{bitscanforwardportable(runsteps)};// at least 1 bit is set inside runsteps as by previous check
			shifter += 8;
			poffset += 256;
			// swap the pointers for the next round, data is moved on each iteration
			psrchi = pdst;
			std::uintptr_t old{atomiclightbarrier.fetch_add(~static_cast<std::uintptr_t>(0))};
			pdst = pdstnext;
			pdstnext = psrchi;
			psrchi += count;
			// skip a step if possible
			runsteps >>= index;
			shifter += index * 8;
			poffset += static_cast<std::size_t>(index) * 256;
			if(!old) do{
				spinpause();
			}while(atomiclightbarrier.load(std::memory_order_relaxed));
		}
		// handle the top two parts differently
		if(80 - 16 <= shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
			[[unlikely]]
#endif
		{
			if(80 - 16 == shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
				[[likely]]
#endif
			{
handletop16:
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
					std::size_t j{(count + 1 + 2) >> 2};// rounded up in the top part
					do{// fill the array, two at a time
						U outea{static_cast<U>(psrchi[0].signexponent)};
						std::uint_least64_t outma{psrchi[0].mantissa};
						U outeb{static_cast<U>(psrchi[-1].signexponent)};
						std::uint_least64_t outmb{psrchi[-1].mantissa};
						psrchi -= 2;
						auto[cura, curb]{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(outma, outea, outmb, outeb)};
						std::size_t offseta{offsetscompanion[cura + (80 - 16) * 256 / 8]--};// the next item will be placed one lower
						std::size_t offsetb{offsetscompanion[curb + (80 - 16) * 256 / 8]--};
						T *pwa = pdst + offseta;
						T *pwb = pdst + offsetb;
						pwa[0].signexponent = static_cast<W>(outea);
						pwa[0].mantissa = outma;
						pwb[0].signexponent = static_cast<W>(outeb);
						pwb[0].mantissa = outmb;
					}while(--j);
				}else{// architecture: limit to four at a time when there's a decent amount of registers
					std::size_t j{(count + 1 + 4) >> 3};// rounded up in the top part
					do{// fill the array, four at a time
						U outea{static_cast<U>(psrchi[0].signexponent)};
						std::uint_least64_t outma{psrchi[0].mantissa};
						U outeb{static_cast<U>(psrchi[-1].signexponent)};
						std::uint_least64_t outmb{psrchi[-1].mantissa};
						U outec{static_cast<U>(psrchi[-2].signexponent)};
						std::uint_least64_t outmc{psrchi[-2].mantissa};
						U outed{static_cast<U>(psrchi[-3].signexponent)};
						std::uint_least64_t outmd{psrchi[-3].mantissa};
						psrchi -= 4;
						auto[cura, curb, curc, curd]{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(outma, outea, outmb, outeb, outmc, outec, outmd, outed)};
						std::size_t offseta{offsetscompanion[cura + (80 - 16) * 256 / 8]--};// the next item will be placed one lower
						std::size_t offsetb{offsetscompanion[curb + (80 - 16) * 256 / 8]--};
						std::size_t offsetc{offsetscompanion[curc + (80 - 16) * 256 / 8]--};
						std::size_t offsetd{offsetscompanion[curd + (80 - 16) * 256 / 8]--};
						T *pwa = pdst + offseta;
						T *pwb = pdst + offsetb;
						T *pwc = pdst + offsetc;
						T *pwd = pdst + offsetd;
						pwa[0].signexponent = static_cast<W>(outea);
						pwa[0].mantissa = outma;
						pwb[0].signexponent = static_cast<W>(outeb);
						pwb[0].mantissa = outmb;
						pwc[0].signexponent = static_cast<W>(outec);
						pwc[0].mantissa = outmc;
						pwd[0].signexponent = static_cast<W>(outed);
						pwd[0].mantissa = outmd;
					}while(--j);
				}
				if(1 == runsteps)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
					[[unlikely]]
#endif
					break;
				{
					std::uintptr_t old{atomiclightbarrier.fetch_add(~static_cast<std::uintptr_t>(0))};
					// swap the pointers for the next round, data is moved on each iteration
					psrchi = pdst;
					pdst = pdstnext;
					// unused: pdstnext = psrchi;
					psrchi += count;
					if(!old) do{
						spinpause();
					}while(atomiclightbarrier.load(std::memory_order_relaxed));
				}
handletop8:
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
					std::size_t j{(count + 1 + 2) >> 2};// rounded up in the top part
					do{// fill the array, two at a time
						U outea{static_cast<U>(psrchi[0].signexponent)};
						std::uint_least64_t outma{psrchi[0].mantissa};
						U outeb{static_cast<U>(psrchi[-1].signexponent)};
						std::uint_least64_t outmb{psrchi[-1].mantissa};
						psrchi -= 2;
						auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outma, outea, outmb, outeb)};
						std::size_t offseta{offsetscompanion[cura + (80 - 8) * 256 / 8]--};// the next item will be placed one lower
						std::size_t offsetb{offsetscompanion[curb + (80 - 8) * 256 / 8]--};
						T *pwa = pdst + offseta;
						T *pwb = pdst + offsetb;
						pwa[0].signexponent = static_cast<W>(outea);
						pwa[0].mantissa = outma;
						pwb[0].signexponent = static_cast<W>(outeb);
						pwb[0].mantissa = outmb;
					}while(--j);
				}else{// architecture: limit to four at a time when there's a decent amount of registers
					std::size_t j{(count + 1 + 4) >> 3};// rounded up in the top part
					do{// fill the array, four at a time
						U outea{static_cast<U>(psrchi[0].signexponent)};
						std::uint_least64_t outma{psrchi[0].mantissa};
						U outeb{static_cast<U>(psrchi[-1].signexponent)};
						std::uint_least64_t outmb{psrchi[-1].mantissa};
						U outec{static_cast<U>(psrchi[-2].signexponent)};
						std::uint_least64_t outmc{psrchi[-2].mantissa};
						U outed{static_cast<U>(psrchi[-3].signexponent)};
						std::uint_least64_t outmd{psrchi[-3].mantissa};
						psrchi -= 4;
						auto[cura, curb, curc, curd]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outma, outea, outmb, outeb, outmc, outec, outmd, outed)};
						std::size_t offseta{offsetscompanion[cura + (80 - 8) * 256 / 8]--};// the next item will be placed one lower
						std::size_t offsetb{offsetscompanion[curb + (80 - 8) * 256 / 8]--};
						std::size_t offsetc{offsetscompanion[curc + (80 - 8) * 256 / 8]--};
						std::size_t offsetd{offsetscompanion[curd + (80 - 8) * 256 / 8]--};
						T *pwa = pdst + offseta;
						T *pwb = pdst + offsetb;
						T *pwc = pdst + offsetc;
						T *pwd = pdst + offsetd;
						pwa[0].signexponent = static_cast<W>(outea);
						pwa[0].mantissa = outma;
						pwb[0].signexponent = static_cast<W>(outeb);
						pwb[0].mantissa = outmb;
						pwc[0].signexponent = static_cast<W>(outec);
						pwc[0].mantissa = outmc;
						pwd[0].signexponent = static_cast<W>(outed);
						pwd[0].mantissa = outmd;
					}while(--j);
				}
				break;// no further processing beyond the top part
			}
		}
	}
}

// main part for the radixsortcopynoallocmulti2thread() and radixsortnoallocmulti2thread() function implementation templates for 80-bit-based long double types without indirection
// Do not use this function directly.
template<bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, bool ismultithreadcapable, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>),
	void> radixsortnoallocmulti2threadmain(std::size_t count, T const input[], T pdst[], T pdstnext[], X offsets[], unsigned runsteps, unsigned usemultithread, std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t &, std::nullptr_t> atomiclightbarrier)noexcept{
	using W = decltype(T::signexponent);
	using U = std::conditional_t<128 == CHAR_BIT * sizeof(T), std::uint_least64_t, unsigned>;// assume zero-extension to be basically free for U on basically all modern machines, but do not remove padding
	static std::size_t constexpr offsetsstride{80 * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	assert(count && count != MAXSIZE_T);
	// do not pass a nullptr here
	assert(input);
	assert(pdst);
	assert(pdstnext);
	assert(offsets);
	assert(runsteps);
	unsigned shifter{bitscanforwardportable(runsteps)};// at least 1 bit is set inside runsteps as by previous check
	T *psrclo;
	if constexpr(isrevorder && 80 < CHAR_BIT * sizeof(T)){
		psrclo = pdstnext;// reverse ordering is applied here because the padding bytes could matter
	}else{// no reverse ordering applied
		psrclo = const_cast<T *>(input);// psrclo will never be written to
	}
	// skip a step if possible
	runsteps >>= shifter;
	X *poffset{offsets + static_cast<std::size_t>(shifter) * 256};
	if constexpr(ismultithreadcapable) while(1 < 1 + atomiclightbarrier.load(std::memory_order_relaxed)){// continue if it's 0 or -1
		spinpause();// catch up until the other thread releases the barrier
	}// do not place this inside the main loop, as the barrier is released there by cancelling 1 and -1 in interlocked add-fetch operations
	if(80 / 8 - 2 == shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
		[[unlikely]]
#endif
		goto handletop16;// rare, but possible
	if(80 / 8 - 2 < shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
		[[unlikely]]
#endif
		goto handletop8;// rare, but possible
	shifter *= 8;
	for(;;){
		if constexpr(ismultithreadcapable){
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
				std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (1 + usemultithread))};// rounded down in the bottom part
				while(0 <= --j){// fill the array, two at a time
					U outea{static_cast<U>(psrclo[0].signexponent)};
					std::uint_least64_t outma{psrclo[0].mantissa};
					U outeb{static_cast<U>(psrclo[1].signexponent)};
					std::uint_least64_t outmb{psrclo[1].mantissa};
					psrclo += 2;
					auto[cura, curb]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outma, outea, outmb, outeb, shifter)};
					std::size_t offseta{poffset[cura]++};// the next item will be placed one higher
					std::size_t offsetb{poffset[curb]++};
					T *pwa = pdst + offseta;
					T *pwb = pdst + offsetb;
					pwa[0].signexponent = static_cast<W>(outea);
					pwa[0].mantissa = outma;
					pwb[0].signexponent = static_cast<W>(outeb);
					pwb[0].mantissa = outmb;
				}
			}else{// architecture: limit to four at a time when there's a decent amount of registers
				std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (2 + usemultithread))};// rounded down in the bottom part
				while(0 <= --j){// fill the array, four at a time
					U outea{static_cast<U>(psrclo[0].signexponent)};
					std::uint_least64_t outma{psrclo[0].mantissa};
					U outeb{static_cast<U>(psrclo[1].signexponent)};
					std::uint_least64_t outmb{psrclo[1].mantissa};
					U outec{static_cast<U>(psrclo[2].signexponent)};
					std::uint_least64_t outmc{psrclo[2].mantissa};
					U outed{static_cast<U>(psrclo[3].signexponent)};
					std::uint_least64_t outmd{psrclo[3].mantissa};
					psrclo += 4;
					auto[cura, curb, curc, curd]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outma, outea, outmb, outeb, outmc, outec, outmd, outed, shifter)};
					std::size_t offseta{poffset[cura]++};// the next item will be placed one higher
					std::size_t offsetb{poffset[curb]++};
					std::size_t offsetc{poffset[curc]++};
					std::size_t offsetd{poffset[curd]++};
					T *pwa = pdst + offseta;
					T *pwb = pdst + offsetb;
					T *pwc = pdst + offsetc;
					T *pwd = pdst + offsetd;
					pwa[0].signexponent = static_cast<W>(outea);
					pwa[0].mantissa = outma;
					pwb[0].signexponent = static_cast<W>(outeb);
					pwb[0].mantissa = outmb;
					pwc[0].signexponent = static_cast<W>(outec);
					pwc[0].mantissa = outmc;
					pwd[0].signexponent = static_cast<W>(outed);
					pwd[0].mantissa = outmd;
				}
				if(2 & count + 1){// fill in the final two items for a remainder of 2 or 3
					U outea{static_cast<U>(psrclo[0].signexponent)};
					std::uint_least64_t outma{psrclo[0].mantissa};
					U outeb{static_cast<U>(psrclo[1].signexponent)};
					std::uint_least64_t outmb{psrclo[1].mantissa};
					psrclo += 2;
					auto[cura, curb]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outma, outea, outmb, outeb, shifter)};
					std::size_t offseta{poffset[cura]++};// the next item will be placed one higher
					std::size_t offsetb{poffset[curb]++};
					T *pwa = pdst + offseta;
					T *pwb = pdst + offsetb;
					pwa[0].signexponent = static_cast<W>(outea);
					pwa[0].mantissa = outma;
					pwb[0].signexponent = static_cast<W>(outeb);
					pwb[0].mantissa = outmb;
				}
			}
			if(!(1 & count)){// fill in the final item for odd counts
				U oute{static_cast<U>(psrclo[0].signexponent)};
				std::uint_least64_t outm{psrclo[0].mantissa};
				std::size_t cur{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outm, oute, shifter)};
				std::size_t offset{poffset[cur]};
				T *pw = pdst + offset;
				pw[0].signexponent = static_cast<W>(oute);
				pw[0].mantissa = outm;
			}
		}else{// !ismultithreadcapable
			T const *psrchi{psrclo + count};
			do{// fill the array, two at a time: one low-to-middle, one high-to-middle
				U outelo{static_cast<U>(psrclo[0].signexponent)};
				std::uint_least64_t outmlo{psrclo[0].mantissa};
				++psrclo;
				U outehi{static_cast<U>(psrchi[0].signexponent)};
				std::uint_least64_t outmhi{psrchi[0].mantissa};
				--psrchi;
				auto[curlo, curhi]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outmlo, outelo, outmhi, outehi, shifter)};
				std::size_t offsetlo{poffset[curlo]++};// the next item will be placed one higher
				std::size_t offsethi{poffset[curhi + offsetsstride]--};// the next item will be placed one lower
				T *pwlo = pdst + offsetlo;
				T *pwhi = pdst + offsethi;
				pwlo[0].signexponent = static_cast<W>(outelo);
				pwlo[0].mantissa = outmlo;
				pwhi[0].signexponent = static_cast<W>(outehi);
				pwhi[0].mantissa = outmhi;
			}while(psrclo < psrchi);
			if(psrclo == psrchi){// fill in the final item for odd counts
				U oute{static_cast<U>(psrclo[0].signexponent)};
				std::uint_least64_t outm{psrclo[0].mantissa};
				std::size_t cur{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outm, oute, shifter)};
				std::size_t offset{poffset[cur]};
				T *pw = pdst + offset;
				pw[0].signexponent = static_cast<W>(oute);
				pw[0].mantissa = outm;
			}
		}
		runsteps >>= 1;
		if(!runsteps)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
			[[unlikely]]
#endif
			break;
		{
			unsigned index{bitscanforwardportable(runsteps)};// at least 1 bit is set inside runsteps as by previous check
			shifter += 8;
			poffset += 256;
			// swap the pointers for the next round, data is moved on each iteration
			psrclo = pdst;
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			std::uintptr_t old;
			if constexpr(ismultithreadcapable) old = atomiclightbarrier.fetch_add(usemultithread);
			pdst = pdstnext;
			pdstnext = psrclo;
			// skip a step if possible
			runsteps >>= index;
			shifter += index * 8;
			poffset += static_cast<std::size_t>(index) * 256;
			if constexpr(ismultithreadcapable) if(old < usemultithread) do{
				spinpause();
			}while(atomiclightbarrier.load(std::memory_order_relaxed));
		}
		// handle the top two parts differently
		if(80 - 16 <= shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
			[[unlikely]]
#endif
		{
			if(80 - 16 == shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
				[[likely]]
#endif
			{
handletop16:
				if constexpr(ismultithreadcapable){
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
						std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (1 + usemultithread))};// rounded down in the bottom part
						while(0 <= --j){// fill the array, two at a time
							U outea{static_cast<U>(psrclo[0].signexponent)};
							std::uint_least64_t outma{psrclo[0].mantissa};
							U outeb{static_cast<U>(psrclo[1].signexponent)};
							std::uint_least64_t outmb{psrclo[1].mantissa};
							psrclo += 2;
							auto[cura, curb]{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(outma, outea, outmb, outeb)};
							std::size_t offseta{offsets[cura + (80 - 16) * 256 / 8]++};// the next item will be placed one higher
							std::size_t offsetb{offsets[curb + (80 - 16) * 256 / 8]++};
							T *pwa = pdst + offseta;
							T *pwb = pdst + offsetb;
							pwa[0].signexponent = static_cast<W>(outea);
							pwa[0].mantissa = outma;
							pwb[0].signexponent = static_cast<W>(outeb);
							pwb[0].mantissa = outmb;
						}
					}else{// architecture: limit to four at a time when there's a decent amount of registers
						std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (2 + usemultithread))};// rounded down in the bottom part
						while(0 <= --j){// fill the array, four at a time
							U outea{static_cast<U>(psrclo[0].signexponent)};
							std::uint_least64_t outma{psrclo[0].mantissa};
							U outeb{static_cast<U>(psrclo[1].signexponent)};
							std::uint_least64_t outmb{psrclo[1].mantissa};
							U outec{static_cast<U>(psrclo[2].signexponent)};
							std::uint_least64_t outmc{psrclo[2].mantissa};
							U outed{static_cast<U>(psrclo[3].signexponent)};
							std::uint_least64_t outmd{psrclo[3].mantissa};
							psrclo += 4;
							auto[cura, curb, curc, curd]{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(outma, outea, outmb, outeb, outmc, outec, outmd, outed)};
							std::size_t offseta{offsets[cura + (80 - 16) * 256 / 8]++};// the next item will be placed one higher
							std::size_t offsetb{offsets[curb + (80 - 16) * 256 / 8]++};
							std::size_t offsetc{offsets[curc + (80 - 16) * 256 / 8]++};
							std::size_t offsetd{offsets[curd + (80 - 16) * 256 / 8]++};
							T *pwa = pdst + offseta;
							T *pwb = pdst + offsetb;
							T *pwc = pdst + offsetc;
							T *pwd = pdst + offsetd;
							pwa[0].signexponent = static_cast<W>(outea);
							pwa[0].mantissa = outma;
							pwb[0].signexponent = static_cast<W>(outeb);
							pwb[0].mantissa = outmb;
							pwc[0].signexponent = static_cast<W>(outec);
							pwc[0].mantissa = outmc;
							pwd[0].signexponent = static_cast<W>(outed);
							pwd[0].mantissa = outmd;
						}
						if(2 & count + 1){// fill in the final two items for a remainder of 2 or 3
							U outea{static_cast<U>(psrclo[0].signexponent)};
							std::uint_least64_t outma{psrclo[0].mantissa};
							U outeb{static_cast<U>(psrclo[1].signexponent)};
							std::uint_least64_t outmb{psrclo[1].mantissa};
							psrclo += 2;
							auto[cura, curb]{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(outma, outea, outmb, outeb)};
							std::size_t offseta{offsets[cura + (80 - 16) * 256 / 8]++};// the next item will be placed one higher
							std::size_t offsetb{offsets[curb + (80 - 16) * 256 / 8]++};
							T *pwa = pdst + offseta;
							T *pwb = pdst + offsetb;
							pwa[0].signexponent = static_cast<W>(outea);
							pwa[0].mantissa = outma;
							pwb[0].signexponent = static_cast<W>(outeb);
							pwb[0].mantissa = outmb;
						}
					}
					if(!(1 & count)){// fill in the final item for odd counts
						U oute{static_cast<U>(psrclo[0].signexponent)};
						std::uint_least64_t outm{psrclo[0].mantissa};
						std::size_t cur{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(outm, oute)};
						std::size_t offset{offsets[cur + (80 - 16) * 256 / 8]};
						T *pw = pdst + offset;
						pw[0].signexponent = static_cast<W>(oute);
						pw[0].mantissa = outm;
					}
				}else{// !ismultithreadcapable
					T const *psrchi{psrclo + count};
					do{// fill the array, two at a time: one low-to-middle, one high-to-middle
						U outelo{static_cast<U>(psrclo[0].signexponent)};
						std::uint_least64_t outmlo{psrclo[0].mantissa};
						++psrclo;
						U outehi{static_cast<U>(psrchi[0].signexponent)};
						std::uint_least64_t outmhi{psrchi[0].mantissa};
						--psrchi;
						auto[curlo, curhi]{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(outmlo, outelo, outmhi, outehi)};
						std::size_t offsetlo{offsets[curlo + (80 - 16) * 256 / 8]++};// the next item will be placed one higher
						std::size_t offsethi{offsets[curhi + (80 - 16) * 256 / 8 + offsetsstride]--};// the next item will be placed one lower
						T *pwlo = pdst + offsetlo;
						T *pwhi = pdst + offsethi;
						pwlo[0].signexponent = static_cast<W>(outelo);
						pwlo[0].mantissa = outmlo;
						pwhi[0].signexponent = static_cast<W>(outehi);
						pwhi[0].mantissa = outmhi;
					}while(psrclo < psrchi);
					if(psrclo == psrchi){// fill in the final item for odd counts
						U oute{static_cast<U>(psrclo[0].signexponent)};
						std::uint_least64_t outm{psrclo[0].mantissa};
						std::size_t cur{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(outm, oute)};
						std::size_t offset{offsets[cur + (80 - 16) * 256 / 8]};
						T *pw = pdst + offset;
						pw[0].signexponent = static_cast<W>(oute);
						pw[0].mantissa = outm;
					}
				}
				runsteps >>= 1;
				if(!runsteps)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
					[[unlikely]]
#endif
					break;
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
				[[maybe_unused]]
#endif
				std::uintptr_t old;
				if constexpr(ismultithreadcapable) old = atomiclightbarrier.fetch_add(usemultithread);
				// swap the pointers for the next round, data is moved on each iteration
				psrclo = pdst;
				pdst = pdstnext;
				// unused: pdstnext = psrclo;
				if constexpr(ismultithreadcapable) if(old < usemultithread) do{
					spinpause();
				}while(atomiclightbarrier.load(std::memory_order_relaxed));
			}
handletop8:
			if constexpr(ismultithreadcapable){
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
					std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (1 + usemultithread))};// rounded down in the bottom part
					while(0 <= --j){// fill the array, two at a time
						U outea{static_cast<U>(psrclo[0].signexponent)};
						std::uint_least64_t outma{psrclo[0].mantissa};
						U outeb{static_cast<U>(psrclo[1].signexponent)};
						std::uint_least64_t outmb{psrclo[1].mantissa};
						psrclo += 2;
						auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outma, outea, outmb, outeb)};
						std::size_t offseta{offsets[cura + (80 - 8) * 256 / 8]++};// the next item will be placed one higher
						std::size_t offsetb{offsets[curb + (80 - 8) * 256 / 8]++};
						T *pwa = pdst + offseta;
						T *pwb = pdst + offsetb;
						pwa[0].signexponent = static_cast<W>(outea);
						pwa[0].mantissa = outma;
						pwb[0].signexponent = static_cast<W>(outeb);
						pwb[0].mantissa = outmb;
					}
				}else{// architecture: limit to four at a time when there's a decent amount of registers
					std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (2 + usemultithread))};// rounded down in the bottom part
					while(0 <= --j){// fill the array, four at a time
						U outea{static_cast<U>(psrclo[0].signexponent)};
						std::uint_least64_t outma{psrclo[0].mantissa};
						U outeb{static_cast<U>(psrclo[1].signexponent)};
						std::uint_least64_t outmb{psrclo[1].mantissa};
						U outec{static_cast<U>(psrclo[2].signexponent)};
						std::uint_least64_t outmc{psrclo[2].mantissa};
						U outed{static_cast<U>(psrclo[3].signexponent)};
						std::uint_least64_t outmd{psrclo[3].mantissa};
						psrclo += 4;
						auto[cura, curb, curc, curd]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outma, outea, outmb, outeb, outmc, outec, outmd, outed)};
						std::size_t offseta{offsets[cura + (80 - 8) * 256 / 8]++};// the next item will be placed one higher
						std::size_t offsetb{offsets[curb + (80 - 8) * 256 / 8]++};
						std::size_t offsetc{offsets[curc + (80 - 8) * 256 / 8]++};
						std::size_t offsetd{offsets[curd + (80 - 8) * 256 / 8]++};
						T *pwa = pdst + offseta;
						T *pwb = pdst + offsetb;
						T *pwc = pdst + offsetc;
						T *pwd = pdst + offsetd;
						pwa[0].signexponent = static_cast<W>(outea);
						pwa[0].mantissa = outma;
						pwb[0].signexponent = static_cast<W>(outeb);
						pwb[0].mantissa = outmb;
						pwc[0].signexponent = static_cast<W>(outec);
						pwc[0].mantissa = outmc;
						pwd[0].signexponent = static_cast<W>(outed);
						pwd[0].mantissa = outmd;
					}
					if(2 & count + 1){// fill in the final two items for a remainder of 2 or 3
						U outea{static_cast<U>(psrclo[0].signexponent)};
						std::uint_least64_t outma{psrclo[0].mantissa};
						U outeb{static_cast<U>(psrclo[1].signexponent)};
						std::uint_least64_t outmb{psrclo[1].mantissa};
						psrclo += 2;
						auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outma, outea, outmb, outeb)};
						std::size_t offseta{offsets[cura + (80 - 8) * 256 / 8]++};// the next item will be placed one higher
						std::size_t offsetb{offsets[curb + (80 - 8) * 256 / 8]++};
						T *pwa = pdst + offseta;
						T *pwb = pdst + offsetb;
						pwa[0].signexponent = static_cast<W>(outea);
						pwa[0].mantissa = outma;
						pwb[0].signexponent = static_cast<W>(outeb);
						pwb[0].mantissa = outmb;
					}
				}
				if(!(1 & count)){// fill in the final item for odd counts
					U oute{static_cast<U>(psrclo[0].signexponent)};
					std::uint_least64_t outm{psrclo[0].mantissa};
					std::size_t cur{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outm, oute)};
					std::size_t offset{offsets[cur + (80 - 8) * 256 / 8]};
					T *pw = pdst + offset;
					pw[0].signexponent = static_cast<W>(oute);
					pw[0].mantissa = outm;
				}
			}else{// !ismultithreadcapable
				T const *psrchi{psrclo + count};
				do{// fill the array, two at a time: one low-to-middle, one high-to-middle
					U outelo{static_cast<U>(psrclo[0].signexponent)};
					std::uint_least64_t outmlo{psrclo[0].mantissa};
					++psrclo;
					U outehi{static_cast<U>(psrchi[0].signexponent)};
					std::uint_least64_t outmhi{psrchi[0].mantissa};
					--psrchi;
					auto[curlo, curhi]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outmlo, outelo, outmhi, outehi)};
					std::size_t offsetlo{offsets[curlo + (80 - 8) * 256 / 8]++};// the next item will be placed one higher
					std::size_t offsethi{offsets[curhi + (80 - 8) * 256 / 8 + offsetsstride]--};// the next item will be placed one lower
					T *pwlo = pdst + offsetlo;
					T *pwhi = pdst + offsethi;
					pwlo[0].signexponent = static_cast<W>(outelo);
					pwlo[0].mantissa = outmlo;
					pwhi[0].signexponent = static_cast<W>(outehi);
					pwhi[0].mantissa = outmhi;
				}while(psrclo < psrchi);
				if(psrclo == psrchi){// fill in the final item for odd counts
					U oute{static_cast<U>(psrclo[0].signexponent)};
					std::uint_least64_t outm{psrclo[0].mantissa};
					std::size_t cur{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outm, oute)};
					std::size_t offset{offsets[cur + (80 - 8) * 256 / 8]};
					T *pw = pdst + offset;
					pw[0].signexponent = static_cast<W>(oute);
					pw[0].mantissa = outm;
				}
			}
			break;// no further processing beyond the top part
		}
	}
}

// multi-threading companion for the radixsortcopynoallocmulti2thread() function implementation template for 80-bit-based long double types without indirection
// Do not use this function directly.
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>),
	void> radixsortcopynoallocmulti2threadmtc(std::size_t count, T const input[], T output[], T buffer[], std::atomic_uintptr_t &atomiclightbarrier)noexcept{
	// do not pass a nullptr here
	assert(input);
	assert(output);
	assert(buffer);
	static std::size_t constexpr offsetsstride{80 * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	X offsetscompanion[offsetsstride]{};// a sizeable amount of indices, but it's worth it, zeroed in advance here
	radixsortnoallocmulti2threadinitmtc<isrevorder, isabsvalue, issignmode, isfltpmode, true, T, X>(count, input, output, buffer, offsetscompanion);

	X *offsets;
	{// barrier and pointer exchange with the main thread
		std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsetscompanion))};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed);
			}while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == other);
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		offsets = reinterpret_cast<X *>(other);// retrieve the pointer
	}

	// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
	auto[runsteps, paritybool]{generateoffsetsmultimtc<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, offsets, offsetscompanion)};

	{// barrier and (flipped bits) runsteps, paritybool value exchange with the main thread
		// paritybool is either 0 or 1 here, so we can pack it together with runsteps and add usemultithread on top
		std::uintptr_t compound{static_cast<std::uintptr_t>(runsteps) * 2 + static_cast<std::uintptr_t>(paritybool) + 1};
		while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == atomiclightbarrier.load(std::memory_order_relaxed)){
			spinpause();// catch up
		}
		std::uintptr_t other{atomiclightbarrier.fetch_add(compound)};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed) - compound;
			}while(!other);
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		other += compound;// combine
		unsigned lowercarryoutbits{2 + paritybool};
		paritybool = static_cast<unsigned>(other) & 1;// piece together the parity from both threads
		other -= lowercarryoutbits;// this will remove possiby two bits of carry-out before the next right shift
		runsteps = static_cast<unsigned>(other >> 1);// this can shift out a 0 or a 1 bit here, depending on the leftovers of parity
	}

	// perform the bidirectional 8-bit sorting sequence
	// flip the relevant bits inside runsteps first
	if(runsteps ^= (1u << 80 / 8) - 1)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
		[[likely]]
#endif
	{// perform the bidirectional 8-bit sorting sequence
		T *pdst{buffer}, *pdstnext{output};// for the next iteration
		if(paritybool){// swap if the count of sorting actions to do is odd
			pdst = output;
			pdstnext = buffer;
		}
		radixsortnoallocmulti2threadmainmtc<isrevorder, isabsvalue, issignmode, isfltpmode, T, X>(count, input, pdst, pdstnext, offsetscompanion, runsteps, atomiclightbarrier);
	}
}

// radixsortcopynoalloc() function implementation template for 80-bit-based long double types without indirection
// Platforms with a native 80-bit long double type are all little endian, hence that is the only implementation here.
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	, bool ismultithreadcapable = true
#endif
	>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_unsigned_v<X> &&
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>),
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	radixsortcopynoallocmulti1thread
#else
	radixsortcopynoallocmulti2thread
#endif
	(std::size_t count, T const input[], T output[], T buffer[])noexcept{
	using W = decltype(T::signexponent);
	using U = std::conditional_t<128 == CHAR_BIT * sizeof(T), std::uint_least64_t, unsigned>;// assume zero-extension to be basically free for U on basically all modern machines, but do not remove padding
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	static bool constexpr ismultithreadcapable{false};
#endif
	if constexpr(ismultithreadcapable){
		assert(1 < std::thread::hardware_concurrency());// only use multi-threading if there is more than one hardware thread
		assert(15 <= count);// a 0 or 1 count array is only allowed here in single-threaded function mode
	}
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);
	assert(buffer);
	// All the code in this function is adapted for count to be one below its input value here.
	--count;
	if(ismultithreadcapable || 0 < static_cast<std::ptrdiff_t>(count)){// a 0 or 1 count array is only allowed here in single-threaded function mode
		static std::size_t constexpr offsetsstride{80 * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
		// conditionally enable multi-threading here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t, std::nullptr_t> atomiclightbarrier{};
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::future<void>, std::nullptr_t> asynchandle;

		// count the 256 configurations, all in one go
		if constexpr(ismultithreadcapable){
			try{
				asynchandle = std::async(std::launch::async, radixsortcopynoallocmulti2threadmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, X>, count, input, output, buffer, std::ref(atomiclightbarrier));
				usemultithread = 1;
			}catch(...){// std::async may fail gracefully here
				assert(false);
			}
		}
		X offsets[offsetsstride * (2 - ismultithreadcapable)];// a sizeable amount of indices, but it's worth it
		std::memset(offsets, 0, offsetsstride * sizeof(X));// zeroed in advance here
		std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
		if constexpr(ismultithreadcapable){
			// architecture: limit to one at a time when there's few registers
			if constexpr(defaultgprfilesize < gprfilesize::large) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
			else i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
		}
		if constexpr(isrevorder && 80 < CHAR_BIT * sizeof(T)){// also reverse the array at the same time
			// reverse ordering is applied here because the padding bytes could matter, hence the check above
			T const *pinput{input + count};
			T *poutput{output};
			T *pbuffer{buffer};
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				do{
					U cure{pinput->signexponent};
					std::uint_least64_t curm{pinput->mantissa};
					--pinput;
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curm, cure, poutput, pbuffer);
						++poutput;
						++pbuffer;
					}
					unsigned cure0{static_cast<unsigned>(cure & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						poutput[0].signexponent = static_cast<W>(cure);
						pbuffer[0].signexponent = static_cast<W>(cure);
					}
					cure >>= 8;
					unsigned curm0{static_cast<unsigned>(curm & 0xFFu)};
					unsigned curm1{static_cast<unsigned>(curm >> 8)};
					unsigned curm2{static_cast<unsigned>(curm >> 16)};
					unsigned curm3{static_cast<unsigned>(curm >> 24)};
					unsigned curm4{static_cast<unsigned>(curm >> 32)};
					unsigned curm5{static_cast<unsigned>(curm >> 40)};
					unsigned curm6{static_cast<unsigned>(curm >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						poutput[0].mantissa = curm;
						++poutput;
						pbuffer[0].mantissa = curm;
						++pbuffer;
					}
					curm >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(cure0)];
					cure &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsets[curm0];
					curm1 &= 0xFFu;
					curm2 &= 0xFFu;
					curm3 &= 0xFFu;
					curm4 &= 0xFFu;
					curm5 &= 0xFFu;
					curm6 &= 0xFFu;
					++offsets[9 * 256 + static_cast<std::size_t>(cure)];
					++offsets[7 * 256 + static_cast<std::size_t>(curm)];
					++offsets[256 + static_cast<std::size_t>(curm1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curm2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curm3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curm4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curm5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curm6)];
				}while(0 <= --i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				do{
					U curehi{static_cast<U>(pinput[0].signexponent)};
					std::uint_least64_t curmhi{pinput[0].mantissa};
					U curelo{static_cast<U>(pinput[-1].signexponent)};
					std::uint_least64_t curmlo{pinput[-1].mantissa};
					pinput -= 2;
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(
							curmhi, curehi, poutput, pbuffer,
							curmlo, curelo, poutput + 1, pbuffer + 1);
						poutput += 2;
						pbuffer += 2;
					}
					// register pressure performance issue on several platforms: first do the high half here
					unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						poutput[0].signexponent = static_cast<W>(curehi);
						pbuffer[0].signexponent = static_cast<W>(curehi);
					}
					curehi >>= 8;
					unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
					unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
					unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
					unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
					unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
					unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
					unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						poutput[0].mantissa = curmhi;
						pbuffer[0].mantissa = curmhi;
					}
					curmhi >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(curehi0)];
					curehi &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsets[curmhi0];
					curmhi1 &= 0xFFu;
					curmhi2 &= 0xFFu;
					curmhi3 &= 0xFFu;
					curmhi4 &= 0xFFu;
					curmhi5 &= 0xFFu;
					curmhi6 &= 0xFFu;
					++offsets[9 * 256 + static_cast<std::size_t>(curehi)];
					++offsets[7 * 256 + static_cast<std::size_t>(curmhi)];
					++offsets[256 + static_cast<std::size_t>(curmhi1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curmhi2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curmhi3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curmhi4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curmhi5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curmhi6)];
					// register pressure performance issue on several platforms: do the low half here second
					unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						poutput[1].signexponent = static_cast<W>(curelo);
						pbuffer[1].signexponent = static_cast<W>(curelo);
					}
					curelo >>= 8;
					unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
					unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
					unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
					unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
					unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
					unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
					unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						poutput[1].mantissa = curmlo;
						poutput += 2;
						pbuffer[1].mantissa = curmlo;
						pbuffer += 2;
					}
					curmlo >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(curelo0)];
					curelo &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsets[curmlo0];
					curmlo1 &= 0xFFu;
					curmlo2 &= 0xFFu;
					curmlo3 &= 0xFFu;
					curmlo4 &= 0xFFu;
					curmlo5 &= 0xFFu;
					curmlo6 &= 0xFFu;
					++offsets[7 * 256 + static_cast<std::size_t>(curmlo)];
					++offsets[9 * 256 + static_cast<std::size_t>(curelo)];
					++offsets[256 + static_cast<std::size_t>(curmlo1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curmlo2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curmlo3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curmlo4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curmlo5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curmlo6)];
					i -= 2;
				}while(0 < i);
				if(!(1 & i)){// fill in the final item for odd counts
					U cure{pinput->signexponent};
					std::uint_least64_t curm{pinput->mantissa};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curm, cure, poutput, pbuffer);
					}
					unsigned cure0{static_cast<unsigned>(cure & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						poutput[0].signexponent = static_cast<W>(cure);
						pbuffer[0].signexponent = static_cast<W>(cure);
					}
					cure >>= 8;
					unsigned curm0{static_cast<unsigned>(curm & 0xFFu)};
					unsigned curm1{static_cast<unsigned>(curm >> 8)};
					unsigned curm2{static_cast<unsigned>(curm >> 16)};
					unsigned curm3{static_cast<unsigned>(curm >> 24)};
					unsigned curm4{static_cast<unsigned>(curm >> 32)};
					unsigned curm5{static_cast<unsigned>(curm >> 40)};
					unsigned curm6{static_cast<unsigned>(curm >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						poutput[0].mantissa = curm;
						pbuffer[0].mantissa = curm;
					}
					curm >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(cure0)];
					cure &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsets[curm0];
					curm1 &= 0xFFu;
					curm2 &= 0xFFu;
					curm3 &= 0xFFu;
					curm4 &= 0xFFu;
					curm5 &= 0xFFu;
					curm6 &= 0xFFu;
					++offsets[9 * 256 + static_cast<std::size_t>(cure)];
					++offsets[7 * 256 + static_cast<std::size_t>(curm)];
					++offsets[256 + static_cast<std::size_t>(curm1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curm2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curm3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curm4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curm5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curm6)];
				}
			}
		}else{// not in reverse order
			T const *pinput{input};
			T *poutput{output};
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				do{
					U cure{pinput->signexponent};
					std::uint_least64_t curm{pinput->mantissa};
					++pinput;
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curm, cure, poutput);
						++poutput;
					}
					unsigned cure0{static_cast<unsigned>(cure & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						poutput[0].signexponent = static_cast<W>(cure);
					}
					cure >>= 8;
					unsigned curm0{static_cast<unsigned>(curm & 0xFFu)};
					unsigned curm1{static_cast<unsigned>(curm >> 8)};
					unsigned curm2{static_cast<unsigned>(curm >> 16)};
					unsigned curm3{static_cast<unsigned>(curm >> 24)};
					unsigned curm4{static_cast<unsigned>(curm >> 32)};
					unsigned curm5{static_cast<unsigned>(curm >> 40)};
					unsigned curm6{static_cast<unsigned>(curm >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						poutput[0].mantissa = curm;
						++poutput;
					}
					curm >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(cure0)];
					cure &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
					++offsets[curm0];
					curm1 &= 0xFFu;
					curm2 &= 0xFFu;
					curm3 &= 0xFFu;
					curm4 &= 0xFFu;
					curm5 &= 0xFFu;
					curm6 &= 0xFFu;
					++offsets[9 * 256 + static_cast<std::size_t>(cure)];
					++offsets[7 * 256 + static_cast<std::size_t>(curm)];
					++offsets[256 + static_cast<std::size_t>(curm1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curm2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curm3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curm4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curm5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curm6)];
				}while(0 <= --i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				do{
					U curelo{static_cast<U>(pinput[0].signexponent)};
					std::uint_least64_t curmlo{pinput[0].mantissa};
					U curehi{static_cast<U>(pinput[1].signexponent)};
					std::uint_least64_t curmhi{pinput[1].mantissa};
					pinput += 2;
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(
							curmlo, curelo, poutput,
							curmhi, curehi, poutput + 1);
						poutput += 2;
					}
					unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						poutput[0].signexponent = static_cast<W>(curelo);
					}
					curelo >>= 8;
					unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
					unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
					unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
					unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
					unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
					unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
					unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						poutput[0].mantissa = curmlo;
					}
					curmlo >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(curelo0)];
					curelo &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
					++offsets[curmlo0];
					curmlo1 &= 0xFFu;
					curmlo2 &= 0xFFu;
					curmlo3 &= 0xFFu;
					curmlo4 &= 0xFFu;
					curmlo5 &= 0xFFu;
					curmlo6 &= 0xFFu;
					++offsets[9 * 256 + static_cast<std::size_t>(curelo)];
					++offsets[7 * 256 + static_cast<std::size_t>(curmlo)];
					++offsets[256 + static_cast<std::size_t>(curmlo1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curmlo2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curmlo3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curmlo4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curmlo5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curmlo6)];
					// register pressure performance issue on several platforms: do the low half here second
					unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						poutput[1].signexponent = static_cast<W>(curehi);
					}
					curehi >>= 8;
					unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
					unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
					unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
					unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
					unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
					unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
					unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						poutput[1].mantissa = curmhi;
						poutput += 2;
					}
					curmhi >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(curehi0)];
					curehi &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
					++offsets[curmhi0];
					curmhi1 &= 0xFFu;
					curmhi2 &= 0xFFu;
					curmhi3 &= 0xFFu;
					curmhi4 &= 0xFFu;
					curmhi5 &= 0xFFu;
					curmhi6 &= 0xFFu;
					++offsets[9 * 256 + static_cast<std::size_t>(curehi)];
					++offsets[7 * 256 + static_cast<std::size_t>(curmhi)];
					++offsets[256 + static_cast<std::size_t>(curmhi1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curmhi2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curmhi3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curmhi4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curmhi5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curmhi6)];
					i -= 2;
				}while(0 < i);
				if(!(1 & i)){// fill in the final item for odd counts
					U cure{pinput->signexponent};
					std::uint_least64_t curm{pinput->mantissa};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curm, cure, poutput);
					}
					unsigned cure0{static_cast<unsigned>(cure & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						poutput[0].signexponent = static_cast<W>(cure);
					}
					cure >>= 8;
					unsigned curm0{static_cast<unsigned>(curm & 0xFFu)};
					unsigned curm1{static_cast<unsigned>(curm >> 8)};
					unsigned curm2{static_cast<unsigned>(curm >> 16)};
					unsigned curm3{static_cast<unsigned>(curm >> 24)};
					unsigned curm4{static_cast<unsigned>(curm >> 32)};
					unsigned curm5{static_cast<unsigned>(curm >> 40)};
					unsigned curm6{static_cast<unsigned>(curm >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						poutput[0].mantissa = curm;
					}
					curm >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(cure0)];
					cure &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
					++offsets[curm0];
					curm1 &= 0xFFu;
					curm2 &= 0xFFu;
					curm3 &= 0xFFu;
					curm4 &= 0xFFu;
					curm5 &= 0xFFu;
					curm6 &= 0xFFu;
					++offsets[9 * 256 + static_cast<std::size_t>(cure)];
					++offsets[7 * 256 + static_cast<std::size_t>(curm)];
					++offsets[256 + static_cast<std::size_t>(curm1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curm2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curm3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curm4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curm5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curm6)];
				}
			}
		}

		// barrier and pointer exchange with the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, X *, std::nullptr_t> offsetscompanion;
		if constexpr(ismultithreadcapable){
			std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsets) & -static_cast<std::intptr_t>(usemultithread))};
			// simply do not spin if usemultithread is zero
			if(usemultithread > other){
				do{
					spinpause();
					other = atomiclightbarrier.load(std::memory_order_relaxed);
				}while(reinterpret_cast<std::uintptr_t>(offsets) == other);
				// reset the barrier after use, only one thread will do this
				// no busy-wait dependency on this store, hence relaxed memory order is fine
				reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
				// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
			}
			// this will just be zero if usemultithread is zero
			offsetscompanion = reinterpret_cast<X *>(other);// retrieve the pointer
		}else offsetscompanion = nullptr;

		// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
		auto[runsteps, paritybool]{generateoffsetsmulti<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, offsets, offsetscompanion, usemultithread)};

		// barrier and (flipped bits) runsteps, paritybool value exchange with the companion thread
		if constexpr(ismultithreadcapable){
			// paritybool is either 0 or 1 here, so we can pack it together with runsteps and add usemultithread on top
			std::uintptr_t compound{static_cast<std::uintptr_t>(runsteps) * 2 + static_cast<std::uintptr_t>(paritybool) + static_cast<std::uintptr_t>(usemultithread)};
			while(reinterpret_cast<std::uintptr_t>(offsets) == atomiclightbarrier.load(std::memory_order_relaxed)){
				spinpause();// catch up
			}
			std::uintptr_t other{atomiclightbarrier.fetch_add(compound & -static_cast<std::intptr_t>(usemultithread))};
			// simply do not spin if usemultithread is zero
			if(usemultithread > other){
				do{
					spinpause();
					other = atomiclightbarrier.load(std::memory_order_relaxed) - compound;
				}while(!other);
				// reset the barrier after use, only one thread will do this
				// no busy-wait dependency on this store, hence relaxed memory order is fine
				reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
				// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
			}
			other += compound;// combine
			unsigned lowercarryoutbits{2 * usemultithread + paritybool};
			paritybool = static_cast<unsigned>(other) & 1;// piece together the parity from both threads
			other -= lowercarryoutbits;// this will remove possiby two bits of carry-out before the next right shift
			runsteps = static_cast<unsigned>(other >> 1);// this can shift out a 0 or a 1 bit here, depending on the leftovers of parity
		}

		// perform the bidirectional 8-bit sorting sequence
		// flip the relevant bits inside runsteps first
		if(runsteps ^= (1u << 80 / 8) - 1)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
			[[likely]]
#endif
		{
			T *pdst{buffer}, *pdstnext{output};// for the next iteration
			if(paritybool){// swap if the count of sorting actions to do is odd
				pdst = output;
				pdstnext = buffer;
			}
			radixsortnoallocmulti2threadmain<isrevorder, isabsvalue, issignmode, isfltpmode, ismultithreadcapable, T, X>(count, input, pdst, pdstnext, offsets, runsteps, usemultithread, atomiclightbarrier);
		}
	}else if(0 == static_cast<std::ptrdiff_t>(count)) *output = *input;// copy the single element if the count is 1
}

// multi-threading companion for the radixsortnoallocmulti2thread() function implementation template for 80-bit-based long double types without indirection
// Do not use this function directly.
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>),
	void> radixsortnoallocmulti2threadmtc(std::size_t count, T input[], T buffer[], std::atomic_uintptr_t &atomiclightbarrier)noexcept{
	// do not pass a nullptr here
	assert(input);
	assert(buffer);
	static std::size_t constexpr offsetsstride{80 * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	X offsetscompanion[offsetsstride]{};// a sizeable amount of indices, but it's worth it, zeroed in advance here
	radixsortnoallocmulti2threadinitmtc<isrevorder, isabsvalue, issignmode, isfltpmode, false, T, X>(count, input, buffer, nullptr, offsetscompanion);

	X *offsets;
	{// barrier and pointer exchange with the main thread
		std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsetscompanion))};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed);
			}while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == other);
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		offsets = reinterpret_cast<X *>(other);// retrieve the pointer
	}

	// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
	auto[runsteps, paritybool]{generateoffsetsmultimtc<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, offsets, offsetscompanion)};

	{// barrier and (flipped bits) runsteps, paritybool value exchange with the main thread
		// paritybool is either 0 or 1 here, so we can pack it together with runsteps and add usemultithread on top
		std::uintptr_t compound{static_cast<std::uintptr_t>(runsteps) * 2 + static_cast<std::uintptr_t>(paritybool) + 1};
		while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == atomiclightbarrier.load(std::memory_order_relaxed)){
			spinpause();// catch up
		}
		std::uintptr_t other{atomiclightbarrier.fetch_add(compound)};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed) - compound;
			}while(!other);
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		other += compound;// combine
		unsigned lowercarryoutbits{2 + paritybool};
		paritybool = static_cast<unsigned>(other) & 1;// piece together the parity from both threads
		other -= lowercarryoutbits;// this will remove possiby two bits of carry-out before the next right shift
		runsteps = static_cast<unsigned>(other >> 1);// this can shift out a 0 or a 1 bit here, depending on the leftovers of parity
	}

	// perform the bidirectional 8-bit sorting sequence
	// flip the relevant bits inside runsteps first
	if(runsteps ^= (1u << 80 / 8) - 1)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
		[[likely]]
#endif
	{// perform the bidirectional 8-bit sorting sequence
		T *psrclo{input}, *pdst{buffer};
		if(paritybool){// swap if the count of sorting actions to do is odd
			psrclo = buffer;
			pdst = input;
		}
		radixsortnoallocmulti2threadmainmtc<isrevorder, isabsvalue, issignmode, isfltpmode, T, X>(count, psrclo, pdst, psrclo, offsetscompanion, runsteps, atomiclightbarrier);
	}
}

// radixsortnoalloc() function implementation template for 80-bit-based long double types without indirection
// Platforms with a native 80-bit long double type are all little endian, hence that is the only implementation here.
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	, bool ismultithreadcapable = true
#endif
	>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_unsigned_v<X> &&
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>),
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	radixsortnoallocmulti1thread
#else
	radixsortnoallocmulti2thread
#endif
	(std::size_t count, T input[], T buffer[], bool movetobuffer = false)noexcept{
	using W = decltype(T::signexponent);
	using U = std::conditional_t<128 == CHAR_BIT * sizeof(T), std::uint_least64_t, unsigned>;// assume zero-extension to be basically free for U on basically all modern machines, but do not remove padding
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	static bool constexpr ismultithreadcapable{false};
#endif
	if constexpr(ismultithreadcapable){
		assert(1 < std::thread::hardware_concurrency());// only use multi-threading if there is more than one hardware thread
		assert(15 <= count);// a 0 or 1 count array is only allowed here in single-threaded function mode
	}
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(buffer);
	// All the code in this function is adapted for count to be one below its input value here.
	--count;
	if(ismultithreadcapable || 0 < static_cast<std::ptrdiff_t>(count)){// a 0 or 1 count array is only allowed here in single-threaded function mode
		static std::size_t constexpr offsetsstride{80 * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
		// conditionally enable multi-threading here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t, std::nullptr_t> atomiclightbarrier{};
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::future<void>, std::nullptr_t> asynchandle;

		// count the 256 configurations, all in one go
		if constexpr(ismultithreadcapable){
			try{
				asynchandle = std::async(std::launch::async, radixsortnoallocmulti2threadmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, X>, count, input, buffer, std::ref(atomiclightbarrier));
				usemultithread = 1;
			}catch(...){// std::async may fail gracefully here
				assert(false);
			}
		}
		X offsets[offsetsstride * (2 - ismultithreadcapable)];// a sizeable amount of indices, but it's worth it
		std::memset(offsets, 0, offsetsstride * sizeof(X));// zeroed in advance here
		if constexpr(isrevorder && 80 < CHAR_BIT * sizeof(T)){// also reverse the array at the same time
			// reverse ordering is applied here because the padding bytes could matter, hence the check above
			T *pinputlo, *pinputhi, *pbufferlo, *pbufferhi;
			if constexpr(!ismultithreadcapable){
				pinputlo = input;
				pinputhi = input + count;
				pbufferlo = buffer;
				pbufferhi = buffer + count;
			}else{// if mulitithreaded, the half count will be rounded up in the companion thread
				std::ptrdiff_t stride{-static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2)};
				pinputlo = input + stride;
				pinputhi = input + (count - stride);
				pbufferlo = buffer + stride;
				pbufferhi = buffer + (count - stride);
			}
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				do{
					U curelo{pinputlo->signexponent};
					std::uint_least64_t curmlo{pinputlo->mantissa};
					U curehi{pinputhi->signexponent};
					std::uint_least64_t curmhi{pinputhi->mantissa};
					// register pressure performance issue on several platforms: first do the low half here
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curmlo, curelo, pinputhi, pbufferhi);
						--pinputhi;
						--pbufferhi;
					}
					unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pinputhi[0].signexponent = static_cast<W>(curelo);
						pbufferhi[0].signexponent = static_cast<W>(curelo);
					}
					curelo >>= 8;
					unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
					unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
					unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
					unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
					unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
					unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
					unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pinputhi[0].mantissa = curmlo;
						--pinputhi;
						pbufferhi[0].mantissa = curmlo;
						--pbufferhi;
					}
					curmlo >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(curelo0)];
					curelo &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsets[curmlo0];
					curmlo1 &= 0xFFu;
					curmlo2 &= 0xFFu;
					curmlo3 &= 0xFFu;
					curmlo4 &= 0xFFu;
					curmlo5 &= 0xFFu;
					curmlo6 &= 0xFFu;
					++offsets[9 * 256 + static_cast<std::size_t>(curelo)];
					++offsets[7 * 256 + static_cast<std::size_t>(curmlo)];
					++offsets[256 + static_cast<std::size_t>(curmlo1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curmlo2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curmlo3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curmlo4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curmlo5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curmlo6)];
					// register pressure performance issue on several platforms: do the high half here second
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curmhi, curehi, pinputlo, pbufferlo);
						++pinputlo;
						++pbufferlo;
					}
					unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pinputlo[0].signexponent = static_cast<W>(curehi);
						pbufferlo[0].signexponent = static_cast<W>(curehi);
					}
					curehi >>= 8;
					unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
					unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
					unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
					unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
					unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
					unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
					unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pinputlo[0].mantissa = curmlo;
						++pinputlo;
						pbufferlo[0].mantissa = curmhi;
						++pbufferlo;
					}
					curmhi >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(curehi0)];
					curehi &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsets[curmhi0];
					curmhi1 &= 0xFFu;
					curmhi2 &= 0xFFu;
					curmhi3 &= 0xFFu;
					curmhi4 &= 0xFFu;
					curmhi5 &= 0xFFu;
					curmhi6 &= 0xFFu;
					++offsets[9 * 256 + static_cast<std::size_t>(curehi)];
					++offsets[7 * 256 + static_cast<std::size_t>(curmhi)];
					++offsets[256 + static_cast<std::size_t>(curmhi1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curmhi2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curmhi3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curmhi4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curmhi5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curmhi6)];
				}while(pinputlo < pinputhi);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				do{
					U curelo{pinputlo->signexponent};
					std::uint_least64_t curmlo{pinputlo->mantissa};
					U curehi{pinputhi->signexponent};
					std::uint_least64_t curmhi{pinputhi->mantissa};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(
							curmlo, curelo, pinputhi, pbufferhi,
							curmhi, curehi, pinputlo, pbufferlo);
						--pinputhi;
						--pbufferhi;
						++pinputlo;
						++pbufferlo;
					}
					// register pressure performance issue on several platforms: first do the low half here
					unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pinputhi[0].signexponent = static_cast<W>(curelo);
						pbufferhi[0].signexponent = static_cast<W>(curelo);
					}
					curelo >>= 8;
					unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
					unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
					unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
					unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
					unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
					unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
					unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pinputhi[0].mantissa = curmlo;
						--pinputhi;
						pbufferhi[0].mantissa = curmlo;
						--pbufferhi;
					}
					curmlo >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(curelo0)];
					curelo &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsets[curmlo0];
					curmlo1 &= 0xFFu;
					curmlo2 &= 0xFFu;
					curmlo3 &= 0xFFu;
					curmlo4 &= 0xFFu;
					curmlo5 &= 0xFFu;
					curmlo6 &= 0xFFu;
					++offsets[9 * 256 + static_cast<std::size_t>(curelo)];
					++offsets[7 * 256 + static_cast<std::size_t>(curmlo)];
					++offsets[256 + static_cast<std::size_t>(curmlo1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curmlo2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curmlo3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curmlo4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curmlo5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curmlo6)];
					// register pressure performance issue on several platforms: do the high half here second
					unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pinputlo[0].signexponent = static_cast<W>(curehi);
						pbufferlo[0].signexponent = static_cast<W>(curehi);
					}
					curehi >>= 8;
					unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
					unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
					unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
					unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
					unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
					unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
					unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pinputlo[0].mantissa = curmlo;
						++pinputlo;
						pbufferlo[0].mantissa = curmhi;
						++pbufferlo;
					}
					curmhi >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(curehi0)];
					curehi &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsets[curmhi0];
					curmhi1 &= 0xFFu;
					curmhi2 &= 0xFFu;
					curmhi3 &= 0xFFu;
					curmhi4 &= 0xFFu;
					curmhi5 &= 0xFFu;
					curmhi6 &= 0xFFu;
					++offsets[9 * 256 + static_cast<std::size_t>(curehi)];
					++offsets[7 * 256 + static_cast<std::size_t>(curmhi)];
					++offsets[256 + static_cast<std::size_t>(curmhi1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curmhi2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curmhi3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curmhi4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curmhi5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curmhi6)];
				}while(pinputlo < pinputhi);
			}
			if(pinputlo == pinputhi){// fill in the final item for odd counts
				U cure{static_cast<U>(pinputlo[0].signexponent)};
				std::uint_least64_t curm{pinputlo[0].mantissa};
				// no write to input, as this is the midpoint
				if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(curm, cure, pbufferhi);
				}
				unsigned cure0{static_cast<unsigned>(cure & 0xFFu)};
				if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
					pbufferhi[0].signexponent = static_cast<W>(cure);
				}
				cure >>= 8;
				unsigned curm0{static_cast<unsigned>(curm & 0xFFu)};
				unsigned curm1{static_cast<unsigned>(curm >> 8)};
				unsigned curm2{static_cast<unsigned>(curm >> 16)};
				unsigned curm3{static_cast<unsigned>(curm >> 24)};
				unsigned curm4{static_cast<unsigned>(curm >> 32)};
				unsigned curm5{static_cast<unsigned>(curm >> 40)};
				unsigned curm6{static_cast<unsigned>(curm >> 48)};
				if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
					pbufferhi[0].mantissa = curm;
				}
				curm >>= 56;
				++offsets[8 * 256 + static_cast<std::size_t>(cure0)];
				cure &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
				++offsets[curm0];
				curm1 &= 0xFFu;
				curm2 &= 0xFFu;
				curm3 &= 0xFFu;
				curm4 &= 0xFFu;
				curm5 &= 0xFFu;
				curm6 &= 0xFFu;
				++offsets[9 * 256 + static_cast<std::size_t>(cure)];
				++offsets[7 * 256 + static_cast<std::size_t>(curm)];
				++offsets[256 + static_cast<std::size_t>(curm1)];
				++offsets[2 * 256 + static_cast<std::size_t>(curm2)];
				++offsets[3 * 256 + static_cast<std::size_t>(curm3)];
				++offsets[4 * 256 + static_cast<std::size_t>(curm4)];
				++offsets[5 * 256 + static_cast<std::size_t>(curm5)];
				++offsets[6 * 256 + static_cast<std::size_t>(curm6)];
			}
		}else{// not in reverse order
			T *pinput{input};
			T *pbuffer{buffer};
			std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
			if constexpr(ismultithreadcapable){
				// architecture: limit to one at a time when there's few registers
				if constexpr(defaultgprfilesize < gprfilesize::large) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
				else i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
			}
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				do{
					U cure{pinput->signexponent};
					std::uint_least64_t curm{pinput->mantissa};
					++pinput;
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curm, cure, pbuffer);
						++pbuffer;
					}
					unsigned cure0{static_cast<unsigned>(cure & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pbuffer[0].signexponent = static_cast<W>(cure);
					}
					cure >>= 8;
					unsigned curm0{static_cast<unsigned>(curm & 0xFFu)};
					unsigned curm1{static_cast<unsigned>(curm >> 8)};
					unsigned curm2{static_cast<unsigned>(curm >> 16)};
					unsigned curm3{static_cast<unsigned>(curm >> 24)};
					unsigned curm4{static_cast<unsigned>(curm >> 32)};
					unsigned curm5{static_cast<unsigned>(curm >> 40)};
					unsigned curm6{static_cast<unsigned>(curm >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pbuffer[0].mantissa = curm;
						++pbuffer;
					}
					curm >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(cure0)];
					cure &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
					++offsets[curm0];
					curm1 &= 0xFFu;
					curm2 &= 0xFFu;
					curm3 &= 0xFFu;
					curm4 &= 0xFFu;
					curm5 &= 0xFFu;
					curm6 &= 0xFFu;
					++offsets[9 * 256 + static_cast<std::size_t>(cure)];
					++offsets[7 * 256 + static_cast<std::size_t>(curm)];
					++offsets[256 + static_cast<std::size_t>(curm1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curm2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curm3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curm4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curm5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curm6)];
				}while(0 <= --i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				do{
					U curelo{static_cast<U>(pinput[0].signexponent)};
					std::uint_least64_t curmlo{pinput[0].mantissa};
					U curehi{static_cast<U>(pinput[1].signexponent)};
					std::uint_least64_t curmhi{pinput[1].mantissa};
					pinput += 2;
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(
							curmlo, curelo, pbuffer,
							curmhi, curehi, pbuffer + 1);
						pbuffer += 2;
					}
					// register pressure performance issue on several platforms: first do the low half here
					unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pbuffer[0].signexponent = static_cast<W>(curelo);
					}
					curelo >>= 8;
					unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
					unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
					unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
					unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
					unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
					unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
					unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pbuffer[0].mantissa = curmlo;
					}
					curmlo >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(curelo0)];
					curelo &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
					++offsets[curmlo0];
					curmlo1 &= 0xFFu;
					curmlo2 &= 0xFFu;
					curmlo3 &= 0xFFu;
					curmlo4 &= 0xFFu;
					curmlo5 &= 0xFFu;
					curmlo6 &= 0xFFu;
					++offsets[9 * 256 + static_cast<std::size_t>(curelo)];
					++offsets[7 * 256 + static_cast<std::size_t>(curmlo)];
					++offsets[256 + static_cast<std::size_t>(curmlo1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curmlo2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curmlo3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curmlo4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curmlo5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curmlo6)];
					// register pressure performance issue on several platforms: do the high half here second
					unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pbuffer[1].signexponent = static_cast<W>(curehi);
					}
					curehi >>= 8;
					unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
					unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
					unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
					unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
					unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
					unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
					unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pbuffer[1].signexponent = static_cast<W>(curmhi);
						pbuffer += 2;
					}
					curmhi >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(curehi0)];
					curehi &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
					++offsets[curmhi0];
					curmhi1 &= 0xFFu;
					curmhi2 &= 0xFFu;
					curmhi3 &= 0xFFu;
					curmhi4 &= 0xFFu;
					curmhi5 &= 0xFFu;
					curmhi6 &= 0xFFu;
					++offsets[9 * 256 + static_cast<std::size_t>(curehi)];
					++offsets[7 * 256 + static_cast<std::size_t>(curmhi)];
					++offsets[256 + static_cast<std::size_t>(curmhi1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curmhi2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curmhi3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curmhi4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curmhi5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curmhi6)];
					i -= 2;
				}while(0 < i);
				if(!(1 & i)){// fill in the final item for odd counts
					U cure{pinput->signexponent};
					std::uint_least64_t curm{pinput->mantissa};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curm, cure, pbuffer);
					}
					unsigned cure0{static_cast<unsigned>(cure & 0xFFu)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pbuffer[0].signexponent = static_cast<W>(cure);
					}
					cure >>= 8;
					unsigned curm0{static_cast<unsigned>(curm & 0xFFu)};
					unsigned curm1{static_cast<unsigned>(curm >> 8)};
					unsigned curm2{static_cast<unsigned>(curm >> 16)};
					unsigned curm3{static_cast<unsigned>(curm >> 24)};
					unsigned curm4{static_cast<unsigned>(curm >> 32)};
					unsigned curm5{static_cast<unsigned>(curm >> 40)};
					unsigned curm6{static_cast<unsigned>(curm >> 48)};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)){
						pbuffer[0].mantissa = curm;
					}
					curm >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(cure0)];
					cure &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
					++offsets[curm0];
					curm1 &= 0xFFu;
					curm2 &= 0xFFu;
					curm3 &= 0xFFu;
					curm4 &= 0xFFu;
					curm5 &= 0xFFu;
					curm6 &= 0xFFu;
					++offsets[9 * 256 + static_cast<std::size_t>(cure)];
					++offsets[7 * 256 + static_cast<std::size_t>(curm)];
					++offsets[256 + static_cast<std::size_t>(curm1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curm2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curm3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curm4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curm5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curm6)];
				}
			}
		}

		// barrier and pointer exchange with the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, X *, std::nullptr_t> offsetscompanion;
		if constexpr(ismultithreadcapable){
			std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsets) & -static_cast<std::intptr_t>(usemultithread))};
			// simply do not spin if usemultithread is zero
			if(usemultithread > other){
				do{
					spinpause();
					other = atomiclightbarrier.load(std::memory_order_relaxed);
				}while(reinterpret_cast<std::uintptr_t>(offsets) == other);
				// reset the barrier after use, only one thread will do this
				// no busy-wait dependency on this store, hence relaxed memory order is fine
				reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
				// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
			}
			// this will just be zero if usemultithread is zero
			offsetscompanion = reinterpret_cast<X *>(other);// retrieve the pointer
		}else offsetscompanion = nullptr;

		// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
		auto[runsteps, paritybool]{generateoffsetsmulti<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, offsets, offsetscompanion, usemultithread, movetobuffer)};

		// barrier and (flipped bits) runsteps, paritybool value exchange with the companion thread
		if constexpr(ismultithreadcapable){
			// paritybool is either 0 or 1 here, so we can pack it together with runsteps and add usemultithread on top
			std::uintptr_t compound{static_cast<std::uintptr_t>(runsteps) * 2 + static_cast<std::uintptr_t>(paritybool) + static_cast<std::uintptr_t>(usemultithread)};
			while(reinterpret_cast<std::uintptr_t>(offsets) == atomiclightbarrier.load(std::memory_order_relaxed)){
				spinpause();// catch up
			}
			std::uintptr_t other{atomiclightbarrier.fetch_add(compound & -static_cast<std::intptr_t>(usemultithread))};
			// simply do not spin if usemultithread is zero
			if(usemultithread > other){
				do{
					spinpause();
					other = atomiclightbarrier.load(std::memory_order_relaxed) - compound;
				}while(!other);
				// reset the barrier after use, only one thread will do this
				// no busy-wait dependency on this store, hence relaxed memory order is fine
				reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
				// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
			}
			other += compound;// combine
			unsigned lowercarryoutbits{2 * usemultithread + paritybool};
			paritybool = static_cast<unsigned>(other) & 1;// piece together the parity from both threads
			other -= lowercarryoutbits;// this will remove possiby two bits of carry-out before the next right shift
			runsteps = static_cast<unsigned>(other >> 1);// this can shift out a 0 or a 1 bit here, depending on the leftovers of parity
		}

		// perform the bidirectional 8-bit sorting sequence
		// flip the relevant bits inside runsteps first
		if(runsteps ^= (1u << 80 / 8) - 1)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
			[[likely]]
#endif
		{
			T *psrclo{input}, *pdst{buffer};
			if(paritybool){// swap if the count of sorting actions to do is odd
				psrclo = buffer;
				pdst = input;
			}
			radixsortnoallocmulti2threadmain<isrevorder, isabsvalue, issignmode, isfltpmode, ismultithreadcapable, T, X>(count, psrclo, pdst, psrclo, offsets, runsteps, usemultithread, atomiclightbarrier);
		}
	}else if(0 == static_cast<std::ptrdiff_t>(count)) *buffer = *input;// copy the single element if the count is 1
}

// initialisation part, multi-threading companion for the radixsortnoallocmulti2thread() function implementation template for multi-part types without indirection
// Do not use this function directly.
template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	64 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void> radixsortnoallocmulti2threadinitmtc(std::size_t count, T const input[], T pout[], X offsetscompanion[])noexcept{
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
	assert(7 <= count);// this function is not for small arrays, 8 is the minimum original array count for 16-bit inputs
	// do not pass a nullptr here
	assert(input);
	assert(pout);
	assert(offsetscompanion);
	if constexpr(64 == CHAR_BIT * sizeof(T)){
		if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
		}else{// 64-bit, not in reverse order
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					U cur{input[i]};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, pout + i);
					}
					// register pressure performance issue on several platforms: first do the gh half here
					U cur0{cur & 0xFFu};
					U cur1{cur >> 8};
					U cur2{cur >> 16};
					U cur3{cur >> 24};
					U cur4{cur >> 32};
					U cur5{cur >> 40};
					U cur6{cur >> 48};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i] = static_cast<T>(cur);
					cur >>= 56;
					++offsetscompanion[cur0];
					cur1 &= 0xFFu;
					cur2 &= 0xFFu;
					cur3 &= 0xFFu;
					cur4 &= 0xFFu;
					cur5 &= 0xFFu;
					cur6 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(cur3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(cur4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(cur5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(cur6)];
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(cur)];
				}while(--i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					U curhi{input[i]};
					U curlo{input[i - 1]};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(
							curhi, pout + i,
							curlo, pout + i - 1);
					}
					// register pressure performance issue on several platforms: first do the high half here
					U curhi0{curhi & 0xFFu};
					U curhi1{curhi >> 8};
					U curhi2{curhi >> 16};
					U curhi3{curhi >> 24};
					U curhi4{curhi >> 32};
					U curhi5{curhi >> 40};
					U curhi6{curhi >> 48};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i] = static_cast<T>(curhi);
					curhi >>= 56;
					++offsetscompanion[curhi0];
					curhi1 &= 0xFFu;
					curhi2 &= 0xFFu;
					curhi3 &= 0xFFu;
					curhi4 &= 0xFFu;
					curhi5 &= 0xFFu;
					curhi6 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curhi5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curhi6)];
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curhi)];
					// register pressure performance issue on several platforms: do the low half here second
					U curlo0{curlo & 0xFFu};
					U curlo1{curlo >> 8};
					U curlo2{curlo >> 16};
					U curlo3{curlo >> 24};
					U curlo4{curlo >> 32};
					U curlo5{curlo >> 40};
					U curlo6{curlo >> 48};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i - 1] = static_cast<T>(curlo);
					curlo >>= 56;
					++offsetscompanion[curlo0];
					curlo1 &= 0xFFu;
					curlo2 &= 0xFFu;
					curlo3 &= 0xFFu;
					curlo4 &= 0xFFu;
					curlo5 &= 0xFFu;
					curlo6 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curlo5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curlo6)];
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curlo)];
				}while(i -= 2);
			}
		}
	}else if constexpr(56 == CHAR_BIT * sizeof(T)){
		if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
		}else{// 56-bit, not in reverse order
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					U cur{input[i]};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, pout + i);
					}
					// register pressure performance issue on several platforms: first do the gh half here
					U cur0{cur & 0xFFu};
					U cur1{cur >> 8};
					U cur2{cur >> 16};
					U cur3{cur >> 24};
					U cur4{cur >> 32};
					U cur5{cur >> 40};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i] = static_cast<T>(cur);
					cur >>= 48;
					++offsetscompanion[cur0];
					cur1 &= 0xFFu;
					cur2 &= 0xFFu;
					cur3 &= 0xFFu;
					cur4 &= 0xFFu;
					cur5 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(cur3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(cur4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(cur5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(cur)];
				}while(--i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					U curhi{input[i]};
					U curlo{input[i - 1]};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(
							curhi, pout + i,
							curlo, pout + i - 1);
					}
					// register pressure performance issue on several platforms: first do the high half here
					U curhi0{curhi & 0xFFu};
					U curhi1{curhi >> 8};
					U curhi2{curhi >> 16};
					U curhi3{curhi >> 24};
					U curhi4{curhi >> 32};
					U curhi5{curhi >> 40};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i] = static_cast<T>(curhi);
					curhi >>= 48;
					++offsetscompanion[curhi0];
					curhi1 &= 0xFFu;
					curhi2 &= 0xFFu;
					curhi3 &= 0xFFu;
					curhi4 &= 0xFFu;
					curhi5 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curhi5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curhi)];
					// register pressure performance issue on several platforms: do the low half here second
					U curlo0{curlo & 0xFFu};
					U curlo1{curlo >> 8};
					U curlo2{curlo >> 16};
					U curlo3{curlo >> 24};
					U curlo4{curlo >> 32};
					U curlo5{curlo >> 40};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i - 1] = static_cast<T>(curlo);
					curlo >>= 48;
					++offsetscompanion[curlo0];
					curlo1 &= 0xFFu;
					curlo2 &= 0xFFu;
					curlo3 &= 0xFFu;
					curlo4 &= 0xFFu;
					curlo5 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curlo5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curlo)];
				}while(i -= 2);
			}
		}
	}else if constexpr(48 == CHAR_BIT * sizeof(T)){
		if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
		}else{// 48-bit, not in reverse order
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					U cur{input[i]};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, pout + i);
					}
					// register pressure performance issue on several platforms: first do the gh half here
					U cur0{cur & 0xFFu};
					U cur1{cur >> 8};
					U cur2{cur >> 16};
					U cur3{cur >> 24};
					U cur4{cur >> 32};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i] = static_cast<T>(cur);
					cur >>= 40;
					++offsetscompanion[cur0];
					cur1 &= 0xFFu;
					cur2 &= 0xFFu;
					cur3 &= 0xFFu;
					cur4 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(cur3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(cur4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(cur)];
				}while(--i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					U curhi{input[i]};
					U curlo{input[i - 1]};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(
							curhi, pout + i,
							curlo, pout + i - 1);
					}
					// register pressure performance issue on several platforms: first do the high half here
					U curhi0{curhi & 0xFFu};
					U curhi1{curhi >> 8};
					U curhi2{curhi >> 16};
					U curhi3{curhi >> 24};
					U curhi4{curhi >> 32};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i] = static_cast<T>(curhi);
					curhi >>= 40;
					++offsetscompanion[curhi0];
					curhi1 &= 0xFFu;
					curhi2 &= 0xFFu;
					curhi3 &= 0xFFu;
					curhi4 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curhi)];
					// register pressure performance issue on several platforms: do the low half here second
					U curlo0{curlo & 0xFFu};
					U curlo1{curlo >> 8};
					U curlo2{curlo >> 16};
					U curlo3{curlo >> 24};
					U curlo4{curlo >> 32};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i - 1] = static_cast<T>(curlo);
					curlo >>= 40;
					++offsetscompanion[curlo0];
					curlo1 &= 0xFFu;
					curlo2 &= 0xFFu;
					curlo3 &= 0xFFu;
					curlo4 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curlo)];
				}while(i -= 2);
			}
		}
	}else if constexpr(40 == CHAR_BIT * sizeof(T)){
		if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
		}else{// 40-bit, not in reverse order
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					U cur{input[i]};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, pout + i);
					}
					// register pressure performance issue on several platforms: first do the gh half here
					U cur0{cur & 0xFFu};
					U cur1{cur >> 8};
					U cur2{cur >> 16};
					U cur3{cur >> 24};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i] = static_cast<T>(cur);
					cur >>= 32;
					++offsetscompanion[cur0];
					cur1 &= 0xFFu;
					cur2 &= 0xFFu;
					cur3 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(cur3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(cur)];
				}while(--i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					U curhi{input[i]};
					U curlo{input[i - 1]};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(
							curhi, pout + i,
							curlo, pout + i - 1);
					}
					U curhi0{curhi & 0xFFu};
					U curhi1{curhi >> 8};
					U curhi2{curhi >> 16};
					U curhi3{curhi >> 24};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i] = static_cast<T>(curhi);
					curhi >>= 32;
					U curlo0{curlo & 0xFFu};
					U curlo1{curlo >> 8};
					U curlo2{curlo >> 16};
					U curlo3{curlo >> 24};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i - 1] = static_cast<T>(curhi);
					curlo >>= 32;
					++offsetscompanion[curhi0];
					curhi1 &= 0xFFu;
					curhi2 &= 0xFFu;
					curhi3 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
					++offsetscompanion[curlo0];
					curlo1 &= 0xFFu;
					curlo2 &= 0xFFu;
					curlo3 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi)];
					++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo)];
				}while(i -= 2);
			}
		}
	}else if constexpr(32 == CHAR_BIT * sizeof(T)){
		if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
		}else{// 32-bit, not in reverse order
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					U cur{input[i]};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, pout + i);
					}
					// register pressure performance issue on several platforms: first do the gh half here
					U cur0{cur & 0xFFu};
					U cur1{cur >> 8};
					U cur2{cur >> 16};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i] = static_cast<T>(cur);
					cur >>= 24;
					++offsetscompanion[cur0];
					cur1 &= 0xFFu;
					cur2 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(cur)];
				}while(--i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					U cura{input[i]};
					U curb{input[i - 1]};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(
							cura, pout + i,
							curb, pout + i - 1);
					}
					U cur0a{cura & 0xFFu};
					U cur1a{cura >> 8};
					U cur2a{cura >> 16};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i] = static_cast<T>(cura);
					cura >>= 24;
					U cur0b{curb & 0xFFu};
					U cur1b{curb >> 8};
					U cur2b{curb >> 16};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i - 1] = static_cast<T>(curb);
					curb >>= 24;
					++offsetscompanion[cur0a];
					cur1a &= 0xFFu;
					cur2a &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
					++offsetscompanion[cur0b];
					cur1b &= 0xFFu;
					cur2b &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur1a)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2a)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(cura)];
					++offsetscompanion[256 + static_cast<std::size_t>(cur1b)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2b)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curb)];
				}while(i -= 2);
			}
		}
	}else if constexpr(24 == CHAR_BIT * sizeof(T)){
		if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
		}else{// 24-bit, not in reverse order
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					U cur{input[i]};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, pout + i);
					}
					// register pressure performance issue on several platforms: first do the gh half here
					U cur0{cur & 0xFFu};
					U cur1{cur >> 8};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i] = static_cast<T>(cur);
					cur >>= 16;
					++offsetscompanion[cur0];
					cur1 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur)];
				}while(--i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 3) / 6) * 3};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					U cura{input[i]};
					U curb{input[i - 1]};
					U curc{input[i - 2]};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(
							cura, pout + i,
							curb, pout + i - 1,
							curc, pout + i - 2);
					}
					U cur0a{cura & 0xFFu};
					U cur1a{cura >> 8};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i] = static_cast<T>(cura);
					cura >>= 16;
					U cur0b{curb & 0xFFu};
					U cur1b{curb >> 8};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i - 1] = static_cast<T>(curb);
					curb >>= 16;
					U cur0c{curc & 0xFFu};
					U cur1c{curc >> 8};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i - 2] = static_cast<T>(curc);
					curc >>= 16;
					++offsetscompanion[cur0a];
					cur1a &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
					++offsetscompanion[cur0b];
					cur1b &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
					++offsetscompanion[cur0c];
					cur1c &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur1a)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cura)];
					++offsetscompanion[256 + static_cast<std::size_t>(cur1b)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curb)];
					++offsetscompanion[256 + static_cast<std::size_t>(cur1c)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curc)];
				}while(i -= 3);
			}
		}
	}else if constexpr(16 == CHAR_BIT * sizeof(T)){
		if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
		}else{// 16-bit, not in reverse order
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					U cur{input[i]};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, pout + i);
					}
					// register pressure performance issue on several platforms: first do the gh half here
					U cur0{cur & 0xFFu};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i] = static_cast<T>(cur);
					cur >>= 8;
					++offsetscompanion[cur0];
					if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur)];
				}while(--i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 4) >> 3) * 4};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					U cura{input[i]};
					U curb{input[i - 1]};
					U curc{input[i - 2]};
					U curd{input[i - 3]};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(
							cura, pout + i,
							curb, pout + i - 1,
							curc, pout + i - 2,
							curd, pout + i - 3);
					}
					U cur0a{cura & 0xFFu};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i] = static_cast<T>(cura);
					cura >>= 8;
					U cur0b{curb & 0xFFu};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i - 1] = static_cast<T>(curb);
					curb >>= 8;
					U cur0c{curc & 0xFFu};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i - 2] = static_cast<T>(curc);
					curc >>= 8;
					U cur0d{curd & 0xFFu};
					if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) pout[i - 3] = static_cast<T>(curd);
					curd >>= 8;
					++offsetscompanion[cur0a];
					if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
					++offsetscompanion[cur0b];
					if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
					++offsetscompanion[cur0c];
					if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
					++offsetscompanion[cur0d];
					if constexpr(isabsvalue && issignmode && isfltpmode) curd &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cura)];
					++offsetscompanion[256 + static_cast<std::size_t>(curb)];
					++offsetscompanion[256 + static_cast<std::size_t>(curc)];
					++offsetscompanion[256 + static_cast<std::size_t>(curd)];
				}while(i -= 4);
			}
		}
	}else static_assert(false, "Implementing larger types will require additional work and optimisation for this library.");
}

// main part, multi-threading companion for the radixsortnoallocmulti2thread() function implementation template for multi-part types without indirection
// Do not use this function directly.
template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	64 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void> radixsortnoallocmulti2threadmainmtc(std::size_t count, T const input[], T pdst[], T pdstnext[], X offsetscompanion[], unsigned runsteps, std::atomic_uintptr_t &atomiclightbarrier)noexcept{
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
	assert(7 <= count);// this function is not for small arrays, 8 is the minimum original array count for 16-bit inputs
	// do not pass a nullptr here
	assert(input);
	assert(pdst);
	assert(pdstnext);
	assert(offsetscompanion);
	assert(runsteps);
	unsigned shifter{bitscanforwardportable(runsteps)};// at least 1 bit is set inside runsteps as by previous check
	T *psrchi;
	if constexpr(false){// useless when not handling indirection: isrevorder){
		psrchi = pdstnext + count;
	}else{
		psrchi = const_cast<T *>(input) + count;// psrchi will never be written to
	}
	// skip a step if possible
	runsteps >>= shifter;
	X *poffset{offsetscompanion + static_cast<std::size_t>(shifter) * 256};
	while(1 < atomiclightbarrier.load(std::memory_order_relaxed)){// continue if it's 0 or 1
		spinpause();// catch up until the other thread releases the barrier
	}// do not place this inside the main loop, as the barrier is released there by cancelling 1 and -1 in interlocked add-fetch operations
	if constexpr(!isabsvalue && isfltpmode) if(CHAR_BIT * sizeof(T) / 8 - 1 == shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
		[[unlikely]]
#endif
		goto handletop8;// rare, but possible
	shifter *= 8;
	for(;;){
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
			std::size_t j{(count + 1 + 2) >> 2};// rounded up in the top part
			do{// fill the array, two at a time
				U outa{psrchi[0]};
				U outb{psrchi[-1]};
				psrchi -= 2;
				auto[cura, curb]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, shifter)};
				std::size_t offseta{poffset[cura]--};// the next item will be placed one lower
				std::size_t offsetb{poffset[curb]--};
				pdst[offseta] = static_cast<T>(outa);
				pdst[offsetb] = static_cast<T>(outb);
			}while(--j);
		}else{// architecture: limit to four at a time when there's a decent amount of registers
			std::size_t j{(count + 1 + 4) >> 3};// rounded up in the top part
			do{// fill the array, four at a time
				U outa{psrchi[0]};
				U outb{psrchi[-1]};
				U outc{psrchi[-2]};
				U outd{psrchi[-3]};
				psrchi -= 4;
				auto[cura, curb, curc, curd]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd, shifter)};
				std::size_t offseta{poffset[cura]--};// the next item will be placed one lower
				std::size_t offsetb{poffset[curb]--};
				std::size_t offsetc{poffset[curc]--};
				std::size_t offsetd{poffset[curd]--};
				pdst[offseta] = static_cast<T>(outa);
				pdst[offsetb] = static_cast<T>(outb);
				pdst[offsetc] = static_cast<T>(outc);
				pdst[offsetd] = static_cast<T>(outd);
			}while(--j);
		}
		runsteps >>= 1;
		if(!runsteps)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
			[[unlikely]]
#endif
			break;
		{
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			unsigned index;
			if constexpr(16 < CHAR_BIT * sizeof(T)) index = bitscanforwardportable(runsteps);// at least 1 bit is set inside runsteps as by previous check
			shifter += 8;
			poffset += 256;
			// swap the pointers for the next round, data is moved on each iteration
			psrchi = pdst;
			std::uintptr_t old{atomiclightbarrier.fetch_add(~static_cast<std::uintptr_t>(0))};
			pdst = pdstnext;
			pdstnext = psrchi;
			psrchi += count;
			// skip a step if possible
			if constexpr(16 < CHAR_BIT * sizeof(T)){
				runsteps >>= index;
				shifter += index * 8;
				poffset += static_cast<std::size_t>(index) * 256;
			}
			if(!old) do{
				spinpause();
			}while(atomiclightbarrier.load(std::memory_order_relaxed));
		}
		// handle the top part for floating-point differently
		if(!isabsvalue && isfltpmode && CHAR_BIT * sizeof(T) - 8 == shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
			[[unlikely]]
#endif
		{
handletop8:// this prevents "!isabsvalue && isfltpmode" to be made constexpr here, but that's fine
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
				std::size_t j{(count + 1 + 2) >> 2};// rounded up in the top part
				do{// fill the array, two at a time
					U outa{psrchi[0]};
					U outb{psrchi[-1]};
					psrchi -= 2;
					auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb)};
					std::size_t offseta{offsetscompanion[cura + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]--};// the next item will be placed one lower
					std::size_t offsetb{offsetscompanion[curb + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]--};
					pdst[offseta] = static_cast<T>(outa);
					pdst[offsetb] = static_cast<T>(outb);
				}while(--j);
			}else{// architecture: limit to four at a time when there's a decent amount of registers
				std::size_t j{(count + 1 + 4) >> 3};// rounded up in the top part
				do{// fill the array, four at a time
					U outa{psrchi[0]};
					U outb{psrchi[-1]};
					U outc{psrchi[-2]};
					U outd{psrchi[-3]};
					psrchi -= 4;
					auto[cura, curb, curc, curd]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd)};
					std::size_t offseta{offsetscompanion[cura + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]--};// the next item will be placed one lower
					std::size_t offsetb{offsetscompanion[curb + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]--};
					std::size_t offsetc{offsetscompanion[curc + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]--};
					std::size_t offsetd{offsetscompanion[curd + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]--};
					pdst[offseta] = static_cast<T>(outa);
					pdst[offsetb] = static_cast<T>(outb);
					pdst[offsetc] = static_cast<T>(outc);
					pdst[offsetd] = static_cast<T>(outd);
				}while(--j);
			}
			break;// no further processing beyond the top part
		}
	}
}

// main part for the radixsortcopynoallocmulti2thread() and radixsortnoallocmulti2thread() function implementation templates for multi-part types without indirection
// Do not use this function directly.
template<bool isabsvalue, bool issignmode, bool isfltpmode, bool ismultithreadcapable, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	64 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void> radixsortnoallocmulti2threadmain(std::size_t count, T const input[], T pdst[], T pdstnext[], X offsets[], unsigned runsteps, unsigned usemultithread, std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t &, std::nullptr_t> atomiclightbarrier)noexcept{
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
	static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	assert(count && count != MAXSIZE_T);
	// do not pass a nullptr here
	assert(input);
	assert(pdst);
	assert(pdstnext);
	assert(offsets);
	assert(runsteps);
	unsigned shifter{bitscanforwardportable(runsteps)};// at least 1 bit is set inside runsteps as by previous check
	T *psrclo;
	if constexpr(false){// useless when not handling indirection: isrevorder){
		psrclo = pdstnext;
	}else{
		psrclo = const_cast<T *>(input);// psrclo will never be written to
	}
	// skip a step if possible
	runsteps >>= shifter;
	X *poffset{offsets + static_cast<std::size_t>(shifter) * 256};
	if constexpr(ismultithreadcapable) while(1 < 1 + atomiclightbarrier.load(std::memory_order_relaxed)){// continue if it's 0 or -1
		spinpause();// catch up until the other thread releases the barrier
	}// do not place this inside the main loop, as the barrier is released there by cancelling 1 and -1 in interlocked add-fetch operations
	if constexpr(!isabsvalue && isfltpmode) if(CHAR_BIT * sizeof(T) / 8 - 1 == shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
		[[unlikely]]
#endif
		goto handletop8;// rare, but possible
	shifter *= 8;
	for(;;){
		if constexpr(ismultithreadcapable){
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
				std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (1 + usemultithread))};// rounded down in the bottom part
				while(0 <= --j){// fill the array, two at a time
					U outa{psrclo[0]};
					U outb{psrclo[1]};
					psrclo += 2;
					auto[cura, curb]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, shifter)};
					std::size_t offseta{poffset[cura]++};// the next item will be placed one higher
					std::size_t offsetb{poffset[curb]++};
					pdst[offseta] = static_cast<T>(outa);
					pdst[offsetb] = static_cast<T>(outb);
				}
			}else{// architecture: limit to four at a time when there's a decent amount of registers
				std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (2 + usemultithread))};// rounded down in the bottom part
				while(0 <= --j){// fill the array, four at a time
					U outa{psrclo[0]};
					U outb{psrclo[1]};
					U outc{psrclo[2]};
					U outd{psrclo[3]};
					psrclo += 4;
					auto[cura, curb, curc, curd]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd, shifter)};
					std::size_t offseta{poffset[cura]++};// the next item will be placed one higher
					std::size_t offsetb{poffset[curb]++};
					std::size_t offsetc{poffset[curc]++};
					std::size_t offsetd{poffset[curd]++};
					pdst[offseta] = static_cast<T>(outa);
					pdst[offsetb] = static_cast<T>(outb);
					pdst[offsetc] = static_cast<T>(outc);
					pdst[offsetd] = static_cast<T>(outd);
				}
				if(2 & count + 1){// fill in the final two items for a remainder of 2 or 3
					U outa{psrclo[0]};
					U outb{psrclo[1]};
					psrclo += 2;
					auto[cura, curb]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, shifter)};
					std::size_t offseta{poffset[cura]++};// the next item will be placed one higher
					std::size_t offsetb{poffset[curb]++};
					pdst[offseta] = static_cast<T>(outa);
					pdst[offsetb] = static_cast<T>(outb);
				}
			}
			if(!(1 & count)){// fill in the final item for odd counts
				U out{psrclo[0]};
				std::size_t cur{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(out, shifter)};
				std::size_t offset{poffset[cur]};
				pdst[offset] = static_cast<T>(out);
			}
		}else{// !ismultithreadcapable
			T const *psrchi{psrclo + count};
			do{// fill the array, two at a time: one low-to-middle, one high-to-middle
				U outlo{*psrclo++};
				U outhi{*psrchi--};
				auto[curlo, curhi]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outlo, outhi, shifter)};
				std::size_t offsetlo{poffset[curlo]++};// the next item will be placed one higher
				std::size_t offsethi{poffset[curhi + offsetsstride]--};// the next item will be placed one lower
				pdst[offsetlo] = static_cast<T>(outlo);
				pdst[offsethi] = static_cast<T>(outhi);
			}while(psrclo < psrchi);
			if(psrclo == psrchi){// fill in the final item for odd counts
				U out{*psrclo};
				std::size_t cur{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(out, shifter)};
				std::size_t offset{poffset[cur]};
				pdst[offset] = static_cast<T>(out);
			}
		}
		runsteps >>= 1;
		if(!runsteps)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
			[[unlikely]]
#endif
			break;
		{
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			unsigned index;
			if constexpr(16 < CHAR_BIT * sizeof(T)) index = bitscanforwardportable(runsteps);// at least 1 bit is set inside runsteps as by previous check
			shifter += 8;
			poffset += 256;
			// swap the pointers for the next round, data is moved on each iteration
			psrclo = pdst;
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			std::uintptr_t old;
			if constexpr(ismultithreadcapable) old = atomiclightbarrier.fetch_add(usemultithread);
			pdst = pdstnext;
			pdstnext = psrclo;
			// skip a step if possible
			if constexpr(16 < CHAR_BIT * sizeof(T)){
				runsteps >>= index;
				shifter += index * 8;
				poffset += static_cast<std::size_t>(index) * 256;
			}
			if constexpr(ismultithreadcapable) if(old < usemultithread) do{
				spinpause();
			}while(atomiclightbarrier.load(std::memory_order_relaxed));
		}
		// handle the top part for floating-point differently
		if(!isabsvalue && isfltpmode && CHAR_BIT * sizeof(T) - 8 == shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
			[[unlikely]]
#endif
		{
handletop8:// this prevents "!isabsvalue && isfltpmode" to be made constexpr here, but that's fine
			if constexpr(ismultithreadcapable){
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
					std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (1 + usemultithread))};// rounded down in the bottom part
					while(0 <= --j){// fill the array, two at a time
						U outa{psrclo[0]};
						U outb{psrclo[1]};
						psrclo += 2;
						auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb)};
						std::size_t offseta{offsets[cura + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};// the next item will be placed one higher
						std::size_t offsetb{offsets[curb + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};
						pdst[offseta] = static_cast<T>(outa);
						pdst[offsetb] = static_cast<T>(outb);
					}
				}else{// architecture: limit to four at a time when there's a decent amount of registers
					std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (2 + usemultithread))};// rounded down in the bottom part
					while(0 <= --j){// fill the array, four at a time
						U outa{psrclo[0]};
						U outb{psrclo[1]};
						U outc{psrclo[2]};
						U outd{psrclo[3]};
						psrclo += 4;
						auto[cura, curb, curc, curd]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd)};
						std::size_t offseta{offsets[cura + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};// the next item will be placed one higher
						std::size_t offsetb{offsets[curb + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};
						std::size_t offsetc{offsets[curc + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};
						std::size_t offsetd{offsets[curd + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};
						pdst[offseta] = static_cast<T>(outa);
						pdst[offsetb] = static_cast<T>(outb);
						pdst[offsetc] = static_cast<T>(outc);
						pdst[offsetd] = static_cast<T>(outd);
					}
					if(2 & count + 1){// fill in the final two items for a remainder of 2 or 3
						U outa{psrclo[0]};
						U outb{psrclo[1]};
						psrclo += 2;
						auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode,T, U>(outa, outb)};
						std::size_t offseta{offsets[cura + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};// the next item will be placed one higher
						std::size_t offsetb{offsets[curb + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};
						pdst[offseta] = static_cast<T>(outa);
						pdst[offsetb] = static_cast<T>(outb);
					}
				}
				if(!(1 & count)){// fill in the final item for odd counts
					U out{psrclo[0]};
					std::size_t cur{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(out)};
					std::size_t offset{offsets[cur + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]};
					pdst[offset] = static_cast<T>(out);
				}
			}else{// !ismultithreadcapable
				T const *psrchi{psrclo + count};
				do{// fill the array, two at a time: one low-to-middle, one high-to-middle
					U outlo{*psrclo++};
					U outhi{*psrchi--};
					auto[curlo, curhi]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outlo, outhi)};
					std::size_t offsetlo{offsets[curlo + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};// the next item will be placed one higher
					std::size_t offsethi{offsets[curhi + (CHAR_BIT * sizeof(T) - 8) * 256 / 8 + offsetsstride]--};// the next item will be placed one lower
					pdst[offsetlo] = static_cast<T>(outlo);
					pdst[offsethi] = static_cast<T>(outhi);
				}while(psrclo < psrchi);
				if(psrclo == psrchi){// fill in the final item for odd counts
					U out{*psrclo};
					std::size_t cur{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(out)};
					std::size_t offset{offsets[cur + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]};
					pdst[offset] = static_cast<T>(out);
				}
			}
			break;// no further processing beyond the top part
		}
	}
}

// multi-threading companion for the radixsortcopynoallocmulti2thread() function implementation template for 80-bit-based long double types without indirection
// Do not use this function directly.
template<bool isdescsort, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	64 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void> radixsortcopynoallocmulti2threadmtc(std::size_t count, T const input[], T output[], T buffer[], std::atomic_uintptr_t &atomiclightbarrier)noexcept{
	// do not pass a nullptr here
	assert(input);
	assert(output);
	assert(buffer);
	static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	X offsetscompanion[offsetsstride]{};// a sizeable amount of indices, but it's worth it, zeroed in advance here
	radixsortnoallocmulti2threadinitmtc<isabsvalue, issignmode, isfltpmode, T, X>(count, input, output, offsetscompanion);

	X *offsets;
	{// barrier and pointer exchange with the main thread
		std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsetscompanion))};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed);
			}while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == other);
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		offsets = reinterpret_cast<X *>(other);// retrieve the pointer
	}

	// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
	auto[runsteps, paritybool]{generateoffsetsmultimtc<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, offsets, offsetscompanion)};

	{// barrier and (flipped bits) runsteps, paritybool value exchange with the main thread
		// paritybool is either 0 or 1 here, so we can pack it together with runsteps and add usemultithread on top
		std::uintptr_t compound{static_cast<std::uintptr_t>(runsteps) * 2 + static_cast<std::uintptr_t>(paritybool) + 1};
		while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == atomiclightbarrier.load(std::memory_order_relaxed)){
			spinpause();// catch up
		}
		std::uintptr_t other{atomiclightbarrier.fetch_add(compound)};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed) - compound;
			}while(!other);
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		other += compound;// combine
		unsigned lowercarryoutbits{2 + paritybool};
		paritybool = static_cast<unsigned>(other) & 1;// piece together the parity from both threads
		other -= lowercarryoutbits;// this will remove possiby two bits of carry-out before the next right shift
		runsteps = static_cast<unsigned>(other >> 1);// this can shift out a 0 or a 1 bit here, depending on the leftovers of parity
	}

	// perform the bidirectional 8-bit sorting sequence
	// flip the relevant bits inside runsteps first
	if(runsteps ^= (1u << CHAR_BIT * sizeof(T) / 8) - 1)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
		[[likely]]
#endif
	{// perform the bidirectional 8-bit sorting sequence
		T *pdst{buffer}, *pdstnext{output};// for the next iteration
		if(paritybool){// swap if the count of sorting actions to do is odd
			pdst = output;
			pdstnext = buffer;
		}
		radixsortnoallocmulti2threadmainmtc<isabsvalue, issignmode, isfltpmode, T, X>(count, input, pdst, pdstnext, offsetscompanion, runsteps, atomiclightbarrier);
	}
}

// radixsortcopynoalloc() function implementation template for multi-part types without indirection
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	, bool ismultithreadcapable = true
#endif
	>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	64 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	radixsortcopynoallocmulti1thread
#else
	radixsortcopynoallocmulti2thread
#endif
	(std::size_t count, T const input[], T output[], T buffer[])noexcept{
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	static bool constexpr ismultithreadcapable{false};
#endif
	if constexpr(ismultithreadcapable){
		assert(1 < std::thread::hardware_concurrency());// only use multi-threading if there is more than one hardware thread
		assert(15 <= count);// a 0 or 1 count array is only allowed here in single-threaded function mode
	}
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);
	assert(buffer);
	// All the code in this function is adapted for count to be one below its input value here.
	--count;
	if(ismultithreadcapable || 0 < static_cast<std::ptrdiff_t>(count)){// a 0 or 1 count array is only allowed here in single-threaded function mode
		static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
		// conditionally enable multi-threading here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t, std::nullptr_t> atomiclightbarrier{};
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::future<void>, std::nullptr_t> asynchandle;

		// count the 256 configurations, all in one go
		if constexpr(ismultithreadcapable){
			try{
				asynchandle = std::async(std::launch::async, radixsortcopynoallocmulti2threadmtc<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>, count, input, output, buffer, std::ref(atomiclightbarrier));
				usemultithread = 1;
			}catch(...){// std::async may fail gracefully here
				assert(false);
			}
		}
		X offsets[offsetsstride * (2 - ismultithreadcapable)];// a sizeable amount of indices, but it's worth it
		std::memset(offsets, 0, offsetsstride * sizeof(X));// zeroed in advance here
		if constexpr(64 == CHAR_BIT * sizeof(T)){
			if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
			}else{// 64-bit, not in reverse order
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
					do{
						U cur{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, output + i);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						U cur5{cur >> 40};
						U cur6{cur >> 48};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[0] = static_cast<T>(cur);
						cur >>= 56;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						cur5 &= 0xFFu;
						cur6 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
						++offsets[6 * 256 + static_cast<std::size_t>(cur6)];
						++offsets[7 * 256 + static_cast<std::size_t>(cur)];
					}while(0 <= --i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
					do{
						U curhi{input[i]};
						U curlo{input[i - 1]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								curhi, output + i,
								curlo, output + i - 1);
						}
						// register pressure performance issue on several platforms: first do the high half here
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						U curhi4{curhi >> 32};
						U curhi5{curhi >> 40};
						U curhi6{curhi >> 48};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i] = static_cast<T>(curhi);
						curhi >>= 56;
						++offsets[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						curhi4 &= 0xFFu;
						curhi5 &= 0xFFu;
						curhi6 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(curhi1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curhi5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curhi6)];
						++offsets[7 * 256 + static_cast<std::size_t>(curhi)];
						// register pressure performance issue on several platforms: do the low half here second
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						U curlo4{curlo >> 32};
						U curlo5{curlo >> 40};
						U curlo6{curlo >> 48};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i - 1] = static_cast<T>(curlo);
						curlo >>= 56;
						++offsets[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						curlo4 &= 0xFFu;
						curlo5 &= 0xFFu;
						curlo6 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(curlo1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curlo5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curlo6)];
						++offsets[7 * 256 + static_cast<std::size_t>(curlo)];
						i -= 2;
					}while(0 < i);
					if(!(1 & i)){// fill in the final item for odd counts
						U cur{input[0]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, output);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						U cur5{cur >> 40};
						U cur6{cur >> 48};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[0] = static_cast<T>(cur);
						cur >>= 56;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						cur5 &= 0xFFu;
						cur6 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
						++offsets[6 * 256 + static_cast<std::size_t>(cur6)];
						++offsets[7 * 256 + static_cast<std::size_t>(cur)];
					}
				}
			}
		}else if constexpr(56 == CHAR_BIT * sizeof(T)){
			if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
			}else{// 56-bit, not in reverse order
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
					do{
						U cur{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, output + i);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						U cur5{cur >> 40};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[0] = static_cast<T>(cur);
						cur >>= 48;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						cur5 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
						++offsets[6 * 256 + static_cast<std::size_t>(cur)];
					}while(0 <= --i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
					do{
						U curhi{input[i]};
						U curlo{input[i - 1]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								curhi, output + i,
								curlo, output + i - 1);
						}
						// register pressure performance issue on several platforms: first do the high half here
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						U curhi4{curhi >> 32};
						U curhi5{curhi >> 40};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i] = static_cast<T>(curhi);
						curhi >>= 48;
						++offsets[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						curhi4 &= 0xFFu;
						curhi5 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(curhi1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curhi5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curhi)];
						// register pressure performance issue on several platforms: do the low half here second
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						U curlo4{curlo >> 32};
						U curlo5{curlo >> 40};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i - 1] = static_cast<T>(curlo);
						curlo >>= 48;
						++offsets[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						curlo4 &= 0xFFu;
						curlo5 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(curlo1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curlo5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curlo)];
						i -= 2;
					}while(0 < i);
					if(!(1 & i)){// fill in the final item for odd counts
						U cur{input[0]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, output);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						U cur5{cur >> 40};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[0] = static_cast<T>(cur);
						cur >>= 48;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						cur5 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
						++offsets[6 * 256 + static_cast<std::size_t>(cur)];
					}
				}
			}
		}else if constexpr(48 == CHAR_BIT * sizeof(T)){
			if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
			}else{// 48-bit, not in reverse order
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
					do{
						U cur{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, output + i);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[0] = static_cast<T>(cur);
						cur >>= 40;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsets[5 * 256 + static_cast<std::size_t>(cur)];
					}while(0 <= --i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
					do{
						U curhi{input[i]};
						U curlo{input[i - 1]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								curhi, output + i,
								curlo, output + i - 1);
						}
						// register pressure performance issue on several platforms: first do the high half here
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						U curhi4{curhi >> 32};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i] = static_cast<T>(curhi);
						curhi >>= 40;
						++offsets[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						curhi4 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(curhi1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curhi)];
						// register pressure performance issue on several platforms: do the low half here second
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						U curlo4{curlo >> 32};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i - 1] = static_cast<T>(curlo);
						curlo >>= 40;
						++offsets[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						curlo4 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(curlo1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curlo)];
						i -= 2;
					}while(0 < i);
					if(!(1 & i)){// fill in the final item for odd counts
						U cur{input[0]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, output);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[0] = static_cast<T>(cur);
						cur >>= 40;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsets[5 * 256 + static_cast<std::size_t>(cur)];
					}
				}
			}
		}else if constexpr(40 == CHAR_BIT * sizeof(T)){
			if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
			}else{// 40-bit, not in reverse order
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
					do{
						U cur{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, output + i);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[0] = static_cast<T>(cur);
						cur >>= 32;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur)];
					}while(0 <= --i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
					do{
						U curhi{input[i]};
						U curlo{input[i - 1]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								curhi, output + i,
								curlo, output + i - 1);
						}
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i] = static_cast<T>(curhi);
						curhi >>= 32;
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i - 1] = static_cast<T>(curlo);
						curlo >>= 32;
						++offsets[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsets[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(curhi1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curhi)];
						++offsets[256 + static_cast<std::size_t>(curlo1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curlo)];
						i -= 2;
					}while(0 < i);
					if(!(1 & i)){// fill in the final item for odd counts
						U cur{input[0]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, output);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[0] = static_cast<T>(cur);
						cur >>= 32;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur)];
					}
				}
			}
		}else if constexpr(32 == CHAR_BIT * sizeof(T)){
			if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
			}else{// 32-bit, not in reverse order
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
					do{
						U cur{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, output + i);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[0] = static_cast<T>(cur);
						cur >>= 24;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur)];
					}while(0 <= --i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
					do{
						U cura{input[i]};
						U curb{input[i - 1]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								cura, output + i,
								curb, output + i - 1);
						}
						U cur0a{cura & 0xFFu};
						U cur1a{cura >> 8};
						U cur2a{cura >> 16};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i] = static_cast<T>(cura);
						cura >>= 24;
						U cur0b{curb & 0xFFu};
						U cur1b{curb >> 8};
						U cur2b{curb >> 16};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i - 1] = static_cast<T>(curb);
						curb >>= 24;
						++offsets[cur0a];
						cur1a &= 0xFFu;
						cur2a &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
						++offsets[cur0b];
						cur1b &= 0xFFu;
						cur2b &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1a)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2a)];
						++offsets[3 * 256 + static_cast<std::size_t>(cura)];
						++offsets[256 + static_cast<std::size_t>(cur1b)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2b)];
						++offsets[3 * 256 + static_cast<std::size_t>(curb)];
						i -= 2;
					}while(0 < i);
					if(!(1 & i)){// fill in the final item for odd counts
						U cur{input[0]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, output);
						}
						U cur0{cur & 0xFFu};
						U cur1{static_cast<unsigned>(cur) >> 8};
						U cur2{static_cast<unsigned>(cur) >> 16};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[0] = static_cast<T>(cur);
						cur >>= 24;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur)];
					}
				}
			}
		}else if constexpr(24 == CHAR_BIT * sizeof(T)){
			if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
			}else{// 24-bit, not in reverse order
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
					do{
						U cur{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, output + i);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[0] = static_cast<T>(cur);
						cur >>= 16;
						++offsets[cur0];
						cur1 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur)];
					}while(0 <= --i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>(count + 1 + 3) / 6 * 3;
					i -= 2;
					if(0 <= i)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
						[[likely]]
#endif
						do{
						U cura{input[i + 2]};
						U curb{input[i + 1]};
						U curc{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								cura, output + i + 2,
								curb, output + i + 1,
								curc, output + i);
						}
						U cur0a{cura & 0xFFu};
						U cur1a{cura >> 8};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i + 2] = static_cast<T>(cura);
						cura >>= 16;
						U cur0b{curb & 0xFFu};
						U cur1b{curb >> 8};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i + 1] = static_cast<T>(curb);
						curb >>= 16;
						U cur0c{curc & 0xFFu};
						U cur1c{curc >> 8};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i] = static_cast<T>(curc);
						curc >>= 16;
						++offsets[cur0a];
						cur1a &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
						++offsets[cur0b];
						cur1b &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
						++offsets[cur0c];
						cur1c &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1a)];
						++offsets[2 * 256 + static_cast<std::size_t>(cura)];
						++offsets[256 + static_cast<std::size_t>(cur1b)];
						++offsets[2 * 256 + static_cast<std::size_t>(curb)];
						++offsets[256 + static_cast<std::size_t>(cur1c)];
						++offsets[2 * 256 + static_cast<std::size_t>(curc)];
						i -= 3;
					}while(0 <= i);
					if(2 & i){// fill in the final two items for a remainder of 2 or 3
						U cura{input[i + 2]};
						U curb{input[i + 1]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								cura, output + i + 2,
								curb, output + i + 1);
						}
						U cur0a{cura & 0xFFu};
						U cur1a{cura >> 8};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i + 2] = static_cast<T>(cura);
						cura >>= 16;
						U cur0b{curb & 0xFFu};
						U cur1b{curb >> 8};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i + 1] = static_cast<T>(curb);
						curb >>= 16;
						++offsets[cur0a];
						cur1a &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
						++offsets[cur0b];
						cur1b &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1a)];
						++offsets[2 * 256 + static_cast<std::size_t>(cura)];
						++offsets[256 + static_cast<std::size_t>(cur1b)];
						++offsets[2 * 256 + static_cast<std::size_t>(curb)];
					}else if(1 & i){// fill in the final item for odd counts
						U cur{input[0]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, output);
						}
						U cur0{cur & 0xFFu};
						U cur1{static_cast<unsigned>(cur) >> 8};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[0] = static_cast<T>(cur);
						cur >>= 16;
						++offsets[cur0];
						cur1 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur)];
					}
				}
			}
		}else if constexpr(16 == CHAR_BIT * sizeof(T)){
			if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
			}else{// 16-bit, not in reverse order
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
					do{
						U cur{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, output + i);
						}
						U cur0{cur & 0xFFu};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[0] = static_cast<T>(cur);
						cur >>= 8;
						++offsets[cur0];
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur)];
					}while(0 <= --i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 4) >> 3) * 4;
					i -= 3;
					if(0 <= i)
	#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
						[[likely]]
	#endif
						do{
						U cura{input[i + 3]};
						U curb{input[i + 2]};
						U curc{input[i + 1]};
						U curd{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								cura, output + i + 3,
								curb, output + i + 2,
								curc, output + i + 1,
								curd, output + i);
						}
						U cur0a{cura & 0xFFu};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i + 3] = static_cast<T>(cura);
						cura >>= 8;
						U cur0b{curb & 0xFFu};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i + 2] = static_cast<T>(curb);
						curb >>= 8;
						U cur0c{curc & 0xFFu};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i + 1] = static_cast<T>(curc);
						curc >>= 8;
						U cur0d{curd & 0xFFu};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i] = static_cast<T>(curd);
						curd >>= 8;
						++offsets[cur0a];
						if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
						++offsets[cur0b];
						if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
						++offsets[cur0c];
						if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
						++offsets[cur0d];
						if constexpr(isabsvalue && issignmode && isfltpmode) curd &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cura)];
						++offsets[256 + static_cast<std::size_t>(curb)];
						++offsets[256 + static_cast<std::size_t>(curc)];
						++offsets[256 + static_cast<std::size_t>(curd)];
						i -= 4;
					}while(0 <= i);
					if(2 & i){// fill in the final two items for a remainder of 2 or 3
						U cura{input[i + 3]};
						U curb{input[i + 2]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								cura, output + i + 3,
								curb, output + i + 2);
						}
						U cur0a{cura & 0xFFu};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i + 3] = static_cast<T>(cura);
						cura >>= 8;
						U cur0b{curb & 0xFFu};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[i + 2] = static_cast<T>(curb);
						curb >>= 8;
						++offsets[cur0a];
						if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
						++offsets[cur0b];
						if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cura)];
						++offsets[256 + static_cast<std::size_t>(curb)];
					}
					if(1 & i){// fill in the final item for odd counts
						U cur{input[0]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, output);
						}
						U cur0{cur & 0xFFu};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) output[0] = static_cast<T>(cur);
						cur >>= 8;
						++offsets[cur0];
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur)];
					}
				}
			}
		}else static_assert(false, "Implementing larger types will require additional work and optimisation for this library.");

		// barrier and pointer exchange with the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, X *, std::nullptr_t> offsetscompanion;
		if constexpr(ismultithreadcapable){
			std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsets) & -static_cast<std::intptr_t>(usemultithread))};
			// simply do not spin if usemultithread is zero
			if(usemultithread > other){
				do{
					spinpause();
					other = atomiclightbarrier.load(std::memory_order_relaxed);
				}while(reinterpret_cast<std::uintptr_t>(offsets) == other);
				// reset the barrier after use, only one thread will do this
				// no busy-wait dependency on this store, hence relaxed memory order is fine
				reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
				// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
			}
			// this will just be zero if usemultithread is zero
			offsetscompanion = reinterpret_cast<X *>(other);// retrieve the pointer
		}else offsetscompanion = nullptr;

		// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
		auto[runsteps, paritybool]{generateoffsetsmulti<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, offsets, offsetscompanion, usemultithread)};

		// barrier and (flipped bits) runsteps, paritybool value exchange with the companion thread
		if constexpr(ismultithreadcapable){
			// paritybool is either 0 or 1 here, so we can pack it together with runsteps and add usemultithread on top
			std::uintptr_t compound{static_cast<std::uintptr_t>(runsteps) * 2 + static_cast<std::uintptr_t>(paritybool) + static_cast<std::uintptr_t>(usemultithread)};
			while(reinterpret_cast<std::uintptr_t>(offsets) == atomiclightbarrier.load(std::memory_order_relaxed)){
				spinpause();// catch up
			}
			std::uintptr_t other{atomiclightbarrier.fetch_add(compound & -static_cast<std::intptr_t>(usemultithread))};
			// simply do not spin if usemultithread is zero
			if(usemultithread > other){
				do{
					spinpause();
					other = atomiclightbarrier.load(std::memory_order_relaxed) - compound;
				}while(!other);
				// reset the barrier after use, only one thread will do this
				// no busy-wait dependency on this store, hence relaxed memory order is fine
				reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
				// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
			}
			other += compound;// combine
			unsigned lowercarryoutbits{2 * usemultithread + paritybool};
			paritybool = static_cast<unsigned>(other) & 1;// piece together the parity from both threads
			other -= lowercarryoutbits;// this will remove possiby two bits of carry-out before the next right shift
			runsteps = static_cast<unsigned>(other >> 1);// this can shift out a 0 or a 1 bit here, depending on the leftovers of parity
		}

		// perform the bidirectional 8-bit sorting sequence
		// flip the relevant bits inside runsteps first
		if(runsteps ^= (1u << CHAR_BIT * sizeof(T) / 8) - 1)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
			[[likely]]
#endif
		{
			T *pdst{buffer}, *pdstnext{output};// for the next iteration
			if(paritybool){// swap if the count of sorting actions to do is odd
				pdst = output;
				pdstnext = buffer;
			}
			radixsortnoallocmulti2threadmain<isabsvalue, issignmode, isfltpmode, ismultithreadcapable, T, X>(count, input, pdst, pdstnext, offsets, runsteps, usemultithread, atomiclightbarrier);
		}
	}else if(0 == static_cast<std::ptrdiff_t>(count)) *output = *input;// copy the single element if the count is 1
}

// multi-threading companion for the radixsortnoallocmulti2thread() function implementation template for multi-part types without indirection
// Do not use this function directly.
template<bool isdescsort, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	64 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void> radixsortnoallocmulti2threadmtc(std::size_t count, T input[], T buffer[], std::atomic_uintptr_t &atomiclightbarrier)noexcept{
	// do not pass a nullptr here
	assert(input);
	assert(buffer);
	static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	X offsetscompanion[offsetsstride]{};// a sizeable amount of indices, but it's worth it, zeroed in advance here
	radixsortnoallocmulti2threadinitmtc<isabsvalue, issignmode, isfltpmode, T, X>(count, input, buffer, offsetscompanion);

	X *offsets;
	{// barrier and pointer exchange with the main thread
		std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsetscompanion))};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed);
			}while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == other);
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		offsets = reinterpret_cast<X *>(other);// retrieve the pointer
	}

	// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
	auto[runsteps, paritybool]{generateoffsetsmultimtc<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, offsets, offsetscompanion)};

	{// barrier and (flipped bits) runsteps, paritybool value exchange with the main thread
		// paritybool is either 0 or 1 here, so we can pack it together with runsteps and add usemultithread on top
		std::uintptr_t compound{static_cast<std::uintptr_t>(runsteps) * 2 + static_cast<std::uintptr_t>(paritybool) + 1};
		while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == atomiclightbarrier.load(std::memory_order_relaxed)){
			spinpause();// catch up
		}
		std::uintptr_t other{atomiclightbarrier.fetch_add(compound)};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed) - compound;
			}while(!other);
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		other += compound;// combine
		unsigned lowercarryoutbits{2 + paritybool};
		paritybool = static_cast<unsigned>(other) & 1;// piece together the parity from both threads
		other -= lowercarryoutbits;// this will remove possiby two bits of carry-out before the next right shift
		runsteps = static_cast<unsigned>(other >> 1);// this can shift out a 0 or a 1 bit here, depending on the leftovers of parity
	}

	// perform the bidirectional 8-bit sorting sequence
	// flip the relevant bits inside runsteps first
	if(runsteps ^= (1u << CHAR_BIT * sizeof(T) / 8) - 1)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
		[[likely]]
#endif
	{// perform the bidirectional 8-bit sorting sequence
		T *psrclo{input}, *pdst{buffer};
		if(paritybool){// swap if the count of sorting actions to do is odd
			psrclo = buffer;
			pdst = input;
		}
		radixsortnoallocmulti2threadmainmtc<isabsvalue, issignmode, isfltpmode, T, X>(count, psrclo, pdst, psrclo, offsetscompanion, runsteps, atomiclightbarrier);
	}
}

// radixsortnoalloc() function implementation template for multi-part types without indirection
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	, bool ismultithreadcapable = true
#endif
	>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	64 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	radixsortnoallocmulti1thread
#else
	radixsortnoallocmulti2thread
#endif
	(std::size_t count, T input[], T buffer[], bool movetobuffer = false)noexcept{
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	static bool constexpr ismultithreadcapable{false};
#endif
	if constexpr(ismultithreadcapable){
		assert(1 < std::thread::hardware_concurrency());// only use multi-threading if there is more than one hardware thread
		assert(15 <= count);// a 0 or 1 count array is only allowed here in single-threaded function mode
	}
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(buffer);
	// All the code in this function is adapted for count to be one below its input value here.
	--count;
	if(ismultithreadcapable || 0 < static_cast<std::ptrdiff_t>(count)){// a 0 or 1 count array is only allowed here in single-threaded function mode
		static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
		// conditionally enable multi-threading here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t, std::nullptr_t> atomiclightbarrier{};
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::future<void>, std::nullptr_t> asynchandle;

		// count the 256 configurations, all in one go
		if constexpr(ismultithreadcapable){
			try{
				asynchandle = std::async(std::launch::async, radixsortnoallocmulti2threadmtc<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>, count, input, buffer, std::ref(atomiclightbarrier));
				usemultithread = 1;
			}catch(...){// std::async may fail gracefully here
				assert(false);
			}
		}
		X offsets[offsetsstride * (2 - ismultithreadcapable)];// a sizeable amount of indices, but it's worth it
		std::memset(offsets, 0, offsetsstride * sizeof(X));// zeroed in advance here
		if constexpr(64 == CHAR_BIT * sizeof(T)){
			if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
			}else{// 64-bit, not in reverse order
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
					do{
						U cur{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, buffer + i);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						U cur5{cur >> 40};
						U cur6{cur >> 48};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i] = static_cast<T>(cur);
						cur >>= 56;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						cur5 &= 0xFFu;
						cur6 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
						++offsets[6 * 256 + static_cast<std::size_t>(cur6)];
						++offsets[7 * 256 + static_cast<std::size_t>(cur)];
					}while(0 <= --i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
					do{
						U curhi{input[i]};
						U curlo{input[i - 1]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								curhi, buffer + i,
								curlo, buffer + i - 1);
						}
						// register pressure performance issue on several platforms: first do the high half here
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						U curhi4{curhi >> 32};
						U curhi5{curhi >> 40};
						U curhi6{curhi >> 48};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i] = static_cast<T>(curhi);
						curhi >>= 56;
						++offsets[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						curhi4 &= 0xFFu;
						curhi5 &= 0xFFu;
						curhi6 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(curhi1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curhi5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curhi6)];
						++offsets[7 * 256 + static_cast<std::size_t>(curhi)];
						// register pressure performance issue on several platforms: do the low half here second
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						U curlo4{curlo >> 32};
						U curlo5{curlo >> 40};
						U curlo6{curlo >> 48};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i - 1] = static_cast<T>(curlo);
						curlo >>= 56;
						++offsets[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						curlo4 &= 0xFFu;
						curlo5 &= 0xFFu;
						curlo6 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(curlo1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curlo5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curlo6)];
						++offsets[7 * 256 + static_cast<std::size_t>(curlo)];
						i -= 2;
					}while(0 < i);
					if(!(1 & i)){// fill in the final item for odd counts
						U cur{input[0]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, buffer);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						U cur5{cur >> 40};
						U cur6{cur >> 48};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[0] = static_cast<T>(cur);
						cur >>= 56;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						cur5 &= 0xFFu;
						cur6 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
						++offsets[6 * 256 + static_cast<std::size_t>(cur6)];
						++offsets[7 * 256 + static_cast<std::size_t>(cur)];
					}
				}
			}
		}else if constexpr(56 == CHAR_BIT * sizeof(T)){
			if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
			}else{// 56-bit, not in reverse order
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
					do{
						U cur{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, buffer + i);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						U cur5{cur >> 40};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i] = static_cast<T>(cur);
						cur >>= 48;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						cur5 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
						++offsets[6 * 256 + static_cast<std::size_t>(cur)];
					}while(0 <= --i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
					do{
						U curhi{input[i]};
						U curlo{input[i - 1]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								curhi, buffer + i,
								curlo, buffer + i - 1);
						}
						// register pressure performance issue on several platforms: first do the high half here
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						U curhi4{curhi >> 32};
						U curhi5{curhi >> 40};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i] = static_cast<T>(curhi);
						curhi >>= 48;
						++offsets[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						curhi4 &= 0xFFu;
						curhi5 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(curhi1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curhi5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curhi)];
						// register pressure performance issue on several platforms: do the low half here second
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						U curlo4{curlo >> 32};
						U curlo5{curlo >> 40};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i - 1] = static_cast<T>(curlo);
						curlo >>= 48;
						++offsets[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						curlo4 &= 0xFFu;
						curlo5 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(curlo1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curlo5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curlo)];
						i -= 2;
					}while(0 < i);
					if(!(1 & i)){// fill in the final item for odd counts
						U cur{input[0]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, buffer);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						U cur5{cur >> 40};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[0] = static_cast<T>(cur);
						cur >>= 48;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						cur5 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
						++offsets[6 * 256 + static_cast<std::size_t>(cur)];
					}
				}
			}
		}else if constexpr(48 == CHAR_BIT * sizeof(T)){
			if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
			}else{// 48-bit, not in reverse order
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
					do{
						U cur{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, buffer + i);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i] = static_cast<T>(cur);
						cur >>= 40;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsets[5 * 256 + static_cast<std::size_t>(cur)];
					}while(0 <= --i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
					do{
						U curhi{input[i]};
						U curlo{input[i - 1]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								curhi, buffer + i,
								curlo, buffer + i - 1);
						}
						// register pressure performance issue on several platforms: first do the high half here
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						U curhi4{curhi >> 32};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i] = static_cast<T>(curhi);
						curhi >>= 40;
						++offsets[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						curhi4 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(curhi1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curhi)];
						// register pressure performance issue on several platforms: do the low half here second
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						U curlo4{curlo >> 32};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i - 1] = static_cast<T>(curlo);
						curlo >>= 40;
						++offsets[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						curlo4 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(curlo1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curlo)];
						i -= 2;
					}while(0 < i);
					if(!(1 & i)){// fill in the final item for odd counts
						U cur{input[0]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, buffer);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[0] = static_cast<T>(cur);
						cur >>= 40;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsets[5 * 256 + static_cast<std::size_t>(cur)];
					}
				}
			}
		}else if constexpr(40 == CHAR_BIT * sizeof(T)){
			if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
			}else{// 40-bit, not in reverse order
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
					do{
						U cur{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, buffer + i);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i] = static_cast<T>(cur);
						cur >>= 32;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur)];
					}while(0 <= --i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
					do{
						U curhi{input[i]};
						U curlo{input[i - 1]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								curhi, buffer + i,
								curlo, buffer + i - 1);
						}
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i] = static_cast<T>(curhi);
						curhi >>= 32;
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i - 1] = static_cast<T>(curlo);
						curlo >>= 32;
						++offsets[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsets[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(curhi1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curhi)];
						++offsets[256 + static_cast<std::size_t>(curlo1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curlo)];
						i -= 2;
					}while(0 < i);
					if(!(1 & i)){// fill in the final item for odd counts
						U cur{input[0]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, buffer);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[0] = static_cast<T>(cur);
						cur >>= 32;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur)];
					}
				}
			}
		}else if constexpr(32 == CHAR_BIT * sizeof(T)){
			if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
			}else{// 32-bit, not in reverse order
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
					do{
						U cur{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, buffer + i);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i] = static_cast<T>(cur);
						cur >>= 24;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur)];
					}while(0 <= --i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
					do{
						U cura{input[i]};
						U curb{input[i - 1]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								cura, buffer + i,
								curb, buffer + i - 1);
						}
						U cur0a{cura & 0xFFu};
						U cur1a{cura >> 8};
						U cur2a{cura >> 16};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i] = static_cast<T>(cura);
						cura >>= 24;
						U cur0b{curb & 0xFFu};
						U cur1b{curb >> 8};
						U cur2b{curb >> 16};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i - 1] = static_cast<T>(curb);
						curb >>= 24;
						++offsets[cur0a];
						cur1a &= 0xFFu;
						cur2a &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
						++offsets[cur0b];
						cur1b &= 0xFFu;
						cur2b &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1a)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2a)];
						++offsets[3 * 256 + static_cast<std::size_t>(cura)];
						++offsets[256 + static_cast<std::size_t>(cur1b)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2b)];
						++offsets[3 * 256 + static_cast<std::size_t>(curb)];
						i -= 2;
					}while(0 < i);
					if(!(1 & i)){// fill in the final item for odd counts
						U cur{input[0]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, buffer);
						}
						U cur0{cur & 0xFFu};
						U cur1{static_cast<unsigned>(cur) >> 8};
						U cur2{static_cast<unsigned>(cur) >> 16};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[0] = static_cast<T>(cur);
						cur >>= 24;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur)];
					}
				}
			}
		}else if constexpr(24 == CHAR_BIT * sizeof(T)){
			if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
			}else{// 24-bit, not in reverse order
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
					do{
						U cur{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, buffer + i);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i] = static_cast<T>(cur);
						cur >>= 16;
						++offsets[cur0];
						cur1 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur)];
					}while(0 <= --i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 3) / 6) * 3;
					i -= 2;
					if(0 <= i)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
						[[likely]]
#endif
						do{
						U cura{input[i + 2]};
						U curb{input[i + 1]};
						U curc{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								cura, buffer + i + 2,
								curb, buffer + i + 1,
								curc, buffer + i);
						}
						U cur0a{cura & 0xFFu};
						U cur1a{cura >> 8};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i + 3] = static_cast<T>(cura);
						cura >>= 16;
						U cur0b{curb & 0xFFu};
						U cur1b{curb >> 8};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i + 2] = static_cast<T>(curb);
						curb >>= 16;
						U cur0c{curc & 0xFFu};
						U cur1c{curc >> 8};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i + 1] = static_cast<T>(curc);
						curc >>= 16;
						++offsets[cur0a];
						cur1a &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
						++offsets[cur0b];
						cur1b &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
						++offsets[cur0c];
						cur1c &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1a)];
						++offsets[2 * 256 + static_cast<std::size_t>(cura)];
						++offsets[256 + static_cast<std::size_t>(cur1b)];
						++offsets[2 * 256 + static_cast<std::size_t>(curb)];
						++offsets[256 + static_cast<std::size_t>(cur1c)];
						++offsets[2 * 256 + static_cast<std::size_t>(curc)];
						i -= 3;
					}while(0 <= i);
					if(2 & i){// fill in the final two items for a remainder of 2 or 3
						U cura{input[i + 2]};
						U curb{input[i + 1]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								cura, buffer + i + 2,
								curb, buffer + i + 1);
						}
						U cur0a{cura & 0xFFu};
						U cur1a{cura >> 8};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i + 2] = static_cast<T>(cura);
						cura >>= 16;
						U cur0b{curb & 0xFFu};
						U cur1b{curb >> 8};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i + 1] = static_cast<T>(curb);
						curb >>= 16;
						++offsets[cur0a];
						cur1a &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
						++offsets[cur0b];
						cur1b &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1a)];
						++offsets[2 * 256 + static_cast<std::size_t>(cura)];
						++offsets[256 + static_cast<std::size_t>(cur1b)];
						++offsets[2 * 256 + static_cast<std::size_t>(curb)];
					}
					if(1 & i){// fill in the final item for odd counts
						U cur{input[0]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, buffer);
						}
						U cur0{cur & 0xFFu};
						U cur1{static_cast<unsigned>(cur) >> 8};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[0] = static_cast<T>(cur);
						cur >>= 16;
						++offsets[cur0];
						cur1 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur)];
					}
				}
			}
		}else if constexpr(16 == CHAR_BIT * sizeof(T)){
			if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
			}else{// 16-bit, not in reverse order
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
					do{
						U cur{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, buffer + i);
						}
						U cur0{cur & 0xFFu};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i] = static_cast<T>(cur);
						cur >>= 8;
						++offsets[cur0];
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur)];
					}while(0 <= --i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 4) >> 3) * 4;
					i -= 3;
					if(0 <= i)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
						[[likely]]
#endif
						do{
						U cura{input[i + 3]};
						U curb{input[i + 2]};
						U curc{input[i + 1]};
						U curd{input[i]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								cura, buffer + i + 3,
								curb, buffer + i + 2,
								curc, buffer + i + 1,
								curd, buffer + i);
						}
						U cur0a{cura & 0xFFu};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i + 3] = static_cast<T>(cura);
						cura >>= 8;
						U cur0b{curb & 0xFFu};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i + 2] = static_cast<T>(curb);
						curb >>= 8;
						U cur0c{curc & 0xFFu};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i + 1] = static_cast<T>(curc);
						curc >>= 8;
						U cur0d{curd & 0xFFu};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i] = static_cast<T>(curd);
						curd >>= 8;
						++offsets[cur0a];
						if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
						++offsets[cur0b];
						if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
						++offsets[cur0c];
						if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
						++offsets[cur0d];
						if constexpr(isabsvalue && issignmode && isfltpmode) curd &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cura)];
						++offsets[256 + static_cast<std::size_t>(curb)];
						++offsets[256 + static_cast<std::size_t>(curc)];
						++offsets[256 + static_cast<std::size_t>(curd)];
						i -= 4;
					}while(0 <= i);
					if(2 & i){// fill in the final two items for a remainder of 2 or 3
						U cura{input[i + 3]};
						U curb{input[i + 2]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(
								cura, buffer + i + 3,
								curb, buffer + i + 2);
						}
						U cur0a{cura & 0xFFu};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i + 3] = static_cast<T>(cura);
						cura >>= 8;
						U cur0b{curb & 0xFFu};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[i + 2] = static_cast<T>(curb);
						curb >>= 8;
						++offsets[cur0a];
						if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
						++offsets[cur0b];
						if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cura)];
						++offsets[256 + static_cast<std::size_t>(curb)];
					}
					if(1 & i){// fill in the final item for odd counts
						U cur{input[0]};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, buffer);
						}
						U cur0{cur & 0xFFu};
						if constexpr(isabsvalue == isfltpmode && !(isabsvalue && !issignmode)) buffer[0] = static_cast<T>(cur);
						cur >>= 8;
						++offsets[cur0];
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur)];
					}
				}
			}
		}else static_assert(false, "Implementing larger types will require additional work and optimisation for this library.");

		// barrier and pointer exchange with the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, X *, std::nullptr_t> offsetscompanion;
		if constexpr(ismultithreadcapable){
			std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsets) & -static_cast<std::intptr_t>(usemultithread))};
			// simply do not spin if usemultithread is zero
			if(usemultithread > other){
				do{
					spinpause();
					other = atomiclightbarrier.load(std::memory_order_relaxed);
				}while(reinterpret_cast<std::uintptr_t>(offsets) == other);
				// reset the barrier after use, only one thread will do this
				// no busy-wait dependency on this store, hence relaxed memory order is fine
				reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
				// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
			}
			// this will just be zero if usemultithread is zero
			offsetscompanion = reinterpret_cast<X *>(other);// retrieve the pointer
		}else offsetscompanion = nullptr;

		// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
		auto[runsteps, paritybool]{generateoffsetsmulti<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, offsets, offsetscompanion, usemultithread, movetobuffer)};

		// barrier and (flipped bits) runsteps, paritybool value exchange with the companion thread
		if constexpr(ismultithreadcapable){
			// paritybool is either 0 or 1 here, so we can pack it together with runsteps and add usemultithread on top
			std::uintptr_t compound{static_cast<std::uintptr_t>(runsteps) * 2 + static_cast<std::uintptr_t>(paritybool) + static_cast<std::uintptr_t>(usemultithread)};
			while(reinterpret_cast<std::uintptr_t>(offsets) == atomiclightbarrier.load(std::memory_order_relaxed)){
				spinpause();// catch up
			}
			std::uintptr_t other{atomiclightbarrier.fetch_add(compound & -static_cast<std::intptr_t>(usemultithread))};
			// simply do not spin if usemultithread is zero
			if(usemultithread > other){
				do{
					spinpause();
					other = atomiclightbarrier.load(std::memory_order_relaxed) - compound;
				}while(!other);
				// reset the barrier after use, only one thread will do this
				// no busy-wait dependency on this store, hence relaxed memory order is fine
				reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
				// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
			}
			other += compound;// combine
			unsigned lowercarryoutbits{2 * usemultithread + paritybool};
			paritybool = static_cast<unsigned>(other) & 1;// piece together the parity from both threads
			other -= lowercarryoutbits;// this will remove possiby two bits of carry-out before the next right shift
			runsteps = static_cast<unsigned>(other >> 1);// this can shift out a 0 or a 1 bit here, depending on the leftovers of parity
		}

		// perform the bidirectional 8-bit sorting sequence
		// flip the relevant bits inside runsteps first
		if(runsteps ^= (1u << CHAR_BIT * sizeof(T) / 8) - 1)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
			[[likely]]
#endif
		{
			T *psrclo{input}, *pdst{buffer};
			if(paritybool){// swap if the count of sorting actions to do is odd
				psrclo = buffer;
				pdst = input;
			}
			radixsortnoallocmulti2threadmain<isabsvalue, issignmode, isfltpmode, ismultithreadcapable, T, X>(count, psrclo, pdst, psrclo, offsets, runsteps, usemultithread, atomiclightbarrier);
		}
	}else if(0 == static_cast<std::ptrdiff_t>(count)) *buffer = *input;// copy the single element if the count is 1
}

// initialisation part, multi-threading companion for the radixsortcopynoallocmulti2thread() and radixsortnoallocmulti2thread() function implementation templates for 80-bit-based long double types with indirection
// Platforms with a native 80-bit long double type are all little endian, hence that is the only implementation here.
// Do not use this function directly.
template<auto indirection1, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, bool isinputconst, typename V, typename X, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	(std::is_same_v<longdoubletest128, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<longdoubletest96, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<longdoubletest80, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<long double, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> &&
	64 == LDBL_MANT_DIG &&
	16384 == LDBL_MAX_EXP &&
	128 >= CHAR_BIT * sizeof(long double) &&
	64 < CHAR_BIT * sizeof(long double)),
	void> radixsortnoallocmulti2threadinitmtc(std::size_t count, std::conditional_t<isinputconst, V *const *, V **> input, V *pout[], std::conditional_t<isinputconst, V **, std::nullptr_t> pdst, X offsetscompanion[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>;
	using W = decltype(T::signexponent);
	using U =
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::conditional_t<128 == CHAR_BIT * sizeof(T), std::uint_least64_t,
#endif
		unsigned
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		>
#endif
		;// assume zero-extension to be basically free for U on basically all modern machines
	assert(3 <= count);// this function is not for small arrays, 4 is the minimum original array count
	// do not pass a nullptr here
	assert(input);
	assert(pout);
	if(isinputconst) assert(pdst);
	assert(offsetscompanion);
	if constexpr(isrevorder){// also reverse the array at the same time
		if constexpr(isinputconst){
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
				pout += count - i;
				pdst += count - i;
				do{
					V *p{input[0]};
					++input;
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					pout[i] = p;
					pdst[i] = p;
					auto cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
					std::uint64_t curm{cur.mantissa};
					U cure{static_cast<U>(cur.signexponent)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curm, cure);
					}
					unsigned cure0{static_cast<unsigned>(cure & 0xFFu)};
					cure >>= 8;
					unsigned curm0{static_cast<unsigned>(curm & 0xFFu)};
					unsigned curm1{static_cast<unsigned>(curm >> 8)};
					unsigned curm2{static_cast<unsigned>(curm >> 16)};
					unsigned curm3{static_cast<unsigned>(curm >> 24)};
					unsigned curm4{static_cast<unsigned>(curm >> 32)};
					unsigned curm5{static_cast<unsigned>(curm >> 40)};
					unsigned curm6{static_cast<unsigned>(curm >> 48)};
					curm >>= 56;
					++offsetscompanion[8 * 256 + static_cast<std::size_t>(cure0)];
					cure &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsetscompanion[curm0];
					curm1 &= 0xFFu;
					curm2 &= 0xFFu;
					curm3 &= 0xFFu;
					curm4 &= 0xFFu;
					curm5 &= 0xFFu;
					curm6 &= 0xFFu;
					++offsetscompanion[9 * 256 + static_cast<std::size_t>(cure)];
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curm)];
					++offsetscompanion[256 + static_cast<std::size_t>(curm1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curm2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curm3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curm4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curm5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curm6)];
				}while(0 <= --i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
				pout += count - i;
				pdst += count - i;
				do{
					V *plo{input[0]};
					V *phi{input[1]};
					input += 2;
					auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
					pout[i] = plo;
					pdst[i] = plo;
					auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
					pout[i - 1] = phi;
					pdst[i - 1] = phi;
					auto curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
					auto curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
					std::uint64_t curmlo{curlo.mantissa};
					U curelo{static_cast<U>(curlo.signexponen)};
					std::uint64_t curmhi{curhi.mantissa};
					U curehi{static_cast<U>(curhi.signexponent)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curmlo, curelo, curmhi, curehi);
					}
					// register pressure performance issue on several platforms: first do the low half here
					unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
					curelo >>= 8;
					unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
					unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
					unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
					unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
					unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
					unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
					unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
					curmlo >>= 56;
					++offsetscompanion[8 * 256 + static_cast<std::size_t>(curelo0)];
					curelo &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsetscompanion[curmlo0];
					curmlo1 &= 0xFFu;
					curmlo2 &= 0xFFu;
					curmlo3 &= 0xFFu;
					curmlo4 &= 0xFFu;
					curmlo5 &= 0xFFu;
					curmlo6 &= 0xFFu;
					++offsetscompanion[9 * 256 + static_cast<std::size_t>(curelo)];
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curmlo)];
					++offsetscompanion[256 + static_cast<std::size_t>(curmlo1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curmlo2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curmlo3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curmlo4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curmlo5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curmlo6)];
					// register pressure performance issue on several platforms: do the high half here second
					unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
					curehi >>= 8;
					unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
					unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
					unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
					unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
					unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
					unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
					unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
					curmhi >>= 56;
					++offsetscompanion[8 * 256 + static_cast<std::size_t>(curehi0)];
					curehi &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsetscompanion[curmhi0];
					curmhi1 &= 0xFFu;
					curmhi2 &= 0xFFu;
					curmhi3 &= 0xFFu;
					curmhi4 &= 0xFFu;
					curmhi5 &= 0xFFu;
					curmhi6 &= 0xFFu;
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curmhi)];
					++offsetscompanion[9 * 256 + static_cast<std::size_t>(curehi)];
					++offsetscompanion[256 + static_cast<std::size_t>(curmhi1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curmhi2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curmhi3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curmhi4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curmhi5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curmhi6)];
					i -= 2;
				}while(0 <= i);
			}
		}else{// !isinputconst
			V **pinputlo{input}, **pinputhi{input + count};
			V **poutputlo{pout}, **poutputhi{pout + count};
			std::size_t i{(count + 1 + 2) >> 2};// rounded up in the companion thread
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				do{
					V *plo{pinputlo[0]};
					V *phi{pinputhi[0]};
					// register pressure performance issue on several platforms: first do the low half here
					auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
					*pinputhi-- = plo;
					*poutputhi-- = plo;
					auto curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
					std::uint64_t curmlo{curlo.mantissa};
					U curelo{static_cast<U>(curlo.signexponent)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curmlo, curelo);
					}
					unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
					curelo >>= 8;
					unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
					unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
					unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
					unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
					unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
					unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
					unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
					curmlo >>= 56;
					++offsetscompanion[8 * 256 + static_cast<std::size_t>(curelo0)];
					curelo &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsetscompanion[curmlo0];
					curmlo1 &= 0xFFu;
					curmlo2 &= 0xFFu;
					curmlo3 &= 0xFFu;
					curmlo4 &= 0xFFu;
					curmlo5 &= 0xFFu;
					curmlo6 &= 0xFFu;
					++offsetscompanion[9 * 256 + static_cast<std::size_t>(curelo)];
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curmlo)];
					++offsetscompanion[256 + static_cast<std::size_t>(curmlo1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curmlo2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curmlo3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curmlo4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curmlo5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curmlo6)];
					// register pressure performance issue on several platforms: do the high half here second
					auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
					*pinputlo++ = phi;
					*poutputlo++ = phi;
					auto curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
					std::uint64_t curmhi{curhi.mantissa};
					U curehi{static_cast<U>(curhi.signexponent)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curmhi, curehi);
					}
					unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
					curehi >>= 8;
					unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
					unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
					unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
					unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
					unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
					unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
					unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
					curmhi >>= 56;
					++offsetscompanion[8 * 256 + static_cast<std::size_t>(curehi0)];
					curehi &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsetscompanion[curmhi0];
					curmhi1 &= 0xFFu;
					curmhi2 &= 0xFFu;
					curmhi3 &= 0xFFu;
					curmhi4 &= 0xFFu;
					curmhi5 &= 0xFFu;
					curmhi6 &= 0xFFu;
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curmhi)];
					++offsetscompanion[9 * 256 + static_cast<std::size_t>(curehi)];
					++offsetscompanion[256 + static_cast<std::size_t>(curmhi1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curmhi2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curmhi3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curmhi4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curmhi5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curmhi6)];
				}while(--i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				do{
					V *plo{pinputlo[0]};
					V *phi{pinputhi[0]};
					auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
					*pinputhi-- = plo;
					*poutputhi-- = plo;
					auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
					*pinputlo++ = phi;
					*poutputlo++ = phi;
					auto curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
					auto curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
					std::uint64_t curmlo{curlo.mantissa};
					U curelo{static_cast<U>(curlo.signexponent)};
					std::uint64_t curmhi{curhi.mantissa};
					U curehi{static_cast<U>(curhi.signexponent)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curmlo, curelo, curmhi, curehi);
					}
					// register pressure performance issue on several platforms: first do the low half here
					unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
					curelo >>= 8;
					unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
					unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
					unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
					unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
					unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
					unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
					unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
					curmlo >>= 56;
					++offsetscompanion[8 * 256 + static_cast<std::size_t>(curelo0)];
					curelo &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsetscompanion[curmlo0];
					curmlo1 &= 0xFFu;
					curmlo2 &= 0xFFu;
					curmlo3 &= 0xFFu;
					curmlo4 &= 0xFFu;
					curmlo5 &= 0xFFu;
					curmlo6 &= 0xFFu;
					++offsetscompanion[9 * 256 + static_cast<std::size_t>(curelo)];
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curmlo)];
					++offsetscompanion[256 + static_cast<std::size_t>(curmlo1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curmlo2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curmlo3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curmlo4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curmlo5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curmlo6)];
					// register pressure performance issue on several platforms: do the high half here second
					unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
					curehi >>= 8;
					unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
					unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
					unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
					unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
					unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
					unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
					unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
					curmhi >>= 56;
					++offsetscompanion[8 * 256 + static_cast<std::size_t>(curehi0)];
					curehi &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
					++offsetscompanion[curmhi0];
					curmhi1 &= 0xFFu;
					curmhi2 &= 0xFFu;
					curmhi3 &= 0xFFu;
					curmhi4 &= 0xFFu;
					curmhi5 &= 0xFFu;
					curmhi6 &= 0xFFu;
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curmhi)];
					++offsetscompanion[9 * 256 + static_cast<std::size_t>(curehi)];
					++offsetscompanion[256 + static_cast<std::size_t>(curmhi1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curmhi2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curmhi3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curmhi4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curmhi5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curmhi6)];
				}while(--i);
			}
		}
	}else{// not in reverse order
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
			// unsigned counter, not zero inclusive inside the loop
			std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
			input += count - i;
			pout += count - i;
			do{
				V *p{input[i]};
				auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
				pout[i] = p;
				auto cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
				std::uint64_t curm{cur.mantissa};
				U cure{static_cast<U>(cur.signexponent)};
				if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(curm, cure);
				}
				unsigned cure0{static_cast<unsigned>(cure & 0xFFu)};
				cure >>= 8;
				unsigned curm0{static_cast<unsigned>(curm & 0xFFu)};
				unsigned curm1{static_cast<unsigned>(curm >> 8)};
				unsigned curm2{static_cast<unsigned>(curm >> 16)};
				unsigned curm3{static_cast<unsigned>(curm >> 24)};
				unsigned curm4{static_cast<unsigned>(curm >> 32)};
				unsigned curm5{static_cast<unsigned>(curm >> 40)};
				unsigned curm6{static_cast<unsigned>(curm >> 48)};
				curm >>= 56;
				++offsetscompanion[8 * 256 + static_cast<std::size_t>(cure0)];
				cure &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
				++offsetscompanion[curm0];
				curm1 &= 0xFFu;
				curm2 &= 0xFFu;
				curm3 &= 0xFFu;
				curm4 &= 0xFFu;
				curm5 &= 0xFFu;
				curm6 &= 0xFFu;
				++offsetscompanion[9 * 256 + static_cast<std::size_t>(cure)];
				++offsetscompanion[7 * 256 + static_cast<std::size_t>(curm)];
				++offsetscompanion[256 + static_cast<std::size_t>(curm1)];
				++offsetscompanion[2 * 256 + static_cast<std::size_t>(curm2)];
				++offsetscompanion[3 * 256 + static_cast<std::size_t>(curm3)];
				++offsetscompanion[4 * 256 + static_cast<std::size_t>(curm4)];
				++offsetscompanion[5 * 256 + static_cast<std::size_t>(curm5)];
				++offsetscompanion[6 * 256 + static_cast<std::size_t>(curm6)];
			}while(--i);
		}else{// architecture: do not limit as much when there's a reasonable amount of registers
			// unsigned counter, not zero inclusive inside the loop
			std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
			input += count - i;
			pout += count - i;
			do{
				V *phi{input[i]};
				V *plo{input[i - 1]};
				auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
				pout[i] = phi;
				auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
				pout[i - 1] = plo;
				auto curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
				auto curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
				std::uint64_t curmhi{curhi.mantissa};
				U curehi{static_cast<U>(curhi.signexponent)};
				std::uint64_t curmlo{curlo.mantissa};
				U curelo{static_cast<U>(curlo.signexponent)};
				if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(curmhi, curehi, curmlo, curelo);
				}
				// register pressure performance issue on several platforms: first do the high half here
				unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
				curehi >>= 8;
				unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
				unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
				unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
				unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
				unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
				unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
				unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
				curmhi >>= 56;
				++offsetscompanion[8 * 256 + static_cast<std::size_t>(curehi0)];
				curehi &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
				++offsetscompanion[curmhi0];
				curmhi1 &= 0xFFu;
				curmhi2 &= 0xFFu;
				curmhi3 &= 0xFFu;
				curmhi4 &= 0xFFu;
				curmhi5 &= 0xFFu;
				curmhi6 &= 0xFFu;
				++offsetscompanion[9 * 256 + static_cast<std::size_t>(curehi)];
				++offsetscompanion[7 * 256 + static_cast<std::size_t>(curmhi)];
				++offsetscompanion[256 + static_cast<std::size_t>(curmhi1)];
				++offsetscompanion[2 * 256 + static_cast<std::size_t>(curmhi2)];
				++offsetscompanion[3 * 256 + static_cast<std::size_t>(curmhi3)];
				++offsetscompanion[4 * 256 + static_cast<std::size_t>(curmhi4)];
				++offsetscompanion[5 * 256 + static_cast<std::size_t>(curmhi5)];
				++offsetscompanion[6 * 256 + static_cast<std::size_t>(curmhi6)];
				// register pressure performance issue on several platforms: do the low half here second
				unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
				curelo >>= 8;
				unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
				unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
				unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
				unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
				unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
				unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
				unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
				curmlo >>= 56;
				++offsetscompanion[8 * 256 + static_cast<std::size_t>(curelo0)];
				curelo &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
				++offsetscompanion[curmlo0];
				curmlo1 &= 0xFFu;
				curmlo2 &= 0xFFu;
				curmlo3 &= 0xFFu;
				curmlo4 &= 0xFFu;
				curmlo5 &= 0xFFu;
				curmlo6 &= 0xFFu;
				++offsetscompanion[9 * 256 + static_cast<std::size_t>(curelo)];
				++offsetscompanion[7 * 256 + static_cast<std::size_t>(curmlo)];
				++offsetscompanion[256 + static_cast<std::size_t>(curmlo1)];
				++offsetscompanion[2 * 256 + static_cast<std::size_t>(curmlo2)];
				++offsetscompanion[3 * 256 + static_cast<std::size_t>(curmlo3)];
				++offsetscompanion[4 * 256 + static_cast<std::size_t>(curmlo4)];
				++offsetscompanion[5 * 256 + static_cast<std::size_t>(curmlo5)];
				++offsetscompanion[6 * 256 + static_cast<std::size_t>(curmlo6)];
			}while(i -= 2);
		}
	}
}

// main part, multi-threading companion for the radixsortcopynoallocmulti2thread() and radixsortnoallocmulti2thread() function implementation templates for 80-bit-based long double types with indirection
// Platforms with a native 80-bit long double type are all little endian, hence that is the only implementation here.
// Do not use this function directly.
template<auto indirection1, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename X, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	(std::is_same_v<longdoubletest128, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<longdoubletest96, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<longdoubletest80, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<long double, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> &&
	64 == LDBL_MANT_DIG &&
	16384 == LDBL_MAX_EXP &&
	128 >= CHAR_BIT * sizeof(long double) &&
	64 < CHAR_BIT * sizeof(long double)),
	void> radixsortnoallocmulti2threadmainmtc(std::size_t count, V *const input[], V *pdst[], V *pdstnext[], X offsetscompanion[], unsigned runsteps, std::atomic_uintptr_t &atomiclightbarrier, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>;
	using W = decltype(T::signexponent);
	using U =
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::conditional_t<128 == CHAR_BIT * sizeof(T), std::uint_least64_t,
#endif
		unsigned
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		>
#endif
		;// assume zero-extension to be basically free for U on basically all modern machines
	assert(3 <= count);// this function is not for small arrays, 4 is the minimum original array count
	// do not pass a nullptr here
	assert(input);
	assert(pdst);
	assert(pdstnext);
	assert(offsetscompanion);
	assert(runsteps);
	unsigned shifter{bitscanforwardportable(runsteps)};// at least 1 bit is set inside runsteps as by previous check
	V **psrchi;
	if constexpr(isrevorder){
		psrchi = pdstnext + count;
	}else{
		psrchi = const_cast<V **>(input) + count;// psrchi will never be written to
	}
	// skip a step if possible
	runsteps >>= shifter;
	X *poffset{offsetscompanion + static_cast<std::size_t>(shifter) * 256};
	while(1 < atomiclightbarrier.load(std::memory_order_relaxed)){// continue if it's 0 or 1
		spinpause();// catch up until the other thread releases the barrier
	}// do not place this inside the main loop, as the barrier is released there by cancelling 1 and -1 in interlocked add-fetch operations
	if(80 / 8 - 2 == shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
		[[unlikely]]
#endif
		goto handletop16;// rare, but possible
	if(80 / 8 - 2 < shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
		[[unlikely]]
#endif
		goto handletop8;// rare, but possible
	shifter *= 8;
	for(;;){
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
			std::size_t j{(count + 1 + 2) >> 2};// rounded up in the top part
			do{// fill the array, two at a time
				V *pa{psrchi[0]};
				V *pb{psrchi[-1]};
				psrchi -= 2;
				auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
				auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
				auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
				auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
				auto[cura, curb]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, shifter)};
				std::size_t offseta{poffset[cura]--};// the next item will be placed one lower
				std::size_t offsetb{poffset[curb]--};
				pdst[offseta] = pa;
				pdst[offsetb] = pb;
			}while(--j);
		}else{// architecture: limit to four at a time when there's a decent amount of registers
			std::size_t j{(count + 1 + 4) >> 3};// rounded up in the top part
			do{// fill the array, four at a time
				V *pa{psrchi[0]};
				V *pb{psrchi[-1]};
				V *pc{psrchi[-2]};
				V *pd{psrchi[-3]};
				psrchi -= 4;
				auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
				auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
				auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
				auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
				auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
				auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
				auto outc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
				auto outd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
				auto[cura, curb, curc, curd]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd, shifter)};
				std::size_t offseta{poffset[cura]--};// the next item will be placed one lower
				std::size_t offsetb{poffset[curb]--};
				std::size_t offsetc{poffset[curc]--};
				std::size_t offsetd{poffset[curd]--};
				pdst[offseta] = pa;
				pdst[offsetb] = pb;
				pdst[offsetc] = pc;
				pdst[offsetd] = pd;
			}while(--j);
		}
		runsteps >>= 1;
		if(!runsteps)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
			[[unlikely]]
#endif
			break;
		{
			unsigned index{bitscanforwardportable(runsteps)};// at least 1 bit is set inside runsteps as by previous check
			shifter += 8;
			poffset += 256;
			// swap the pointers for the next round, data is moved on each iteration
			psrchi = pdst;
			std::uintptr_t old{atomiclightbarrier.fetch_add(~static_cast<std::uintptr_t>(0))};
			pdst = pdstnext;
			pdstnext = psrchi;
			psrchi += count;
			// skip a step if possible
			runsteps >>= index;
			shifter += index * 8;
			poffset += static_cast<std::size_t>(index) * 256;
			if constexpr(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
				if(!old) do{
					spinpause();
				}while(atomiclightbarrier.load(std::memory_order_relaxed));
			}else{// detect exceptions
				if(!old) do{
					spinpause();
					old = atomiclightbarrier.load(std::memory_order_relaxed);
				}while(~static_cast<std::uintptr_t>(0) == old);
				if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == old) return;// the main thread produced an exception
			}
		}
		// handle the top two parts differently
		if(80 - 16 <= shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
			[[unlikely]]
#endif
		{
			if(80 - 16 == shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
				[[likely]]
#endif
			{
handletop16:
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
					std::size_t j{(count + 1 + 2) >> 2};// rounded up in the top part
					do{// fill the array, two at a time
						V *pa{psrchi[0]};
						V *pb{psrchi[-1]};
						psrchi -= 2;
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						auto[cura, curb]{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb)};
						std::size_t offseta{offsetscompanion[cura + (80 - 16) * 256 / 8]--};// the next item will be placed one lower
						std::size_t offsetb{offsetscompanion[curb + (80 - 16) * 256 / 8]--};
						pdst[offseta] = pa;
						pdst[offsetb] = pb;
					}while(--j);
				}else{// architecture: limit to four at a time when there's a decent amount of registers
					std::size_t j{(count + 1 + 4) >> 3};// rounded up in the top part
					do{// fill the array, four at a time
						V *pa{psrchi[0]};
						V *pb{psrchi[-1]};
						V *pc{psrchi[-2]};
						V *pd{psrchi[-3]};
						psrchi -= 4;
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
						auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
						auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						auto outc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
						auto outd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
						auto[cura, curb, curc, curd]{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd)};
						std::size_t offseta{offsetscompanion[cura + (80 - 16) * 256 / 8]--};// the next item will be placed one lower
						std::size_t offsetb{offsetscompanion[curb + (80 - 16) * 256 / 8]--};
						std::size_t offsetc{offsetscompanion[curc + (80 - 16) * 256 / 8]--};
						std::size_t offsetd{offsetscompanion[curd + (80 - 16) * 256 / 8]--};
						pdst[offseta] = pa;
						pdst[offsetb] = pb;
						pdst[offsetc] = pc;
						pdst[offsetd] = pd;
					}while(--j);
				}
				if(1 == runsteps)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
					[[unlikely]]
#endif
					break;
				{
					std::uintptr_t old{atomiclightbarrier.fetch_add(~static_cast<std::uintptr_t>(0))};
					// swap the pointers for the next round, data is moved on each iteration
					psrchi = pdst;
					pdst = pdstnext;
					// unused: pdstnext = psrchi;
					psrchi += count;
					if constexpr(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
						if(!old) do{
							spinpause();
						}while(atomiclightbarrier.load(std::memory_order_relaxed));
					}else{// detect exceptions
						if(!old) do{
							spinpause();
							old = atomiclightbarrier.load(std::memory_order_relaxed);
						}while(~static_cast<std::uintptr_t>(0) == old);
						if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == old) return;// the main thread produced an exception
					}
				}
handletop8:
				if constexpr (defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
					std::size_t j{(count + 1 + 2) >> 2};// rounded up in the top part
					do{// fill the array, two at a time
						V *pa{psrchi[0]};
						V *pb{psrchi[-1]};
						psrchi -= 2;
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb)};
						std::size_t offseta{offsetscompanion[cura + (80 - 8) * 256 / 8]--};// the next item will be placed one lower
						std::size_t offsetb{offsetscompanion[curb + (80 - 8) * 256 / 8]--};
						pdst[offseta] = pa;
						pdst[offsetb] = pb;
					}while(--j);
				}else{// architecture: limit to four at a time when there's a decent amount of registers
					std::size_t j{(count + 1 + 4) >> 3};// rounded up in the top part
					do{// fill the array, four at a time
						V *pa{psrchi[0]};
						V *pb{psrchi[-1]};
						V *pc{psrchi[-2]};
						V *pd{psrchi[-3]};
						psrchi -= 4;
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
						auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
						auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						auto outc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
						auto outd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
						auto[cura, curb, curc, curd]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd)};
						std::size_t offseta{offsetscompanion[cura + (80 - 8) * 256 / 8]--};// the next item will be placed one lower
						std::size_t offsetb{offsetscompanion[curb + (80 - 8) * 256 / 8]--};
						std::size_t offsetc{offsetscompanion[curc + (80 - 8) * 256 / 8]--};
						std::size_t offsetd{offsetscompanion[curd + (80 - 8) * 256 / 8]--};
						pdst[offseta] = pa;
						pdst[offsetb] = pb;
						pdst[offsetc] = pc;
						pdst[offsetd] = pd;
					}while(--j);
				}
				break;// no further processing beyond the top part
			}
		}
	}
}

// main part for the radixsortcopynoallocmulti2thread() and radixsortnoallocmulti2thread() function implementation templates for 80-bit-based long double types with indirection
// Do not use this function directly.
template<auto indirection1, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, bool ismultithreadcapable, typename V, typename X, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	(std::is_same_v<longdoubletest128, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<longdoubletest96, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<longdoubletest80, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<long double, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> &&
	64 == LDBL_MANT_DIG &&
	16384 == LDBL_MAX_EXP &&
	128 >= CHAR_BIT * sizeof(long double) &&
	64 < CHAR_BIT * sizeof(long double)),
	void> radixsortnoallocmulti2threadmain(std::size_t count, V *const input[], V *pdst[], V *pdstnext[], X offsets[], unsigned runsteps, unsigned usemultithread, std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t &, std::nullptr_t> atomiclightbarrier, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	using U =
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::conditional_t<128 == CHAR_BIT * sizeof(T), std::uint_least64_t,
#endif
		unsigned
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		>
#endif
		;// assume zero-extension to be basically free for U on basically all modern machines
	static std::size_t constexpr offsetsstride{80 * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	assert(count && count != MAXSIZE_T);
	// do not pass a nullptr here
	assert(input);
	assert(pdst);
	assert(pdstnext);
	assert(offsets);
	assert(runsteps);
	unsigned shifter{bitscanforwardportable(runsteps)};// at least 1 bit is set inside runsteps as by previous check
	V **psrclo;
	if constexpr(isrevorder){
		psrclo = pdstnext;
	}else{
		psrclo = const_cast<V **>(input);// psrclo will never be written to
	}
	// skip a step if possible
	runsteps >>= shifter;
	X *poffset{offsets + static_cast<std::size_t>(shifter) * 256};
	if constexpr(ismultithreadcapable) while(1 < 1 + atomiclightbarrier.load(std::memory_order_relaxed)){// continue if it's 0 or -1
		spinpause();// catch up until the other thread releases the barrier
	}// do not place this inside the main loop, as the barrier is released there by cancelling 1 and -1 in interlocked add-fetch operations
	if(80 / 8 - 2 == shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
		[[unlikely]]
#endif
	goto handletop16;// rare, but possible
	if(80 / 8 - 2 < shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
		[[unlikely]]
#endif
	goto handletop8;// rare, but possible
	shifter *= 8;
	for(;;){
		if constexpr(ismultithreadcapable){
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
				std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (1 + usemultithread))};// rounded down in the bottom part
				while(0 <= --j){// fill the array, two at a time
					V *pa{psrclo[0]};
					V *pb{psrclo[1]};
					psrclo += 2;
					auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
					auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
					auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
					auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
					auto[cura, curb]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, shifter)};
					std::size_t offseta{poffset[cura]++};// the next item will be placed one higher
					std::size_t offsetb{poffset[curb]++};
					pdst[offseta] = pa;
					pdst[offsetb] = pb;
				}
			}else{// architecture: limit to four at a time when there's a decent amount of registers
				std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (2 + usemultithread))};// rounded down in the bottom part
				while(0 <= --j){// fill the array, four at a time
					V *pa{psrclo[0]};
					V *pb{psrclo[1]};
					V *pc{psrclo[2]};
					V *pd{psrclo[3]};
					psrclo += 4;
					auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
					auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
					auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
					auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
					auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
					auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
					auto outc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
					auto outd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
					auto[cura, curb, curc, curd]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd, shifter)};
					std::size_t offseta{poffset[cura]++};// the next item will be placed one higher
					std::size_t offsetb{poffset[curb]++};
					std::size_t offsetc{poffset[curc]++};
					std::size_t offsetd{poffset[curd]++};
					pdst[offseta] = pa;
					pdst[offsetb] = pb;
					pdst[offsetc] = pc;
					pdst[offsetd] = pd;
				}
				if(2 & count + 1){// fill in the final two items for a remainder of 2 or 3
					V *pa{psrclo[0]};
					V *pb{psrclo[1]};
					psrclo += 2;
					auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
					auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
					auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
					auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
					auto[cura, curb]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, shifter)};
					std::size_t offseta{poffset[cura]++};// the next item will be placed one higher
					std::size_t offsetb{poffset[curb]++};
					pdst[offseta] = pa;
					pdst[offsetb] = pb;
				}
			}
			if(!(1 & count)){// fill in the final item for odd counts
				V *p{psrclo[0]};
				auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
				auto out{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
				std::size_t cur{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(out, shifter)};
				std::size_t offset{poffset[cur]};
				pdst[offset] = p;
			}
		}else{// !ismultithreadcapable
			V *const *psrchi{psrclo + count};
			do{// fill the array, two at a time: one low-to-middle, one high-to-middle
				V *plo{*psrclo++};
				V *phi{*psrchi--};
				auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
				auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
				auto outlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo)};
				auto outhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi)};
				auto[curlo, curhi]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outlo, outhi, shifter)};
				std::size_t offsetlo{poffset[curlo]++};// the next item will be placed one higher
				std::size_t offsethi{poffset[curhi + offsetsstride]--};// the next item will be placed one lower
				pdst[offsetlo] = plo;
				pdst[offsethi] = phi;
			}while(psrclo < psrchi);
			if(psrclo == psrchi){// fill in the final item for odd counts
				V *p{*psrclo};
				auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
				auto out{indirectinput2<indirection1, indirection2, isindexed2, T>(im)};
				std::size_t cur{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(out, shifter)};
				std::size_t offset{poffset[cur]};
				pdst[offset] = p;
			}
		}
		runsteps >>= 1;
		if(!runsteps)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
			[[unlikely]]
#endif
			break;
		{
			unsigned index{bitscanforwardportable(runsteps)};// at least 1 bit is set inside runsteps as by previous check
			shifter += 8;
			poffset += 256;
			// swap the pointers for the next round, data is moved on each iteration
			psrclo = pdst;
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			std::uintptr_t old;
			if constexpr(ismultithreadcapable) old = atomiclightbarrier.fetch_add(usemultithread);
			pdst = pdstnext;
			pdstnext = psrclo;
			// skip a step if possible
			runsteps >>= index;
			shifter += index * 8;
			poffset += static_cast<std::size_t>(index) * 256;
			if constexpr(ismultithreadcapable){
				if constexpr(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
					if(!old) do{
						spinpause();
					}while(atomiclightbarrier.load(std::memory_order_relaxed));
				}else{// detect exceptions
					if(!old) do{
						spinpause();
						old = atomiclightbarrier.load(std::memory_order_relaxed);
					}while(~static_cast<std::uintptr_t>(0) == old);
					if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == old) return;// the companion thread produced an exception
				}
			}
		}
		// handle the top two parts differently
		if(80 - 16 <= shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
			[[unlikely]]
#endif
		{
			if(80 - 16 == shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
				[[likely]]
#endif
			{
handletop16:
				if constexpr(ismultithreadcapable){
					if constexpr (defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
						std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (1 + usemultithread))};// rounded down in the bottom part
						while(0 <= --j){// fill the array, two at a time
							V *pa{psrclo[0]};
							V *pb{psrclo[1]};
							psrclo += 2;
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							auto[cura, curb]{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb)};
							std::size_t offseta{offsets[cura + (80 - 16) * 256 / 8]++};// the next item will be placed one higher
							std::size_t offsetb{offsets[curb + (80 - 16) * 256 / 8]++};
							pdst[offseta] = pa;
							pdst[offsetb] = pb;
						}
					}else{// architecture: limit to four at a time when there's a decent amount of registers
						std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (2 + usemultithread))};// rounded down in the bottom part
						while(0 <= --j){// fill the array, four at a time
							V *pa{psrclo[0]};
							V *pb{psrclo[1]};
							V *pc{psrclo[2]};
							V *pd{psrclo[3]};
							psrclo += 4;
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
							auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
							auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							auto outc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
							auto outd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
							auto[cura, curb, curc, curd]{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd)};
							std::size_t offseta{offsets[cura + (80 - 16) * 256 / 8]++};// the next item will be placed one higher
							std::size_t offsetb{offsets[curb + (80 - 16) * 256 / 8]++};
							std::size_t offsetc{offsets[curc + (80 - 16) * 256 / 8]++};
							std::size_t offsetd{offsets[curd + (80 - 16) * 256 / 8]++};
							pdst[offseta] = pa;
							pdst[offsetb] = pb;
							pdst[offsetc] = pc;
							pdst[offsetd] = pd;
						}
						if(2 & count + 1){// fill in the final two items for a remainder of 2 or 3
							V *pa{psrclo[0]};
							V *pb{psrclo[1]};
							psrclo += 2;
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							auto[cura, curb]{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb)};
							std::size_t offseta{offsets[cura + (80 - 16) * 256 / 8]++};// the next item will be placed one higher
							std::size_t offsetb{offsets[curb + (80 - 16) * 256 / 8]++};
							pdst[offseta] = pa;
							pdst[offsetb] = pb;
						}
					}
					if(!(1 & count)){// fill in the final item for odd counts
						V *p{psrclo[0]};
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						auto out{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						std::size_t cur{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(out)};
						std::size_t offset{offsets[cur + (80 - 16) * 256 / 8]};
						pdst[offset] = p;
					}
				}else{// !ismultithreadcapable
					V *const *psrchi{psrclo + count};
					do{// fill the array, two at a time: one low-to-middle, one high-to-middle
						V *plo{*psrclo++};
						V *phi{*psrchi--};
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						auto outlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo)};
						auto outhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi)};
						auto[curlo, curhi]{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(outlo, outhi)};
						std::size_t offsetlo{offsets[curlo + (80 - 16) * 256 / 8]++};// the next item will be placed one higher
						std::size_t offsethi{offsets[curhi + (80 - 16) * 256 / 8 + offsetsstride]--};// the next item will be placed one lower
						pdst[offsetlo] = plo;
						pdst[offsethi] = phi;
					}while(psrclo < psrchi);
					if(psrclo == psrchi){// fill in the final item for odd counts
						V *p{*psrclo};
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						auto out{indirectinput2<indirection1, indirection2, isindexed2, T>(im)};
						std::size_t cur{filterbelowtop8<isabsvalue, issignmode, isfltpmode, T, U>(out)};
						std::size_t offset{offsets[cur + (80 - 16) * 256 / 8]};
						pdst[offset] = p;
					}
				}
			}
			if(1 == runsteps)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
				[[unlikely]]
#endif
				break;
			{
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
				[[maybe_unused]]
#endif
				std::uintptr_t old;
				if constexpr(ismultithreadcapable) old = atomiclightbarrier.fetch_add(usemultithread);
				// swap the pointers for the next round, data is moved on each iteration
				psrclo = pdst;
				pdst = pdstnext;
				// unused: pdstnext = psrclo;
				if constexpr(ismultithreadcapable){
					if constexpr(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
						if(!old) do{
							spinpause();
						}while(atomiclightbarrier.load(std::memory_order_relaxed));
					}else{// detect exceptions
						if(!old) do{
							spinpause();
							old = atomiclightbarrier.load(std::memory_order_relaxed);
						}while(~static_cast<std::uintptr_t>(0) == old);
						if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == old) return;// the companion thread produced an exception
					}
				}
			}
handletop8:
			if constexpr(ismultithreadcapable){
				if constexpr (defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
					std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (1 + usemultithread))};// rounded down in the bottom part
					while(0 <= --j){// fill the array, two at a time
						V *pa{psrclo[0]};
						V *pb{psrclo[1]};
						psrclo += 2;
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb)};
						std::size_t offseta{offsets[cura + (80 - 8) * 256 / 8]++};// the next item will be placed one higher
						std::size_t offsetb{offsets[curb + (80 - 8) * 256 / 8]++};
						pdst[offseta] = pa;
						pdst[offsetb] = pb;
					}
				}else{// architecture: limit to four at a time when there's a decent amount of registers
					std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (2 + usemultithread))};// rounded down in the bottom part
					while(0 <= --j){// fill the array, four at a time
						V *pa{psrclo[0]};
						V *pb{psrclo[1]};
						V *pc{psrclo[2]};
						V *pd{psrclo[3]};
						psrclo += 4;
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
						auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
						auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						auto outc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
						auto outd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
						auto[cura, curb, curc, curd]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd)};
						std::size_t offseta{offsets[cura + (80 - 8) * 256 / 8]++};// the next item will be placed one higher
						std::size_t offsetb{offsets[curb + (80 - 8) * 256 / 8]++};
						std::size_t offsetc{offsets[curc + (80 - 8) * 256 / 8]++};
						std::size_t offsetd{offsets[curd + (80 - 8) * 256 / 8]++};
						pdst[offseta] = pa;
						pdst[offsetb] = pb;
						pdst[offsetc] = pc;
						pdst[offsetd] = pd;
					}
					if(2 & count + 1){// fill in the final two items for a remainder of 2 or 3
						V *pa{psrclo[0]};
						V *pb{psrclo[1]};
						psrclo += 2;
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb)};
						std::size_t offseta{offsets[cura + (80 - 8) * 256 / 8]++};// the next item will be placed one higher
						std::size_t offsetb{offsets[curb + (80 - 8) * 256 / 8]++};
						pdst[offseta] = pa;
						pdst[offsetb] = pb;
					}
				}
				if(!(1 & count)){// fill in the final item for odd counts
					V *p{psrclo[0]};
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					auto out{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
					std::size_t cur{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(out)};
					std::size_t offset{offsets[cur + (80 - 8) * 256 / 8]};
					pdst[offset] = p;
				}
			}else{// !ismultithreadcapable
				V *const *psrchi{psrclo + count};
				do{// fill the array, two at a time: one low-to-middle, one high-to-middle
					V *plo{*psrclo++};
					V *phi{*psrchi--};
					auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
					auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
					auto outlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo)};
					auto outhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi)};
					auto[curlo, curhi]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outlo, outhi)};
					std::size_t offsetlo{offsets[curlo + (80 - 8) * 256 / 8]++};// the next item will be placed one higher
					std::size_t offsethi{offsets[curhi + (80 - 8) * 256 / 8 + offsetsstride]--};// the next item will be placed one lower
					pdst[offsetlo] = plo;
					pdst[offsethi] = phi;
				}while(psrclo < psrchi);
				if(psrclo == psrchi){// fill in the final item for odd counts
					V *p{*psrclo};
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					auto out{indirectinput2<indirection1, indirection2, isindexed2, T>(im)};
					std::size_t cur{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(out)};
					std::size_t offset{offsets[cur + (80 - 8) * 256 / 8]};
					pdst[offset] = p;
				}
			}
			break;// no further processing beyond the top part
		}
	}
}

// multi-threading companion for the radixsortcopynoallocmulti2thread() function implementation template for 80-bit-based long double types with indirection
// Do not use this function directly.
template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename X, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	(std::is_same_v<longdoubletest128, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<longdoubletest96, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<longdoubletest80, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<long double, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> &&
	64 == LDBL_MANT_DIG &&
	16384 == LDBL_MAX_EXP &&
	128 >= CHAR_BIT * sizeof(long double) &&
	64 < CHAR_BIT * sizeof(long double)),
	void> radixsortcopynoallocmulti2threadmtc(std::size_t count, V *const input[], V *output[], V *buffer[], std::atomic_uintptr_t &atomiclightbarrier, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>;
	// do not pass a nullptr here
	assert(input);
	assert(output);
	assert(buffer);
	static std::size_t constexpr offsetsstride{80 * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	X offsetscompanion[offsetsstride]{};// a sizeable amount of indices, but it's worth it, zeroed in advance here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
	[[maybe_unused]]
#endif
	std::conditional_t<std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>,
		std::atomic_uintptr_t &,// nothrow capable indirection1, let the compiler just discard this reference
		atomicvarwrapper> atomicguard{atomiclightbarrier};// may throw, so set up the guard
	radixsortnoallocmulti2threadinitmtc<indirection1, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, true, V, X>(count, input, output, buffer, offsetscompanion, varparameters...);

	X *offsets;
	{// barrier and pointer exchange with the main thread
		std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsetscompanion))};
		// detect exceptions
		if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
			if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the main thread produced an exception
		}
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed);
			}while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == other);
			// detect exceptions
			if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
				if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the main thread produced an exception
			}
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		offsets = reinterpret_cast<X *>(other);// retrieve the pointer
	}

	// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
	auto[runsteps, paritybool]{generateoffsetsmultimtc<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, offsets, offsetscompanion)};

	{// barrier and (flipped bits) runsteps, paritybool value exchange with the main thread
		// no exception detection required here
		// paritybool is either 0 or 1 here, so we can pack it together with runsteps and add usemultithread on top
		std::uintptr_t compound{static_cast<std::uintptr_t>(runsteps) * 2 + static_cast<std::uintptr_t>(paritybool) + 1};
		while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == atomiclightbarrier.load(std::memory_order_relaxed)){
			spinpause();// catch up
		}
		std::uintptr_t other{atomiclightbarrier.fetch_add(compound)};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed) - compound;
			}while(!other);
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		other += compound;// combine
		unsigned lowercarryoutbits{2 + paritybool};
		paritybool = static_cast<unsigned>(other) & 1;// piece together the parity from both threads
		other -= lowercarryoutbits;// this will remove possiby two bits of carry-out before the next right shift
		runsteps = static_cast<unsigned>(other >> 1);// this can shift out a 0 or a 1 bit here, depending on the leftovers of parity
	}

	// perform the bidirectional 8-bit sorting sequence
	// flip the relevant bits inside runsteps first
	if(runsteps ^= (1u << 80 / 8) - 1)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
		[[likely]]
#endif
	{// perform the bidirectional 8-bit sorting sequence
		V **pdst{buffer}, **pdstnext{output};// for the next iteration
		if(paritybool){// swap if the count of sorting actions to do is odd
			pdst = output;
			pdstnext = buffer;
		}
		radixsortnoallocmulti2threadmainmtc<indirection1, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X>(count, input, pdst, pdstnext, offsetscompanion, runsteps, atomiclightbarrier, varparameters...);
	}
}

// radixsortcopynoalloc() function implementation template for 80-bit-based long double types with indirection
// Platforms with a native 80-bit long double type are all little endian, hence that is the only implementation here.
template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename X
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	, bool ismultithreadcapable = true
#endif
	, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	(std::is_same_v<longdoubletest128, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<longdoubletest96, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<longdoubletest80, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<long double, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> &&
	64 == LDBL_MANT_DIG &&
	16384 == LDBL_MAX_EXP &&
	128 >= CHAR_BIT * sizeof(long double) &&
	64 < CHAR_BIT * sizeof(long double)),
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	radixsortcopynoallocmulti1thread
#else
	radixsortcopynoallocmulti2thread
#endif
	(std::size_t count, V *const input[], V *output[], V *buffer[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>;
	using W = decltype(T::signexponent);
	using U =
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::conditional_t<128 == CHAR_BIT * sizeof(T), std::uint_least64_t,
#endif
		unsigned
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		>
#endif
		;// assume zero-extension to be basically free for U on basically all modern machines
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	static bool constexpr ismultithreadcapable{false};
#endif
	if constexpr(ismultithreadcapable){
		assert(1 < std::thread::hardware_concurrency());// only use multi-threading if there is more than one hardware thread
		assert(15 <= count);// a 0 or 1 count array is only allowed here in single-threaded function mode
	}
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);
	assert(buffer);
	// All the code in this function is adapted for count to be one below its input value here.
	--count;
	if(ismultithreadcapable || 0 < static_cast<std::ptrdiff_t>(count)){// a 0 or 1 count array is only allowed here in single-threaded function mode
		static std::size_t constexpr offsetsstride{80 * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
		// conditionally enable multi-threading here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t, std::nullptr_t> atomiclightbarrier{};
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::future<void>, std::nullptr_t> asynchandle;

		// count the 256 configurations, all in one go
		if constexpr(ismultithreadcapable){
			try{
				asynchandle = std::async(std::launch::async, radixsortcopynoallocmulti2threadmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X, vararguments...>, count, input, output, buffer, std::ref(atomiclightbarrier), varparameters...);
				usemultithread = 1;
			}catch(...){// std::async may fail gracefully here
				assert(false);
			}
		}
		X offsets[offsetsstride * (2 - ismultithreadcapable)];// a sizeable amount of indices, but it's worth it
		std::memset(offsets, 0, offsetsstride * sizeof(X));// zeroed in advance here
		{// scope atomicguard, so it's always destructed before asynchandle
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			std::conditional_t<ismultithreadcapable,
				std::conditional_t<std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>,
					std::atomic_uintptr_t &,// nothrow capable indirection1, let the compiler just discard this reference
					atomicvarwrapper>,// may throw, so set up the guard
				std::nullptr_t> atomicguard{atomiclightbarrier};
			std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			std::conditional_t<ismultithreadcapable, std::ptrdiff_t, std::nullptr_t> stride;
			if constexpr(ismultithreadcapable){
				// architecture: limit to one at a time when there's few registers
				if constexpr(defaultgprfilesize < gprfilesize::large) stride = -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
				else stride = -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
				i -= stride;
			}
			if constexpr(isrevorder){// also reverse the array at the same time
				V *const *pinput{input};
				if constexpr(ismultithreadcapable) pinput += stride;
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					do{
						V *p{pinput[0]};
						++pinput;
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						output[i] = p;
						buffer[i] = p;
						auto cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						std::uint64_t curm{cur.mantissa};
						U cure{static_cast<U>(cur.signexponent)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curm, cure);
						}
						unsigned cure0{static_cast<unsigned>(cure & 0xFFu)};
						cure >>= 8;
						unsigned curm0{static_cast<unsigned>(curm & 0xFFu)};
						unsigned curm1{static_cast<unsigned>(curm >> 8)};
						unsigned curm2{static_cast<unsigned>(curm >> 16)};
						unsigned curm3{static_cast<unsigned>(curm >> 24)};
						unsigned curm4{static_cast<unsigned>(curm >> 32)};
						unsigned curm5{static_cast<unsigned>(curm >> 40)};
						unsigned curm6{static_cast<unsigned>(curm >> 48)};
						curm >>= 56;
						++offsets[8 * 256 + static_cast<std::size_t>(cure0)];
						cure &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
						++offsets[curm0];
						curm1 &= 0xFFu;
						curm2 &= 0xFFu;
						curm3 &= 0xFFu;
						curm4 &= 0xFFu;
						curm5 &= 0xFFu;
						curm6 &= 0xFFu;
						++offsets[9 * 256 + static_cast<std::size_t>(cure)];
						++offsets[7 * 256 + static_cast<std::size_t>(curm)];
						++offsets[256 + static_cast<std::size_t>(curm1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curm2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curm3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curm4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curm5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curm6)];
					}while(0 <= --i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					do{
						V *plo{pinput[0]};
						V *phi{pinput[1]};
						pinput += 2;
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						output[i] = plo;
						buffer[i] = plo;
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						output[i - 1] = phi;
						buffer[i - 1] = phi;
						auto curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						auto curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						std::uint64_t curmlo{curlo.mantissa};
						U curelo{static_cast<U>(curlo.signexponent)};
						std::uint64_t curmhi{curhi.mantissa};
						U curehi{static_cast<U>(curhi.signexponent)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curmlo, curelo, curmhi, curehi);
						}
						// register pressure performance issue on several platforms: first do the low half here
						unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
						curelo >>= 8;
						unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
						unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
						unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
						unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
						unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
						unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
						unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
						curmlo >>= 56;
						++offsets[8 * 256 + static_cast<std::size_t>(curelo0)];
						curelo &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
						++offsets[curmlo0];
						curmlo1 &= 0xFFu;
						curmlo2 &= 0xFFu;
						curmlo3 &= 0xFFu;
						curmlo4 &= 0xFFu;
						curmlo5 &= 0xFFu;
						curmlo6 &= 0xFFu;
						++offsets[9 * 256 + static_cast<std::size_t>(curelo)];
						++offsets[7 * 256 + static_cast<std::size_t>(curmlo)];
						++offsets[256 + static_cast<std::size_t>(curmlo1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curmlo2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curmlo3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curmlo4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curmlo5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curmlo6)];
						// register pressure performance issue on several platforms: do the high half here second
						unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
						curehi >>= 8;
						unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
						unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
						unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
						unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
						unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
						unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
						unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
						curmhi >>= 56;
						++offsets[8 * 256 + static_cast<std::size_t>(curehi0)];
						curehi &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
						++offsets[curmhi0];
						curmhi1 &= 0xFFu;
						curmhi2 &= 0xFFu;
						curmhi3 &= 0xFFu;
						curmhi4 &= 0xFFu;
						curmhi5 &= 0xFFu;
						curmhi6 &= 0xFFu;
						++offsets[7 * 256 + static_cast<std::size_t>(curmhi)];
						++offsets[9 * 256 + static_cast<std::size_t>(curehi)];
						++offsets[256 + static_cast<std::size_t>(curmhi1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curmhi2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curmhi3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curmhi4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curmhi5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curmhi6)];
						i -= 2;
					}while(0 < i);
					if(!(1 & i)){// fill in the final item for odd counts
						V *p{pinput[0]};
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						output[0] = p;
						buffer[0] = p;
						auto cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						std::uint64_t curm{cur.mantissa};
						U cure{static_cast<U>(cur.signexponent)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curm, cure);
						}
						unsigned cure0{static_cast<unsigned>(cure & 0xFFu)};
						cure >>= 8;
						unsigned curm0{static_cast<unsigned>(curm & 0xFFu)};
						unsigned curm1{static_cast<unsigned>(curm >> 8)};
						unsigned curm2{static_cast<unsigned>(curm >> 16)};
						unsigned curm3{static_cast<unsigned>(curm >> 24)};
						unsigned curm4{static_cast<unsigned>(curm >> 32)};
						unsigned curm5{static_cast<unsigned>(curm >> 40)};
						unsigned curm6{static_cast<unsigned>(curm >> 48)};
						curm >>= 56;
						++offsets[8 * 256 + static_cast<std::size_t>(cure0)];
						cure &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
						++offsets[curm0];
						curm1 &= 0xFFu;
						curm2 &= 0xFFu;
						curm3 &= 0xFFu;
						curm4 &= 0xFFu;
						curm5 &= 0xFFu;
						curm6 &= 0xFFu;
						++offsets[9 * 256 + static_cast<std::size_t>(cure)];
						++offsets[7 * 256 + static_cast<std::size_t>(curm)];
						++offsets[256 + static_cast<std::size_t>(curm1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curm2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curm3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curm4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curm5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curm6)];
					}
				}
			}else{// not in reverse order
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					do{
						V *p{input[i]};
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						output[i] = p;
						auto cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						std::uint64_t curm{cur.mantissa};
						U cure{static_cast<U>(cur.signexponent)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curm, cure);
						}
						unsigned cure0{static_cast<unsigned>(cure & 0xFFu)};
						cure >>= 8;
						unsigned curm0{static_cast<unsigned>(curm & 0xFFu)};
						unsigned curm1{static_cast<unsigned>(curm >> 8)};
						unsigned curm2{static_cast<unsigned>(curm >> 16)};
						unsigned curm3{static_cast<unsigned>(curm >> 24)};
						unsigned curm4{static_cast<unsigned>(curm >> 32)};
						unsigned curm5{static_cast<unsigned>(curm >> 40)};
						unsigned curm6{static_cast<unsigned>(curm >> 48)};
						curm >>= 56;
						++offsets[8 * 256 + static_cast<std::size_t>(cure0)];
						cure &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
						++offsets[curm0];
						curm1 &= 0xFFu;
						curm2 &= 0xFFu;
						curm3 &= 0xFFu;
						curm4 &= 0xFFu;
						curm5 &= 0xFFu;
						curm6 &= 0xFFu;
						++offsets[9 * 256 + static_cast<std::size_t>(cure)];
						++offsets[7 * 256 + static_cast<std::size_t>(curm)];
						++offsets[256 + static_cast<std::size_t>(curm1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curm2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curm3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curm4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curm5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curm6)];
					}while(0 <= --i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					do{
						V *plo{input[i]};
						V *phi{input[i - 1]};
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						output[i] = plo;
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						output[i - 1] = phi;
						auto curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						auto curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						std::uint64_t curmlo{curlo.mantissa};
						U curelo{static_cast<U>(curlo.signexponent)};
						std::uint64_t curmhi{curhi.mantissa};
						U curehi{static_cast<U>(curhi.signexponent)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curmlo, curelo, curmhi, curehi);
						}
						// register pressure performance issue on several platforms: first do the low half here
						unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
						curelo >>= 8;
						unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
						unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
						unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
						unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
						unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
						unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
						unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
						curmlo >>= 56;
						++offsets[8 * 256 + static_cast<std::size_t>(curelo0)];
						curelo &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
						++offsets[curmlo0];
						curmlo1 &= 0xFFu;
						curmlo2 &= 0xFFu;
						curmlo3 &= 0xFFu;
						curmlo4 &= 0xFFu;
						curmlo5 &= 0xFFu;
						curmlo6 &= 0xFFu;
						++offsets[9 * 256 + static_cast<std::size_t>(curelo)];
						++offsets[7 * 256 + static_cast<std::size_t>(curmlo)];
						++offsets[256 + static_cast<std::size_t>(curmlo1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curmlo2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curmlo3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curmlo4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curmlo5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curmlo6)];
						// register pressure performance issue on several platforms: do the high half here second
						unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
						curehi >>= 8;
						unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
						unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
						unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
						unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
						unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
						unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
						unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
						curmhi >>= 56;
						++offsets[8 * 256 + static_cast<std::size_t>(curehi0)];
						curehi &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
						++offsets[curmhi0];
						curmhi1 &= 0xFFu;
						curmhi2 &= 0xFFu;
						curmhi3 &= 0xFFu;
						curmhi4 &= 0xFFu;
						curmhi5 &= 0xFFu;
						curmhi6 &= 0xFFu;
						++offsets[7 * 256 + static_cast<std::size_t>(curmhi)];
						++offsets[9 * 256 + static_cast<std::size_t>(curehi)];
						++offsets[256 + static_cast<std::size_t>(curmhi1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curmhi2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curmhi3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curmhi4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curmhi5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curmhi6)];
						i -= 2;
					}while(0 < i);
					if(!(1 & i)){// fill in the final item for odd counts
						V *p{input[0]};
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						output[0] = p;
						auto cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						std::uint64_t curm{cur.mantissa};
						U cure{static_cast<U>(cur.signexponent)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curm, cure);
						}
						unsigned cure0{static_cast<unsigned>(cure & 0xFFu)};
						cure >>= 8;
						unsigned curm0{static_cast<unsigned>(curm & 0xFFu)};
						unsigned curm1{static_cast<unsigned>(curm >> 8)};
						unsigned curm2{static_cast<unsigned>(curm >> 16)};
						unsigned curm3{static_cast<unsigned>(curm >> 24)};
						unsigned curm4{static_cast<unsigned>(curm >> 32)};
						unsigned curm5{static_cast<unsigned>(curm >> 40)};
						unsigned curm6{static_cast<unsigned>(curm >> 48)};
						curm >>= 56;
						++offsets[8 * 256 + static_cast<std::size_t>(cure0)];
						cure &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
						++offsets[curm0];
						curm1 &= 0xFFu;
						curm2 &= 0xFFu;
						curm3 &= 0xFFu;
						curm4 &= 0xFFu;
						curm5 &= 0xFFu;
						curm6 &= 0xFFu;
						++offsets[9 * 256 + static_cast<std::size_t>(cure)];
						++offsets[7 * 256 + static_cast<std::size_t>(curm)];
						++offsets[256 + static_cast<std::size_t>(curm1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curm2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curm3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curm4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curm5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curm6)];
					}
				}
			}

			// barrier and pointer exchange with the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			std::conditional_t<ismultithreadcapable, X *, std::nullptr_t> offsetscompanion;
			if constexpr(ismultithreadcapable){
				std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsets) & -static_cast<std::intptr_t>(usemultithread))};
				// detect exceptions
				if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
					if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the companion thread produced an exception
				}
				// simply do not spin if usemultithread is zero
				if(usemultithread > other){
					do{
						spinpause();
						other = atomiclightbarrier.load(std::memory_order_relaxed);
					}while(reinterpret_cast<std::uintptr_t>(offsets) == other);
					// detect exceptions
					if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
						if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the companion thread produced an exception
					}
					// reset the barrier after use, only one thread will do this
					// no busy-wait dependency on this store, hence relaxed memory order is fine
					reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
					// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
				}
				// this will just be zero if usemultithread is zero
				offsetscompanion = reinterpret_cast<X *>(other);// retrieve the pointer
			}else offsetscompanion = nullptr;

			// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
			auto[runsteps, paritybool]{generateoffsetsmulti<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, offsets, offsetscompanion, usemultithread)};

			// barrier and (flipped bits) runsteps, paritybool value exchange with the companion thread
			// no exception detection required here
			if constexpr(ismultithreadcapable){
				// paritybool is either 0 or 1 here, so we can pack it together with runsteps and add usemultithread on top
				std::uintptr_t compound{static_cast<std::uintptr_t>(runsteps) * 2 + static_cast<std::uintptr_t>(paritybool) + static_cast<std::uintptr_t>(usemultithread)};
				while(reinterpret_cast<std::uintptr_t>(offsets) == atomiclightbarrier.load(std::memory_order_relaxed)){
					spinpause();// catch up
				}
				std::uintptr_t other{atomiclightbarrier.fetch_add(compound & -static_cast<std::intptr_t>(usemultithread))};
				// simply do not spin if usemultithread is zero
				if(usemultithread > other){
					do{
						spinpause();
						other = atomiclightbarrier.load(std::memory_order_relaxed) - compound;
					}while(!other);
					// reset the barrier after use, only one thread will do this
					// no busy-wait dependency on this store, hence relaxed memory order is fine
					reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
					// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
				}
				other += compound;// combine
				unsigned lowercarryoutbits{2 * usemultithread + paritybool};
				paritybool = static_cast<unsigned>(other) & 1;// piece together the parity from both threads
				other -= lowercarryoutbits;// this will remove possiby two bits of carry-out before the next right shift
				runsteps = static_cast<unsigned>(other >> 1);// this can shift out a 0 or a 1 bit here, depending on the leftovers of parity
			}

			// perform the bidirectional 8-bit sorting sequence
			// flip the relevant bits inside runsteps first
			if(runsteps ^= (1u << 80 / 8) - 1)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
				[[likely]]
#endif
			{
				V **pdst{buffer}, **pdstnext{output};// for the next iteration
				if(paritybool){// swap if the count of sorting actions to do is odd
					pdst = output;
					pdstnext = buffer;
				}
				radixsortnoallocmulti2threadmain<indirection1, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, ismultithreadcapable, V, X>(count, input, pdst, pdstnext, offsets, runsteps, usemultithread, atomiclightbarrier, varparameters...);
			}
		}
	}else if(0 == static_cast<std::ptrdiff_t>(count)) *output = *input;// copy the single element if the count is 1
}

// multi-threading companion for the radixsortnoallocmulti2thread() function implementation template for 80-bit-based long double types with indirection
// Do not use this function directly.
template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename X, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	(std::is_same_v<longdoubletest128, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<longdoubletest96, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<longdoubletest80, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<long double, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> &&
	64 == LDBL_MANT_DIG &&
	16384 == LDBL_MAX_EXP &&
	128 >= CHAR_BIT * sizeof(long double) &&
	64 < CHAR_BIT * sizeof(long double)),
	void> radixsortnoallocmulti2threadmtc(std::size_t count, V *input[], V *buffer[], std::atomic_uintptr_t &atomiclightbarrier, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>;
	// do not pass a nullptr here
	assert(input);
	assert(buffer);
	static std::size_t constexpr offsetsstride{80 * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	X offsetscompanion[offsetsstride]{};// a sizeable amount of indices, but it's worth it, zeroed in advance here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
	[[maybe_unused]]
#endif
	std::conditional_t<std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>,
		std::atomic_uintptr_t &,// nothrow capable indirection1, let the compiler just discard this reference
		atomicvarwrapper> atomicguard{atomiclightbarrier};// may throw, so set up the guard
	radixsortnoallocmulti2threadinitmtc<indirection1, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, false, V, X>(count, input, buffer, nullptr, offsetscompanion, varparameters...);

	X *offsets;
	{// barrier and pointer exchange with the main thread
		std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsetscompanion))};
		// detect exceptions
		if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
			if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the main thread produced an exception
		}
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed);
			}while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == other);
			// detect exceptions
			if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
				if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the main thread produced an exception
			}
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		offsets = reinterpret_cast<X *>(other);// retrieve the pointer
	}

	// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
	auto[runsteps, paritybool]{generateoffsetsmultimtc<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, offsets, offsetscompanion)};

	{// barrier and (flipped bits) runsteps, paritybool value exchange with the main thread
		// no exception detection required here
		// paritybool is either 0 or 1 here, so we can pack it together with runsteps and add usemultithread on top
		std::uintptr_t compound{static_cast<std::uintptr_t>(runsteps) * 2 + static_cast<std::uintptr_t>(paritybool) + 1};
		while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == atomiclightbarrier.load(std::memory_order_relaxed)){
			spinpause();// catch up
		}
		std::uintptr_t other{atomiclightbarrier.fetch_add(compound)};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed) - compound;
			}while(!other);
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		other += compound;// combine
		unsigned lowercarryoutbits{2 + paritybool};
		paritybool = static_cast<unsigned>(other) & 1;// piece together the parity from both threads
		other -= lowercarryoutbits;// this will remove possiby two bits of carry-out before the next right shift
		runsteps = static_cast<unsigned>(other >> 1);// this can shift out a 0 or a 1 bit here, depending on the leftovers of parity
	}

	// perform the bidirectional 8-bit sorting sequence
	// flip the relevant bits inside runsteps first
	if(runsteps ^= (1u << 80 / 8) - 1)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
		[[likely]]
#endif
	{// perform the bidirectional 8-bit sorting sequence
		V **psrclo{input}, **pdst{buffer};
		if(paritybool){// swap if the count of sorting actions to do is odd
			psrclo = buffer;
			pdst = input;
		}
		radixsortnoallocmulti2threadmainmtc<indirection1, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X>(count, psrclo, pdst, psrclo, offsetscompanion, runsteps, atomiclightbarrier, varparameters...);
	}
}

// radixsortnoalloc() function implementation template for 80-bit-based long double types with indirection
// Platforms with a native 80-bit long double type are all little endian, hence that is the only implementation here.
template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename X
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	, bool ismultithreadcapable = true
#endif
	, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	(std::is_same_v<longdoubletest128, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<longdoubletest96, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<longdoubletest80, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> ||
	std::is_same_v<long double, std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>> &&
	64 == LDBL_MANT_DIG &&
	16384 == LDBL_MAX_EXP &&
	128 >= CHAR_BIT * sizeof(long double) &&
	64 < CHAR_BIT * sizeof(long double)),
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	radixsortnoallocmulti1thread
#else
	radixsortnoallocmulti2thread
#endif
	(std::size_t count, V *input[], V *buffer[], bool movetobuffer = false, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>;
	using W = decltype(T::signexponent);
	using U =
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::conditional_t<128 == CHAR_BIT * sizeof(T), std::uint_least64_t,
#endif
		unsigned
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		>
#endif
		;// assume zero-extension to be basically free for U on basically all modern machines
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	static bool constexpr ismultithreadcapable{false};
#endif
	if constexpr(ismultithreadcapable){
		assert(1 < std::thread::hardware_concurrency());// only use multi-threading if there is more than one hardware thread
		assert(15 <= count);// a 0 or 1 count array is only allowed here in single-threaded function mode
	}
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(buffer);
	// All the code in this function is adapted for count to be one below its input value here.
	--count;
	if(ismultithreadcapable || 0 < static_cast<std::ptrdiff_t>(count)){// a 0 or 1 count array is only allowed here in single-threaded function mode
		static std::size_t constexpr offsetsstride{80 * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
		// conditionally enable multi-threading here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t, std::nullptr_t> atomiclightbarrier{};
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::future<void>, std::nullptr_t> asynchandle;

		// count the 256 configurations, all in one go
		if constexpr(ismultithreadcapable){
			try{
				asynchandle = std::async(std::launch::async, radixsortnoallocmulti2threadmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X, vararguments...>, count, input, buffer, std::ref(atomiclightbarrier), varparameters...);
				usemultithread = 1;
			}catch(...){// std::async may fail gracefully here
				assert(false);
			}
		}
		X offsets[offsetsstride * (2 - ismultithreadcapable)];// a sizeable amount of indices, but it's worth it
		std::memset(offsets, 0, offsetsstride * sizeof(X));// zeroed in advance here
		{// scope atomicguard, so it's always destructed before asynchandle
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			std::conditional_t<ismultithreadcapable,
				std::conditional_t<std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>,
					std::atomic_uintptr_t &,// nothrow capable indirection1, let the compiler just discard this reference
					atomicvarwrapper>,// may throw, so set up the guard
				std::nullptr_t> atomicguard{atomiclightbarrier};
			if constexpr(isrevorder){// also reverse the array at the same time
				V **pinputlo, **pinputhi, **pbufferlo, **pbufferhi;
				if constexpr(!ismultithreadcapable){
					pinputlo = input;
					pinputhi = input + count;
					pbufferlo = buffer;
					pbufferhi = buffer + count;
				}else{// if mulitithreaded, the half count will be rounded up in the companion thread
					std::ptrdiff_t stride{-static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2)};
					pinputlo = input + stride;
					pinputhi = input + (count - stride);
					pbufferlo = buffer + stride;
					pbufferhi = buffer + (count - stride);
				}
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					do{
						V *plo{pinputlo[0]};
						V *phi{pinputhi[0]};
						// register pressure performance issue on several platforms: first do the low half here
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						*pinputhi-- = plo;
						*pbufferhi-- = plo;
						auto curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						std::uint64_t curmlo{curlo.mantissa};
						U curelo{static_cast<U>(curlo.signexponent)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curmlo, curelo);
						}
						unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
						curelo >>= 8;
						unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
						unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
						unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
						unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
						unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
						unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
						unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
						curmlo >>= 56;
						++offsets[8 * 256 + static_cast<std::size_t>(curelo0)];
						curelo &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
						++offsets[curmlo0];
						curmlo1 &= 0xFFu;
						curmlo2 &= 0xFFu;
						curmlo3 &= 0xFFu;
						curmlo4 &= 0xFFu;
						curmlo5 &= 0xFFu;
						curmlo6 &= 0xFFu;
						++offsets[9 * 256 + static_cast<std::size_t>(curelo)];
						++offsets[7 * 256 + static_cast<std::size_t>(curmlo)];
						++offsets[256 + static_cast<std::size_t>(curmlo1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curmlo2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curmlo3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curmlo4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curmlo5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curmlo6)];
						// register pressure performance issue on several platforms: do the high half here second
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						*pinputlo++ = phi;
						*pbufferlo++ = phi;
						auto curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						std::uint64_t curmhi{curhi.mantissa};
						U curehi{static_cast<U>(curhi.signexponent)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curmhi, curehi);
						}
						unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
						curehi >>= 8;
						unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
						unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
						unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
						unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
						unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
						unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
						unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
						curmhi >>= 56;
						++offsets[8 * 256 + static_cast<std::size_t>(curehi0)];
						curehi &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
						++offsets[curmhi0];
						curmhi1 &= 0xFFu;
						curmhi2 &= 0xFFu;
						curmhi3 &= 0xFFu;
						curmhi4 &= 0xFFu;
						curmhi5 &= 0xFFu;
						curmhi6 &= 0xFFu;
						++offsets[7 * 256 + static_cast<std::size_t>(curmhi)];
						++offsets[9 * 256 + static_cast<std::size_t>(curehi)];
						++offsets[256 + static_cast<std::size_t>(curmhi1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curmhi2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curmhi3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curmhi4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curmhi5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curmhi6)];
					}while(pinputlo < pinputhi);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					do{
						V *plo{pinputlo[0]};
						V *phi{pinputhi[0]};
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						*pinputhi-- = plo;
						*pbufferhi-- = plo;
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						*pinputlo++ = phi;
						*pbufferlo++ = phi;
						auto curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						auto curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						std::uint64_t curmlo{curlo.mantissa};
						U curelo{static_cast<U>(curlo.signexponent)};
						std::uint64_t curmhi{curhi.mantissa};
						U curehi{static_cast<U>(curhi.signexponent)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curmlo, curelo, curmhi, curehi);
						}
						// register pressure performance issue on several platforms: first do the low half here
						unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
						curelo >>= 8;
						unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
						unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
						unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
						unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
						unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
						unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
						unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
						curmlo >>= 56;
						++offsets[8 * 256 + static_cast<std::size_t>(curelo0)];
						curelo &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
						++offsets[curmlo0];
						curmlo1 &= 0xFFu;
						curmlo2 &= 0xFFu;
						curmlo3 &= 0xFFu;
						curmlo4 &= 0xFFu;
						curmlo5 &= 0xFFu;
						curmlo6 &= 0xFFu;
						++offsets[9 * 256 + static_cast<std::size_t>(curelo)];
						++offsets[7 * 256 + static_cast<std::size_t>(curmlo)];
						++offsets[256 + static_cast<std::size_t>(curmlo1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curmlo2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curmlo3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curmlo4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curmlo5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curmlo6)];
						// register pressure performance issue on several platforms: do the high half here second
						unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
						curehi >>= 8;
						unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
						unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
						unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
						unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
						unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
						unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
						unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
						curmhi >>= 56;
						++offsets[8 * 256 + static_cast<std::size_t>(curehi0)];
						curehi &= 0xFFu >> static_cast<unsigned char>(isabsvalue && issignmode && isfltpmode);
						++offsets[curmhi0];
						curmhi1 &= 0xFFu;
						curmhi2 &= 0xFFu;
						curmhi3 &= 0xFFu;
						curmhi4 &= 0xFFu;
						curmhi5 &= 0xFFu;
						curmhi6 &= 0xFFu;
						++offsets[7 * 256 + static_cast<std::size_t>(curmhi)];
						++offsets[9 * 256 + static_cast<std::size_t>(curehi)];
						++offsets[256 + static_cast<std::size_t>(curmhi1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curmhi2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curmhi3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curmhi4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curmhi5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curmhi6)];
					}while(pinputlo < pinputhi);
				}
				if(pinputlo == pinputhi){// fill in the final item for odd counts
					V *p{pinputlo[0]};
					// no write to input, as this is the midpoint
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					*pbufferhi = p;
					auto cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
					std::uint64_t curm{cur.mantissa};
					U cure{static_cast<U>(cur.signexponent)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curm, cure);
					}
					unsigned cure0{static_cast<unsigned>(cure & 0xFFu)};
					cure >>= 8;
					unsigned curm0{static_cast<unsigned>(curm & 0xFFu)};
					unsigned curm1{static_cast<unsigned>(curm >> 8)};
					unsigned curm2{static_cast<unsigned>(curm >> 16)};
					unsigned curm3{static_cast<unsigned>(curm >> 24)};
					unsigned curm4{static_cast<unsigned>(curm >> 32)};
					unsigned curm5{static_cast<unsigned>(curm >> 40)};
					unsigned curm6{static_cast<unsigned>(curm >> 48)};
					curm >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(cure0)];
					cure &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
					++offsets[curm0];
					curm1 &= 0xFFu;
					curm2 &= 0xFFu;
					curm3 &= 0xFFu;
					curm4 &= 0xFFu;
					curm5 &= 0xFFu;
					curm6 &= 0xFFu;
					++offsets[9 * 256 + static_cast<std::size_t>(cure)];
					++offsets[7 * 256 + static_cast<std::size_t>(curm)];
					++offsets[256 + static_cast<std::size_t>(curm1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curm2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curm3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curm4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curm5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curm6)];
				}
			}else{// not in reverse order
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
				if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					do{
						V *phi{input[i]};
						V *plo{input[i - 1]};
						// register pressure performance issue on several platforms: first do the low half here
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						buffer[i] = phi;
						auto curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						std::uint64_t curmhi{curhi.mantissa};
						U curehi{static_cast<U>(curhi.signexponent)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curmhi, curehi);
						}
						unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
						curehi >>= 8;
						unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
						unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
						unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
						unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
						unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
						unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
						unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
						curmhi >>= 56;
						++offsets[8 * 256 + static_cast<std::size_t>(curehi0)];
						curehi &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
						++offsets[curmhi0];
						curmhi1 &= 0xFFu;
						curmhi2 &= 0xFFu;
						curmhi3 &= 0xFFu;
						curmhi4 &= 0xFFu;
						curmhi5 &= 0xFFu;
						curmhi6 &= 0xFFu;
						++offsets[9 * 256 + static_cast<std::size_t>(curehi)];
						++offsets[7 * 256 + static_cast<std::size_t>(curmhi)];
						++offsets[256 + static_cast<std::size_t>(curmhi1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curmhi2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curmhi3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curmhi4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curmhi5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curmhi6)];
						// register pressure performance issue on several platforms: do the high half here second
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						buffer[i - 1] = plo;
						auto curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						std::uint64_t curmlo{curlo.mantissa};
						U curelo{static_cast<U>(curlo.signexponent)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curmlo, curelo);
						}
						unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
						curelo >>= 8;
						unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
						unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
						unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
						unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
						unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
						unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
						unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
						curmlo >>= 56;
						++offsets[8 * 256 + static_cast<std::size_t>(curelo0)];
						curelo &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
						++offsets[curmlo0];
						curmlo1 &= 0xFFu;
						curmlo2 &= 0xFFu;
						curmlo3 &= 0xFFu;
						curmlo4 &= 0xFFu;
						curmlo5 &= 0xFFu;
						curmlo6 &= 0xFFu;
						++offsets[9 * 256 + static_cast<std::size_t>(curelo)];
						++offsets[7 * 256 + static_cast<std::size_t>(curmlo)];
						++offsets[256 + static_cast<std::size_t>(curmlo1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curmlo2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curmlo3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curmlo4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curmlo5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curmlo6)];
						i -= 2;
					}while(0 < i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					do{
						V *phi{input[i]};
						V *plo{input[i - 1]};
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						buffer[i] = phi;
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						buffer[i - 1] = plo;
						auto curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						auto curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						std::uint64_t curmhi{curhi.mantissa};
						U curehi{static_cast<U>(curhi.signexponent)};
						std::uint64_t curmlo{curlo.mantissa};
						U curelo{static_cast<U>(curlo.signexponent)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curmhi, curehi, curmlo, curelo);
						}
						// register pressure performance issue on several platforms: first do the low half here
						unsigned curehi0{static_cast<unsigned>(curehi & 0xFFu)};
						curehi >>= 8;
						unsigned curmhi0{static_cast<unsigned>(curmhi & 0xFFu)};
						unsigned curmhi1{static_cast<unsigned>(curmhi >> 8)};
						unsigned curmhi2{static_cast<unsigned>(curmhi >> 16)};
						unsigned curmhi3{static_cast<unsigned>(curmhi >> 24)};
						unsigned curmhi4{static_cast<unsigned>(curmhi >> 32)};
						unsigned curmhi5{static_cast<unsigned>(curmhi >> 40)};
						unsigned curmhi6{static_cast<unsigned>(curmhi >> 48)};
						curmhi >>= 56;
						++offsets[8 * 256 + static_cast<std::size_t>(curehi0)];
						curehi &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
						++offsets[curmhi0];
						curmhi1 &= 0xFFu;
						curmhi2 &= 0xFFu;
						curmhi3 &= 0xFFu;
						curmhi4 &= 0xFFu;
						curmhi5 &= 0xFFu;
						curmhi6 &= 0xFFu;
						++offsets[9 * 256 + static_cast<std::size_t>(curehi)];
						++offsets[7 * 256 + static_cast<std::size_t>(curmhi)];
						++offsets[256 + static_cast<std::size_t>(curmhi1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curmhi2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curmhi3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curmhi4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curmhi5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curmhi6)];
						// register pressure performance issue on several platforms: do the high half here second
						unsigned curelo0{static_cast<unsigned>(curelo & 0xFFu)};
						curelo >>= 8;
						unsigned curmlo0{static_cast<unsigned>(curmlo & 0xFFu)};
						unsigned curmlo1{static_cast<unsigned>(curmlo >> 8)};
						unsigned curmlo2{static_cast<unsigned>(curmlo >> 16)};
						unsigned curmlo3{static_cast<unsigned>(curmlo >> 24)};
						unsigned curmlo4{static_cast<unsigned>(curmlo >> 32)};
						unsigned curmlo5{static_cast<unsigned>(curmlo >> 40)};
						unsigned curmlo6{static_cast<unsigned>(curmlo >> 48)};
						curmlo >>= 56;
						++offsets[8 * 256 + static_cast<std::size_t>(curelo0)];
						curelo &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
						++offsets[curmlo0];
						curmlo1 &= 0xFFu;
						curmlo2 &= 0xFFu;
						curmlo3 &= 0xFFu;
						curmlo4 &= 0xFFu;
						curmlo5 &= 0xFFu;
						curmlo6 &= 0xFFu;
						++offsets[9 * 256 + static_cast<std::size_t>(curelo)];
						++offsets[7 * 256 + static_cast<std::size_t>(curmlo)];
						++offsets[256 + static_cast<std::size_t>(curmlo1)];
						++offsets[2 * 256 + static_cast<std::size_t>(curmlo2)];
						++offsets[3 * 256 + static_cast<std::size_t>(curmlo3)];
						++offsets[4 * 256 + static_cast<std::size_t>(curmlo4)];
						++offsets[5 * 256 + static_cast<std::size_t>(curmlo5)];
						++offsets[6 * 256 + static_cast<std::size_t>(curmlo6)];
						i -= 2;
					}while(0 < i);
				}
				if(!(1 & i)){// fill in the final item for odd counts
					V *p{input[0]};
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					buffer[0] = p;
					auto cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
					std::uint64_t curm{cur.mantissa};
					U cure{static_cast<U>(cur.signexponent)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curm, cure);
					}
					unsigned cure0{static_cast<unsigned>(cure & 0xFFu)};
					cure >>= 8;
					unsigned curm0{static_cast<unsigned>(curm & 0xFFu)};
					unsigned curm1{static_cast<unsigned>(curm >> 8)};
					unsigned curm2{static_cast<unsigned>(curm >> 16)};
					unsigned curm3{static_cast<unsigned>(curm >> 24)};
					unsigned curm4{static_cast<unsigned>(curm >> 32)};
					unsigned curm5{static_cast<unsigned>(curm >> 40)};
					unsigned curm6{static_cast<unsigned>(curm >> 48)};
					curm >>= 56;
					++offsets[8 * 256 + static_cast<std::size_t>(cure0)];
					cure &= 0xFFu >> static_cast<unsigned>(isabsvalue && issignmode && isfltpmode);
					++offsets[curm0];
					curm1 &= 0xFFu;
					curm2 &= 0xFFu;
					curm3 &= 0xFFu;
					curm4 &= 0xFFu;
					curm5 &= 0xFFu;
					curm6 &= 0xFFu;
					++offsets[9 * 256 + static_cast<std::size_t>(cure)];
					++offsets[7 * 256 + static_cast<std::size_t>(curm)];
					++offsets[256 + static_cast<std::size_t>(curm1)];
					++offsets[2 * 256 + static_cast<std::size_t>(curm2)];
					++offsets[3 * 256 + static_cast<std::size_t>(curm3)];
					++offsets[4 * 256 + static_cast<std::size_t>(curm4)];
					++offsets[5 * 256 + static_cast<std::size_t>(curm5)];
					++offsets[6 * 256 + static_cast<std::size_t>(curm6)];
				}
			}

			// barrier and pointer exchange with the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			std::conditional_t<ismultithreadcapable, X *, std::nullptr_t> offsetscompanion;
			if constexpr(ismultithreadcapable){
				std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsets) & -static_cast<std::intptr_t>(usemultithread))};
				// detect exceptions
				if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
					if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the companion thread produced an exception
				}
				// simply do not spin if usemultithread is zero
				if(usemultithread > other){
					do{
						spinpause();
						other = atomiclightbarrier.load(std::memory_order_relaxed);
					}while(reinterpret_cast<std::uintptr_t>(offsets) == other);
					// detect exceptions
					if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
						if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the companion thread produced an exception
					}
					// reset the barrier after use, only one thread will do this
					// no busy-wait dependency on this store, hence relaxed memory order is fine
					reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
					// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
				}
				// this will just be zero if usemultithread is zero
				offsetscompanion = reinterpret_cast<X *>(other);// retrieve the pointer
			}else offsetscompanion = nullptr;

			// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
			auto[runsteps, paritybool]{generateoffsetsmulti<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, offsets, offsetscompanion, usemultithread, movetobuffer)};

			// barrier and (flipped bits) runsteps, paritybool value exchange with the companion thread
			// no exception detection required here
			if constexpr(ismultithreadcapable){
				// paritybool is either 0 or 1 here, so we can pack it together with runsteps and add usemultithread on top
				std::uintptr_t compound{static_cast<std::uintptr_t>(runsteps) * 2 + static_cast<std::uintptr_t>(paritybool) + static_cast<std::uintptr_t>(usemultithread)};
				while(reinterpret_cast<std::uintptr_t>(offsets) == atomiclightbarrier.load(std::memory_order_relaxed)){
					spinpause();// catch up
				}
				std::uintptr_t other{atomiclightbarrier.fetch_add(compound & -static_cast<std::intptr_t>(usemultithread))};
				// simply do not spin if usemultithread is zero
				if(usemultithread > other){
					do{
						spinpause();
						other = atomiclightbarrier.load(std::memory_order_relaxed) - compound;
					}while(!other);
					// reset the barrier after use, only one thread will do this
					// no busy-wait dependency on this store, hence relaxed memory order is fine
					reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
					// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
				}
				other += compound;// combine
				unsigned lowercarryoutbits{2 * usemultithread + paritybool};
				paritybool = static_cast<unsigned>(other) & 1;// piece together the parity from both threads
				other -= lowercarryoutbits;// this will remove possiby two bits of carry-out before the next right shift
				runsteps = static_cast<unsigned>(other >> 1);// this can shift out a 0 or a 1 bit here, depending on the leftovers of parity
			}

			// perform the bidirectional 8-bit sorting sequence
			// flip the relevant bits inside runsteps first
			if(runsteps ^= (1u << 80 / 8) - 1)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
				[[likely]]
#endif
			{
				V **psrclo{input}, **pdst{buffer};
				if(paritybool){// swap if the count of sorting actions to do is odd
					psrclo = buffer;
					pdst = input;
				}
				radixsortnoallocmulti2threadmain<indirection1, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, ismultithreadcapable, V, X>(count, psrclo, pdst, psrclo, offsets, runsteps, usemultithread, atomiclightbarrier, varparameters...);
			}
		}
	}else if(0 == static_cast<std::ptrdiff_t>(count)) *buffer = *input;// copy the single element if the count is 1
}

// initialisation part, multi-threading companion for the radixsortnoallocmulti2thread() function implementation template for multi-part types with indirection
// Do not use this function directly.
template<auto indirection1, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, bool isinputconst, typename V, typename X, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	64 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortnoallocmulti2threadinitmtc(std::size_t count, std::conditional_t<isinputconst, V *const *, V **> input, V *pout[], std::conditional_t<isinputconst, V **, std::nullptr_t> pdst, X offsetscompanion[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
	assert(7 <= count);// this function is not for small arrays, 8 is the minimum original array count for 16-bit inputs
	// do not pass a nullptr here
	assert(input);
	assert(pout);
	if constexpr(isinputconst) assert(pdst);
	assert(offsetscompanion);
	if constexpr(64 == CHAR_BIT * sizeof(T)){
		if constexpr(isrevorder){// also reverse the array at the same time
			if constexpr(isinputconst){
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					// unsigned counter, not zero inclusive inside the loop
					std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
					pout += count - i;
					pdst += count - i;
					do{
						V *p{input[0]};
						input += 2;
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						pout[i] = p;
						pdst[i] = p;
						U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						U cur5{cur >> 40};
						U cur6{cur >> 48};
						cur >>= 56;
						++offsetscompanion[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						cur5 &= 0xFFu;
						cur6 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(cur5)];
						++offsetscompanion[6 * 256 + static_cast<std::size_t>(cur6)];
						++offsetscompanion[7 * 256 + static_cast<std::size_t>(cur)];
					}while(--i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					// unsigned counter, not zero inclusive inside the loop
					std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
					pout += count - i;
					pdst += count - i;
					do{
						V *phi{input[0]};
						V *plo{input[1]};
						input += 2;
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						pout[i] = phi;
						pdst[i] = phi;
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						pout[i - 1] = plo;
						pdst[i - 1] = plo;
						U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
						}
						// register pressure performance issue on several platforms: first do the high half here
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						U curhi4{curhi >> 32};
						U curhi5{curhi >> 40};
						U curhi6{curhi >> 48};
						curhi >>= 56;
						++offsetscompanion[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						curhi4 &= 0xFFu;
						curhi5 &= 0xFFu;
						curhi6 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curhi5)];
						++offsetscompanion[6 * 256 + static_cast<std::size_t>(curhi6)];
						++offsetscompanion[7 * 256 + static_cast<std::size_t>(curhi)];
						// register pressure performance issue on several platforms: do the low half here second
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						U curlo4{curlo >> 32};
						U curlo5{curlo >> 40};
						U curlo6{curlo >> 48};
						curlo >>= 56;
						++offsetscompanion[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						curlo4 &= 0xFFu;
						curlo5 &= 0xFFu;
						curlo6 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curlo5)];
						++offsetscompanion[6 * 256 + static_cast<std::size_t>(curlo6)];
						++offsetscompanion[7 * 256 + static_cast<std::size_t>(curlo)];
					}while(i -= 2);
				}
			}else{// !isinputconst
				V **pinputlo{input}, **pinputhi{input + count};
				V **poutputlo{pout}, **poutputhi{pout + count};
				std::size_t i{(count + 1 + 2) >> 2};// rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					do{
						V *plo{pinputlo[0]};
						V *phi{pinputhi[0]};
						// register pressure performance issue on several platforms: first do the low half here
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						*pinputhi-- = plo;
						*poutputhi-- = plo;
						U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo);
						}
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						U curlo4{curlo >> 32};
						U curlo5{curlo >> 40};
						U curlo6{curlo >> 48};
						curlo >>= 56;
						++offsetscompanion[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						curlo4 &= 0xFFu;
						curlo5 &= 0xFFu;
						curlo6 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curlo5)];
						++offsetscompanion[6 * 256 + static_cast<std::size_t>(curlo6)];
						++offsetscompanion[7 * 256 + static_cast<std::size_t>(curlo)];
						// register pressure performance issue on several platforms: do the high half here second
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						*pinputlo++ = phi;
						*poutputlo++ = phi;
						U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi);
						}
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						U curhi4{curhi >> 32};
						U curhi5{curhi >> 40};
						U curhi6{curhi >> 48};
						curhi >>= 56;
						++offsetscompanion[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						curhi4 &= 0xFFu;
						curhi5 &= 0xFFu;
						curhi6 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curhi5)];
						++offsetscompanion[6 * 256 + static_cast<std::size_t>(curhi6)];
						++offsetscompanion[7 * 256 + static_cast<std::size_t>(curhi)];
					}while(--i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					do{
						V *plo{pinputlo[0]};
						V *phi{pinputhi[0]};
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						*pinputhi-- = plo;
						*poutputhi-- = plo;
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						*pinputlo++ = phi;
						*poutputlo++ = phi;
						U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo, curhi);
						}
						// register pressure performance issue on several platforms: first do the low half here
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						U curlo4{curlo >> 32};
						U curlo5{curlo >> 40};
						U curlo6{curlo >> 48};
						curlo >>= 56;
						++offsetscompanion[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						curlo4 &= 0xFFu;
						curlo5 &= 0xFFu;
						curlo6 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curlo5)];
						++offsetscompanion[6 * 256 + static_cast<std::size_t>(curlo6)];
						++offsetscompanion[7 * 256 + static_cast<std::size_t>(curlo)];
						// register pressure performance issue on several platforms: do the high half here second
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						U curhi4{curhi >> 32};
						U curhi5{curhi >> 40};
						U curhi6{curhi >> 48};
						curhi >>= 56;
						++offsetscompanion[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						curhi4 &= 0xFFu;
						curhi5 &= 0xFFu;
						curhi6 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curhi5)];
						++offsetscompanion[6 * 256 + static_cast<std::size_t>(curhi6)];
						++offsetscompanion[7 * 256 + static_cast<std::size_t>(curhi)];
					}while(--i);
				}
			}
		}else{// 64-bit, not in reverse order
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 1) >> 1)};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					V *p{input[i]};
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					pout[i] = p;
					U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
					}
					U cur0{cur & 0xFFu};
					U cur1{cur >> 8};
					U cur2{cur >> 16};
					U cur3{cur >> 24};
					U cur4{cur >> 32};
					U cur5{cur >> 40};
					U cur6{cur >> 48};
					cur >>= 56;
					++offsetscompanion[cur0];
					cur1 &= 0xFFu;
					cur2 &= 0xFFu;
					cur3 &= 0xFFu;
					cur4 &= 0xFFu;
					cur5 &= 0xFFu;
					cur6 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(cur3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(cur4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(cur5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(cur6)];
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(cur)];
				}while(--i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					V *phi{input[i]};
					V *plo{input[i - 1]};
					auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
					pout[i] = phi;
					auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
					pout[i - 1] = plo;
					U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
					U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
					}
					// register pressure performance issue on several platforms: first do the high half here
					U curhi0{curhi & 0xFFu};
					U curhi1{curhi >> 8};
					U curhi2{curhi >> 16};
					U curhi3{curhi >> 24};
					U curhi4{curhi >> 32};
					U curhi5{curhi >> 40};
					U curhi6{curhi >> 48};
					curhi >>= 56;
					++offsetscompanion[curhi0];
					curhi1 &= 0xFFu;
					curhi2 &= 0xFFu;
					curhi3 &= 0xFFu;
					curhi4 &= 0xFFu;
					curhi5 &= 0xFFu;
					curhi6 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curhi5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curhi6)];
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curhi)];
					// register pressure performance issue on several platforms: do the low half here second
					U curlo0{curlo & 0xFFu};
					U curlo1{curlo >> 8};
					U curlo2{curlo >> 16};
					U curlo3{curlo >> 24};
					U curlo4{curlo >> 32};
					U curlo5{curlo >> 40};
					U curlo6{curlo >> 48};
					curlo >>= 56;
					++offsetscompanion[curlo0];
					curlo1 &= 0xFFu;
					curlo2 &= 0xFFu;
					curlo3 &= 0xFFu;
					curlo4 &= 0xFFu;
					curlo5 &= 0xFFu;
					curlo6 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curlo5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curlo6)];
					++offsetscompanion[7 * 256 + static_cast<std::size_t>(curlo)];
				}while(i -= 2);
			}
		}
	}else if constexpr(56 == CHAR_BIT * sizeof(T)){
		if constexpr(isrevorder){// also reverse the array at the same time
			if constexpr(isinputconst){
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					// unsigned counter, not zero inclusive inside the loop
					std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
					pout += count - i;
					pdst += count - i;
					do{
						V *p{input[0]};
						input += 2;
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						pout[i] = p;
						pdst[i] = p;
						U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						U cur5{cur >> 40};
						cur >>= 48;
						++offsetscompanion[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						cur5 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(cur5)];
						++offsetscompanion[6 * 256 + static_cast<std::size_t>(cur)];
					}while(--i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					// unsigned counter, not zero inclusive inside the loop
					std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
					pout += count - i;
					pdst += count - i;
					do{
						V *phi{input[0]};
						V *plo{input[1]};
						input += 2;
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						pout[i] = phi;
						pdst[i] = phi;
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						pout[i - 1] = plo;
						pdst[i - 1] = plo;
						U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
						}
						// register pressure performance issue on several platforms: first do the high half here
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						U curhi4{curhi >> 32};
						U curhi5{curhi >> 40};
						curhi >>= 48;
						++offsetscompanion[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						curhi4 &= 0xFFu;
						curhi5 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curhi5)];
						++offsetscompanion[6 * 256 + static_cast<std::size_t>(curhi)];
						// register pressure performance issue on several platforms: do the low half here second
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						U curlo4{curlo >> 32};
						U curlo5{curlo >> 40};
						curlo >>= 48;
						++offsetscompanion[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						curlo4 &= 0xFFu;
						curlo5 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curlo5)];
						++offsetscompanion[6 * 256 + static_cast<std::size_t>(curlo)];
					}while(i -= 2);
				}
			}else{// !isinputconst
				V **pinputlo{input}, **pinputhi{input + count};
				V **poutputlo{pout}, **poutputhi{pout + count};
				std::size_t i{(count + 1 + 2) >> 2};// rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					do{
						V *plo{pinputlo[0]};
						V *phi{pinputhi[0]};
						// register pressure performance issue on several platforms: first do the low half here
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						*pinputhi-- = plo;
						*poutputhi-- = plo;
						U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo);
						}
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						U curlo4{curlo >> 32};
						U curlo5{curlo >> 40};
						curlo >>= 48;
						++offsetscompanion[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						curlo4 &= 0xFFu;
						curlo5 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curlo5)];
						++offsetscompanion[6 * 256 + static_cast<std::size_t>(curlo)];
						// register pressure performance issue on several platforms: do the high half here second
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						*pinputlo++ = phi;
						*poutputlo++ = phi;
						U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi);
						}
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						U curhi4{curhi >> 32};
						U curhi5{curhi >> 40};
						curhi >>= 48;
						++offsetscompanion[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						curhi4 &= 0xFFu;
						curhi5 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curhi5)];
						++offsetscompanion[6 * 256 + static_cast<std::size_t>(curhi)];
					}while(--i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					do{
						V *plo{pinputlo[0]};
						V *phi{pinputhi[0]};
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						*pinputhi-- = plo;
						*poutputhi-- = plo;
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						*pinputlo++ = phi;
						*poutputlo++ = phi;
						U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo, curhi);
						}
						// register pressure performance issue on several platforms: first do the low half here
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						U curlo4{curlo >> 32};
						U curlo5{curlo >> 40};
						curlo >>= 48;
						++offsetscompanion[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						curlo4 &= 0xFFu;
						curlo5 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curlo5)];
						++offsetscompanion[6 * 256 + static_cast<std::size_t>(curlo)];
						// register pressure performance issue on several platforms: do the high half here second
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						U curhi4{curhi >> 32};
						U curhi5{curhi >> 40};
						curhi >>= 48;
						++offsetscompanion[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						curhi4 &= 0xFFu;
						curhi5 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curhi5)];
						++offsetscompanion[6 * 256 + static_cast<std::size_t>(curhi)];
					}while(--i);
				}
			}
		}else{// 56-bit, not in reverse order
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 1) >> 1)};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					V *p{input[i]};
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					pout[i] = p;
					U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
					}
					U cur0{cur & 0xFFu};
					U cur1{cur >> 8};
					U cur2{cur >> 16};
					U cur3{cur >> 24};
					U cur4{cur >> 32};
					U cur5{cur >> 40};
					cur >>= 48;
					++offsetscompanion[cur0];
					cur1 &= 0xFFu;
					cur2 &= 0xFFu;
					cur3 &= 0xFFu;
					cur4 &= 0xFFu;
					cur5 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(cur3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(cur4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(cur5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(cur)];
				}while(--i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					V *phi{input[i]};
					V *plo{input[i - 1]};
					auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
					pout[i] = phi;
					auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
					pout[i - 1] = plo;
					U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
					U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
					}
					// register pressure performance issue on several platforms: first do the high half here
					U curhi0{curhi & 0xFFu};
					U curhi1{curhi >> 8};
					U curhi2{curhi >> 16};
					U curhi3{curhi >> 24};
					U curhi4{curhi >> 32};
					U curhi5{curhi >> 40};
					curhi >>= 48;
					++offsetscompanion[curhi0];
					curhi1 &= 0xFFu;
					curhi2 &= 0xFFu;
					curhi3 &= 0xFFu;
					curhi4 &= 0xFFu;
					curhi5 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curhi5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curhi)];
					// register pressure performance issue on several platforms: do the low half here second
					U curlo0{curlo & 0xFFu};
					U curlo1{curlo >> 8};
					U curlo2{curlo >> 16};
					U curlo3{curlo >> 24};
					U curlo4{curlo >> 32};
					U curlo5{curlo >> 40};
					curlo >>= 48;
					++offsetscompanion[curlo0];
					curlo1 &= 0xFFu;
					curlo2 &= 0xFFu;
					curlo3 &= 0xFFu;
					curlo4 &= 0xFFu;
					curlo5 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curlo5)];
					++offsetscompanion[6 * 256 + static_cast<std::size_t>(curlo)];
				}while(i -= 2);
			}
		}
	}else if constexpr(48 == CHAR_BIT * sizeof(T)){
		if constexpr(isrevorder){// also reverse the array at the same time
			if constexpr(isinputconst){
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					// unsigned counter, not zero inclusive inside the loop
					std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
					pout += count - i;
					pdst += count - i;
					do{
						V *p{input[0]};
						input += 2;
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						pout[i] = p;
						pdst[i] = p;
						U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						cur >>= 40;
						++offsetscompanion[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(cur)];
					}while(--i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					// unsigned counter, not zero inclusive inside the loop
					std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
					pout += count - i;
					pdst += count - i;
					do{
						V *phi{input[0]};
						V *plo{input[1]};
						input += 2;
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						pout[i] = phi;
						pdst[i] = phi;
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						pout[i - 1] = plo;
						pdst[i - 1] = plo;
						U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
						}
						// register pressure performance issue on several platforms: first do the high half here
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						U curhi4{curhi >> 32};
						curhi >>= 40;
						++offsetscompanion[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						curhi4 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curhi)];
						// register pressure performance issue on several platforms: do the low half here second
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						U curlo4{curlo >> 32};
						curlo >>= 40;
						++offsetscompanion[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						curlo4 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curlo)];
					}while(i -= 2);
				}
			}else{// !isinputconst
				V **pinputlo{input}, **pinputhi{input + count};
				V **poutputlo{pout}, **poutputhi{pout + count};
				std::size_t i{(count + 1 + 2) >> 2};// rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					do{
						V *plo{pinputlo[0]};
						V *phi{pinputhi[0]};
						// register pressure performance issue on several platforms: first do the low half here
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						*pinputhi-- = plo;
						*poutputhi-- = plo;
						U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo);
						}
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						U curlo4{curlo >> 32};
						curlo >>= 40;
						++offsetscompanion[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						curlo4 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curlo)];
						// register pressure performance issue on several platforms: do the high half here second
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						*pinputlo++ = phi;
						*poutputlo++ = phi;
						U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi);
						}
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						U curhi4{curhi >> 32};
						curhi >>= 40;
						++offsetscompanion[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						curhi4 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curhi)];
					}while(--i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					do{
						V *plo{pinputlo[0]};
						V *phi{pinputhi[0]};
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						*pinputhi-- = plo;
						*poutputhi-- = plo;
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						*pinputlo++ = phi;
						*poutputlo++ = phi;
						U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo, curhi);
						}
						// register pressure performance issue on several platforms: first do the low half here
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						U curlo4{curlo >> 32};
						curlo >>= 40;
						++offsetscompanion[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						curlo4 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curlo)];
						// register pressure performance issue on several platforms: do the high half here second
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						U curhi4{curhi >> 32};
						curhi >>= 40;
						++offsetscompanion[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						curhi4 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi4)];
						++offsetscompanion[5 * 256 + static_cast<std::size_t>(curhi)];
					}while(--i);
				}
			}
		}else{// 48-bit, not in reverse order
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 1) >> 1)};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					V *p{input[i]};
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					pout[i] = p;
					U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
					}
					U cur0{cur & 0xFFu};
					U cur1{cur >> 8};
					U cur2{cur >> 16};
					U cur3{cur >> 24};
					U cur4{cur >> 32};
					cur >>= 40;
					++offsetscompanion[cur0];
					cur1 &= 0xFFu;
					cur2 &= 0xFFu;
					cur3 &= 0xFFu;
					cur4 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(cur3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(cur4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(cur)];
				}while(--i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					V *phi{input[i]};
					V *plo{input[i - 1]};
					auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
					pout[i] = phi;
					auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
					pout[i - 1] = plo;
					U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
					U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
					}
					// register pressure performance issue on several platforms: first do the high half here
					U curhi0{curhi & 0xFFu};
					U curhi1{curhi >> 8};
					U curhi2{curhi >> 16};
					U curhi3{curhi >> 24};
					U curhi4{curhi >> 32};
					curhi >>= 40;
					++offsetscompanion[curhi0];
					curhi1 &= 0xFFu;
					curhi2 &= 0xFFu;
					curhi3 &= 0xFFu;
					curhi4 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curhi)];
					// register pressure performance issue on several platforms: do the low half here second
					U curlo0{curlo & 0xFFu};
					U curlo1{curlo >> 8};
					U curlo2{curlo >> 16};
					U curlo3{curlo >> 24};
					U curlo4{curlo >> 32};
					curlo >>= 40;
					++offsetscompanion[curlo0];
					curlo1 &= 0xFFu;
					curlo2 &= 0xFFu;
					curlo3 &= 0xFFu;
					curlo4 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo4)];
					++offsetscompanion[5 * 256 + static_cast<std::size_t>(curlo)];
				}while(i -= 2);
			}
		}
	}else if constexpr(40 == CHAR_BIT * sizeof(T)){
		if constexpr(isrevorder){// also reverse the array at the same time
			if constexpr(isinputconst){
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					// unsigned counter, not zero inclusive inside the loop
					std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
					pout += count - i;
					pdst += count - i;
					do{
						V *p{input[0]};
						input += 2;
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						pout[i] = p;
						pdst[i] = p;
						U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						cur >>= 32;
						++offsetscompanion[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(cur)];
					}while(--i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					// unsigned counter, not zero inclusive inside the loop
					std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
					pout += count - i;
					pdst += count - i;
					do{
						V *phi{input[0]};
						V *plo{input[1]};
						input += 2;
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						pout[i] = phi;
						pdst[i] = phi;
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						pout[i - 1] = plo;
						pdst[i - 1] = plo;
						U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
						}
						// register pressure performance issue on several platforms: first do the high half here
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						curhi >>= 32;
						++offsetscompanion[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi)];
						// register pressure performance issue on several platforms: do the low half here second
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						curlo >>= 32;
						++offsetscompanion[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo)];
					}while(i -= 2);
				}
			}else{// !isinputconst
				V **pinputlo{input}, **pinputhi{input + count};
				V **poutputlo{pout}, **poutputhi{pout + count};
				std::size_t i{(count + 1 + 2) >> 2};// rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					do{
						V *plo{pinputlo[0]};
						V *phi{pinputhi[0]};
						// register pressure performance issue on several platforms: first do the low half here
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						*pinputhi-- = plo;
						*poutputhi-- = plo;
						U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo);
						}
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						curlo >>= 32;
						++offsetscompanion[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo)];
						// register pressure performance issue on several platforms: do the high half here second
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						*pinputlo++ = phi;
						*poutputlo++ = phi;
						U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi);
						}
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						curhi >>= 32;
						++offsetscompanion[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi)];
					}while(--i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					do{
						V *plo{pinputlo[0]};
						V *phi{pinputhi[0]};
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						*pinputhi-- = plo;
						*poutputhi-- = plo;
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						*pinputlo++ = phi;
						*poutputlo++ = phi;
						U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo, curhi);
						}
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						U curlo3{curlo >> 24};
						curlo >>= 32;
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						U curhi3{curhi >> 24};
						curhi >>= 32;
						++offsetscompanion[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						curlo3 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsetscompanion[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						curhi3 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo)];
						++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
						++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi)];
					}while(--i);
				}
			}
		}else{// 40-bit, not in reverse order
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 1) >> 1)};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					V *p{input[i]};
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					pout[i] = p;
					U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
					}
					U cur0{cur & 0xFFu};
					U cur1{cur >> 8};
					U cur2{cur >> 16};
					U cur3{cur >> 24};
					cur >>= 32;
					++offsetscompanion[cur0];
					cur1 &= 0xFFu;
					cur2 &= 0xFFu;
					cur3 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(cur3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(cur)];
				}while(--i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					V *phi{input[i]};
					V *plo{input[i - 1]};
					auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
					pout[i] = phi;
					auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
					pout[i - 1] = plo;
					U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
					U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
					}
					U curhi0{curhi & 0xFFu};
					U curhi1{curhi >> 8};
					U curhi2{curhi >> 16};
					U curhi3{curhi >> 24};
					curhi >>= 32;
					U curlo0{curlo & 0xFFu};
					U curlo1{curlo >> 8};
					U curlo2{curlo >> 16};
					U curlo3{curlo >> 24};
					curlo >>= 32;
					++offsetscompanion[curhi0];
					curhi1 &= 0xFFu;
					curhi2 &= 0xFFu;
					curhi3 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
					++offsetscompanion[curlo0];
					curlo1 &= 0xFFu;
					curlo2 &= 0xFFu;
					curlo3 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curhi)];
					++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo3)];
					++offsetscompanion[4 * 256 + static_cast<std::size_t>(curlo)];
				}while(i -= 2);
			}
		}
	}else if constexpr(32 == CHAR_BIT * sizeof(T)){
		if constexpr(isrevorder){// also reverse the array at the same time
			if constexpr(isinputconst){
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					// unsigned counter, not zero inclusive inside the loop
					std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
					pout += count - i;
					pdst += count - i;
					do{
						V *p{input[0]};
						input += 2;
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						pout[i] = p;
						pdst[i] = p;
						U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						cur >>= 24;
						++offsetscompanion[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(cur)];
					}while(--i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					// unsigned counter, not zero inclusive inside the loop
					std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
					pout += count - i;
					pdst += count - i;
					do{
						V *pa{input[0]};
						V *pb{input[1]};
						input += 2;
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						pout[i] = pa;
						pdst[i] = pa;
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						pout[i - 1] = pb;
						pdst[i - 1] = pb;
						U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
						}
						U cur0a{cura & 0xFFu};
						U cur1a{cura >> 8};
						U cur2a{cura >> 16};
						cura >>= 24;
						U cur0b{curb & 0xFFu};
						U cur1b{curb >> 8};
						U cur2b{curb >> 16};
						curb >>= 24;
						++offsetscompanion[cur0a];
						cur1a &= 0xFFu;
						cur2a &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
						++offsetscompanion[cur0b];
						cur1b &= 0xFFu;
						cur2b &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(cur1a)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2a)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(cura)];
						++offsetscompanion[256 + static_cast<std::size_t>(cur1b)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2b)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curb)];
					}while(i -= 2);
				}
			}else{// !isinputconst
				V **pinputlo{input}, **pinputhi{input + count};
				V **poutputlo{pout}, **poutputhi{pout + count};
				std::size_t i{(count + 1 + 2) >> 2};// rounded up in the companion thread
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					do{
						V *plo{pinputlo[0]};
						V *phi{pinputhi[0]};
						// register pressure performance issue on several platforms: first do the low half here
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						*pinputhi-- = plo;
						*poutputhi-- = plo;
						U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo);
						}
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						U curlo2{curlo >> 16};
						curlo >>= 24;
						++offsetscompanion[curlo0];
						curlo1 &= 0xFFu;
						curlo2 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curlo)];
						// register pressure performance issue on several platforms: do the high half here second
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						*pinputlo++ = phi;
						*poutputlo++ = phi;
						U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi);
						}
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						U curhi2{curhi >> 16};
						curhi >>= 24;
						++offsetscompanion[curhi0];
						curhi1 &= 0xFFu;
						curhi2 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi2)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curhi)];
					}while(--i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					do{
						V *pa{pinputlo[0]};
						V *pb{pinputhi[0]};
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						*pinputhi-- = pa;
						*poutputhi-- = pa;
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						*pinputlo++ = pb;
						*poutputlo++ = pb;
						U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
						}
						U cur0a{cura & 0xFFu};
						U cur1a{cura >> 8};
						U cur2a{cura >> 16};
						cura >>= 24;
						U cur0b{curb & 0xFFu};
						U cur1b{curb >> 8};
						U cur2b{curb >> 16};
						curb >>= 24;
						++offsetscompanion[cur0a];
						cur1a &= 0xFFu;
						cur2a &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
						++offsetscompanion[cur0b];
						cur1b &= 0xFFu;
						cur2b &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(cur1a)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2a)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(cura)];
						++offsetscompanion[256 + static_cast<std::size_t>(cur1b)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2b)];
						++offsetscompanion[3 * 256 + static_cast<std::size_t>(curb)];
					}while(--i);
				}
			}
		}else{// 32-bit, not in reverse order
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 1) >> 1)};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					V *p{input[i]};
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					pout[i] = p;
					U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
					}
					U cur0{cur & 0xFFu};
					U cur1{cur >> 8};
					U cur2{cur >> 16};
					cur >>= 24;
					++offsetscompanion[cur0];
					cur1 &= 0xFFu;
					cur2 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(cur)];
				}while(--i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 2) >> 2) * 2};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					V *pa{input[i]};
					V *pb{input[i - 1]};
					auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
					pout[i] = pa;
					auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
					pout[i - 1] = pb;
					U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
					U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
					}
					U cur0a{cura & 0xFFu};
					U cur1a{cura >> 8};
					U cur2a{cura >> 16};
					cura >>= 24;
					U cur0b{curb & 0xFFu};
					U cur1b{curb >> 8};
					U cur2b{curb >> 16};
					curb >>= 24;
					++offsetscompanion[cur0a];
					cur1a &= 0xFFu;
					cur2a &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
					++offsetscompanion[cur0b];
					cur1b &= 0xFFu;
					cur2b &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur1a)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2a)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(cura)];
					++offsetscompanion[256 + static_cast<std::size_t>(cur1b)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur2b)];
					++offsetscompanion[3 * 256 + static_cast<std::size_t>(curb)];
				}while(i -= 2);
			}
		}
	}else if constexpr(24 == CHAR_BIT * sizeof(T)){
		if constexpr(isrevorder){// also reverse the array at the same time
			if constexpr(isinputconst){
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					// unsigned counter, not zero inclusive inside the loop
					std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
					pout += count - i;
					pdst += count - i;
					do{
						V *p{input[0]};
						input += 2;
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						pout[i] = p;
						pdst[i] = p;
						U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						cur >>= 16;
						++offsetscompanion[cur0];
						cur1 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur)];
					}while(--i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					// unsigned counter, not zero inclusive inside the loop
					std::size_t i{((count + 1 + 3) / 6) * 3};// rounded up in the companion thread
					pout += count - i;
					pdst += count - i;
					do{
						V *pa{input[0]};
						V *pb{input[1]};
						V *pc{input[2]};
						input += 3;
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						pout[i] = pa;
						pdst[i] = pa;
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						pout[i - 1] = pb;
						pdst[i - 1] = pb;
						auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
						pout[i - 2] = pc;
						pdst[i - 2] = pc;
						U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc);
						}
						U cur0a{cura & 0xFFu};
						U cur1a{cura >> 8};
						cura >>= 16;
						U cur0b{curb & 0xFFu};
						U cur1b{curb >> 8};
						curb >>= 16;
						U cur0c{curc & 0xFFu};
						U cur1c{curc >> 8};
						curc >>= 16;
						++offsetscompanion[cur0a];
						cur1a &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
						++offsetscompanion[cur0b];
						cur1b &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
						++offsetscompanion[cur0c];
						cur1c &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(cur1a)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(cura)];
						++offsetscompanion[256 + static_cast<std::size_t>(cur1b)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curb)];
						++offsetscompanion[256 + static_cast<std::size_t>(cur1c)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curc)];
					}while(i -= 3);
				}
			}else{// !isinputconst
				V **pinputlo{input}, **pinputhi{input + count};
				V **poutputlo{pout}, **poutputhi{pout + count};
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					std::size_t i{(count + 1 + 2) >> 2};// rounded up in the companion thread
					do{
						V *plo{pinputlo[0]};
						V *phi{pinputhi[0]};
						// register pressure performance issue on several platforms: first do the low half here
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						*pinputhi-- = plo;
						*poutputhi-- = plo;
						U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo);
						}
						U curlo0{curlo & 0xFFu};
						U curlo1{curlo >> 8};
						curlo >>= 16;
						++offsetscompanion[curlo0];
						curlo1 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curlo1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curlo)];
						// register pressure performance issue on several platforms: do the high half here second
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						*pinputlo++ = phi;
						*poutputlo++ = phi;
						U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi);
						}
						U curhi0{curhi & 0xFFu};
						U curhi1{curhi >> 8};
						curhi >>= 16;
						++offsetscompanion[curhi0];
						curhi1 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curhi1)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curhi)];
					}while(--i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					std::size_t i{(count + 1 + 6) / 12};// rounded up in the companion thread
					do{
						V *pa{pinputlo[0]};
						V *pb{pinputhi[0]};
						V *pc{pinputlo[1]};
						V *pd{pinputhi[-1]};
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						pinputhi[0] = pa;
						poutputhi[0] = pa;
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						pinputlo[0] = pb;
						poutputlo[0] = pb;
						auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
						pinputhi[1] = pc;
						poutputhi[1] = pc;
						U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
						// register pressure performance issue on several platforms: first do the high half here
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc);
						}
						U cur0a{cura & 0xFFu};
						U cur1a{cura >> 8};
						cura >>= 16;
						U cur0b{curb & 0xFFu};
						U cur1b{curb >> 8};
						curb >>= 16;
						U cur0c{curc & 0xFFu};
						U cur1c{curc >> 8};
						curc >>= 16;
						++offsetscompanion[cur0a];
						cur1a &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
						++offsetscompanion[cur0b];
						cur1b &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
						++offsetscompanion[cur0c];
						cur1c &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(cur1a)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(cura)];
						++offsetscompanion[256 + static_cast<std::size_t>(cur1b)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curb)];
						++offsetscompanion[256 + static_cast<std::size_t>(cur1c)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curc)];
						V *pe{pinputlo[2]};
						V *pf{pinputhi[-2]};
						auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
						pinputlo[1] = pd;
						poutputlo[1] = pd;
						auto ime{indirectinput1<indirection1, isindexed2, T, V>(pe, varparameters...)};
						pinputhi[-2] = pe;
						pinputhi -= 3;
						poutputhi[-2] = pe;
						poutputhi -= 3;
						auto imf{indirectinput1<indirection1, isindexed2, T, V>(pf, varparameters...)};
						pinputlo[2] = pf;
						pinputlo += 3;
						poutputlo[2] = pf;
						poutputlo += 3;
						U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
						U cure{indirectinput2<indirection1, indirection2, isindexed2, T>(ime, varparameters...)};
						U curf{indirectinput2<indirection1, indirection2, isindexed2, T>(ime, varparameters...)};
						// register pressure performance issue on several platforms: do the low half here second
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curd, cure, curf);
						}
						U cur0d{curd & 0xFFu};
						U cur1d{curd >> 8};
						curd >>= 16;
						U cur0e{cure & 0xFFu};
						U cur1e{cure >> 8};
						cure >>= 16;
						U cur0f{curf & 0xFFu};
						U cur1f{curf >> 8};
						curf >>= 16;
						++offsetscompanion[cur0d];
						cur1d &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curd &= 0x7Fu;
						++offsetscompanion[cur0e];
						cur1e &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cure &= 0x7Fu;
						++offsetscompanion[cur0f];
						cur1f &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) curf &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(cur1d)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curd)];
						++offsetscompanion[256 + static_cast<std::size_t>(cur1e)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(cure)];
						++offsetscompanion[256 + static_cast<std::size_t>(cur1f)];
						++offsetscompanion[2 * 256 + static_cast<std::size_t>(curf)];
					}while(--i);
				}
			}
		}else{// 24-bit, not in reverse order
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 1) >> 1)};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					V *p{input[i]};
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					pout[i] = p;
					U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
					}
					U cur0{cur & 0xFFu};
					U cur1{cur >> 8};
					cur >>= 16;
					++offsetscompanion[cur0];
					cur1 &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur1)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cur)];
				}while(--i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 3) / 6) * 3};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					V *pa{input[i]};
					V *pb{input[i - 1]};
					V *pc{input[i - 2]};
					auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
					pout[i] = pa;
					auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
					pout[i - 1] = pb;
					auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
					pout[i - 2] = pc;
					U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
					U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
					U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc);
					}
					U cur0a{cura & 0xFFu};
					U cur1a{cura >> 8};
					cura >>= 16;
					U cur0b{curb & 0xFFu};
					U cur1b{curb >> 8};
					curb >>= 16;
					U cur0c{curc & 0xFFu};
					U cur1c{curc >> 8};
					curc >>= 16;
					++offsetscompanion[cur0a];
					cur1a &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
					++offsetscompanion[cur0b];
					cur1b &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
					++offsetscompanion[cur0c];
					cur1c &= 0xFFu;
					if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur1a)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(cura)];
					++offsetscompanion[256 + static_cast<std::size_t>(cur1b)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curb)];
					++offsetscompanion[256 + static_cast<std::size_t>(cur1c)];
					++offsetscompanion[2 * 256 + static_cast<std::size_t>(curc)];
				}while(i -= 3);
			}
		}
	}else if constexpr(16 == CHAR_BIT * sizeof(T)){
		if constexpr(isrevorder){// also reverse the array at the same time
			if constexpr(isinputconst){
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					// unsigned counter, not zero inclusive inside the loop
					std::size_t i{(count + 1 + 1) >> 1};// rounded up in the companion thread
					pout += count - i;
					pdst += count - i;
					do{
						V *p{input[0]};
						input += 2;
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						pout[i] = p;
						pdst[i] = p;
						U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
						}
						U cur0{cur & 0xFFu};
						cur >>= 8;
						++offsetscompanion[cur0];
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(cur)];
					}while(--i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					// unsigned counter, not zero inclusive inside the loop
					std::size_t i{((count + 1 + 4) >> 3) * 4};// rounded up in the companion thread
					pout += count - i;
					pdst += count - i;
					do{
						V *pa{input[0]};
						V *pb{input[1]};
						V *pc{input[2]};
						V *pd{input[3]};
						input += 4;
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						pout[i] = pa;
						pdst[i] = pa;
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						pout[i - 1] = pb;
						pdst[i - 1] = pb;
						auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
						pout[i - 2] = pc;
						pdst[i - 2] = pc;
						auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
						pout[i - 3] = pd;
						pdst[i - 3] = pd;
						U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
						U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
						}
						U cur0a{cura & 0xFFu};
						cura >>= 8;
						U cur0b{curb & 0xFFu};
						curb >>= 8;
						U cur0c{curc & 0xFFu};
						curc >>= 8;
						U cur0d{curd & 0xFFu};
						curd >>= 8;
						++offsetscompanion[cur0a];
						if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
						++offsetscompanion[cur0b];
						if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
						++offsetscompanion[cur0c];
						if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
						++offsetscompanion[cur0d];
						if constexpr(isabsvalue && issignmode && isfltpmode) curd &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(cura)];
						++offsetscompanion[256 + static_cast<std::size_t>(curb)];
						++offsetscompanion[256 + static_cast<std::size_t>(curc)];
						++offsetscompanion[256 + static_cast<std::size_t>(curd)];
					}while(i -= 4);
				}
			}else{// !isinputconst
				V **pinputlo{input}, **pinputhi{input + count};
				V **poutputlo{pout}, **poutputhi{pout + count};
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
					std::size_t i{(count + 1 + 2) >> 2};// rounded up in the companion thread
					do{
						V *plo{pinputlo[0]};
						V *phi{pinputhi[0]};
						// register pressure performance issue on several platforms: first do the low half here
						auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
						*pinputhi-- = plo;
						*poutputhi-- = plo;
						U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo);
						}
						U curlo0{curlo & 0xFFu};
						curlo >>= 8;
						++offsetscompanion[curlo0];
						if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curlo)];
						// register pressure performance issue on several platforms: do the high half here second
						auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
						*pinputlo++ = phi;
						*poutputlo++ = phi;
						U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi);
						}
						U curhi0{curhi & 0xFFu};
						curhi >>= 8;
						++offsetscompanion[curhi0];
						if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(curhi)];
					}while(--i);
				}else{// architecture: do not limit as much when there's a reasonable amount of registers
					std::size_t i{(count + 1 + 4) >> 3};// rounded up in the companion thread
					do{
						V *pa{pinputlo[0]};
						V *pb{pinputhi[0]};
						V *pc{pinputlo[1]};
						V *pd{pinputhi[-1]};
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						pinputhi[0] = pa;
						poutputhi[0] = pa;
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						pinputlo[0] = pb;
						poutputlo[0] = pb;
						auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
						pinputhi[-1] = pc;
						pinputhi -= 2;
						poutputhi[-1] = pc;
						poutputhi -= 2;
						auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
						pinputlo[1] = pd;
						pinputlo += 2;
						poutputlo[1] = pd;
						poutputlo += 2;
						U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
						U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
						}
						U cur0a{cura & 0xFFu};
						cura >>= 8;
						U cur0b{curb & 0xFFu};
						curb >>= 8;
						U cur0c{curc & 0xFFu};
						curc >>= 8;
						U cur0d{curd & 0xFFu};
						curd >>= 8;
						++offsetscompanion[cur0a];
						if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
						++offsetscompanion[cur0b];
						if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
						++offsetscompanion[cur0c];
						if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
						++offsetscompanion[cur0d];
						if constexpr(isabsvalue && issignmode && isfltpmode) curd &= 0x7Fu;
						++offsetscompanion[256 + static_cast<std::size_t>(cura)];
						++offsetscompanion[256 + static_cast<std::size_t>(curb)];
						++offsetscompanion[256 + static_cast<std::size_t>(curc)];
						++offsetscompanion[256 + static_cast<std::size_t>(curd)];
					}while(--i);
				}
			}
		}else{// 16-bit, not in reverse order
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 1) >> 1)};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					V *p{input[i]};
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					pout[i] = p;
					U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
					}
					U cur0{cur & 0xFFu};
					cur >>= 8;
					++offsetscompanion[cur0];
					if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cur)];
				}while(--i);
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				// unsigned counter, not zero inclusive inside the loop
				std::size_t i{((count + 1 + 4) >> 3) * 4};// rounded up in the companion thread
				input += count - i;
				pout += count - i;
				do{
					V *pa{input[i]};
					V *pb{input[i - 1]};
					V *pc{input[i - 2]};
					V *pd{input[i - 3]};
					auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
					pout[i] = pa;
					auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
					pout[i - 1] = pb;
					auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
					pout[i - 2] = pc;
					auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
					pout[i - 3] = pd;
					U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
					U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
					U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
					U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
					if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
					}
					U cur0a{cura & 0xFFu};
					cura >>= 8;
					U cur0b{curb & 0xFFu};
					curb >>= 8;
					U cur0c{curc & 0xFFu};
					curc >>= 8;
					U cur0d{curd & 0xFFu};
					curd >>= 8;
					++offsetscompanion[cur0a];
					if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
					++offsetscompanion[cur0b];
					if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
					++offsetscompanion[cur0c];
					if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
					++offsetscompanion[cur0d];
					if constexpr(isabsvalue && issignmode && isfltpmode) curd &= 0x7Fu;
					++offsetscompanion[256 + static_cast<std::size_t>(cura)];
					++offsetscompanion[256 + static_cast<std::size_t>(curb)];
					++offsetscompanion[256 + static_cast<std::size_t>(curc)];
					++offsetscompanion[256 + static_cast<std::size_t>(curd)];
				}while(i -= 4);
			}
		}
	}else static_assert(false, "Implementing larger types will require additional work and optimisation for this library.");
}

// main part, multi-threading companion for the radixsortnoallocmulti2thread() function implementation template for multi-part types with indirection
// Do not use this function directly.
template<auto indirection1, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename X, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	64 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortnoallocmulti2threadmainmtc(std::size_t count, V *const input[], V *pdst[], V *pdstnext[], X offsetscompanion[], unsigned runsteps, std::atomic_uintptr_t &atomiclightbarrier, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
	assert(7 <= count);// this function is not for small arrays, 8 is the minimum original array count for 16-bit inputs
	// do not pass a nullptr here
	assert(input);
	assert(pdst);
	assert(pdstnext);
	assert(offsetscompanion);
	assert(runsteps);
	unsigned shifter{bitscanforwardportable(runsteps)};// at least 1 bit is set inside runsteps as by previous check
	V **psrchi;
	if constexpr(isrevorder){
		psrchi = pdstnext + count;
	}else{
		psrchi = const_cast<V **>(input) + count;// psrchi will never be written to
	}
	// skip a step if possible
	runsteps >>= shifter;
	X *poffset{offsetscompanion + static_cast<std::size_t>(shifter) * 256};
	while(1 < atomiclightbarrier.load(std::memory_order_relaxed)){// continue if it's 0 or 1
		spinpause();// catch up until the other thread releases the barrier
	}// do not place this inside the main loop, as the barrier is released there by cancelling 1 and -1 in interlocked add-fetch operations
	if constexpr(!isabsvalue && isfltpmode) if(CHAR_BIT * sizeof(T) / 8 - 1 == shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
		[[unlikely]]
#endif
		goto handletop8;// rare, but possible
	shifter *= 8;
	for(;;){
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
			std::size_t j{(count + 1 + 2) >> 2};// rounded up in the top part
			do{// fill the array, two at a time
				V *pa{psrchi[0]};
				V *pb{psrchi[-1]};
				psrchi -= 2;
				auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
				auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
				auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
				auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
				auto[cura, curb]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, shifter)};
				std::size_t offseta{poffset[cura]--};// the next item will be placed one lower
				std::size_t offsetb{poffset[curb]--};
				pdst[offseta] = pa;
				pdst[offsetb] = pb;
			}while(--j);
		}else{// architecture: limit to four at a time when there's a decent amount of registers
			std::size_t j{(count + 1 + 4) >> 3};// rounded up in the top part
			do{// fill the array, four at a time
				V *pa{psrchi[0]};
				V *pb{psrchi[-1]};
				V *pc{psrchi[-2]};
				V *pd{psrchi[-3]};
				psrchi -= 4;
				auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
				auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
				auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
				auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
				auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
				auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
				auto outc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
				auto outd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
				auto[cura, curb, curc, curd]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd, shifter)};
				std::size_t offseta{poffset[cura]--};// the next item will be placed one lower
				std::size_t offsetb{poffset[curb]--};
				std::size_t offsetc{poffset[curc]--};
				std::size_t offsetd{poffset[curd]--};
				pdst[offseta] = pa;
				pdst[offsetb] = pb;
				pdst[offsetc] = pc;
				pdst[offsetd] = pd;
			}while(--j);
		}
		runsteps >>= 1;
		if(!runsteps)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
			[[unlikely]]
#endif
			break;
		{
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			unsigned index;
			if constexpr(16 < CHAR_BIT * sizeof(T)) index = bitscanforwardportable(runsteps);// at least 1 bit is set inside runsteps as by previous check
			shifter += 8;
			poffset += 256;
			// swap the pointers for the next round, data is moved on each iteration
			psrchi = pdst;
			std::uintptr_t old{atomiclightbarrier.fetch_add(~static_cast<std::uintptr_t>(0))};
			pdst = pdstnext;
			pdstnext = psrchi;
			psrchi += count;
			// skip a step if possible
			if constexpr(16 < CHAR_BIT * sizeof(T)){
				runsteps >>= index;
				shifter += index * 8;
				poffset += static_cast<std::size_t>(index) * 256;
			}
			if constexpr(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
				if(!old) do{
					spinpause();
				}while(atomiclightbarrier.load(std::memory_order_relaxed));
			}else{// detect exceptions
				if(!old) do{
					spinpause();
					old = atomiclightbarrier.load(std::memory_order_relaxed);
				}while(~static_cast<std::uintptr_t>(0) == old);
				if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == old) return;// the main thread produced an exception
			}
		}
		// handle the top part for floating-point differently
		if(!isabsvalue && isfltpmode && CHAR_BIT * sizeof(T) - 8 == shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
			[[unlikely]]
#endif
		{
handletop8:// this prevents "!isabsvalue && isfltpmode" to be made constexpr here, but that's fine
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
				std::size_t j{(count + 1 + 2) >> 2};// rounded up in the top part
				do{// fill the array, two at a time
					V *pa{psrchi[0]};
					V *pb{psrchi[-1]};
					psrchi -= 2;
					auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
					auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
					auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
					auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
					auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb)};
					std::size_t offseta{offsetscompanion[cura + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]--};// the next item will be placed one lower
					std::size_t offsetb{offsetscompanion[curb + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]--};
					pdst[offseta] = pa;
					pdst[offsetb] = pb;
				}while(--j);
			}else{// architecture: limit to four at a time when there's a decent amount of registers
				std::size_t j{(count + 1 + 4) >> 3};// rounded up in the top part
				do{// fill the array, four at a time
					V *pa{psrchi[0]};
					V *pb{psrchi[-1]};
					V *pc{psrchi[-2]};
					V *pd{psrchi[-3]};
					psrchi -= 4;
					auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
					auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
					auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
					auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
					auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
					auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
					auto outc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
					auto outd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
					auto[cura, curb, curc, curd]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd)};
					std::size_t offseta{offsetscompanion[cura + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]--};// the next item will be placed one lower
					std::size_t offsetb{offsetscompanion[curb + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]--};
					std::size_t offsetc{offsetscompanion[curc + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]--};
					std::size_t offsetd{offsetscompanion[curd + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]--};
					pdst[offseta] = pa;
					pdst[offsetb] = pb;
					pdst[offsetc] = pc;
					pdst[offsetd] = pd;
				}while(--j);
			}
			break;// no further processing beyond the top part
		}
	}
}

// main part for the radixsortcopynoallocmulti2thread() and radixsortnoallocmulti2thread() function implementation templates for 80-bit-based long double types with indirection
// Do not use this function directly.
template<auto indirection1, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, bool ismultithreadcapable, typename V, typename X, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	64 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortnoallocmulti2threadmain(std::size_t count, V *const input[], V *pdst[], V *pdstnext[], X offsets[], unsigned runsteps, unsigned usemultithread, std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t &, std::nullptr_t> atomiclightbarrier, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
	static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	assert(count && count != MAXSIZE_T);
	// do not pass a nullptr here
	assert(input);
	assert(pdst);
	assert(pdstnext);
	assert(offsets);
	assert(runsteps);
	unsigned shifter{bitscanforwardportable(runsteps)};// at least 1 bit is set inside runsteps as by previous check
	V **psrclo;
	if constexpr(isrevorder){
		psrclo = pdstnext;
	}else{
		psrclo = const_cast<V **>(input);// psrclo will never be written to
	}
	// skip a step if possible
	runsteps >>= shifter;
	X *poffset{offsets + static_cast<std::size_t>(shifter) * 256};
	if constexpr(ismultithreadcapable) while(1 < 1 + atomiclightbarrier.load(std::memory_order_relaxed)){// continue if it's 0 or -1
		spinpause();// catch up until the other thread releases the barrier
	}// do not place this inside the main loop, as the barrier is released there by cancelling 1 and -1 in interlocked add-fetch operations
	if constexpr(!isabsvalue && isfltpmode) if(CHAR_BIT * sizeof(T) / 8 - 1 == shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
		[[unlikely]]
#endif
		goto handletop8;// rare, but possible
	shifter *= 8;
	for(;;){
		if constexpr(ismultithreadcapable){
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
				std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (1 + usemultithread))};// rounded down in the bottom part
				while(0 <= --j){// fill the array, two at a time
					V *pa{psrclo[0]};
					V *pb{psrclo[1]};
					psrclo += 2;
					auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
					auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
					auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
					auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
					auto[cura, curb]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, shifter)};
					std::size_t offseta{poffset[cura]++};// the next item will be placed one higher
					std::size_t offsetb{poffset[curb]++};
					pdst[offseta] = pa;
					pdst[offsetb] = pb;
				}
			}else{// architecture: limit to four at a time when there's a decent amount of registers
				std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (2 + usemultithread))};// rounded down in the bottom part
				while(0 <= --j){// fill the array, four at a time
					V *pa{psrclo[0]};
					V *pb{psrclo[1]};
					V *pc{psrclo[2]};
					V *pd{psrclo[3]};
					psrclo += 4;
					auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
					auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
					auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
					auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
					auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
					auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
					auto outc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
					auto outd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
					auto[cura, curb, curc, curd]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd, shifter)};
					std::size_t offseta{poffset[cura]++};// the next item will be placed one higher
					std::size_t offsetb{poffset[curb]++};
					std::size_t offsetc{poffset[curc]++};
					std::size_t offsetd{poffset[curd]++};
					pdst[offseta] = pa;
					pdst[offsetb] = pb;
					pdst[offsetc] = pc;
					pdst[offsetd] = pd;
				}
				if(2 & count + 1){// fill in the final two items for a remainder of 2 or 3
					V *pa{psrclo[0]};
					V *pb{psrclo[1]};
					psrclo += 2;
					auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
					auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
					auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
					auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
					auto[cura, curb]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, shifter)};
					std::size_t offseta{poffset[cura]++};// the next item will be placed one higher
					std::size_t offsetb{poffset[curb]++};
					pdst[offseta] = pa;
					pdst[offsetb] = pb;
				}
			}
			if(!(1 & count)){// fill in the final item for odd counts
				V *p{psrclo[0]};
				auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
				auto out{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
				std::size_t cur{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(out, shifter)};
				std::size_t offset{poffset[cur]};
				pdst[offset] = p;
			}
		}else{// !ismultithreadcapable
			V *const *psrchi{psrclo + count};
			do{// fill the array, two at a time: one low-to-middle, one high-to-middle
				V *plo{*psrclo++};
				V *phi{*psrchi--};
				auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
				auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
				U outlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo)};
				U outhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi)};
				auto[curlo, curhi]{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(outlo, outhi, shifter)};
				std::size_t offsetlo{poffset[curlo]++};// the next item will be placed one higher
				std::size_t offsethi{poffset[curhi + offsetsstride]--};// the next item will be placed one lower
				pdst[offsetlo] = plo;
				pdst[offsethi] = phi;
			}while(psrclo < psrchi);
			if(psrclo == psrchi){// fill in the final item for odd counts
				V *p{*psrclo};
				auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
				U out{indirectinput2<indirection1, indirection2, isindexed2, T>(im)};
				std::size_t cur{filtershift8<isabsvalue, issignmode, isfltpmode, T, U>(out, shifter)};
				std::size_t offset{poffset[cur]};
				pdst[offset] = p;
			}
		}
		runsteps >>= 1;
		if(!runsteps)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
			[[unlikely]]
#endif
			break;
		{
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			unsigned index;
			if constexpr(16 < CHAR_BIT * sizeof(T)) index = bitscanforwardportable(runsteps);// at least 1 bit is set inside runsteps as by previous check
			shifter += 8;
			poffset += 256;
			// swap the pointers for the next round, data is moved on each iteration
			psrclo = pdst;
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			std::uintptr_t old;
			if constexpr(ismultithreadcapable) old = atomiclightbarrier.fetch_add(usemultithread);
			pdst = pdstnext;
			pdstnext = psrclo;
			// skip a step if possible
			if constexpr(16 < CHAR_BIT * sizeof(T)){
				runsteps >>= index;
				shifter += index * 8;
				poffset += static_cast<std::size_t>(index) * 256;
			}
			if constexpr(ismultithreadcapable){
				if constexpr(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
					if(!old) do{
						spinpause();
					}while(atomiclightbarrier.load(std::memory_order_relaxed));
				}else{// detect exceptions
					if(!old) do{
						spinpause();
						old = atomiclightbarrier.load(std::memory_order_relaxed);
					}while(~static_cast<std::uintptr_t>(0) == old);
					if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == old) return;// the companion thread produced an exception
				}
			}
		}
		// handle the top part for floating-point differently
		if(!isabsvalue && isfltpmode && CHAR_BIT * sizeof(T) - 8 == shifter)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(unlikely)
			[[unlikely]]
#endif
		{
handletop8:// this prevents "!isabsvalue && isfltpmode" to be made constexpr here, but that's fine
			if constexpr(ismultithreadcapable){
				if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
					std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (1 + usemultithread))};// rounded down in the bottom part
					while(0 <= --j){// fill the array, two at a time
						V *pa{psrclo[0]};
						V *pb{psrclo[1]};
						psrclo += 2;
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb)};
						std::size_t offseta{offsets[cura + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};// the next item will be placed one higher
						std::size_t offsetb{offsets[curb + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};
						pdst[offseta] = pa;
						pdst[offsetb] = pb;
					}
				}else{// architecture: limit to four at a time when there's a decent amount of registers
					std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (2 + usemultithread))};// rounded down in the bottom part
					while(0 <= --j){// fill the array, four at a time
						V *pa{psrclo[0]};
						V *pb{psrclo[1]};
						V *pc{psrclo[2]};
						V *pd{psrclo[3]};
						psrclo += 4;
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
						auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
						auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						auto outc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
						auto outd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
						auto[cura, curb, curc, curd]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd)};
						std::size_t offseta{offsets[cura + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};// the next item will be placed one higher
						std::size_t offsetb{offsets[curb + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};
						std::size_t offsetc{offsets[curc + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};
						std::size_t offsetd{offsets[curd + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};
						pdst[offseta] = pa;
						pdst[offsetb] = pb;
						pdst[offsetc] = pc;
						pdst[offsetd] = pd;
					}
					if(2 & count + 1){// fill in the final two items for a remainder of 2 or 3
						V *pa{psrclo[0]};
						V *pb{psrclo[1]};
						psrclo += 2;
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb)};
						std::size_t offseta{offsets[cura + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};// the next item will be placed one higher
						std::size_t offsetb{offsets[curb + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};
						pdst[offseta] = pa;
						pdst[offsetb] = pb;
					}
				}
				if(!(1 & count)){// fill in the final item for odd counts
					V *p{psrclo[0]};
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					auto out{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
					std::size_t cur{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(out)};
					std::size_t offset{offsets[cur + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]};
					pdst[offset] = p;
				}
			}else{// !ismultithreadcapable
				V *const *psrchi{psrclo + count};
				do{// fill the array, two at a time: one low-to-middle, one high-to-middle
					V *plo{*psrclo++};
					V *phi{*psrchi--};
					auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
					auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
					U outlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo)};
					U outhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi)};
					auto[curlo, curhi]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outlo, outhi)};
					std::size_t offsetlo{offsets[curlo + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]++};// the next item will be placed one higher
					std::size_t offsethi{offsets[curhi + (CHAR_BIT * sizeof(T) - 8) * 256 / 8 + offsetsstride]--};// the next item will be placed one lower
					pdst[offsetlo] = plo;
					pdst[offsethi] = phi;
				}while(psrclo < psrchi);
				if(psrclo == psrchi){// fill in the final item for odd counts
					V *p{*psrclo};
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					U out{indirectinput2<indirection1, indirection2, isindexed2, T>(im)};
					std::size_t cur{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(out)};
					std::size_t offset{offsets[cur + (CHAR_BIT * sizeof(T) - 8) * 256 / 8]};
					pdst[offset] = p;
				}
			}
			break;// no further processing beyond the top part
		}
	}
}

// multi-threading companion for the radixsortcopynoallocmulti2thread() function implementation template for multi-part types with indirection
// Do not use this function directly.
template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename X, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	64 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortcopynoallocmulti2threadmtc(std::size_t count, V *const input[], V *output[], V *buffer[], std::atomic_uintptr_t &atomiclightbarrier, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>;
	// do not pass a nullptr here
	assert(input);
	assert(output);
	assert(buffer);
	static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	X offsetscompanion[offsetsstride]{};// a sizeable amount of indices, but it's worth it, zeroed in advance here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
	[[maybe_unused]]
#endif
	std::conditional_t<std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>,
		std::atomic_uintptr_t &,// nothrow capable indirection1, let the compiler just discard this reference
		atomicvarwrapper> atomicguard{atomiclightbarrier};// may throw, so set up the guard
	radixsortnoallocmulti2threadinitmtc<indirection1, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, true, V, X>(count, input, output, buffer, offsetscompanion, varparameters...);

	X *offsets;
	{// barrier and pointer exchange with the main thread
		std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsetscompanion))};
		// detect exceptions
		if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
			if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the main thread produced an exception
		}
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed);
			}while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == other);
			// detect exceptions
			if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
				if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the main thread produced an exception
			}
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		offsets = reinterpret_cast<X *>(other);// retrieve the pointer
	}

	// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
	auto[runsteps, paritybool]{generateoffsetsmultimtc<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, offsets, offsetscompanion)};

	{// barrier and (flipped bits) runsteps, paritybool value exchange with the main thread
		// no exception detection required here
		// paritybool is either 0 or 1 here, so we can pack it together with runsteps and add usemultithread on top
		std::uintptr_t compound{static_cast<std::uintptr_t>(runsteps) * 2 + static_cast<std::uintptr_t>(paritybool) + 1};
		while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == atomiclightbarrier.load(std::memory_order_relaxed)){
			spinpause();// catch up
		}
		std::uintptr_t other{atomiclightbarrier.fetch_add(compound)};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed) - compound;
			}while(!other);
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		other += compound;// combine
		unsigned lowercarryoutbits{2 + paritybool};
		paritybool = static_cast<unsigned>(other) & 1;// piece together the parity from both threads
		other -= lowercarryoutbits;// this will remove possiby two bits of carry-out before the next right shift
		runsteps = static_cast<unsigned>(other >> 1);// this can shift out a 0 or a 1 bit here, depending on the leftovers of parity
	}

	// perform the bidirectional 8-bit sorting sequence
	// flip the relevant bits inside runsteps first
	if(runsteps ^= (1u << CHAR_BIT * sizeof(T) / 8) - 1)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
		[[likely]]
#endif
	{// perform the bidirectional 8-bit sorting sequence
		V **pdst{buffer}, **pdstnext{output};// for the next iteration
		if(paritybool){// swap if the count of sorting actions to do is odd
			pdst = output;
			pdstnext = buffer;
		}
		radixsortnoallocmulti2threadmainmtc<indirection1, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X>(count, input, pdst, pdstnext, offsetscompanion, runsteps, atomiclightbarrier, varparameters...);
	}
}

// radixsortcopynoalloc() function implementation template for multi-part types with indirection
template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename X
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	, bool ismultithreadcapable = true
#endif
	, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	64 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	radixsortcopynoallocmulti1thread
#else
	radixsortcopynoallocmulti2thread
#endif
	(std::size_t count, V *const input[], V *output[], V *buffer[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	static bool constexpr ismultithreadcapable{false};
#endif
	if constexpr(ismultithreadcapable){
		assert(1 < std::thread::hardware_concurrency());// only use multi-threading if there is more than one hardware thread
		assert(15 <= count);// a 0 or 1 count array is only allowed here in single-threaded function mode
	}
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);
	assert(buffer);
	// All the code in this function is adapted for count to be one below its input value here.
	--count;
	if(ismultithreadcapable || 0 < static_cast<std::ptrdiff_t>(count)){// a 0 or 1 count array is only allowed here in single-threaded function mode
		static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
		// conditionally enable multi-threading here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t, std::nullptr_t> atomiclightbarrier{};
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::future<void>, std::nullptr_t> asynchandle;

		// count the 256 configurations, all in one go
		if constexpr(ismultithreadcapable){
			try{
				asynchandle = std::async(std::launch::async, radixsortcopynoallocmulti2threadmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X, vararguments...>, count, input, output, buffer, std::ref(atomiclightbarrier), varparameters...);
				usemultithread = 1;
			}catch(...){// std::async may fail gracefully here
				assert(false);
			}
		}
		X offsets[offsetsstride * (2 - ismultithreadcapable)];// a sizeable amount of indices, but it's worth it
		std::memset(offsets, 0, offsetsstride * sizeof(X));// zeroed in advance here
		{// scope atomicguard, so it's always destructed before asynchandle
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			std::conditional_t<ismultithreadcapable,
				std::conditional_t<std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>,
					std::atomic_uintptr_t &,// nothrow capable indirection1, let the compiler just discard this reference
					atomicvarwrapper>,// may throw, so set up the guard
				std::nullptr_t> atomicguard{atomiclightbarrier};
			if constexpr(64 == CHAR_BIT * sizeof(T)){
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
				[[maybe_unused]]
#endif
				std::conditional_t<ismultithreadcapable, std::ptrdiff_t, std::nullptr_t> stride;
				if constexpr(ismultithreadcapable){
					// architecture: limit to one at a time when there's few registers
					if constexpr(defaultgprfilesize < gprfilesize::large) stride = -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
					else stride = -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
					i -= stride;
				}
				if constexpr(isrevorder){// also reverse the array at the same time
					V *const *pinput{input};
					if constexpr(ismultithreadcapable) pinput += stride;
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *p{pinput[0]};
							++pinput;
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							U cur5{cur >> 40};
							U cur6{cur >> 48};
							cur >>= 56;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							cur5 &= 0xFFu;
							cur6 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
							++offsets[6 * 256 + static_cast<std::size_t>(cur6)];
							++offsets[7 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						do{
							V *phi{pinput[0]};
							V *plo{pinput[1]};
							pinput += 2;
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							output[i] = phi;
							buffer[i] = phi;
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							output[i - 1] = plo;
							buffer[i - 1] = plo;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
							}
							// register pressure performance issue on several platforms: first do the high half here
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							U curhi4{curhi >> 32};
							U curhi5{curhi >> 40};
							U curhi6{curhi >> 48};
							curhi >>= 56;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							curhi4 &= 0xFFu;
							curhi5 &= 0xFFu;
							curhi6 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curhi5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curhi6)];
							++offsets[7 * 256 + static_cast<std::size_t>(curhi)];
							// register pressure performance issue on several platforms: do the low half here second
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							U curlo4{curlo >> 32};
							U curlo5{curlo >> 40};
							U curlo6{curlo >> 48};
							curlo >>= 56;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							curlo4 &= 0xFFu;
							curlo5 &= 0xFFu;
							curlo6 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curlo5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curlo6)];
							++offsets[7 * 256 + static_cast<std::size_t>(curlo)];
							i -= 2;
						}while(0 < i);
						if(!(1 & i)){// fill in the final item for odd counts
							V *p{pinput[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							U cur5{cur >> 40};
							U cur6{cur >> 48};
							cur >>= 56;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							cur5 &= 0xFFu;
							cur6 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
							++offsets[6 * 256 + static_cast<std::size_t>(cur6)];
							++offsets[7 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}else{// 64-bit, not in reverse order
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *p{input[i]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							U cur5{cur >> 40};
							U cur6{cur >> 48};
							cur >>= 56;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							cur5 &= 0xFFu;
							cur6 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
							++offsets[6 * 256 + static_cast<std::size_t>(cur6)];
							++offsets[7 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						do{
							V *phi{input[i]};
							V *plo{input[i - 1]};
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							output[i] = phi;
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							output[i - 1] = plo;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
							}
							// register pressure performance issue on several platforms: first do the high half here
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							U curhi4{curhi >> 32};
							U curhi5{curhi >> 40};
							U curhi6{curhi >> 48};
							curhi >>= 56;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							curhi4 &= 0xFFu;
							curhi5 &= 0xFFu;
							curhi6 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curhi5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curhi6)];
							++offsets[7 * 256 + static_cast<std::size_t>(curhi)];
							// register pressure performance issue on several platforms: do the low half here second
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							U curlo4{curlo >> 32};
							U curlo5{curlo >> 40};
							U curlo6{curlo >> 48};
							curlo >>= 56;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							curlo4 &= 0xFFu;
							curlo5 &= 0xFFu;
							curlo6 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curlo5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curlo6)];
							++offsets[7 * 256 + static_cast<std::size_t>(curlo)];
							i -= 2;
						}while(0 < i);
						if(!(1 & i)){// fill in the final item for odd counts
							V *p{input[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[0] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							U cur5{cur >> 40};
							U cur6{cur >> 48};
							cur >>= 56;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							cur5 &= 0xFFu;
							cur6 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
							++offsets[6 * 256 + static_cast<std::size_t>(cur6)];
							++offsets[7 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}
			}else if constexpr(56 == CHAR_BIT * sizeof(T)){
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
				[[maybe_unused]]
#endif
				std::conditional_t<ismultithreadcapable, std::ptrdiff_t, std::nullptr_t> stride;
				if constexpr(ismultithreadcapable){
					stride = -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
					i -= stride;
				}
				if constexpr(isrevorder){// also reverse the array at the same time
					V *const *pinput{input};
					if constexpr(ismultithreadcapable) pinput += stride;
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *p{pinput[0]};
							++pinput;
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							U cur5{cur >> 40};
							cur >>= 48;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							cur5 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
							++offsets[6 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						do{
							V *phi{pinput[0]};
							V *plo{pinput[1]};
							pinput += 2;
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							output[i] = phi;
							buffer[i] = phi;
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							output[i - 1] = plo;
							buffer[i - 1] = plo;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
							}
							// register pressure performance issue on several platforms: first do the high half here
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							U curhi4{curhi >> 32};
							U curhi5{curhi >> 40};
							curhi >>= 48;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							curhi4 &= 0xFFu;
							curhi5 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curhi5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curhi)];
							// register pressure performance issue on several platforms: do the low half here second
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							U curlo4{curlo >> 32};
							U curlo5{curlo >> 40};
							curlo >>= 48;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							curlo4 &= 0xFFu;
							curlo5 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curlo5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curlo)];
							i -= 2;
						}while(0 < i);
						if(!(1 & i)){// fill in the final item for odd counts
							V *p{pinput[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							U cur5{cur >> 40};
							cur >>= 48;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							cur5 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
							++offsets[6 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}else{// 56-bit, not in reverse order
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *p{input[i]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							U cur5{cur >> 40};
							cur >>= 48;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							cur5 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
							++offsets[6 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						do{
							V *phi{input[i]};
							V *plo{input[i - 1]};
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							output[i] = phi;
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							output[i - 1] = plo;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
							}
							// register pressure performance issue on several platforms: first do the high half here
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							U curhi4{curhi >> 32};
							U curhi5{curhi >> 40};
							curhi >>= 48;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							curhi4 &= 0xFFu;
							curhi5 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curhi5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curhi)];
							// register pressure performance issue on several platforms: do the low half here second
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							U curlo4{curlo >> 32};
							U curlo5{curlo >> 40};
							curlo >>= 48;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							curlo4 &= 0xFFu;
							curlo5 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curlo5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curlo)];
							i -= 2;
						}while(0 < i);
						if(!(1 & i)){// fill in the final item for odd counts
							V *p{input[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[0] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							U cur5{cur >> 40};
							cur >>= 48;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							cur5 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
							++offsets[6 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}
			}else if constexpr(48 == CHAR_BIT * sizeof(T)){
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
				[[maybe_unused]]
#endif
				std::conditional_t<ismultithreadcapable, std::ptrdiff_t, std::nullptr_t> stride;
				if constexpr(ismultithreadcapable){
					stride = -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
					i -= stride;
				}
				if constexpr(isrevorder){// also reverse the array at the same time
					V *const *pinput{input};
					if constexpr(ismultithreadcapable) pinput += stride;
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *p{pinput[0]};
							++pinput;
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							cur >>= 40;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						do{
							V *phi{pinput[0]};
							V *plo{pinput[1]};
							pinput += 2;
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							output[i] = phi;
							buffer[i] = phi;
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							output[i - 1] = plo;
							buffer[i - 1] = plo;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
							}
							// register pressure performance issue on several platforms: first do the high half here
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							U curhi4{curhi >> 32};
							curhi >>= 40;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							curhi4 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curhi)];
							// register pressure performance issue on several platforms: do the low half here second
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							U curlo4{curlo >> 32};
							curlo >>= 40;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							curlo4 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curlo)];
							i -= 2;
						}while(0 < i);
						if(!(1 & i)){// fill in the final item for odd counts
							V *p{pinput[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							cur >>= 40;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}else{// 48-bit, not in reverse order
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *p{input[i]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							cur >>= 40;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						do{
							V *phi{input[i]};
							V *plo{input[i - 1]};
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							output[i] = phi;
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							output[i - 1] = plo;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
							}
							// register pressure performance issue on several platforms: first do the high half here
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							U curhi4{curhi >> 32};
							curhi >>= 40;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							curhi4 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curhi)];
							// register pressure performance issue on several platforms: do the low half here second
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							U curlo4{curlo >> 32};
							curlo >>= 40;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							curlo4 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curlo)];
							i -= 2;
						}while(0 < i);
						if(!(1 & i)){// fill in the final item for odd counts
							V *p{input[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[0] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							cur >>= 40;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}
			}else if constexpr(40 == CHAR_BIT * sizeof(T)){
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
				[[maybe_unused]]
#endif
				std::conditional_t<ismultithreadcapable, std::ptrdiff_t, std::nullptr_t> stride;
				if constexpr(ismultithreadcapable){
					stride = -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
					i -= stride;
				}
				if constexpr(isrevorder){// also reverse the array at the same time
					V *const *pinput{input};
					if constexpr(ismultithreadcapable) pinput += stride;
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *p{pinput[0]};
							++pinput;
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							cur >>= 32;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						do{
							V *phi{pinput[0]};
							V *plo{pinput[1]};
							pinput += 2;
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							output[i] = phi;
							buffer[i] = phi;
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							output[i - 1] = plo;
							buffer[i - 1] = plo;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
							}
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							curhi >>= 32;
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							curlo >>= 32;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi)];
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo)];
							i -= 2;
						}while(0 < i);
						if(!(1 & i)){// fill in the final item for odd counts
							V *p{pinput[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							cur >>= 32;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}else{// 40-bit, not in reverse order
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *p{input[i]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							cur >>= 32;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						do{
							V *phi{input[i]};
							V *plo{input[i - 1]};
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							output[i] = phi;
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							output[i - 1] = plo;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
							}
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							curhi >>= 32;
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							curlo >>= 32;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi)];
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo)];
							i -= 2;
						}while(0 < i);
						if(!(1 & i)){// fill in the final item for odd counts
							V *p{input[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[0] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							cur >>= 32;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}
			}else if constexpr(32 == CHAR_BIT * sizeof(T)){
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
				[[maybe_unused]]
#endif
				std::conditional_t<ismultithreadcapable, std::ptrdiff_t, std::nullptr_t> stride;
				if constexpr(ismultithreadcapable){
					stride = -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
					i -= stride;
				}
				if constexpr(isrevorder){// also reverse the array at the same time
					V *const *pinput{input};
					if constexpr(ismultithreadcapable) pinput += stride;
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *p{pinput[0]};
							++pinput;
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							cur >>= 24;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						do{
							V *pa{pinput[0]};
							V *pb{pinput[1]};
							pinput += 2;
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							output[i] = pa;
							buffer[i] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							output[i - 1] = pb;
							buffer[i - 1] = pb;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
							}
							U cur0a{cura & 0xFFu};
							U cur1a{cura >> 8};
							U cur2a{cura >> 16};
							cura >>= 24;
							U cur0b{curb & 0xFFu};
							U cur1b{curb >> 8};
							U cur2b{curb >> 16};
							curb >>= 24;
							++offsets[cur0a];
							cur1a &= 0xFFu;
							cur2a &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							cur1b &= 0xFFu;
							cur2b &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1a)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2a)];
							++offsets[3 * 256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(cur1b)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2b)];
							++offsets[3 * 256 + static_cast<std::size_t>(curb)];
							i -= 2;
						}while(0 < i);
						if(!(1 & i)){// fill in the final item for odd counts
							V *p{pinput[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[0] = p;
							buffer[0] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{static_cast<unsigned>(cur) >> 8};
							U cur2{static_cast<unsigned>(cur) >> 16};
							cur >>= 24;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}else{// 32-bit, not in reverse order
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *p{input[i]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							cur >>= 24;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						do{
							V *pa{input[i]};
							V *pb{input[i - 1]};
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							output[i] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							output[i - 1] = pb;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
							}
							U cur0a{cura & 0xFFu};
							U cur1a{cura >> 8};
							U cur2a{cura >> 16};
							cura >>= 24;
							U cur0b{curb & 0xFFu};
							U cur1b{curb >> 8};
							U cur2b{curb >> 16};
							curb >>= 24;
							++offsets[cur0a];
							cur1a &= 0xFFu;
							cur2a &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							cur1b &= 0xFFu;
							cur2b &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1a)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2a)];
							++offsets[3 * 256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(cur1b)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2b)];
							++offsets[3 * 256 + static_cast<std::size_t>(curb)];
							i -= 2;
						}while(0 < i);
						if(!(1 & i)){// fill in the final item for odd counts
							V *p{input[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[0] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{static_cast<unsigned>(cur) >> 8};
							U cur2{static_cast<unsigned>(cur) >> 16};
							cur >>= 24;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}
			}else if constexpr(24 == CHAR_BIT * sizeof(T)){
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
				[[maybe_unused]]
#endif
				std::conditional_t<ismultithreadcapable, std::ptrdiff_t, std::nullptr_t> stride;
				if constexpr(ismultithreadcapable){
					stride = -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 3) / 6) * 3;
					i -= stride;
				}
				if constexpr(isrevorder){// also reverse the array at the same time
					V *const *pinput{input};
					if constexpr(ismultithreadcapable) pinput += stride;
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *p{pinput[0]};
							++pinput;
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							cur >>= 16;
							++offsets[cur0];
							cur1 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						i -= 2;
						if(0 <= i)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
							[[likely]]
#endif
							do{
							V *pa{pinput[0]};
							V *pb{pinput[1]};
							V *pc{pinput[2]};
							pinput += 3;
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							output[i + 3] = pa;
							buffer[i + 3] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							output[i + 2] = pb;
							buffer[i + 2] = pb;
							auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
							output[i + 1] = pc;
							buffer[i + 1] = pc;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc);
							}
							U cur0a{cura & 0xFFu};
							U cur1a{cura >> 8};
							cura >>= 16;
							U cur0b{curb & 0xFFu};
							U cur1b{curb >> 8};
							curb >>= 16;
							U cur0c{curc & 0xFFu};
							U cur1c{curc >> 8};
							curc >>= 16;
							++offsets[cur0a];
							cur1a &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							cur1b &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[cur0c];
							cur1c &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1a)];
							++offsets[2 * 256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(cur1b)];
							++offsets[2 * 256 + static_cast<std::size_t>(curb)];
							++offsets[256 + static_cast<std::size_t>(cur1c)];
							++offsets[2 * 256 + static_cast<std::size_t>(curc)];
							i -= 3;
						}while(0 <= i);
						if(2 & i){
							V *pa{pinput[0]};
							V *pb{pinput[1]};
							pinput += 2;
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							output[i + 3] = pa;
							buffer[i + 3] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							output[i + 2] = pb;
							buffer[i + 2] = pb;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
							}
							U cur0a{cura & 0xFFu};
							U cur1a{cura >> 8};
							cura >>= 16;
							U cur0b{curb & 0xFFu};
							U cur1b{curb >> 8};
							curb >>= 16;
							++offsets[cur0a];
							cur1a &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							cur1b &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1a)];
							++offsets[2 * 256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(cur1b)];
							++offsets[2 * 256 + static_cast<std::size_t>(curb)];
						}
						if(1 & i){// fill in the final item for odd counts
							V *p{pinput[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[0] = p;
							buffer[0] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{static_cast<unsigned>(cur) >> 8};
							cur >>= 16;
							++offsets[cur0];
							cur1 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}else{// 24-bit, not in reverse order
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *p{input[i]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							cur >>= 16;
							++offsets[cur0];
							cur1 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						i -= 2;
						if(0 <= i)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
							[[likely]]
#endif
							do{
							V *pa{input[i + 2]};
							V *pb{input[i + 1]};
							V *pc{input[i]};
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							output[i + 2] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							output[i + 1] = pb;
							auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
							output[i] = pc;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc);
							}
							U cur0a{cura & 0xFFu};
							U cur1a{cura >> 8};
							cura >>= 16;
							U cur0b{curb & 0xFFu};
							U cur1b{curb >> 8};
							curb >>= 16;
							U cur0c{curc & 0xFFu};
							U cur1c{curc >> 8};
							curc >>= 16;
							++offsets[cur0a];
							cur1a &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							cur1b &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[cur0c];
							cur1c &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1a)];
							++offsets[2 * 256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(cur1b)];
							++offsets[2 * 256 + static_cast<std::size_t>(curb)];
							++offsets[256 + static_cast<std::size_t>(cur1c)];
							++offsets[2 * 256 + static_cast<std::size_t>(curc)];
							i -= 3;
						}while(0 <= i);
						if(2 & i){// fill in the final two items for a remainder of 2 or 3
							V *pa{input[i + 3]};
							V *pb{input[i + 2]};
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							output[i + 3] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							output[i + 2] = pb;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
							}
							U cur0a{cura & 0xFFu};
							U cur1a{cura >> 8};
							cura >>= 16;
							U cur0b{curb & 0xFFu};
							U cur1b{curb >> 8};
							curb >>= 16;
							++offsets[cur0a];
							cur1a &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							cur1b &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1a)];
							++offsets[2 * 256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(cur1b)];
							++offsets[2 * 256 + static_cast<std::size_t>(curb)];
						}
						if(1 & i){// fill in the final item for odd counts
							V *p{input[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[0] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{static_cast<unsigned>(cur) >> 8};
							cur >>= 16;
							++offsets[cur0];
							cur1 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}
			}else if constexpr(16 == CHAR_BIT * sizeof(T)){
				std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
				[[maybe_unused]]
#endif
				std::conditional_t<ismultithreadcapable, std::ptrdiff_t, std::nullptr_t> stride;
				if constexpr(ismultithreadcapable){
					stride = -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 4) >> 3) * 4;
					i -= stride;
				}
				if constexpr(isrevorder){// also reverse the array at the same time
					V *const *pinput{input};
					if constexpr(ismultithreadcapable) pinput += stride;
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *p{pinput[0]};
							++pinput;
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							cur >>= 8;
							++offsets[cur0];
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						i -= 3;
						if(0 <= i)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
							[[likely]]
#endif
							do{
							V *pa{pinput[0]};
							V *pb{pinput[1]};
							V *pc{pinput[2]};
							V *pd{pinput[3]};
							pinput += 4;
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							output[i + 3] = pa;
							buffer[i + 3] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							output[i + 2] = pb;
							buffer[i + 2] = pb;
							auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
							output[i + 1] = pc;
							buffer[i + 1] = pc;
							auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
							output[i] = pd;
							buffer[i] = pd;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
							U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
							}
							U cur0a{cura & 0xFFu};
							cura >>= 8;
							U cur0b{curb & 0xFFu};
							curb >>= 8;
							U cur0c{curc & 0xFFu};
							curc >>= 8;
							U cur0d{curd & 0xFFu};
							curd >>= 8;
							++offsets[cur0a];
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[cur0c];
							if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
							++offsets[cur0d];
							if constexpr(isabsvalue && issignmode && isfltpmode) curd &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(curb)];
							++offsets[256 + static_cast<std::size_t>(curc)];
							++offsets[256 + static_cast<std::size_t>(curd)];
							i -= 4;
						}while(0 <= i);
						if(2 & i){
							V *pa{pinput[0]};
							V *pb{pinput[1]};
							pinput += 2;
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							output[i + 3] = pa;
							buffer[i + 3] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							output[i + 2] = pb;
							buffer[i + 2] = pb;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
							}
							U cur0a{cura & 0xFFu};
							cura >>= 8;
							U cur0b{curb & 0xFFu};
							curb >>= 8;
							++offsets[cur0a];
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(curb)];
						}
						if(1 & i){// fill in the final item for odd counts
							V *p{pinput[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[0] = p;
							buffer[0] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							cur >>= 8;
							++offsets[cur0];
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur)];
						}
					}
				}else{// 16-bit, not in reverse order
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *p{input[i]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							cur >>= 8;
							++offsets[cur0];
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						i -= 3;
						if(0 <= i)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
							[[likely]]
#endif
							do{
							V *pa{input[i + 3]};
							V *pb{input[i + 2]};
							V *pc{input[i + 1]};
							V *pd{input[i]};
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							output[i + 3] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							output[i + 2] = pb;
							auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
							output[i + 1] = pc;
							auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
							output[i] = pd;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
							U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
							}
							U cur0a{cura & 0xFFu};
							cura >>= 8;
							U cur0b{curb & 0xFFu};
							curb >>= 8;
							U cur0c{curc & 0xFFu};
							curc >>= 8;
							U cur0d{curd & 0xFFu};
							curd >>= 8;
							++offsets[cur0a];
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[cur0c];
							if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
							++offsets[cur0d];
							if constexpr(isabsvalue && issignmode && isfltpmode) curd &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(curb)];
							++offsets[256 + static_cast<std::size_t>(curc)];
							++offsets[256 + static_cast<std::size_t>(curd)];
							i -= 4;
						}while(0 <= i);
						if(2 & i){// fill in the final two items for a remainder of 2 or 3
							V *pa{input[i + 3]};
							V *pb{input[i + 2]};
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							output[i + 3] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							output[i + 2] = pb;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
							}
							U cur0a{cura & 0xFFu};
							cura >>= 8;
							U cur0b{curb & 0xFFu};
							curb >>= 8;
							++offsets[cur0a];
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(curb)];
						}
						if(1 & i){// fill in the final item for odd counts
							V *p{input[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							output[0] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							cur >>= 8;
							++offsets[cur0];
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur)];
						}
					}
				}
			}else static_assert(false, "Implementing larger types will require additional work and optimisation for this library.");

			// barrier and pointer exchange with the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			std::conditional_t<ismultithreadcapable, X *, std::nullptr_t> offsetscompanion;
			if constexpr(ismultithreadcapable){
				std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsets) & -static_cast<std::intptr_t>(usemultithread))};
				// detect exceptions
				if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
					if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the companion thread produced an exception
				}
				// simply do not spin if usemultithread is zero
				if(usemultithread > other){
					do{
						spinpause();
						other = atomiclightbarrier.load(std::memory_order_relaxed);
					}while(reinterpret_cast<std::uintptr_t>(offsets) == other);
					// detect exceptions
					if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
						if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the companion thread produced an exception
					}
					// reset the barrier after use, only one thread will do this
					// no busy-wait dependency on this store, hence relaxed memory order is fine
					reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
					// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
				}
				// this will just be zero if usemultithread is zero
				offsetscompanion = reinterpret_cast<X *>(other);// retrieve the pointer
			}else offsetscompanion = nullptr;

			// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
			auto[runsteps, paritybool]{generateoffsetsmulti<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, offsets, offsetscompanion, usemultithread)};

			// barrier and (flipped bits) runsteps, paritybool value exchange with the companion thread
			// no exception detection required here
			if constexpr(ismultithreadcapable){
				// paritybool is either 0 or 1 here, so we can pack it together with runsteps and add usemultithread on top
				std::uintptr_t compound{static_cast<std::uintptr_t>(runsteps) * 2 + static_cast<std::uintptr_t>(paritybool) + static_cast<std::uintptr_t>(usemultithread)};
				while(reinterpret_cast<std::uintptr_t>(offsets) == atomiclightbarrier.load(std::memory_order_relaxed)){
					spinpause();// catch up
				}
				std::uintptr_t other{atomiclightbarrier.fetch_add(compound & -static_cast<std::intptr_t>(usemultithread))};
				// simply do not spin if usemultithread is zero
				if(usemultithread > other){
					do{
						spinpause();
						other = atomiclightbarrier.load(std::memory_order_relaxed) - compound;
					}while(!other);
					// reset the barrier after use, only one thread will do this
					// no busy-wait dependency on this store, hence relaxed memory order is fine
					reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
					// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
				}
				other += compound;// combine
				unsigned lowercarryoutbits{2 * usemultithread + paritybool};
				paritybool = static_cast<unsigned>(other) & 1;// piece together the parity from both threads
				other -= lowercarryoutbits;// this will remove possiby two bits of carry-out before the next right shift
				runsteps = static_cast<unsigned>(other >> 1);// this can shift out a 0 or a 1 bit here, depending on the leftovers of parity
			}

			// perform the bidirectional 8-bit sorting sequence
			// flip the relevant bits inside runsteps first
			if(runsteps ^= (1u << CHAR_BIT * sizeof(T) / 8) - 1)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
				[[likely]]
#endif
			{
				V **pdst{buffer}, **pdstnext{output};// for the next iteration
				if(paritybool){// swap if the count of sorting actions to do is odd
					pdst = output;
					pdstnext = buffer;
				}
				radixsortnoallocmulti2threadmain<indirection1, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, ismultithreadcapable, V, X>(count, input, pdst, pdstnext, offsets, runsteps, usemultithread, atomiclightbarrier, varparameters...);
			}
		}
	}else if(0 == static_cast<std::ptrdiff_t>(count)) *output = *input;// copy the single element if the count is 1
}

// multi-threading companion for the radixsortnoallocmulti2thread() function implementation template for multi-part types with indirection
// Do not use this function directly.
template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename X, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	64 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortnoallocmulti2threadmtc(std::size_t count, V *input[], V *buffer[], std::atomic_uintptr_t &atomiclightbarrier, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>;
	// do not pass a nullptr here
	assert(input);
	assert(buffer);
	static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	X offsetscompanion[offsetsstride]{};// a sizeable amount of indices, but it's worth it, zeroed in advance here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
	[[maybe_unused]]
#endif
	std::conditional_t<std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>,
		std::atomic_uintptr_t &,// nothrow capable indirection1, let the compiler just discard this reference
		atomicvarwrapper> atomicguard{atomiclightbarrier};// may throw, so set up the guard
	radixsortnoallocmulti2threadinitmtc<indirection1, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, false, V, X>(count, input, buffer, nullptr, offsetscompanion, varparameters...);

	X *offsets;
	{// barrier and pointer exchange with the main thread
		std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsetscompanion))};
		// detect exceptions
		if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
			if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the main thread produced an exception
		}
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed);
			}while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == other);
			// detect exceptions
			if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
				if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the main thread produced an exception
			}
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		offsets = reinterpret_cast<X *>(other);// retrieve the pointer
	}

	// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
	auto[runsteps, paritybool]{generateoffsetsmultimtc<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, offsets, offsetscompanion)};

	{// barrier and (flipped bits) runsteps, paritybool value exchange with the main thread
		// no exception detection required here
		// paritybool is either 0 or 1 here, so we can pack it together with runsteps and add usemultithread on top
		std::uintptr_t compound{static_cast<std::uintptr_t>(runsteps) * 2 + static_cast<std::uintptr_t>(paritybool) + 1};
		while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == atomiclightbarrier.load(std::memory_order_relaxed)){
			spinpause();// catch up
		}
		std::uintptr_t other{atomiclightbarrier.fetch_add(compound)};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed) - compound;
			}while(!other);
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		other += compound;// combine
		unsigned lowercarryoutbits{2 + paritybool};
		paritybool = static_cast<unsigned>(other) & 1;// piece together the parity from both threads
		other -= lowercarryoutbits;// this will remove possiby two bits of carry-out before the next right shift
		runsteps = static_cast<unsigned>(other >> 1);// this can shift out a 0 or a 1 bit here, depending on the leftovers of parity
	}

	// perform the bidirectional 8-bit sorting sequence
	// flip the relevant bits inside runsteps first
	if(runsteps ^= (1u << CHAR_BIT * sizeof(T) / 8) - 1)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
		[[likely]]
#endif
	{// perform the bidirectional 8-bit sorting sequence
		V **psrclo{input}, **pdst{buffer};
		if(paritybool){// swap if the count of sorting actions to do is odd
			psrclo = buffer;
			pdst = input;
		}
		radixsortnoallocmulti2threadmainmtc<indirection1, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X>(count, psrclo, pdst, psrclo, offsetscompanion, runsteps, atomiclightbarrier, varparameters...);
	}
}

// radixsortnoalloc() function implementation template for multi-part types with indirection
template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename X
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	, bool ismultithreadcapable = true
#endif
	, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	64 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	radixsortnoallocmulti1thread
#else
	radixsortnoallocmulti2thread
#endif
	(std::size_t count, V *input[], V *buffer[], bool movetobuffer = false, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	static bool constexpr ismultithreadcapable{false};
#endif
	if constexpr(ismultithreadcapable){
		assert(1 < std::thread::hardware_concurrency());// only use multi-threading if there is more than one hardware thread
		assert(15 <= count);// a 0 or 1 count array is only allowed here in single-threaded function mode
	}
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(buffer);
	// All the code in this function is adapted for count to be one below its input value here.
	--count;
	if(ismultithreadcapable || 0 < static_cast<std::ptrdiff_t>(count)){// a 0 or 1 count array is only allowed here in single-threaded function mode
		static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
		// conditionally enable multi-threading here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t, std::nullptr_t> atomiclightbarrier{};
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::future<void>, std::nullptr_t> asynchandle;

		// count the 256 configurations, all in one go
		if constexpr(ismultithreadcapable){
			try{
				asynchandle = std::async(std::launch::async, radixsortnoallocmulti2threadmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X, vararguments...>, count, input, buffer, std::ref(atomiclightbarrier), varparameters...);
				usemultithread = 1;
			}catch(...){// std::async may fail gracefully here
				assert(false);
			}
		}
		X offsets[offsetsstride * (2 - ismultithreadcapable)];// a sizeable amount of indices, but it's worth it
		std::memset(offsets, 0, offsetsstride * sizeof(X));// zeroed in advance here
		{// scope atomicguard, so it's always destructed before asynchandle
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			std::conditional_t<ismultithreadcapable,
				std::conditional_t<std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>,
					std::atomic_uintptr_t &,// nothrow capable indirection1, let the compiler just discard this reference
					atomicvarwrapper>,// may throw, so set up the guard
				std::nullptr_t> atomicguard{atomiclightbarrier};
			if constexpr(64 == CHAR_BIT * sizeof(T)){
				if constexpr(isrevorder){// also reverse the array at the same time
					V **pinputlo, **pinputhi, **pbufferlo, **pbufferhi;
					if constexpr(!ismultithreadcapable){
						pinputlo = input;
						pinputhi = input + count;
						pbufferlo = buffer;
						pbufferhi = buffer + count;
					}else{// if mulitithreaded, the half count will be rounded up in the companion thread
						std::ptrdiff_t stride{-static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2)};
						pinputlo = input + stride;
						pinputhi = input + (count - stride);
						pbufferlo = buffer + stride;
						pbufferhi = buffer + (count - stride);
					}
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *plo{pinputlo[0]};
							V *phi{pinputhi[0]};
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							*pinputhi-- = plo;
							*pbufferhi-- = plo;
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo);
							}
							// register pressure performance issue on several platforms: first do the low half here
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							U curlo4{curlo >> 32};
							U curlo5{curlo >> 40};
							U curlo6{curlo >> 48};
							curlo >>= 56;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							curlo4 &= 0xFFu;
							curlo5 &= 0xFFu;
							curlo6 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curlo5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curlo6)];
							++offsets[7 * 256 + static_cast<std::size_t>(curlo)];
							// register pressure performance issue on several platforms: do the high half here second
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							*pinputlo++ = phi;
							*pbufferlo++ = phi;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi);
							}
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							U curhi4{curhi >> 32};
							U curhi5{curhi >> 40};
							U curhi6{curhi >> 48};
							curhi >>= 56;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							curhi4 &= 0xFFu;
							curhi5 &= 0xFFu;
							curhi6 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curhi5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curhi6)];
							++offsets[7 * 256 + static_cast<std::size_t>(curhi)];
						}while(pinputlo < pinputhi);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						do{
							V *plo{pinputlo[0]};
							V *phi{pinputhi[0]};
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							*pinputhi-- = plo;
							*pbufferhi-- = plo;
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							*pinputlo++ = phi;
							*pbufferlo++ = phi;
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo, curhi);
							}
							// register pressure performance issue on several platforms: first do the low half here
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							U curlo4{curlo >> 32};
							U curlo5{curlo >> 40};
							U curlo6{curlo >> 48};
							curlo >>= 56;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							curlo4 &= 0xFFu;
							curlo5 &= 0xFFu;
							curlo6 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curlo5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curlo6)];
							++offsets[7 * 256 + static_cast<std::size_t>(curlo)];
							// register pressure performance issue on several platforms: do the high half here second
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							U curhi4{curhi >> 32};
							U curhi5{curhi >> 40};
							U curhi6{curhi >> 48};
							curhi >>= 56;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							curhi4 &= 0xFFu;
							curhi5 &= 0xFFu;
							curhi6 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curhi5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curhi6)];
							++offsets[7 * 256 + static_cast<std::size_t>(curhi)];
						}while(pinputlo < pinputhi);
					}
					if(pinputlo == pinputhi){// fill in the final item for odd counts
						V *p{pinputlo[0]};
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						// no write to input, as this is the midpoint
						*pbufferhi = p;
						U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						U cur5{cur >> 40};
						U cur6{cur >> 48};
						cur >>= 56;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						cur5 &= 0xFFu;
						cur6 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
						++offsets[6 * 256 + static_cast<std::size_t>(cur6)];
						++offsets[7 * 256 + static_cast<std::size_t>(cur)];
					}
				}else{// 64-bit, not in reverse order
					std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
						do{
							V *p{input[i]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							U cur5{cur >> 40};
							U cur6{cur >> 48};
							cur >>= 56;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							cur5 &= 0xFFu;
							cur6 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
							++offsets[6 * 256 + static_cast<std::size_t>(cur6)];
							++offsets[7 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
						do{
							V *phi{input[i]};
							V *plo{input[i - 1]};
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							buffer[i] = phi;
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							buffer[i - 1] = plo;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
							}
							// register pressure performance issue on several platforms: first do the high half here
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							U curhi4{curhi >> 32};
							U curhi5{curhi >> 40};
							U curhi6{curhi >> 48};
							curhi >>= 56;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							curhi4 &= 0xFFu;
							curhi5 &= 0xFFu;
							curhi6 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curhi5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curhi6)];
							++offsets[7 * 256 + static_cast<std::size_t>(curhi)];
							// register pressure performance issue on several platforms: do the low half here second
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							U curlo4{curlo >> 32};
							U curlo5{curlo >> 40};
							U curlo6{curlo >> 48};
							curlo >>= 56;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							curlo4 &= 0xFFu;
							curlo5 &= 0xFFu;
							curlo6 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curlo5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curlo6)];
							++offsets[7 * 256 + static_cast<std::size_t>(curlo)];
							i -= 2;
						}while(0 < i);
						if(!(1 & i)){// fill in the final item for odd counts
							V *p{input[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							buffer[0] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							U cur5{cur >> 40};
							U cur6{cur >> 48};
							cur >>= 56;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							cur5 &= 0xFFu;
							cur6 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
							++offsets[6 * 256 + static_cast<std::size_t>(cur6)];
							++offsets[7 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}
			}else if constexpr(56 == CHAR_BIT * sizeof(T)){
				if constexpr(isrevorder){// also reverse the array at the same time
					V **pinputlo, **pinputhi, **pbufferlo, **pbufferhi;
					if constexpr(!ismultithreadcapable){
						pinputlo = input;
						pinputhi = input + count;
						pbufferlo = buffer;
						pbufferhi = buffer + count;
					}else{// if mulitithreaded, the half count will be rounded up in the companion thread
						std::ptrdiff_t stride{-static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2)};
						pinputlo = input + stride;
						pinputhi = input + (count - stride);
						pbufferlo = buffer + stride;
						pbufferhi = buffer + (count - stride);
					}
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *plo{pinputlo[0]};
							V *phi{pinputhi[0]};
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							*pinputhi-- = plo;
							*pbufferhi-- = plo;
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo);
							}
							// register pressure performance issue on several platforms: first do the low half here
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							U curlo4{curlo >> 32};
							U curlo5{curlo >> 40};
							curlo >>= 48;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							curlo4 &= 0xFFu;
							curlo5 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curlo5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curlo)];
							// register pressure performance issue on several platforms: do the high half here second
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							*pinputlo++ = phi;
							*pbufferlo++ = phi;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi);
							}
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							U curhi4{curhi >> 32};
							U curhi5{curhi >> 40};
							curhi >>= 48;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							curhi4 &= 0xFFu;
							curhi5 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curhi5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curhi)];
						}while(pinputlo < pinputhi);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						do{
							V *plo{pinputlo[0]};
							V *phi{pinputhi[0]};
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							*pinputhi-- = plo;
							*pbufferhi-- = plo;
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							*pinputlo++ = phi;
							*pbufferlo++ = phi;
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo, curhi);
							}
							// register pressure performance issue on several platforms: first do the low half here
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							U curlo4{curlo >> 32};
							U curlo5{curlo >> 40};
							curlo >>= 48;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							curlo4 &= 0xFFu;
							curlo5 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curlo5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curlo)];
							// register pressure performance issue on several platforms: do the high half here second
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							U curhi4{curhi >> 32};
							U curhi5{curhi >> 40};
							curhi >>= 48;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							curhi4 &= 0xFFu;
							curhi5 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curhi5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curhi)];
						}while(pinputlo < pinputhi);
					}
					if(pinputlo == pinputhi){// fill in the final item for odd counts
						V *p{pinputlo[0]};
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						// no write to input, as this is the midpoint
						*pbufferhi = p;
						U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						U cur5{cur >> 40};
						cur >>= 48;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						cur5 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
						++offsets[6 * 256 + static_cast<std::size_t>(cur)];
					}
				}else{// 56-bit, not in reverse order
					std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
						do{
							V *p{input[i]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							U cur5{cur >> 40};
							cur >>= 48;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							cur5 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
							++offsets[6 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
						do{
							V *phi{input[i]};
							V *plo{input[i - 1]};
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							buffer[i] = phi;
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							buffer[i - 1] = plo;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
							}
							// register pressure performance issue on several platforms: first do the high half here
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							U curhi4{curhi >> 32};
							U curhi5{curhi >> 40};
							curhi >>= 48;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							curhi4 &= 0xFFu;
							curhi5 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curhi5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curhi)];
							// register pressure performance issue on several platforms: do the low half here second
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							U curlo4{curlo >> 32};
							U curlo5{curlo >> 40};
							curlo >>= 48;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							curlo4 &= 0xFFu;
							curlo5 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curlo5)];
							++offsets[6 * 256 + static_cast<std::size_t>(curlo)];
							i -= 2;
						}while(0 < i);
						if(!(1 & i)){// fill in the final item for odd counts
							V *p{input[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							buffer[0] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, buffer);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							U cur5{cur >> 40};
							cur >>= 48;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							cur5 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur5)];
							++offsets[6 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}
			}else if constexpr(48 == CHAR_BIT * sizeof(T)){
				if constexpr(isrevorder){// also reverse the array at the same time
					V **pinputlo, **pinputhi, **pbufferlo, **pbufferhi;
					if constexpr(!ismultithreadcapable){
						pinputlo = input;
						pinputhi = input + count;
						pbufferlo = buffer;
						pbufferhi = buffer + count;
					}else{// if mulitithreaded, the half count will be rounded up in the companion thread
						std::ptrdiff_t stride{-static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2)};
						pinputlo = input + stride;
						pinputhi = input + (count - stride);
						pbufferlo = buffer + stride;
						pbufferhi = buffer + (count - stride);
					}
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *plo{pinputlo[0]};
							V *phi{pinputhi[0]};
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							*pinputhi-- = plo;
							*pbufferhi-- = plo;
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo);
							}
							// register pressure performance issue on several platforms: first do the low half here
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							U curlo4{curlo >> 32};
							curlo >>= 40;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							curlo4 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curlo)];
							// register pressure performance issue on several platforms: do the high half here second
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							*pinputlo++ = phi;
							*pbufferlo++ = phi;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi);
							}
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							U curhi4{curhi >> 32};
							curhi >>= 40;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							curhi4 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curhi)];
						}while(pinputlo < pinputhi);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						do{
							V *plo{pinputlo[0]};
							V *phi{pinputhi[0]};
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							*pinputhi-- = plo;
							*pbufferhi-- = plo;
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							*pinputlo++ = phi;
							*pbufferlo++ = phi;
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo, curhi);
							}
							// register pressure performance issue on several platforms: first do the low half here
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							U curlo4{curlo >> 32};
							curlo >>= 40;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							curlo4 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curlo)];
							// register pressure performance issue on several platforms: do the high half here second
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							U curhi4{curhi >> 32};
							curhi >>= 40;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							curhi4 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curhi)];
						}while(pinputlo < pinputhi);
					}
					if(pinputlo == pinputhi){// fill in the final item for odd counts
						U cur{pinputlo[0]};
						// no write to input, as this is the midpoint
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						U cur4{cur >> 32};
						cur >>= 40;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						cur4 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
						++offsets[5 * 256 + static_cast<std::size_t>(cur)];
					}
				}else{// 48-bit, not in reverse order
					std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
						do{
							V *p{input[i]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							cur >>= 40;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
						do{
							V *phi{input[i]};
							V *plo{input[i - 1]};
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							buffer[i] = phi;
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							buffer[i - 1] = plo;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
							}
							// register pressure performance issue on several platforms: first do the high half here
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							U curhi4{curhi >> 32};
							curhi >>= 40;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							curhi4 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curhi)];
							// register pressure performance issue on several platforms: do the low half here second
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							U curlo4{curlo >> 32};
							curlo >>= 40;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							curlo4 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo4)];
							++offsets[5 * 256 + static_cast<std::size_t>(curlo)];
							i -= 2;
						}while(0 < i);
						if(!(1 & i)){// fill in the final item for odd counts
							V *p{input[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							buffer[0] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							U cur4{cur >> 32};
							cur >>= 40;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							cur4 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur4)];
							++offsets[5 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}
			}else if constexpr(40 == CHAR_BIT * sizeof(T)){
				if constexpr(isrevorder){// also reverse the array at the same time
					V **pinputlo, **pinputhi, **pbufferlo, **pbufferhi;
					if constexpr(!ismultithreadcapable){
						pinputlo = input;
						pinputhi = input + count;
						pbufferlo = buffer;
						pbufferhi = buffer + count;
					}else{// if mulitithreaded, the half count will be rounded up in the companion thread
						std::ptrdiff_t stride{-static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2)};
						pinputlo = input + stride;
						pinputhi = input + (count - stride);
						pbufferlo = buffer + stride;
						pbufferhi = buffer + (count - stride);
					}
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *plo{pinputlo[0]};
							V *phi{pinputhi[0]};
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							*pinputhi-- = plo;
							*pbufferhi-- = plo;
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo);
							}
							// register pressure performance issue on several platforms: first do the low half here
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							curlo >>= 32;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo)];
							// register pressure performance issue on several platforms: do the high half here second
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							*pinputlo++ = phi;
							*pbufferlo++ = phi;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi);
							}
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							curhi >>= 32;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi)];
						}while(pinputlo < pinputhi);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						do{
							V *plo{pinputlo[0]};
							V *phi{pinputhi[0]};
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							*pinputhi-- = plo;
							*pbufferhi-- = plo;
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							*pinputlo++ = phi;
							*pbufferlo++ = phi;
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo, curhi);
							}
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							curlo >>= 32;
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							curhi >>= 32;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo)];
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi)];
						}while(pinputlo < pinputhi);
					}
					if(pinputlo == pinputhi){// fill in the final item for odd counts
						V *p{pinputlo[0]};
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						// no write to input, as this is the midpoint
						*pbufferhi = p;
						U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
						}
						U cur0{cur & 0xFFu};
						U cur1{cur >> 8};
						U cur2{cur >> 16};
						U cur3{cur >> 24};
						cur >>= 32;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						cur3 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
						++offsets[4 * 256 + static_cast<std::size_t>(cur)];
					}
				}else{// 40-bit, not in reverse order
					std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
						do{
							V *p{input[i]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							cur >>= 32;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
						do{
							V *phi{input[i]};
							V *plo{input[i - 1]};
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							buffer[i] = phi;
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							buffer[i - 1] = plo;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi, curlo);
							}
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							U curhi3{curhi >> 24};
							curhi >>= 32;
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							U curlo3{curlo >> 24};
							curlo >>= 32;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							curhi3 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							curlo3 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curhi)];
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo3)];
							++offsets[4 * 256 + static_cast<std::size_t>(curlo)];
							i -= 2;
						}while(0 < i);
						if(!(1 & i)){// fill in the final item for odd counts
							V *p{input[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							buffer[0] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							U cur3{cur >> 24};
							cur >>= 32;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							cur3 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur3)];
							++offsets[4 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}
			}else if constexpr(32 == CHAR_BIT * sizeof(T)){
				if constexpr(isrevorder){// also reverse the array at the same time
					V **pinputlo, **pinputhi, **pbufferlo, **pbufferhi;
					if constexpr(!ismultithreadcapable){
						pinputlo = input;
						pinputhi = input + count;
						pbufferlo = buffer;
						pbufferhi = buffer + count;
					}else{// if mulitithreaded, the half count will be rounded up in the companion thread
						std::ptrdiff_t stride{-static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2)};
						pinputlo = input + stride;
						pinputhi = input + (count - stride);
						pbufferlo = buffer + stride;
						pbufferhi = buffer + (count - stride);
					}
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *plo{pinputlo[0]};
							V *phi{pinputhi[0]};
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							*pinputhi-- = plo;
							*pbufferhi-- = plo;
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo);
							}
							// register pressure performance issue on several platforms: first do the low half here
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							U curlo2{curlo >> 16};
							curlo >>= 24;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							curlo2 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curlo)];
							// register pressure performance issue on several platforms: do the high half here second
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							*pinputlo++ = phi;
							*pbufferlo++ = phi;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi);
							}
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							U curhi2{curhi >> 16};
							curhi >>= 24;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							curhi2 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi2)];
							++offsets[3 * 256 + static_cast<std::size_t>(curhi)];
						}while(pinputlo < pinputhi);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						do{
							V *pa{pinputlo[0]};
							V *pb{pinputhi[0]};
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							*pinputhi-- = pa;
							*pbufferhi-- = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							*pinputlo++ = pb;
							*pbufferlo++ = pb;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
							}
							U cur0a{cura & 0xFFu};
							U cur1a{cura >> 8};
							U cur2a{cura >> 16};
							cura >>= 24;
							U cur0b{curb & 0xFFu};
							U cur1b{curb >> 8};
							U cur2b{curb >> 16};
							curb >>= 24;
							++offsets[cur0a];
							cur1a &= 0xFFu;
							cur2a &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							cur1b &= 0xFFu;
							cur2b &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1a)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2a)];
							++offsets[3 * 256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(cur1b)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2b)];
							++offsets[3 * 256 + static_cast<std::size_t>(curb)];
						}while(pinputlo < pinputhi);
					}
					if(pinputlo == pinputhi){// fill in the final item for odd counts
						V *p{pinputlo[0]};
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						// no write to input, as this is the midpoint
						*pbufferhi = p;
						U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
						}
						U cur0{cur & 0xFFu};
						U cur1{static_cast<unsigned>(cur) >> 8};
						U cur2{static_cast<unsigned>(cur) >> 16};
						cur >>= 24;
						++offsets[cur0];
						cur1 &= 0xFFu;
						cur2 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
						++offsets[3 * 256 + static_cast<std::size_t>(cur)];
					}
				}else{// 32-bit, not in reverse order
					std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
						do{
							V *p{input[i]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							U cur2{cur >> 16};
							cur >>= 24;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
						do{
							V *pa{input[i]};
							V *pb{input[i - 1]};
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							buffer[i] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							buffer[i - 1] = pb;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
							}
							U cur0a{cura & 0xFFu};
							U cur1a{cura >> 8};
							U cur2a{cura >> 16};
							cura >>= 24;
							U cur0b{curb & 0xFFu};
							U cur1b{curb >> 8};
							U cur2b{curb >> 16};
							curb >>= 24;
							++offsets[cur0a];
							cur1a &= 0xFFu;
							cur2a &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							cur1b &= 0xFFu;
							cur2b &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1a)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2a)];
							++offsets[3 * 256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(cur1b)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2b)];
							++offsets[3 * 256 + static_cast<std::size_t>(curb)];
							i -= 2;
						}while(0 < i);
						if(!(1 & i)){// fill in the final item for odd counts
							V *p{input[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							buffer[0] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{static_cast<unsigned>(cur) >> 8};
							U cur2{static_cast<unsigned>(cur) >> 16};
							cur >>= 24;
							++offsets[cur0];
							cur1 &= 0xFFu;
							cur2 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur2)];
							++offsets[3 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}
			}else if constexpr(24 == CHAR_BIT * sizeof(T)){
				if constexpr(isrevorder){// also reverse the array at the same time
					V **pinputlo, **pinputhi, **pbufferlo, **pbufferhi;
					std::size_t initialcount;
					if constexpr(!ismultithreadcapable){
						initialcount = count + 1;
						pinputlo = input;
						pinputhi = input + count;
						pbufferlo = buffer;
						pbufferhi = buffer + count;
					}else{// if mulitithreaded, the half count will be rounded up in the companion thread
						// architecture: limit to one at a time when there's few registers
						std::ptrdiff_t stride;
						if constexpr(defaultgprfilesize < gprfilesize::large) stride = -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2);
						else stride = -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 6) / 12);
						initialcount = count - stride + 1;
						pinputlo = input + stride;
						pinputhi = input + (count - stride);
						pbufferlo = buffer + stride;
						pbufferhi = buffer + (count - stride);
					}
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *plo{pinputlo[0]};
							V *phi{pinputhi[0]};
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							*pinputhi-- = plo;
							*pbufferhi-- = plo;
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo);
							}
							// register pressure performance issue on several platforms: first do the low half here
							U curlo0{curlo & 0xFFu};
							U curlo1{curlo >> 8};
							curlo >>= 16;
							++offsets[curlo0];
							curlo1 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curlo)];
							// register pressure performance issue on several platforms: do the high half here second
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							*pinputlo++ = phi;
							*pbufferlo++ = phi;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi);
							}
							U curhi0{curhi & 0xFFu};
							U curhi1{curhi >> 8};
							curhi >>= 16;
							++offsets[curhi0];
							curhi1 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi1)];
							++offsets[2 * 256 + static_cast<std::size_t>(curhi)];
						}while(pinputlo < pinputhi);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						initialcount %= 6;
						if(4 & initialcount){// possibly initialise with 4 entries before the loop below
							V *pa{pinputlo[0]};
							V *pb{pinputhi[0]};
							V *pc{pinputlo[1]};
							V *pd{pinputhi[-1]};
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							pinputhi[0] = pa;
							pbufferhi[0] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							pinputlo[0] = pb;
							pbufferlo[0] = pb;
							auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
							pinputhi[1] = pc;
							pinputhi -= 2;
							pbufferhi[1] = pc;
							pbufferhi -= 2;
							auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
							pinputlo[-1] = pd;
							pinputlo += 2;
							pbufferlo[-1] = pd;
							pbufferlo += 2;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
							U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
							}
							U cur0a{cura & 0xFFu};
							U cur1a{cura >> 8};
							cura >>= 16;
							U cur0b{curb & 0xFFu};
							U cur1b{curb >> 8};
							curb >>= 16;
							U cur0c{curc & 0xFFu};
							U cur1c{curc >> 8};
							curc >>= 16;
							U cur0d{curd & 0xFFu};
							U cur1d{curd >> 8};
							curd >>= 16;
							++offsets[cur0a];
							cur1a &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							cur1b &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[cur0c];
							cur1c &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
							++offsets[cur0d];
							cur1d &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curd &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1a)];
							++offsets[2 * 256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(cur1b)];
							++offsets[2 * 256 + static_cast<std::size_t>(curb)];
							++offsets[256 + static_cast<std::size_t>(cur1c)];
							++offsets[2 * 256 + static_cast<std::size_t>(curc)];
							++offsets[256 + static_cast<std::size_t>(cur1d)];
							++offsets[2 * 256 + static_cast<std::size_t>(curd)];
						}else if(2 & initialcount){// possibly initialise with 2 entries before the loop below
							V *pa{pinputlo[0]};
							V *pb{pinputhi[0]};
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							*pinputhi-- = pa;
							*pbufferhi-- = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							*pinputlo++ = pb;
							*pbufferlo++ = pb;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
							}
							U cur0a{cura & 0xFFu};
							U cur1a{cura >> 8};
							cura >>= 16;
							U cur0b{curb & 0xFFu};
							U cur1b{curb >> 8};
							curb >>= 16;
							++offsets[cur0a];
							cur1a &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							cur1b &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1a)];
							++offsets[2 * 256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(cur1b)];
							++offsets[2 * 256 + static_cast<std::size_t>(curb)];
						}
						if(5 <= count)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
							[[likely]]
#endif
							do{
							V *pa{pinputlo[0]};
							V *pb{pinputhi[0]};
							V *pc{pinputlo[1]};
							V *pd{pinputhi[-1]};
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							pinputhi[0] = pa;
							pbufferhi[0] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							pinputlo[0] = pb;
							pbufferlo[0] = pb;
							auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
							pinputhi[1] = pc;
							pbufferhi[1] = pc;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
							// register pressure performance issue on several platforms: first do the high half here
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc);
							}
							U cur0a{cura & 0xFFu};
							U cur1a{cura >> 8};
							cura >>= 16;
							U cur0b{curb & 0xFFu};
							U cur1b{curb >> 8};
							curb >>= 16;
							U cur0c{curc & 0xFFu};
							U cur1c{curc >> 8};
							curc >>= 16;
							++offsets[cur0a];
							cur1a &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							cur1b &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[cur0c];
							cur1c &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1a)];
							++offsets[2 * 256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(cur1b)];
							++offsets[2 * 256 + static_cast<std::size_t>(curb)];
							++offsets[256 + static_cast<std::size_t>(cur1c)];
							++offsets[2 * 256 + static_cast<std::size_t>(curc)];
							V *pe{pinputlo[2]};
							V *pf{pinputhi[-2]};
							auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
							pinputlo[1] = pd;
							pbufferlo[1] = pd;
							auto ime{indirectinput1<indirection1, isindexed2, T, V>(pe, varparameters...)};
							pinputhi[-2] = pe;
							pinputhi -= 3;
							pbufferhi[-2] = pe;
							pbufferhi -= 3;
							auto imf{indirectinput1<indirection1, isindexed2, T, V>(pf, varparameters...)};
							pinputlo[2] = pf;
							pinputlo += 3;
							pbufferlo[2] = pf;
							pbufferlo += 3;
							U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
							U cure{indirectinput2<indirection1, indirection2, isindexed2, T>(ime, varparameters...)};
							U curf{indirectinput2<indirection1, indirection2, isindexed2, T>(ime, varparameters...)};
							// register pressure performance issue on several platforms: do the low half here second
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curd, cure, curf);
							}
							U cur0d{curd & 0xFFu};
							U cur1d{curd >> 8};
							curd >>= 16;
							U cur0e{cure & 0xFFu};
							U cur1e{cure >> 8};
							cure >>= 16;
							U cur0f{curf & 0xFFu};
							U cur1f{curf >> 8};
							curf >>= 16;
							++offsets[cur0d];
							cur1d &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curd &= 0x7Fu;
							++offsets[cur0e];
							cur1e &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cure &= 0x7Fu;
							++offsets[cur0f];
							cur1f &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curf &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1d)];
							++offsets[2 * 256 + static_cast<std::size_t>(curd)];
							++offsets[256 + static_cast<std::size_t>(cur1e)];
							++offsets[2 * 256 + static_cast<std::size_t>(cure)];
							++offsets[256 + static_cast<std::size_t>(cur1f)];
							++offsets[2 * 256 + static_cast<std::size_t>(curf)];
						}while(pinputlo < pinputhi);
					}
					if(pinputlo == pinputhi){// fill in the final item for odd counts
						V *p{pinputlo[0]};
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						// no write to input, as this is the midpoint
						*pbufferhi = p;
						U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
						}
						U cur0{cur & 0xFFu};
						U cur1{static_cast<unsigned>(cur) >> 8};
						cur >>= 16;
						++offsets[cur0];
						cur1 &= 0xFFu;
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur1)];
						++offsets[2 * 256 + static_cast<std::size_t>(cur)];
					}
				}else{// 24-bit, not in reverse order
					std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
						do{
							V *p{input[i]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{cur >> 8};
							cur >>= 16;
							++offsets[cur0];
							cur1 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 3) / 6) * 3;
						i -= 2;
						if(0 <= i)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
							[[likely]]
#endif
							do{
							V *pa{input[i + 2]};
							V *pb{input[i + 1]};
							V *pc{input[i]};
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							buffer[i + 2] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							buffer[i + 1] = pb;
							auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
							buffer[i] = pc;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc);
							}
							U cur0a{cura & 0xFFu};
							U cur1a{cura >> 8};
							cura >>= 16;
							U cur0b{curb & 0xFFu};
							U cur1b{curb >> 8};
							curb >>= 16;
							U cur0c{curc & 0xFFu};
							U cur1c{curc >> 8};
							curc >>= 16;
							++offsets[cur0a];
							cur1a &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							cur1b &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[cur0c];
							cur1c &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1a)];
							++offsets[2 * 256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(cur1b)];
							++offsets[2 * 256 + static_cast<std::size_t>(curb)];
							++offsets[256 + static_cast<std::size_t>(cur1c)];
							++offsets[2 * 256 + static_cast<std::size_t>(curc)];
							i -= 3;
						}while(0 <= i);
						if(2 & i){// fill in the final two items for a remainder of 2 or 3
							V *pa{input[i + 2]};
							V *pb{input[i + 1]};
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							buffer[i + 2] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							buffer[i + 1] = pb;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
							}
							U cur0a{cura & 0xFFu};
							U cur1a{cura >> 8};
							cura >>= 16;
							U cur0b{curb & 0xFFu};
							U cur1b{curb >> 8};
							curb >>= 16;
							++offsets[cur0a];
							cur1a &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							cur1b &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1a)];
							++offsets[2 * 256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(cur1b)];
							++offsets[2 * 256 + static_cast<std::size_t>(curb)];
						}
						if(1 & i){// fill in the final item for odd counts
							V *p{input[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							buffer[0] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							U cur1{static_cast<unsigned>(cur) >> 8};
							cur >>= 16;
							++offsets[cur0];
							cur1 &= 0xFFu;
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur1)];
							++offsets[2 * 256 + static_cast<std::size_t>(cur)];
						}
					}
				}
			}else if constexpr(16 == CHAR_BIT * sizeof(T)){
				if constexpr(isrevorder){// also reverse the array at the same time
					V **pinputlo, **pinputhi, **pbufferlo, **pbufferhi;
					if constexpr(!ismultithreadcapable){
						pinputlo = input;
						pinputhi = input + count;
						pbufferlo = buffer;
						pbufferhi = buffer + count;
					}else{// if mulitithreaded, the half count will be rounded up in the companion thread
						// architecture: limit to one at a time when there's few registers
						std::ptrdiff_t stride;
						if constexpr(defaultgprfilesize < gprfilesize::large) stride = -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2);
						else stride = -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 4) >> 3);
						pinputlo = input + stride;
						pinputhi = input + (count - stride);
						pbufferlo = buffer + stride;
						pbufferhi = buffer + (count - stride);
					}
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						do{
							V *plo{pinputlo[0]};
							V *phi{pinputhi[0]};
							auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
							*pinputhi-- = plo;
							*pbufferhi-- = plo;
							U curlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curlo);
							}
							// register pressure performance issue on several platforms: first do the low half here
							U curlo0{curlo & 0xFFu};
							curlo >>= 8;
							++offsets[curlo0];
							if constexpr(isabsvalue && issignmode && isfltpmode) curlo &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curlo)];
							// register pressure performance issue on several platforms: do the high half here second
							auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
							*pinputlo++ = phi;
							*pbufferlo++ = phi;
							U curhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(curhi);
							}
							U curhi0{curhi & 0xFFu};
							curhi >>= 8;
							++offsets[curhi0];
							if constexpr(isabsvalue && issignmode && isfltpmode) curhi &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(curhi)];
						}while(pinputlo < pinputhi);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						if(2 & count + 1){// possibly initialise with 2 entries before the loop below
							V *pa{pinputlo[0]};
							V *pb{pinputhi[0]};
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							*pinputhi-- = pa;
							*pbufferhi-- = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							*pinputlo++ = pb;
							*pbufferlo++ = pb;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
							}
							U cur0a{cura & 0xFFu};
							cura >>= 8;
							U cur0b{curb & 0xFFu};
							curb >>= 8;
							++offsets[cur0a];
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(curb)];
						}
						if(3 <= count)
	#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
							[[likely]]
	#endif
							do{
							V *pa{pinputlo[0]};
							V *pb{pinputhi[0]};
							V *pc{pinputlo[1]};
							V *pd{pinputhi[-1]};
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							pinputhi[0] = pa;
							pbufferhi[0] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							pinputlo[0] = pb;
							pbufferlo[0] = pb;
							auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
							pinputhi[-1] = pc;
							pinputhi -= 2;
							pbufferhi[-1] = pc;
							pbufferhi -= 2;
							auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
							pinputlo[1] = pd;
							pinputlo += 2;
							pbufferlo[1] = pd;
							pbufferlo += 2;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
							U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
							}
							U cur0a{cura & 0xFFu};
							cura >>= 8;
							U cur0b{curb & 0xFFu};
							curb >>= 8;
							U cur0c{curc & 0xFFu};
							curc >>= 8;
							U cur0d{curd & 0xFFu};
							curd >>= 8;
							++offsets[cur0a];
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[cur0c];
							if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
							++offsets[cur0d];
							if constexpr(isabsvalue && issignmode && isfltpmode) curd &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(curb)];
							++offsets[256 + static_cast<std::size_t>(curc)];
							++offsets[256 + static_cast<std::size_t>(curd)];
						}while(pinputlo < pinputhi);
					}
					if(pinputlo == pinputhi){// fill in the final item for odd counts
						V *p{pinputlo[0]};
						auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
						// no write to input, as this is the midpoint
						*pbufferhi = p;
						U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
						if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
						}
						U cur0{cur & 0xFFu};
						cur >>= 8;
						++offsets[cur0];
						if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
						++offsets[256 + static_cast<std::size_t>(cur)];
					}
				}else{// 16-bit, not in reverse order
					std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
					if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to one at a time when there's few registers
						if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 1) >> 1);
						do{
							V *p{input[i]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							buffer[i] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							cur >>= 8;
							++offsets[cur0];
							if constexpr(isabsvalue && issignmode && isfltpmode) cur &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cur)];
						}while(0 <= --i);
					}else{// architecture: do not limit as much when there's a reasonable amount of registers
						if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 4) >> 3) * 4;
						i -= 3;
						if(0 <= i)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
							[[likely]]
#endif
							do{
							V *pa{input[i + 3]};
							V *pb{input[i + 2]};
							V *pc{input[i + 1]};
							V *pd{input[i]};
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							buffer[i + 3] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							buffer[i + 2] = pb;
							auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
							buffer[i + 1] = pc;
							auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
							buffer[i] = pd;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
							U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
							}
							U cur0a{cura & 0xFFu};
							cura >>= 8;
							U cur0b{curb & 0xFFu};
							curb >>= 8;
							U cur0c{curc & 0xFFu};
							curc >>= 8;
							U cur0d{curd & 0xFFu};
							curd >>= 8;
							++offsets[cur0a];
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[cur0c];
							if constexpr(isabsvalue && issignmode && isfltpmode) curc &= 0x7Fu;
							++offsets[cur0d];
							if constexpr(isabsvalue && issignmode && isfltpmode) curd &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(curb)];
							++offsets[256 + static_cast<std::size_t>(curc)];
							++offsets[256 + static_cast<std::size_t>(curd)];
							i -= 4;
						}while(0 <= i);
						if(2 & i){// fill in the final two items for a remainder of 2 or 3
							V *pa{input[i + 3]};
							V *pb{input[i + 2]};
							auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
							buffer[i + 3] = pa;
							auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
							buffer[i + 2] = pb;
							U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
							U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
							}
							U cur0a{cura & 0xFFu};
							cura >>= 8;
							U cur0b{curb & 0xFFu};
							curb >>= 8;
							++offsets[cur0a];
							if constexpr(isabsvalue && issignmode && isfltpmode) cura &= 0x7Fu;
							++offsets[cur0b];
							if constexpr(isabsvalue && issignmode && isfltpmode) curb &= 0x7Fu;
							++offsets[256 + static_cast<std::size_t>(cura)];
							++offsets[256 + static_cast<std::size_t>(curb)];
						}
						if(1 & i){// fill in the final item for odd counts
							V *p{input[0]};
							auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
							buffer[0] = p;
							U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
							if constexpr(isabsvalue != isfltpmode || isabsvalue && !issignmode){
								filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
							}
							U cur0{cur & 0xFFu};
							cur >>= 8;
							++offsets[cur0];
							++offsets[256 + static_cast<std::size_t>(cur)];
						}
					}
				}
			}else static_assert(false, "Implementing larger types will require additional work and optimisation for this library.");

			// barrier and pointer exchange with the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			std::conditional_t<ismultithreadcapable, X *, std::nullptr_t> offsetscompanion;
			if constexpr(ismultithreadcapable){
				std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsets) & -static_cast<std::intptr_t>(usemultithread))};
				// detect exceptions
				if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
					if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the companion thread produced an exception
				}
				// simply do not spin if usemultithread is zero
				if(usemultithread > other){
					do{
						spinpause();
						other = atomiclightbarrier.load(std::memory_order_relaxed);
					}while(reinterpret_cast<std::uintptr_t>(offsets) == other);
					// detect exceptions
					if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
						if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the companion thread produced an exception
					}
					// reset the barrier after use, only one thread will do this
					// no busy-wait dependency on this store, hence relaxed memory order is fine
					reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
					// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
				}
				// this will just be zero if usemultithread is zero
				offsetscompanion = reinterpret_cast<X *>(other);// retrieve the pointer
			}else offsetscompanion = nullptr;

			// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
			auto[runsteps, paritybool]{generateoffsetsmulti<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, offsets, offsetscompanion, usemultithread, movetobuffer)};

			// barrier and (flipped bits) runsteps, paritybool value exchange with the companion thread
			// no exception detection required here
			if constexpr(ismultithreadcapable){
				// paritybool is either 0 or 1 here, so we can pack it together with runsteps and add usemultithread on top
				std::uintptr_t compound{static_cast<std::uintptr_t>(runsteps) * 2 + static_cast<std::uintptr_t>(paritybool) + static_cast<std::uintptr_t>(usemultithread)};
				while(reinterpret_cast<std::uintptr_t>(offsets) == atomiclightbarrier.load(std::memory_order_relaxed)){
					spinpause();// catch up
				}
				std::uintptr_t other{atomiclightbarrier.fetch_add(compound & -static_cast<std::intptr_t>(usemultithread))};
				// simply do not spin if usemultithread is zero
				if(usemultithread > other){
					do{
						spinpause();
						other = atomiclightbarrier.load(std::memory_order_relaxed) - compound;
					}while(!other);
					// reset the barrier after use, only one thread will do this
					// no busy-wait dependency on this store, hence relaxed memory order is fine
					reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
					// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
				}
				other += compound;// combine
				unsigned lowercarryoutbits{2 * usemultithread + paritybool};
				paritybool = static_cast<unsigned>(other) & 1;// piece together the parity from both threads
				other -= lowercarryoutbits;// this will remove possiby two bits of carry-out before the next right shift
				runsteps = static_cast<unsigned>(other >> 1);// this can shift out a 0 or a 1 bit here, depending on the leftovers of parity
			}

			// perform the bidirectional 8-bit sorting sequence
			// flip the relevant bits inside runsteps first
			if(runsteps ^= (1u << CHAR_BIT * sizeof(T) / 8) - 1)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
				[[likely]]
#endif
			{
				V **psrclo{input}, **pdst{buffer};
				if(paritybool){// swap if the count of sorting actions to do is odd
					psrclo = buffer;
					pdst = input;
				}
				radixsortnoallocmulti2threadmain<indirection1, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, ismultithreadcapable, V, X>(count, psrclo, pdst, psrclo, offsets, runsteps, usemultithread, atomiclightbarrier, varparameters...);
			}
		}
	}else if(0 == static_cast<std::ptrdiff_t>(count)) *buffer = *input;// copy the single element if the count is 1
}

// Function implementation templates for single-part types

// initialisation part, multi-threading companion for the radixsortcopynoallocsingle() and radixsortnoallocsingle() function implementation templates for single-part types without indirection
// Do not use this function directly.
template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T) &&
	((isabsvalue && issignmode) ||// both regular absolute modes
	(!isabsvalue && issignmode && isfltpmode)),// regular floating-point mode
	void> radixsortnoallocsingleinitmtc(std::size_t count, T const input[], T pout[], X offsetscompanion[])noexcept{
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
	assert(3 <= count);// this function is not for small arrays, 4 is the minimum original array count
	// do not pass a nullptr here
	assert(input);
	assert(pout);
	assert(offsetscompanion);
	// unsigned counter, not zero inclusive inside the loop
	// architecture: limit to two at a time when there's few registers
	std::size_t i{(defaultgprfilesize < gprfilesize::large)? ((count + 1 + 2) >> 2) * 2 : ((count + 1 + 8) >> 4) * 8};// rounded up in the companion thread
	input += count - i;
	pout += count - i;
	if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
		do{
			U cura{input[i]};
			U curb{input[i - 1]};
			if constexpr(isabsvalue != isfltpmode){// two-register filters only
				// register pressure performance issue on several platforms: first do the high half here
				filterinput<isabsvalue, issignmode, isfltpmode, T>(
					cura, pout + i,
					curb, pout + i - 1);
			}else{
				pout[i] = static_cast<T>(cura);
				pout[i - 1] = static_cast<T>(curb);
				if constexpr(isabsvalue && isfltpmode){// one-register filters only
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
				}
			}
			++offsetscompanion[cura];
			++offsetscompanion[curb];
		}while(i -= 2);
	}else{// architecture: do not limit as much when there's a reasonable amount of registers
		do{
			U cura{input[i]};
			U curb{input[i - 1]};
			U curc{input[i - 2]};
			U curd{input[i - 3]};
			if constexpr(isabsvalue != isfltpmode){// two-register filters only
				// register pressure performance issue on several platforms: first do the high half here
				filterinput<isabsvalue, issignmode, isfltpmode, T>(
					cura, pout + i,
					curb, pout + i - 1,
					curc, pout + i - 2,
					curd, pout + i - 3);
				++offsetscompanion[cura];
				++offsetscompanion[curb];
				++offsetscompanion[curc];
				++offsetscompanion[curd];
			}
			U cure{input[i - 4]};
			U curf{input[i - 5]};
			U curg{input[i - 6]};
			U curh{input[i - 7]};
			if constexpr(isabsvalue != isfltpmode){// two-register filters only
				// register pressure performance issue on several platforms: do the low half here second
				filterinput<isabsvalue, issignmode, isfltpmode, T>(
					cure, pout + i - 4,
					curf, pout + i - 5,
					curg, pout + i - 6,
					curh, pout + i - 7);
				++offsetscompanion[cure];
				++offsetscompanion[curf];
				++offsetscompanion[curg];
				++offsetscompanion[curh];
			}else{
				pout[i] = static_cast<T>(cura);
				pout[i - 1] = static_cast<T>(curb);
				pout[i - 2] = static_cast<T>(curc);
				pout[i - 3] = static_cast<T>(curd);
				pout[i - 4] = static_cast<T>(cure);
				pout[i - 5] = static_cast<T>(curf);
				pout[i - 6] = static_cast<T>(curg);
				pout[i - 7] = static_cast<T>(curh);
				if constexpr(isabsvalue && isfltpmode){// one-register filters only
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd, cure, curf, curg, curh);
				}
				++offsetscompanion[cura];
				++offsetscompanion[curb];
				++offsetscompanion[curc];
				++offsetscompanion[curd];
				++offsetscompanion[cure];
				++offsetscompanion[curf];
				++offsetscompanion[curg];
				++offsetscompanion[curh];
			}
		}while(i -= 8);
	}
}

// initialisation part, multi-threading companion for the radixsortcopynoallocsingle() and radixsortnoallocsingle() function implementation templates for single-part types without indirection
// Do not use this function directly.
template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T) &&
	!(isabsvalue && issignmode) &&// both regular absolute modes
	!(!isabsvalue && issignmode && isfltpmode),// regular floating-point mode
	void> radixsortnoallocsingleinitmtc(std::size_t count, T const input[], X offsetscompanion[])noexcept{
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
	assert(3 <= count);// this function is not for small arrays, 4 is the minimum original array count
	// do not pass a nullptr here
	assert(input);
	assert(offsetscompanion);
	// unsigned counter, not zero inclusive inside the loop
	std::size_t i{((count + 1 + 8) >> 4) * 8};// rounded up in the companion thread
	input += count - i;
	do{
		U cura{input[i]};
		U curb{input[i - 1]};
		U curc{input[i - 2]};
		U curd{input[i - 3]};
		if constexpr(isabsvalue != isfltpmode){// two-register filters only
			// register pressure performance issue on several platforms: first do the high half here
			filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
			++offsetscompanion[cura];
			++offsetscompanion[curb];
			++offsetscompanion[curc];
			++offsetscompanion[curd];
		}
		U cure{input[i - 4]};
		U curf{input[i - 5]};
		U curg{input[i - 6]};
		U curh{input[i - 7]};
		if constexpr(isabsvalue != isfltpmode){// two-register filters only
			// register pressure performance issue on several platforms: do the low half here second
			filterinput<isabsvalue, issignmode, isfltpmode, T>(cure, curf, curg, curh);
		}else{
			if constexpr(isabsvalue && isfltpmode){// one-register filters only
				filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd, cure, curf, curg, curh);
			}
			++offsetscompanion[cura];
			++offsetscompanion[curb];
			++offsetscompanion[curc];
			++offsetscompanion[curd];
		}
		++offsetscompanion[cure];
		++offsetscompanion[curf];
		++offsetscompanion[curg];
		++offsetscompanion[curh];
	}while(i -= 8);
}

// main part, multi-threading companion for the radixsortcopynoallocsingle() and radixsortnoallocsingle() function implementation templates for single-part types without indirection
// Do not use this function directly.
template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T) &&
	((isabsvalue && issignmode) ||	// both regular absolute modes
	(!isabsvalue && issignmode && isfltpmode)),// regular floating-point mode
	void> radixsortnoallocsinglemainmtc(std::size_t count, T const psrclo[], T pdst[], X offsetscompanion[])noexcept{
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
	assert(3 <= count);// this function is not for small arrays, 4 is the minimum original array count
	// do not pass a nullptr here
	assert(psrclo);
	assert(pdst);
	assert(offsetscompanion);
	T const *psrchi{psrclo + count};
	if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
		std::size_t j{(count + 1 + 2) >> 2};// rounded up in the top part
		do{// fill the array, two at a time
			U outa{psrchi[0]};
			U outb{psrchi[-1]};
			psrchi -= 2;
			auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb)};
			std::size_t offseta, offsetb;// this is only allowed for the single-part version, containing just one sorting pass
			if constexpr(false){// useless if not using indirection: isrevorder){
				offseta = offsetscompanion[cura]++;// the next item will be placed one higher
				offsetb = offsetscompanion[curb]++;
			}else{
				offseta = offsetscompanion[cura]--;// the next item will be placed one lower
				offsetb = offsetscompanion[curb]--;
			}
			pdst[offseta] = static_cast<T>(outa);
			pdst[offsetb] = static_cast<T>(outb);
		}while(--j);
	}else{// architecture: limit to four at a time when there's a decent amount of registers
		std::size_t j{(count + 1 + 4) >> 3};// rounded up in the top part
		do{// fill the array, four at a time
			U outa{psrchi[0]};
			U outb{psrchi[-1]};
			U outc{psrchi[-2]};
			U outd{psrchi[-3]};
			psrchi -= 4;
			auto[cura, curb, curc, curd]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd)};
			std::size_t offseta, offsetb, offsetc, offsetd;// this is only allowed for the single-part version, containing just one sorting pass
			if constexpr(false){// useless if not using indirection: isrevorder){
				offseta = offsetscompanion[cura]++;// the next item will be placed one higher
				offsetb = offsetscompanion[curb]++;
				offsetc = offsetscompanion[curc]++;
				offsetd = offsetscompanion[curd]++;
			}else{
				offseta = offsetscompanion[cura]--;// the next item will be placed one lower
				offsetb = offsetscompanion[curb]--;
				offsetc = offsetscompanion[curc]--;
				offsetd = offsetscompanion[curd]--;
			}
			pdst[offseta] = static_cast<T>(outa);
			pdst[offsetb] = static_cast<T>(outb);
			pdst[offsetc] = static_cast<T>(outc);
			pdst[offsetd] = static_cast<T>(outd);
		}while(--j);
	}
}

// main part, multi-threading companion for the radixsortcopynoallocsingle() and radixsortnoallocsingle() function implementation templates for single-part types without indirection
// Do not use this function directly.
template<bool isdescsort, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T) &&
	!(isabsvalue && issignmode) &&// both regular absolute modes
	!(!isabsvalue && issignmode && isfltpmode),// regular floating-point mode
	void> radixsortnoallocsinglemainmtc(std::size_t count, T pdst[], X const offsets[], X const offsetscompanion[])noexcept{
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
	assert(3 <= count);// this function is not for small arrays, 4 is the minimum original array count
	// do not pass a nullptr here
	assert(pdst);
	assert(offsets);
	assert(offsetscompanion);
	// the code here is mainly copied from generateoffsetssinglemtc()
	// isdescsort is frequently optimised away in this part, e.g.: isdescsort * 2 - 1 generates 1 or -1
	// Determining the starting point depends on several factors here.
	static std::size_t constexpr offsetsstride{8 * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	X const *t{offsets + (offsetsstride - 1)// high-to-low or low-to-high
		- (!isabsvalue && issignmode) * (offsetsstride / 2 - isdescsort)
		- (isdescsort && (isabsvalue || !issignmode)) * (offsetsstride - 1)
		- (isabsvalue && !issignmode && isfltpmode) * (1 - isdescsort * 2)};
	X const *u{offsetscompanion + (offsetsstride - 1)// high-to-low or low-to-high
		- (!isabsvalue && issignmode) * (offsetsstride / 2 - isdescsort)
		- (isdescsort && (isabsvalue || !issignmode)) * (offsetsstride - 1)
		- (isabsvalue && !issignmode && isfltpmode) * (1 - isdescsort * 2)};
	U length{static_cast<U>(*t) + static_cast<U>(*u)};
	T *pfill{pdst + count + 1};
	int filler;
	if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
	}else{// not reversed order
		if constexpr(!isabsvalue && issignmode){// handle the sign bit, virtually offset the top part by half the range here
			// note: regular floating-point mode is not relevant here
			filler = isdescsort? 0x80 : 0x7F;
			t += isdescsort * 2 - 1;
			u += isdescsort * 2 - 1;
			unsigned j{256 / 2 - 1};
			do{
				pfill = reinterpret_cast<T *>(std::memset(pfill - length, filler, length));
				length = static_cast<U>(*t) + static_cast<U>(*u);
				filler += isdescsort * 2 - 1;
				t += isdescsort * 2 - 1;
				u += isdescsort * 2 - 1;
			}while(--j);
		}else{// unsigned or signed absolute
			// note: both regular absolute modes are not relevant here
			// custom loop for the special mode: absolute floating-point, but negative inputs will sort just below their positive counterparts
			if constexpr(isabsvalue && !issignmode && isfltpmode){// starts at one removed from the initial index
				filler = isdescsort? 0x80 : 0x7F;
				t += 1 - isdescsort * 2;// step back
				u += 1 - isdescsort * 2;// step back
				unsigned j{256 / 4 - 1};// double the number of items per loop
				do{
					pfill = reinterpret_cast<T *>(std::memset(pfill - length, filler, length));
					length = static_cast<U>(*t) + static_cast<U>(*u);// even
					pfill = reinterpret_cast<T *>(std::memset(pfill - length, filler - 0x80, length));// only 8 bits are used
					length = static_cast<U>(t[isdescsort * 6 - 3]) + static_cast<U>(u[isdescsort * 6 - 3]);// odd
					filler += isdescsort * 2 - 1;
					t += isdescsort * 4 - 2;// step forward twice
					u += isdescsort * 4 - 2;
				}while(--j);
				pfill = reinterpret_cast<T *>(std::memset(pfill - length, filler, length));
				length = static_cast<U>(*t) + static_cast<U>(*u);// even
				filler -= 0x80;// only 8 bits are used
			}else{// all other modes
				filler = isdescsort? 0 : 0xFF;
				t += isdescsort * 2 - 1;
				u += isdescsort * 2 - 1;
				unsigned j{256 / 2 - 1};
				do{
					pfill = reinterpret_cast<T *>(std::memset(pfill - length, filler, length));
					length = static_cast<U>(*t) + static_cast<U>(*u);
					filler += isdescsort * 2 - 1;
					t += isdescsort * 2 - 1;
					u += isdescsort * 2 - 1;
				}while(--j);
			}
		}
	}
	std::memset(pfill - length, filler, length);
}

// main part for the radixsortcopynoallocsingle() and radixsortnoallocsingle() function implementation templates for single-part types without indirection
// Do not use this function directly.
template<bool isabsvalue, bool issignmode, bool isfltpmode, bool ismultithreadcapable, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T) &&
	((isabsvalue && issignmode) ||// both regular absolute modes
	(!isabsvalue && issignmode && isfltpmode)),// regular floating-point mode
	void> radixsortnoallocsinglemain(std::size_t count, T const psrclo[], T pdst[], X offsets[], unsigned usemultithread)noexcept{
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
	assert(count && count != MAXSIZE_T);
	// do not pass a nullptr here
	assert(psrclo);
	assert(pdst);
	assert(offsets);
	if constexpr(ismultithreadcapable){
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
			std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (1 + usemultithread))};// rounded down in the bottom part
			while(0 <= --j){// fill the array, two at a time
				U outa{psrclo[0]};
				U outb{psrclo[1]};
				psrclo += 2;
				auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb)};
				std::size_t offseta, offsetb;// this is only allowed for the single-part version, containing just one sorting pass
				if constexpr(false){// useless if not using indirection: isrevorder){
					offseta = offsets[cura]--;// the next item will be placed one lower
					offsetb = offsets[curb]--;
				}else{
					offseta = offsets[cura]++;// the next item will be placed one higher
					offsetb = offsets[curb]++;
				}
				pdst[offseta] = static_cast<T>(outa);
				pdst[offsetb] = static_cast<T>(outb);
			}
		}else{// architecture: limit to four at a time when there's a decent amount of registers
			std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (2 + usemultithread))};// rounded down in the bottom part
			while(0 <= --j){// fill the array, four at a time
				U outa{psrclo[0]};
				U outb{psrclo[1]};
				U outc{psrclo[2]};
				U outd{psrclo[3]};
				psrclo += 4;
				auto[cura, curb, curc, curd]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd)};
				std::size_t offseta, offsetb, offsetc, offsetd;// this is only allowed for the single-part version, containing just one sorting pass
				if constexpr(false){// useless if not using indirection: isrevorder){
					offseta = offsets[cura]--;// the next item will be placed one lower
					offsetb = offsets[curb]--;
					offsetc = offsets[curc]--;
					offsetd = offsets[curd]--;
				}else{
					offseta = offsets[cura]++;// the next item will be placed one higher
					offsetb = offsets[curb]++;
					offsetc = offsets[curc]++;
					offsetd = offsets[curd]++;
				}
				pdst[offseta] = static_cast<T>(outa);
				pdst[offsetb] = static_cast<T>(outb);
				pdst[offsetc] = static_cast<T>(outc);
				pdst[offsetd] = static_cast<T>(outd);
			}
			if(2 & count + 1){// fill in the final two items for a remainder of 2 or 3
				U outa{psrclo[0]};
				U outb{psrclo[1]};
				psrclo += 2;
				auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb)};
				std::size_t offseta, offsetb;// this is only allowed for the single-part version, containing just one sorting pass
				if constexpr(false){// useless if not using indirection: isrevorder){
					offseta = offsets[cura]--;// the next item will be placed one lower
					offsetb = offsets[curb]--;
				}else{
					offseta = offsets[cura]++;// the next item will be placed one higher
					offsetb = offsets[curb]++;
				}
				pdst[offseta] = static_cast<T>(outa);
				pdst[offsetb] = static_cast<T>(outb);
			}
		}
		if(!(1 & count)){// fill in the final item for odd counts
			U out{psrclo[0]};
			std::size_t cur{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(out)};
			std::size_t offset;// this is only allowed for the single-part version, containing just one sorting pass
			if constexpr(false){// useless if not using indirection: isrevorder){
				offset = offsets[cur]--;// the next item will be placed one lower
			}else{
				offset = offsets[cur]++;// the next item will be placed one higher
			}
			pdst[offset] = static_cast<T>(out);
		}
	}else{// !ismultithreadcapable
		static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
		T const *psrchi{psrclo + count};
		do{// fill the array, two at a time: one low-to-middle, one high-to-middle
			U outlo{*psrclo++};
			U outhi{*psrchi--};
			auto[curlo, curhi]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outlo, outhi)};
			std::size_t offsetlo, offsethi;// this is only allowed for the single-part version, containing just one sorting pass
			if constexpr(false){// useless if not using indirection: isrevorder){
				offsetlo = offsets[curlo + offsetsstride]--;// the next item will be placed one lower
				offsethi = offsets[curhi]++;// the next item will be placed one higher
			}else{
				offsetlo = offsets[curlo]++;// the next item will be placed one higher
				offsethi = offsets[curhi + offsetsstride]--;// the next item will be placed one lower
			}
			pdst[offsetlo] = static_cast<T>(outlo);
			pdst[offsethi] = static_cast<T>(outhi);
		}while(psrclo < psrchi);
		if(psrclo == psrchi){// fill in the final item for odd counts
			U out{*psrclo};
			std::size_t cur{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(out)};
			std::size_t offset;// this is only allowed for the single-part version, containing just one sorting pass
			if constexpr(false){// useless if not using indirection: isrevorder){
				offset = offsets[cur + offsetsstride];
			}else{
				offset = offsets[cur];
			}
			pdst[offset] = static_cast<T>(out);
		}
	}
}

// main part for the radixsortcopynoallocsingle() and radixsortnoallocsingle() function implementation templates for single-part types without indirection
// Do not use this function directly.
template<bool isdescsort, bool isabsvalue, bool issignmode, bool isfltpmode, bool ismultithreadcapable, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T) &&
	!(isabsvalue && issignmode) &&// both regular absolute modes
	!(!isabsvalue && issignmode && isfltpmode),// regular floating-point mode
	void> radixsortnoallocsinglemain(T pdst[], X const offsets[], X const offsetscompanion[], unsigned usemultithread)noexcept{
	using U = std::conditional_t<sizeof(X) < sizeof(unsigned), unsigned, X>;// assume zero-extension to be basically free for U on basically all modern machines
	// do not pass a nullptr here
	assert(pdst);
	assert(offsets);
	if constexpr(ismultithreadcapable) if(usemultithread) assert(offsetscompanion);
	// the code here is mainly copied from generateoffsetssingle()
	// isdescsort is frequently optimised away in this part, e.g.: isdescsort * 2 - 1 generates 1 or -1
	// Determining the starting point depends on several factors here.
	static std::size_t constexpr offsetsstride{8 * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	X const *t{offsets// low-to-high or high-to-low
		+ (!isabsvalue && issignmode) * ((offsetsstride + isfltpmode) / 2 - isdescsort)
		+ (isdescsort && (isabsvalue || !issignmode)) * (offsetsstride - 1)
		+ (isabsvalue && !issignmode && isfltpmode) * (1 - isdescsort * 2)};
	U length{*t};
	T *pfill{pdst};
	int filler;
	if constexpr(ismultithreadcapable) if(usemultithread){// multi-threaded version
		X const *u{offsetscompanion// low-to-high or high-to-low
			+ (!isabsvalue && issignmode) * ((offsetsstride + isfltpmode) / 2 - isdescsort)
			+ (isdescsort && (isabsvalue || !issignmode)) * (offsetsstride - 1)
			+ (isabsvalue && !issignmode && isfltpmode) * (1 - isdescsort * 2)};
		length += *u;
		if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
		}else{// not reversed order
			if constexpr(!isabsvalue && issignmode){// handle the sign bit, virtually offset the top part by half the range here
				// note: regular floating-point mode is not relevant here
				filler = isdescsort? 0x7F : 0x80;
				t += 1 - isdescsort * 2;
				u += 1 - isdescsort * 2;
				unsigned j{256 / 2 - 1};
				do{
					pfill = reinterpret_cast<T *>(std::memset(pfill, filler, length)) + length;
					length = static_cast<U>(*t) + static_cast<U>(*u);
					filler += 1 - isdescsort * 2;
					t += 1 - isdescsort * 2;
					u += 1 - isdescsort * 2;
				}while(--j);
			}else{// unsigned or signed absolute
				// note: both regular absolute modes are not relevant here
				// custom loop for the special mode: absolute floating-point, but negative inputs will sort just below their positive counterparts
				if constexpr(isabsvalue && !issignmode && isfltpmode){// starts at one removed from the initial index
					filler = isdescsort? 0x7F : 0x80;
					t += isdescsort * 2 - 1;// step back
					u += isdescsort * 2 - 1;// step back
					unsigned j{256 / 4 - 1};// double the number of items per loop
					do{
						pfill = reinterpret_cast<T *>(std::memset(pfill, filler, length)) + length;
						length = static_cast<U>(*t) + static_cast<U>(*u);// even
						pfill = reinterpret_cast<T *>(std::memset(pfill, filler - 0x80, length)) + length;// only 8 bits are used
						length = static_cast<U>(t[3 - isdescsort * 6]) + static_cast<U>(u[3 - isdescsort * 6]);// odd
						filler += 1 - isdescsort * 2;
						t += 2 - isdescsort * 4;// step forward twice
						u += 2 - isdescsort * 4;
					}while(--j);
					pfill = reinterpret_cast<T *>(std::memset(pfill, filler, length)) + length;
					length = static_cast<U>(*t) + static_cast<U>(*u);// even
					filler -= 0x80;// only 8 bits are used
				}else{// all other modes
					filler = isdescsort? 0xFF : 0;
					t += 1 - isdescsort * 2;
					u += 1 - isdescsort * 2;
					unsigned j{256 / 2 - 1};
					do{
						pfill = reinterpret_cast<T *>(std::memset(pfill, filler, length)) + length;
						length = static_cast<U>(*t) + static_cast<U>(*u);
						filler += 1 - isdescsort * 2;
						t += 1 - isdescsort * 2;
						u += 1 - isdescsort * 2;
					}while(--j);
				}
			}
		}
		goto exit;
	}
	// single-threaded version
	if constexpr(false){// useless when not handling indirection: isrevorder){// also reverse the array at the same time
	}else{// not reversed order
		if constexpr(!isabsvalue && issignmode){// handle the sign bit, virtually offset the top part by half the range here
			// note: regular floating-point mode is not relevant here
			filler = isdescsort? 0x7F : 0x80;
			t += 1 - isdescsort * 2;
			unsigned j{256 / 2 - 1};
			do{
				pfill = reinterpret_cast<T *>(std::memset(pfill, filler, length)) + length;
				length = *t;
				filler += 1 - isdescsort * 2;
				t += 1 - isdescsort * 2;
			}while(--j);
			pfill = reinterpret_cast<T *>(std::memset(pfill, filler, length)) + length;
			length = t[256 * (isdescsort * 2 - 1)];
			filler += 1 - isdescsort * 2;// only 8 bits are used
			t += (256 - 1) * (isdescsort * 2 - 1);// offset to the start/end of the range
			j = 256 / 2 - 1;
			do{
				pfill = reinterpret_cast<T *>(std::memset(pfill, filler, length)) + length;
				length = *t;
				filler += 1 - isdescsort * 2;
				t += 1 - isdescsort * 2;
			}while(--j);
		}else{// unsigned or signed absolute
			// note: both regular absolute modes are not relevant here
			// custom loop for the special mode: absolute floating-point, but negative inputs will sort just below their positive counterparts
			if constexpr(isabsvalue && !issignmode && isfltpmode){// starts at one removed from the initial index
				filler = isdescsort? 0x7F : 0x80;
				t += isdescsort * 2 - 1;// step back
				unsigned j{256 / 2 - 1};// double the number of items per loop
				do{
					pfill = reinterpret_cast<T *>(std::memset(pfill, filler, length)) + length;
					length = *t;// even
					pfill = reinterpret_cast<T *>(std::memset(pfill, filler - 0x80, length)) + length;// only 8 bits are used
					length = t[3 - isdescsort * 6];// odd
					filler += 1 - isdescsort * 2;
					t += 2 - isdescsort * 4;// step forward twice
				}while(--j);
				pfill = reinterpret_cast<T *>(std::memset(pfill, filler, length)) + length;
				length = *t;// even
				filler -= 0x80;// only 8 bits are used
			}else{// all other modes
				filler = isdescsort? 0xFF : 0;
				t += 1 - isdescsort * 2;
				unsigned j{256 - 1};
				do{
					pfill = reinterpret_cast<T *>(std::memset(pfill, filler, length)) + length;
					length = *t;
					filler += 1 - isdescsort * 2;
					t += 1 - isdescsort * 2;
				}while(--j);
			}
		}
	}
exit:
	std::memset(pfill, filler, length);
}

// main part, multi-threading companion for the radixsortcopynoallocsingle() function implementation template for single-part types without indirection
// Do not use this function directly.
template<bool isdescsort, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T) &&
	((isabsvalue && issignmode) ||// both regular absolute modes
	(!isabsvalue && issignmode && isfltpmode)),// regular floating-point mode
	void> radixsortcopynoallocsinglemtc(std::size_t count, T const input[], T output[], std::atomic_uintptr_t &atomiclightbarrier)noexcept{
	// do not pass a nullptr here
	assert(input);
	assert(output);
	static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	X offsetscompanion[offsetsstride]{};// a sizeable amount of indices, but it's worth it, zeroed in advance here
	radixsortnoallocsingleinitmtc<isabsvalue, issignmode, isfltpmode, T, X>(count, input, output, offsetscompanion);

	X *offsets;
	{// barrier and pointer exchange with the main thread
		std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsetscompanion))};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed);
			}while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == other);
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		offsets = reinterpret_cast<X *>(other);// retrieve the pointer
	}

	// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
	unsigned allareidentical{generateoffsetssinglemtc<isdescsort, false, isabsvalue, issignmode, isfltpmode, X>(count, offsets, offsetscompanion)};// isrevorder is set to false because it's useless when not using indirection

	{// barrier and allareidentical value exchange with the main thread
		++allareidentical;// send over a 1 or a 2
		while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == atomiclightbarrier.load(std::memory_order_relaxed)){
			spinpause();// catch up
		}
		std::uintptr_t other{atomiclightbarrier.fetch_add(allareidentical)};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed) - allareidentical;
			}while(!other);
		}
		// only one of the two threads can set the all are identical state
		allareidentical -= static_cast<unsigned>(other);// codes:
		// 0: continue processing
		// -1: input from the main thread
		// 1: input from this thread
	}

	if(!allareidentical)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
		[[likely]]
#endif
	{// perform the bidirectional 8-bit sorting sequence
		radixsortnoallocsinglemainmtc<isabsvalue, issignmode, isfltpmode, T, X>(count, input, output, offsetscompanion);
	}
}

// main part, multi-threading companion for the radixsortcopynoallocsingle() function implementation template for single-part types without indirection
// Do not use this function directly.
template<bool isdescsort, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T) &&
	!(isabsvalue && issignmode) &&// both regular absolute modes
	!(!isabsvalue && issignmode && isfltpmode),// regular floating-point mode
	void> radixsortcopynoallocsinglemtc(std::size_t count, T const input[], T output[], std::atomic_uintptr_t &atomiclightbarrier)noexcept{
	// do not pass a nullptr here
	assert(input);
	assert(output);
	static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	X offsetscompanion[offsetsstride]{};// a sizeable amount of indices, but it's worth it, zeroed in advance here
	radixsortnoallocsingleinitmtc<isabsvalue, issignmode, isfltpmode, T, X>(count, input, offsetscompanion);

	X *offsets;
	{// barrier and pointer exchange with the main thread
		std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsetscompanion))};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed);
			}while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == other);
		}
		offsets = reinterpret_cast<X *>(other);// retrieve the pointer
	}

	// the single-part version without indirection here only has to do a linear fill based on the offsets, making this simpler than any other version
	// perform the bidirectional 8-bit fill sequence
	radixsortnoallocsinglemainmtc<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, output, offsets, offsetscompanion);
}

// radixsortcopynoalloc() function implementation template for single-part types without indirection
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	, bool ismultithreadcapable = true
#endif
	>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T) &&
	((isabsvalue && issignmode) ||// both regular absolute modes
	(!isabsvalue && issignmode && isfltpmode)),// regular floating-point mode
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	radixsortcopynoallocsingle1thread
#else
	radixsortcopynoallocsingle2thread
#endif
	(std::size_t count, T const input[], T output[])noexcept{
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	static bool constexpr ismultithreadcapable{false};
#endif
	if constexpr(ismultithreadcapable){
		assert(1 < std::thread::hardware_concurrency());// only use multi-threading if there is more than one hardware thread
		assert(15 <= count);// a 0 or 1 count array is only allowed here in single-threaded function mode
	}
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);
	// All the code in this function is adapted for count to be one below its input value here.
	--count;
	if(ismultithreadcapable || 0 < static_cast<std::ptrdiff_t>(count)){// a 0 or 1 count array is only allowed here in single-threaded function mode
		static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
		// conditionally enable multi-threading here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t, std::nullptr_t> atomiclightbarrier{};
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::future<void>, std::nullptr_t> asynchandle;

		// count the 256 configurations, all in one go
		if constexpr(ismultithreadcapable){
			try{
				asynchandle = std::async(std::launch::async, radixsortcopynoallocsinglemtc<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>, count, input, output, std::ref(atomiclightbarrier));
				usemultithread = 1;
			}catch(...){// std::async may fail gracefully here
				assert(false);
			}
		}
		X offsets[offsetsstride * (2 - ismultithreadcapable)];// a sizeable amount of indices, but it's worth it
		std::memset(offsets, 0, offsetsstride * sizeof(X));// zeroed in advance here
		std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
			if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
			do{
				U cura{input[i]};
				U curb{input[i - 1]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(
						cura, output + i,
						curb, output + i - 1);
					++offsets[cura];
				}else{
					output[i] = static_cast<T>(cura);
					++offsets[cura];
					output[i - 1] = static_cast<T>(curb);
				}
				++offsets[curb];
				i -= 2;
			}while(0 < i);
			if(!(1 & i)){// fill in the final item for odd counts
				U cur{input[0]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, output);
				}else output[0] = static_cast<T>(cur);
				++offsets[cur];
			}
		}else{// architecture: do not limit as much when there's a reasonable amount of registers
			if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 8) >> 4) * 8;
			i -= 7;
			if(0 <= i)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
				[[likely]]
#endif
				do{
				U cura{input[i + 7]};
				U curb{input[i + 6]};
				U curc{input[i + 5]};
				U curd{input[i + 4]};
				if constexpr(isabsvalue != isfltpmode){// two-register filters only
					// register pressure performance issue on several platforms: first do the high half here
					filterinput<isabsvalue, issignmode, isfltpmode, T>(
						cura, output + i + 7,
						curb, output + i + 6,
						curc, output + i + 5,
						curd, output + i + 4);
					++offsets[cura];
					++offsets[curb];
					++offsets[curc];
					++offsets[curd];
				}
				U cure{input[i + 3]};
				U curf{input[i + 2]};
				U curg{input[i + 1]};
				U curh{input[i]};
				if constexpr(isabsvalue != isfltpmode){// two-register filters only
					// register pressure performance issue on several platforms: do the low half here second
					filterinput<isabsvalue, issignmode, isfltpmode, T>(
						cure, output + i + 3,
						curf, output + i + 2,
						curg, output + i + 1,
						curh, output + i);
					++offsets[cure];
					++offsets[curf];
					++offsets[curg];
				}else if constexpr(isabsvalue && isfltpmode){// one-register filters only
					filterinput<isabsvalue, issignmode, isfltpmode, T>(
						cura, output + i + 7,
						curb, output + i + 6,
						curc, output + i + 5,
						curd, output + i + 4,
						cure, output + i + 3,
						curf, output + i + 2,
						curg, output + i + 1,
						curh, output + i);
					++offsets[cura];
					++offsets[curb];
					++offsets[curc];
					++offsets[curd];
					++offsets[cure];
					++offsets[curf];
					++offsets[curg];
				}else{
					output[i + 7] = static_cast<T>(cura);
					++offsets[cura];
					output[i + 6] = static_cast<T>(curb);
					++offsets[curb];
					output[i + 5] = static_cast<T>(curc);
					++offsets[curc];
					output[i + 4] = static_cast<T>(curd);
					++offsets[curd];
					output[i + 3] = static_cast<T>(cure);
					++offsets[cure];
					output[i + 2] = static_cast<T>(curf);
					++offsets[curf];
					output[i + 1] = static_cast<T>(curg);
					++offsets[curg];
					output[i] = static_cast<T>(curh);
				}
				++offsets[curh];
				i -= 8;
			}while(0 <= i);
			if(4 & i){// fill in the final four items for a remainder of 4 to 7
				U cura{input[i + 7]};
				U curb{input[i + 6]};
				U curc{input[i + 5]};
				U curd{input[i + 4]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(
						cura, output + i + 7,
						curb, output + i + 6,
						curc, output + i + 5,
						curd, output + i + 4);
					i -= 4;// required for the "if(2 & i){" part
					++offsets[cura];
					++offsets[curb];
					++offsets[curc];
				}else{
					output[i + 7] = static_cast<T>(cura);
					++offsets[cura];
					output[i + 6] = static_cast<T>(curb);
					++offsets[curb];
					output[i + 5] = static_cast<T>(curc);
					++offsets[curc];
					output[i + 4] = static_cast<T>(curd);
					i -= 4;// required for the "if(2 & i){" part
				}
				++offsets[curd];
			}
			if(2 & i){// fill in the final two items for a remainder of 2 or 3
				U cura{input[i + 7]};
				U curb{input[i + 6]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(
						cura, output + i + 7,
						curb, output + i + 6);
					++offsets[cura];
				}else{
					output[i + 7] = static_cast<T>(cura);
					++offsets[cura];
					output[i + 6] = static_cast<T>(curb);
				}
				++offsets[curb];
				}
			if(1 & i){// fill in the final item for odd counts
				U cur{input[0]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, output);
				}else output[0] = static_cast<T>(cur);
				++offsets[cur];
			}
		}

		// barrier and pointer exchange with the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, X *, std::nullptr_t> offsetscompanion;
		if constexpr(ismultithreadcapable){
			std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsets) & -static_cast<std::intptr_t>(usemultithread))};
			// simply do not spin if usemultithread is zero
			if(usemultithread > other){
				do{
					spinpause();
					other = atomiclightbarrier.load(std::memory_order_relaxed);
				}while(reinterpret_cast<std::uintptr_t>(offsets) == other);
				// reset the barrier after use, only one thread will do this
				// no busy-wait dependency on this store, hence relaxed memory order is fine
				reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
				// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
			}
			// this will just be zero if usemultithread is zero
			offsetscompanion = reinterpret_cast<X *>(other);// retrieve the pointer
		}else offsetscompanion = nullptr;

		// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
		unsigned allareidentical{generateoffsetssingle<isdescsort, false, isabsvalue, issignmode, isfltpmode, std::nullptr_t, X>(count, offsets, offsetscompanion, usemultithread)};// isrevorder is set to false because it's useless when not using indirection

		// barrier and allareidentical value exchange with the companion thread
		if constexpr(ismultithreadcapable){
			allareidentical += usemultithread;// send over a 1 or a 2 when multithreading
			while(reinterpret_cast<std::uintptr_t>(offsets) == atomiclightbarrier.load(std::memory_order_relaxed)){
				spinpause();// catch up
			}
			std::uintptr_t other{atomiclightbarrier.fetch_add(allareidentical)};
			// simply do not spin if usemultithread is zero
			if(usemultithread > other){
				do{
					spinpause();
					other = atomiclightbarrier.load(std::memory_order_relaxed) - allareidentical;
				}while(!other);
			}
			// only one of the two threads can set the all are identical state
			allareidentical -= static_cast<unsigned>(other);// codes:
			// 0: continue processing
			// -1: input from the companion thread
			// 1: input from this thread
		}

		if(!allareidentical)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
			[[likely]]
#endif
		{// perform the bidirectional 8-bit sorting sequence
			radixsortnoallocsinglemain<isabsvalue, issignmode, isfltpmode, ismultithreadcapable, T, X>(count, input, output, offsets, usemultithread);
		}
	}else if(0 == static_cast<std::ptrdiff_t>(count)) *output = *input;// copy the single element if the count is 1
}

// radixsortcopynoalloc() function implementation template for single-part types without indirection
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	, bool ismultithreadcapable = true
#endif
	>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T) &&
	!(isabsvalue && issignmode) &&// both regular absolute modes
	!(!isabsvalue && issignmode && isfltpmode),// regular floating-point mode
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	radixsortcopynoallocsingle1thread
#else
	radixsortcopynoallocsingle2thread
#endif
	(std::size_t count, T const input[], T output[])noexcept{
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	static bool constexpr ismultithreadcapable{false};
#endif
	if constexpr(ismultithreadcapable){
		assert(1 < std::thread::hardware_concurrency());// only use multi-threading if there is more than one hardware thread
		assert(15 <= count);// a 0 or 1 count array is only allowed here in single-threaded function mode
	}
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);
	// All the code in this function is adapted for count to be one below its input value here.
	--count;
	if(ismultithreadcapable || 0 < static_cast<std::ptrdiff_t>(count)){// a 0 or 1 count array is only allowed here in single-threaded function mode
		static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
		// conditionally enable multi-threading here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t, std::nullptr_t> atomiclightbarrier{};
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::future<void>, std::nullptr_t> asynchandle;

		// count the 256 configurations, all in one go
		if constexpr(ismultithreadcapable){
			try{
				asynchandle = std::async(std::launch::async, radixsortcopynoallocsinglemtc<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>, count, input, output, std::ref(atomiclightbarrier));
				usemultithread = 1;
			}catch(...){// std::async may fail gracefully here
				assert(false);
			}
		}
		X offsets[offsetsstride * (2 - ismultithreadcapable)];// a sizeable amount of indices, but it's worth it
		std::memset(offsets, 0, offsetsstride * sizeof(X));// zeroed in advance here
		std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
			if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
			do{
				U cura{input[i]};
				U curb{input[i - 1]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(
						cura, output + i,
						curb, output + i - 1);
					++offsets[cura];
				}else{
					output[i] = static_cast<T>(cura);
					++offsets[cura];
					output[i - 1] = static_cast<T>(curb);
				}
				++offsets[curb];
				i -= 2;
			}while(0 < i);
			if(!(1 & i)){// fill in the final item for odd counts
				U cur{input[0]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, output);
				}else output[0] = static_cast<T>(cur);
				++offsets[cur];
			}
		}else{// architecture: do not limit as much when there's a reasonable amount of registers
			if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 8) >> 4) * 8;
			i -= 7;
			if(0 <= i)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
				[[likely]]
#endif
				do{
				U cura{input[i + 7]};
				U curb{input[i + 6]};
				U curc{input[i + 5]};
				U curd{input[i + 4]};
				if constexpr(isabsvalue != isfltpmode){// two-register filters only
					// register pressure performance issue on several platforms: first do the high half here
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
					++offsets[cura];
					++offsets[curb];
					++offsets[curc];
					++offsets[curd];
				}
				U cure{input[i + 3]};
				U curf{input[i + 2]};
				U curg{input[i + 1]};
				U curh{input[i]};
				if constexpr(isabsvalue != isfltpmode){// two-register filters only
					// register pressure performance issue on several platforms: do the low half here second
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cure, curf, curg, curh);
				}else{
					if constexpr(isabsvalue && isfltpmode){// one-register filters only
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd, cure, curf, curg, curh);
					}
					++offsets[cura];
					++offsets[curb];
					++offsets[curc];
					++offsets[curd];
				}
				++offsets[cure];
				++offsets[curf];
				++offsets[curg];
				++offsets[curh];
				i -= 8;
			}while(0 <= i);
			if(4 & i){// fill in the final four items for a remainder of 4 to 7
				U cura{input[i + 7]};
				U curb{input[i + 6]};
				U curc{input[i + 5]};
				U curd{input[i + 4]};
				i -= 4;// required for the "if(2 & i){" part
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
				}
				++offsets[cura];
				++offsets[curb];
				++offsets[curc];
				++offsets[curd];
			}
			if(2 & i){// fill in the final two items for a remainder of 2 or 3
				U cura{input[i + 7]};
				U curb{input[i + 6]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
				}
				++offsets[cura];
				++offsets[curb];
			}
			if(1 & i){// fill in the final item for odd counts
				U cur{input[0]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
				}
				++offsets[cur];
			}
		}

		// barrier and pointer exchange with the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, X *, std::nullptr_t> offsetscompanion;
		if constexpr(ismultithreadcapable){
			std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsets) & -static_cast<std::intptr_t>(usemultithread))};
			// simply do not spin if usemultithread is zero
			if(usemultithread > other){
				do{
					spinpause();
					other = atomiclightbarrier.load(std::memory_order_relaxed);
				}while(reinterpret_cast<std::uintptr_t>(offsets) == other);
				// reset the barrier after use, only one thread will do this
				// no busy-wait dependency on this store, hence relaxed memory order is fine
				reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
				// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
			}
			// this will just be zero if usemultithread is zero
			offsetscompanion = reinterpret_cast<X *>(other);// retrieve the pointer
		}else offsetscompanion = nullptr;

		// the single-part version without indirection here only has to do a linear fill based on the offsets, making this simpler than any other version
		// perform the bidirectional 8-bit fill sequence
		radixsortnoallocsinglemain<isdescsort, isabsvalue, issignmode, isfltpmode, ismultithreadcapable, T, X>(output, offsets, offsetscompanion, usemultithread);
	}else if(0 == static_cast<std::ptrdiff_t>(count)) *output = *input;// copy the single element if the count is 1
}

// main part, multi-threading companion for the radixsortnoallocsingle() function implementation template for single-part types without indirection
// Do not use this function directly.
template<bool isdescsort, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T) &&
	((isabsvalue && issignmode) ||// both regular absolute modes
	(!isabsvalue && issignmode && isfltpmode)),// regular floating-point mode
	void> radixsortnoallocsinglemtc(std::size_t count, T input[], T buffer[], std::atomic_uintptr_t &atomiclightbarrier)noexcept{
	static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(buffer);
	X offsetscompanion[offsetsstride]{};// a sizeable amount of indices, but it's worth it, zeroed in advance here
	radixsortnoallocsingleinitmtc<isabsvalue, issignmode, isfltpmode, T, X>(count, input, buffer, offsetscompanion);

	X *offsets;
	{// barrier and pointer exchange with the main thread
		std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsetscompanion))};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed);
			}while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == other);
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
			reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		offsets = reinterpret_cast<X *>(other);// retrieve the pointer
	}

	// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
	unsigned allareidentical{generateoffsetssinglemtc<isdescsort, false, isabsvalue, issignmode, isfltpmode, X>(count, offsets, offsetscompanion)};// isrevorder is set to false because it's useless when not using indirection

	{// barrier and allareidentical value exchange with the main thread
		++allareidentical;// send over a 1 or a 2
		while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == atomiclightbarrier.load(std::memory_order_relaxed)){
			spinpause();// catch up
		}
		std::uintptr_t other{atomiclightbarrier.fetch_add(allareidentical)};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed) - allareidentical;
			}while(!other);
		}
		// only one of the two threads can set the all are identical state
		allareidentical -= static_cast<unsigned>(other);// codes:
		// 0: continue processing
		// -1: input from the main thread
		// 1: input from this thread
	}

	if(!allareidentical)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
		[[likely]]
#endif
	{// perform the bidirectional 8-bit sorting sequence
		radixsortnoallocsinglemainmtc<isabsvalue, issignmode, isfltpmode, T, X>(count, buffer, input, offsetscompanion);
	}
}

// main part, multi-threading companion for the radixsortnoallocsingle() function implementation template for single-part types without indirection
// Do not use this function directly.
template<bool isdescsort, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T) &&
	!(isabsvalue && issignmode) &&// both regular absolute modes
	!(!isabsvalue && issignmode && isfltpmode),// regular floating-point mode
	void> radixsortnoallocsinglemtc(std::size_t count, T input[], std::atomic_uintptr_t &atomiclightbarrier)noexcept{
	static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	X offsetscompanion[offsetsstride]{};// a sizeable amount of indices, but it's worth it, zeroed in advance here
	radixsortnoallocsingleinitmtc<isabsvalue, issignmode, isfltpmode, T, X>(count, input, offsetscompanion);

	X *offsets;
	{// barrier and pointer exchange with the main thread
		std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsetscompanion))};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed);
			}while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == other);
		}
		offsets = reinterpret_cast<X *>(other);// retrieve the pointer
	}

	// the single-part version without indirection here only has to do a linear fill based on the offsets, making this simpler than any other version
	// perform the bidirectional 8-bit fill sequence
	radixsortnoallocsinglemainmtc<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>(count, input, offsets, offsetscompanion);
}

// radixsortnoalloc() function implementation template for single-part types without indirection
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	, bool ismultithreadcapable = true
#endif
	>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T) &&
	((isabsvalue && issignmode) ||// both regular absolute modes
	(!isabsvalue && issignmode && isfltpmode)),// regular floating-point mode
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	radixsortnoallocsingle1thread
#else
	radixsortnoallocsingle2thread
#endif
	(std::size_t count, T input[], T buffer[])noexcept{
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	static bool constexpr ismultithreadcapable{false};
#endif
	if constexpr(ismultithreadcapable){
		assert(1 < std::thread::hardware_concurrency());// only use multi-threading if there is more than one hardware thread
		assert(15 <= count);// a 0 or 1 count array is only allowed here in single-threaded function mode
	}
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(buffer);
	// All the code in this function is adapted for count to be one below its input value here.
	--count;
	if(ismultithreadcapable || 0 < static_cast<std::ptrdiff_t>(count)){// a 0 or 1 count array is only allowed here in single-threaded function mode
		static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
		// conditionally enable multi-threading here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t, std::nullptr_t> atomiclightbarrier{};
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::future<void>, std::nullptr_t> asynchandle;

		// count the 256 configurations, all in one go
		if constexpr(ismultithreadcapable){
			try{
				asynchandle = std::async(std::launch::async, radixsortnoallocsinglemtc<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>, count, input, buffer, std::ref(atomiclightbarrier));
				usemultithread = 1;
			}catch(...){// std::async may fail gracefully here
				assert(false);
			}
		}
		X offsets[offsetsstride * (2 - ismultithreadcapable)];// a sizeable amount of indices, but it's worth it
		std::memset(offsets, 0, offsetsstride * sizeof(X));// zeroed in advance here
		std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
			if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
			do{
				U cura{input[i]};
				U curb{input[i - 1]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(
						cura, buffer + i,
						curb, buffer + i - 1);
					++offsets[cura];
				}else{
					buffer[i] = static_cast<T>(cura);
					++offsets[cura];
					buffer[i - 1] = static_cast<T>(curb);
				}
				++offsets[curb];
				i -= 2;
			}while(0 < i);
			if(!(1 & i)){// fill in the final item for odd counts
				U cur{input[0]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, buffer);
				}else buffer[0] = static_cast<T>(cur);
				++offsets[cur];
			}
		}else{// architecture: do not limit as much when there's a reasonable amount of registers
			if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 8) >> 4) * 8;
			i -= 7;
			if(0 <= i)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
				[[likely]]
#endif
				do{
				U cura{input[i + 7]};
				U curb{input[i + 6]};
				U curc{input[i + 5]};
				U curd{input[i + 4]};
				if constexpr(isabsvalue != isfltpmode){// two-register filters only
					// register pressure performance issue on several platforms: first do the high half here
					filterinput<isabsvalue, issignmode, isfltpmode, T>(
						cura, buffer + i + 7,
						curb, buffer + i + 6,
						curc, buffer + i + 5,
						curd, buffer + i + 4);
					++offsets[cura];
					++offsets[curb];
					++offsets[curc];
					++offsets[curd];
				}
				U cure{input[i + 3]};
				U curf{input[i + 2]};
				U curg{input[i + 1]};
				U curh{input[i]};
				if constexpr(isabsvalue != isfltpmode){// two-register filters only
					// register pressure performance issue on several platforms: do the low half here second
					filterinput<isabsvalue, issignmode, isfltpmode, T>(
						cure, buffer + i + 3,
						curf, buffer + i + 2,
						curg, buffer + i + 1,
						curh, buffer + i);
					++offsets[cure];
					++offsets[curf];
					++offsets[curg];
				}else if constexpr(isabsvalue && isfltpmode){// one-register filters only
					filterinput<isabsvalue, issignmode, isfltpmode, T>(
						cura, buffer + i + 7,
						curb, buffer + i + 6,
						curc, buffer + i + 5,
						curd, buffer + i + 4,
						cure, buffer + i + 3,
						curf, buffer + i + 2,
						curg, buffer + i + 1,
						curh, buffer + i);
					++offsets[cura];
					++offsets[curb];
					++offsets[curc];
					++offsets[curd];
					++offsets[cure];
					++offsets[curf];
					++offsets[curg];
				}else{
					buffer[i + 7] = static_cast<T>(cura);
					++offsets[cura];
					buffer[i + 6] = static_cast<T>(curb);
					++offsets[curb];
					buffer[i + 5] = static_cast<T>(curc);
					++offsets[curc];
					buffer[i + 4] = static_cast<T>(curd);
					++offsets[curd];
					buffer[i + 3] = static_cast<T>(cure);
					++offsets[cure];
					buffer[i + 2] = static_cast<T>(curf);
					++offsets[curf];
					buffer[i + 1] = static_cast<T>(curg);
					++offsets[curg];
					buffer[i] = static_cast<T>(curh);
				}
				++offsets[curh];
				i -= 8;
			}while(0 <= i);
			if(4 & i){// fill in the final four items for a remainder of 4 to 7
				U cura{input[i + 7]};
				U curb{input[i + 6]};
				U curc{input[i + 5]};
				U curd{input[i + 4]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(
						cura, buffer + i + 7,
						curb, buffer + i + 6,
						curc, buffer + i + 5,
						curd, buffer + i + 4);
					i -= 4;// required for the "if(2 & i){" part
					++offsets[cura];
					++offsets[curb];
					++offsets[curc];
				}else{
					buffer[i + 7] = static_cast<T>(cura);
					++offsets[cura];
					buffer[i + 6] = static_cast<T>(curb);
					++offsets[curb];
					buffer[i + 5] = static_cast<T>(curc);
					++offsets[curc];
					buffer[i + 4] = static_cast<T>(curd);
					i -= 4;// required for the "if(2 & i){" part
				}
				++offsets[curd];
			}
			if(2 & i){// fill in the final two items for a remainder of 2 or 3
				U cura{input[i + 7]};
				U curb{input[i + 6]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(
						cura, buffer + i + 7,
						curb, buffer + i + 6);
					++offsets[cura];
				}else{
					buffer[i + 7] = static_cast<T>(cura);
					++offsets[cura];
					buffer[i + 6] = static_cast<T>(curb);
				}
				++offsets[curb];
			}
			if(1 & i){// fill in the final item for odd counts
				U cur{input[0]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cur, buffer);
				}else buffer[0] = static_cast<T>(cur);
				++offsets[cur];
			}
		}

		// barrier and pointer exchange with the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, X *, std::nullptr_t> offsetscompanion;
		if constexpr(ismultithreadcapable){
			std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsets) & -static_cast<std::intptr_t>(usemultithread))};
			// simply do not spin if usemultithread is zero
			if(usemultithread > other){
				do{
					spinpause();
					other = atomiclightbarrier.load(std::memory_order_relaxed);
				}while(reinterpret_cast<std::uintptr_t>(offsets) == other);
				// reset the barrier after use, only one thread will do this
				// no busy-wait dependency on this store, hence relaxed memory order is fine
				reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
				// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
			}
			// this will just be zero if usemultithread is zero
			offsetscompanion = reinterpret_cast<X *>(other);// retrieve the pointer
		}else offsetscompanion = nullptr;

		// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
		unsigned allareidentical{generateoffsetssingle<isdescsort, false, isabsvalue, issignmode, isfltpmode, std::nullptr_t, X>(count, offsets, offsetscompanion, usemultithread)};// isrevorder is set to false because it's useless when not using indirection

		// barrier and allareidentical value exchange with the companion thread
		if constexpr(ismultithreadcapable){
			allareidentical += usemultithread;// send over a 1 or a 2 when multithreading
			while(reinterpret_cast<std::uintptr_t>(offsets) == atomiclightbarrier.load(std::memory_order_relaxed)){
				spinpause();// catch up
			}
			std::uintptr_t other{atomiclightbarrier.fetch_add(allareidentical)};
			// simply do not spin if usemultithread is zero
			if(usemultithread > other){
				do{
					spinpause();
					other = atomiclightbarrier.load(std::memory_order_relaxed) - allareidentical;
				}while(!other);
			}
			// only one of the two threads can set the all are identical state
			allareidentical -= static_cast<unsigned>(other);// codes:
			// 0: continue processing
			// -1: input from the companion thread
			// 1: input from this thread
		}

		if(!allareidentical)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
			[[likely]]
#endif
		{// perform the bidirectional 8-bit sorting sequence
			radixsortnoallocsinglemain<isabsvalue, issignmode, isfltpmode, ismultithreadcapable, T, X>(count, buffer, input, offsets, usemultithread);
		}
	}
}

// radixsortnoalloc() function implementation template for single-part types without indirection
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename X
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	, bool ismultithreadcapable = true
#endif
	>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_unsigned_v<X> &&
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T) &&
	!(isabsvalue && issignmode) &&// both regular absolute modes
	!(!isabsvalue && issignmode && isfltpmode),// regular floating-point mode
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	radixsortnoallocsingle1thread
#else
	radixsortnoallocsingle2thread
#endif
	(std::size_t count, T input[])noexcept{
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	static bool constexpr ismultithreadcapable{false};
#endif
	if constexpr(ismultithreadcapable){
		assert(1 < std::thread::hardware_concurrency());// only use multi-threading if there is more than one hardware thread
		assert(15 <= count);// a 0 or 1 count array is only allowed here in single-threaded function mode
	}
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	// All the code in this function is adapted for count to be one below its input value here.
	--count;
	if(ismultithreadcapable || 0 < static_cast<std::ptrdiff_t>(count)){// a 0 or 1 count array is only allowed here in single-threaded function mode
		static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
		// conditionally enable multi-threading here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t, std::nullptr_t> atomiclightbarrier{};
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::future<void>, std::nullptr_t> asynchandle;

		// count the 256 configurations, all in one go
		if constexpr(ismultithreadcapable){
			try{
				asynchandle = std::async(std::launch::async, radixsortnoallocsinglemtc<isdescsort, isabsvalue, issignmode, isfltpmode, T, X>, count, input, std::ref(atomiclightbarrier));
				usemultithread = 1;
			}catch(...){// std::async may fail gracefully here
				assert(false);
			}
		}
		X offsets[offsetsstride]{};// a sizeable amount of indices, but it's worth it, zeroed in advance here
		std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
			if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
			do{
				U cura{input[i]};
				U curb{input[i - 1]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
				}
				++offsets[cura];
				++offsets[curb];
				i -= 2;
			}while(0 < i);
			if(!(1 & i)){// fill in the final item for odd counts
				U cur{input[0]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
				}
				++offsets[cur];
			}
		}else{// architecture: do not limit as much when there's a reasonable amount of registers
			if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 8) >> 4) * 8;
			i -= 7;
			if(0 <= i)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
				[[likely]]
#endif
				do{
				U cura{input[i + 7]};
				U curb{input[i + 6]};
				U curc{input[i + 5]};
				U curd{input[i + 4]};
				if constexpr(isabsvalue != isfltpmode){// two-register filters only
					// register pressure performance issue on several platforms: first do the high half here
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
					++offsets[cura];
					++offsets[curb];
					++offsets[curc];
					++offsets[curd];
				}
				U cure{input[i + 3]};
				U curf{input[i + 2]};
				U curg{input[i + 1]};
				U curh{input[i]};
				if constexpr(isabsvalue != isfltpmode){// two-register filters only
					// register pressure performance issue on several platforms: do the low half here second
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cure, curf, curg, curh);
				}else{
					if constexpr(isabsvalue && isfltpmode){// one-register filters only
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd, cure, curf, curg, curh);
					}
					++offsets[cura];
					++offsets[curb];
					++offsets[curc];
					++offsets[curd];
				}
				++offsets[cure];
				++offsets[curf];
				++offsets[curg];
				++offsets[curh];
				i -= 8;
			}while(0 <= i);
			if(4 & i){// fill in the final four items for a remainder of 4 to 7
				U cura{input[i + 7]};
				U curb{input[i + 6]};
				U curc{input[i + 5]};
				U curd{input[i + 4]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
				}
				i -= 4;// required for the "if(2 & i){" part
				++offsets[cura];
				++offsets[curb];
				++offsets[curc];
				++offsets[curd];
			}
			if(2 & i){// fill in the final two items for a remainder of 2 or 3
				U cura{input[i + 7]};
				U curb{input[i + 6]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
				}
				++offsets[cura];
				++offsets[curb];
			}
			if(1 & i){// fill in the final item for odd counts
				U cur{input[0]};
				if constexpr(isabsvalue || isfltpmode){
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
				}
				++offsets[cur];
			}
		}

		// barrier and pointer exchange with the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, X *, std::nullptr_t> offsetscompanion;
		if constexpr(ismultithreadcapable){
			std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsets) & -static_cast<std::intptr_t>(usemultithread))};
			// simply do not spin if usemultithread is zero
			if(usemultithread > other){
				do{
					spinpause();
					other = atomiclightbarrier.load(std::memory_order_relaxed);
				}while(reinterpret_cast<std::uintptr_t>(offsets) == other);
			}
			// this will just be zero if usemultithread is zero
			offsetscompanion = reinterpret_cast<X *>(other);// retrieve the pointer
		}else offsetscompanion = nullptr;

		// the single-part version without indirection here only has to do a linear fill based on the offsets, making this simpler than any other version
		// perform the bidirectional 8-bit fill sequence
		radixsortnoallocsinglemain<isdescsort, isabsvalue, issignmode, isfltpmode, ismultithreadcapable, T, X>(input, offsets, offsetscompanion, usemultithread);
	}
}

// initialisation part, multi-threading companion for the radixsortcopynoallocsingle() and radixsortnoallocsingle() function implementation templates for single-part types with indirection
// Do not use this function directly.
template<auto indirection1, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename X, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortnoallocsingleinitmtc(std::size_t count, V *const input[], V *pout[], X offsetscompanion[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
	assert(15 <= count);// this function is not for small arrays, 16 is the minimum original array count
	// do not pass a nullptr here
	assert(input);
	assert(pout);
	assert(offsetscompanion);
	// unsigned counter, not zero inclusive inside the loop
	// architecture: limit to two at a time when there's few registers
	std::size_t i{(defaultgprfilesize < gprfilesize::large)? ((count + 1 + 2) >> 2) * 2 : ((count + 1 + 8) >> 4) * 8};// rounded up in the top part
	input += count - i;
	pout += count - i;
	if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
		do{
			V *pa{input[i]};
			V *pb{input[i - 1]};
			auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
			pout[i] = pa;
			auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
			pout[i - 1] = pb;
			U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
			U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
			if constexpr(isabsvalue || isfltpmode){
				filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
			}
			++offsetscompanion[cura];
			++offsetscompanion[curb];
		}while(i -= 2);
	}else{// architecture: do not limit as much when there's a reasonable amount of registers
		do{
			V *pa{input[i]};
			V *pb{input[i - 1]};
			V *pc{input[i - 2]};
			V *pd{input[i - 3]};
			if constexpr(isabsvalue != isfltpmode){// two-register filters only
				auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
				pout[i] = pa;
				auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
				pout[i - 1] = pb;
				auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
				pout[i - 2] = pc;
				auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
				pout[i - 3] = pd;
				U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
				U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
				U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
				U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
				// register pressure performance issue on several platforms: first do the high half here
				filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
				++offsetscompanion[cura];
				++offsetscompanion[curb];
				++offsetscompanion[curc];
				++offsetscompanion[curd];
			}
			V *pe{input[i - 4]};
			V *pf{input[i - 5]};
			V *pg{input[i - 6]};
			V *ph{input[i - 7]};
			if constexpr(isabsvalue != isfltpmode){// two-register filters only
				auto ime{indirectinput1<indirection1, isindexed2, T, V>(pe, varparameters...)};
				pout[i - 4] = pe;
				auto imf{indirectinput1<indirection1, isindexed2, T, V>(pf, varparameters...)};
				pout[i - 5] = pf;
				auto img{indirectinput1<indirection1, isindexed2, T, V>(pg, varparameters...)};
				pout[i - 6] = pg;
				auto imh{indirectinput1<indirection1, isindexed2, T, V>(ph, varparameters...)};
				pout[i - 7] = ph;
				U cure{indirectinput2<indirection1, indirection2, isindexed2, T>(ime, varparameters...)};
				U curf{indirectinput2<indirection1, indirection2, isindexed2, T>(imf, varparameters...)};
				U curg{indirectinput2<indirection1, indirection2, isindexed2, T>(img, varparameters...)};
				U curh{indirectinput2<indirection1, indirection2, isindexed2, T>(imh, varparameters...)};
				// register pressure performance issue on several platforms: do the low half here second
				filterinput<isabsvalue, issignmode, isfltpmode, T>(cure, curf, curg, curh);
				++offsetscompanion[cure];
				++offsetscompanion[curf];
				++offsetscompanion[curg];
				++offsetscompanion[curh];
			}else{
				auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
				pout[i] = pa;
				auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
				pout[i - 1] = pb;
				auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
				pout[i - 2] = pc;
				auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
				pout[i - 3] = pd;
				auto ime{indirectinput1<indirection1, isindexed2, T, V>(pe, varparameters...)};
				pout[i - 4] = pe;
				auto imf{indirectinput1<indirection1, isindexed2, T, V>(pf, varparameters...)};
				pout[i - 5] = pf;
				auto img{indirectinput1<indirection1, isindexed2, T, V>(pg, varparameters...)};
				pout[i - 6] = pg;
				auto imh{indirectinput1<indirection1, isindexed2, T, V>(ph, varparameters...)};
				pout[i - 7] = ph;
				U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
				U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
				U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
				U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
				U cure{indirectinput2<indirection1, indirection2, isindexed2, T>(ime, varparameters...)};
				U curf{indirectinput2<indirection1, indirection2, isindexed2, T>(imf, varparameters...)};
				U curg{indirectinput2<indirection1, indirection2, isindexed2, T>(img, varparameters...)};
				U curh{indirectinput2<indirection1, indirection2, isindexed2, T>(imh, varparameters...)};
				if constexpr(isabsvalue && isfltpmode){// one-register filters only
					filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd, cure, curf, curg, curh);
				}
				++offsetscompanion[cura];
				++offsetscompanion[curb];
				++offsetscompanion[curc];
				++offsetscompanion[curd];
				++offsetscompanion[cure];
				++offsetscompanion[curf];
				++offsetscompanion[curg];
				++offsetscompanion[curh];
			}
		}while(i -= 8);
	}
}

// main part, multi-threading companion for the radixsortcopynoallocsingle() and radixsortnoallocsingle() function implementation templates for single-part types with indirection
// Do not use this function directly.
template<auto indirection1, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename X, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortnoallocsinglemainmtc(std::size_t count, V *const psrclo[], V *pdst[], X offsetscompanion[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
	assert(15 <= count);// this function is not for small arrays, 16 is the minimum original array count
	// do not pass a nullptr here
	assert(psrclo);
	assert(pdst);
	assert(offsetscompanion);
	V *const *psrchi{psrclo + count};
	if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
		std::size_t j{(count + 1 + 2) >> 2};// rounded up in the top part
		do{// fill the array, two at a time
			V *pa{psrchi[0]};
			V *pb{psrchi[-1]};
			psrchi -= 2;
			auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
			auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
			auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
			auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
			auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb)};
			std::size_t offseta, offsetb;// this is only allowed for the single-part version, containing just one sorting pass
			if constexpr(isrevorder){
				offseta = offsetscompanion[cura]++;// the next item will be placed one higher
				offsetb = offsetscompanion[curb]++;
			}else{
				offseta = offsetscompanion[cura]--;// the next item will be placed one lower
				offsetb = offsetscompanion[curb]--;
			}
			pdst[offseta] = pa;
			pdst[offsetb] = pb;
		}while(--j);
	}else{// architecture: limit to four at a time when there's a decent amount of registers
		std::size_t j{(count + 1 + 4) >> 3};// rounded up in the top part
		do{// fill the array, four at a time
			V *pa{psrchi[0]};
			V *pb{psrchi[-1]};
			V *pc{psrchi[-2]};
			V *pd{psrchi[-3]};
			psrchi -= 4;
			auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
			auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
			auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
			auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
			auto outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
			auto outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
			auto outc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
			auto outd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
			auto[cura, curb, curc, curd]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd)};
			std::size_t offseta, offsetb, offsetc, offsetd;// this is only allowed for the single-part version, containing just one sorting pass
			if constexpr(isrevorder){
				offseta = offsetscompanion[cura]++;// the next item will be placed one higher
				offsetb = offsetscompanion[curb]++;
				offsetc = offsetscompanion[curc]++;
				offsetd = offsetscompanion[curd]++;
			}else{
				offseta = offsetscompanion[cura]--;// the next item will be placed one lower
				offsetb = offsetscompanion[curb]--;
				offsetc = offsetscompanion[curc]--;
				offsetd = offsetscompanion[curd]--;
			}
			pdst[offseta] = pa;
			pdst[offsetb] = pb;
			pdst[offsetc] = pc;
			pdst[offsetd] = pd;
		}while(--j);
	}
}

// main part for the radixsortcopynoallocsingle() and radixsortnoallocsingle() function implementation templates for single-part types with indirection
// Do not use this function directly.
template<auto indirection1, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, bool ismultithreadcapable, typename V, typename X, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortnoallocsinglemain(std::size_t count, V *const psrclo[], V *pdst[], X offsets[], unsigned usemultithread, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
	assert(count && count != MAXSIZE_T);
	// do not pass a nullptr here
	assert(psrclo);
	assert(pdst);
	assert(offsets);
	if constexpr(ismultithreadcapable){
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
			std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (1 + usemultithread))};// rounded down in the bottom part
			while(0 <= --j){// fill the array, two at a time
				V *pa{psrclo[0]};
				V *pb{psrclo[1]};
				auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
				auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
				U outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima)};
				U outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb)};
				psrclo += 2;
				auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb)};
				std::size_t offseta, offsetb;// this is only allowed for the single-part version, containing just one sorting pass
				if constexpr(isrevorder){
					offseta = offsets[cura]--;// the next item will be placed one lower
					offsetb = offsets[curb]--;
				}else{
					offseta = offsets[cura]++;// the next item will be placed one higher
					offsetb = offsets[curb]++;
				}
				pdst[offseta] = pa;
				pdst[offsetb] = pb;
			}
		}else{// architecture: limit to four at a time when there's a decent amount of registers
			std::ptrdiff_t j{static_cast<std::ptrdiff_t>((count + 1) >> (2 + usemultithread))};// rounded down in the bottom part
			while(0 <= --j){// fill the array, four at a time
				V *pa{psrclo[0]};
				V *pb{psrclo[1]};
				V *pc{psrclo[2]};
				V *pd{psrclo[3]};
				auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
				auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
				auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
				auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
				U outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima)};
				U outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb)};
				U outc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc)};
				U outd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd)};
				psrclo += 4;
				auto[cura, curb, curc, curd]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb, outc, outd)};
				std::size_t offseta, offsetb, offsetc, offsetd;// this is only allowed for the single-part version, containing just one sorting pass
				if constexpr(isrevorder){
					offseta = offsets[cura]--;// the next item will be placed one lower
					offsetb = offsets[curb]--;
					offsetc = offsets[curc]--;
					offsetd = offsets[curd]--;
				}else{
					offseta = offsets[cura]++;// the next item will be placed one higher
					offsetb = offsets[curb]++;
					offsetc = offsets[curc]++;
					offsetd = offsets[curd]++;
				}
				pdst[offseta] = pa;
				pdst[offsetb] = pb;
				pdst[offsetc] = pc;
				pdst[offsetd] = pd;
			}
			if(2 & count + 1){// fill in the final two items for a remainder of 2 or 3
				V *pa{psrclo[0]};
				V *pb{psrclo[1]};
				auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
				auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
				U outa{indirectinput2<indirection1, indirection2, isindexed2, T>(ima)};
				U outb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb)};
				psrclo += 2;
				auto[cura, curb]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outa, outb)};
				std::size_t offseta, offsetb;// this is only allowed for the single-part version, containing just one sorting pass
				if constexpr(isrevorder){
					offseta = offsets[cura]--;// the next item will be placed one lower
					offsetb = offsets[curb]--;
				}else{
					offseta = offsets[cura]++;// the next item will be placed one higher
					offsetb = offsets[curb]++;
				}
				pdst[offseta] = pa;
				pdst[offsetb] = pb;
			}
		}
		if(!(1 & count)){// fill in the final item for odd counts
			V *p{psrclo[0]};
			auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
			U out{indirectinput2<indirection1, indirection2, isindexed2, T>(im)};
			std::size_t cur{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(out)};
			std::size_t offset;// this is only allowed for the single-part version, containing just one sorting pass
			if constexpr(isrevorder){
				offset = offsets[cur]--;// the next item will be placed one lower
			}else{
				offset = offsets[cur]++;// the next item will be placed one higher
			}
			pdst[offset] = p;
		}
	}else{// !ismultithreadcapable
		static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
		V *const *psrchi{psrclo + count};
		do{// fill the array, two at a time: one low-to-middle, one high-to-middle
			V *plo{*psrclo++};
			V *phi{*psrchi--};
			auto imlo{indirectinput1<indirection1, isindexed2, T, V>(plo, varparameters...)};
			auto imhi{indirectinput1<indirection1, isindexed2, T, V>(phi, varparameters...)};
			U outlo{indirectinput2<indirection1, indirection2, isindexed2, T>(imlo)};
			U outhi{indirectinput2<indirection1, indirection2, isindexed2, T>(imhi)};
			auto[curlo, curhi]{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(outlo, outhi)};
			std::size_t offsetlo, offsethi;// this is only allowed for the single-part version, containing just one sorting pass
			if constexpr(isrevorder){
				offsetlo = offsets[curlo + offsetsstride]--;// the next item will be placed one lower
				offsethi = offsets[curhi]++;// the next item will be placed one higher
			}else{
				offsetlo = offsets[curlo]++;// the next item will be placed one higher
				offsethi = offsets[curhi + offsetsstride]--;// the next item will be placed one lower
			}
			pdst[offsetlo] = plo;
			pdst[offsethi] = phi;
		}while(psrclo < psrchi);
		if(psrclo == psrchi){// fill in the final item for odd counts
			V *p{*psrclo};
			auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
			U out{indirectinput2<indirection1, indirection2, isindexed2, T>(im)};
			std::size_t cur{filtertop8<isabsvalue, issignmode, isfltpmode, T, U>(out)};
			std::size_t offset;// this is only allowed for the single-part version, containing just one sorting pass
			if constexpr(isrevorder){
				offset = offsets[cur + offsetsstride];
			}else{
				offset = offsets[cur];
			}
			pdst[offset] = p;
		}
	}
}

// multi-threading companion for the radixsortcopynoallocsingle() function implementation template for single-part types with indirection
// Do not use this function directly.
template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename X, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortcopynoallocsinglemtc(std::size_t count, V *const input[], V *output[], std::atomic_uintptr_t &atomiclightbarrier, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	// do not pass a nullptr here
	assert(input);
	assert(output);
	static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	X offsetscompanion[offsetsstride]{};// a sizeable amount of indices, but it's worth it, zeroed in advance here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
	[[maybe_unused]]
#endif
	std::conditional_t<std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>,
		std::atomic_uintptr_t &,// nothrow capable indirection1, let the compiler just discard this reference
		atomicvarwrapper> atomicguard{atomiclightbarrier};// may throw, so set up the guard
	radixsortnoallocsingleinitmtc<indirection1, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X>(count, input, output, offsetscompanion, varparameters...);

	X *offsets;
	{// barrier and pointer exchange with the main thread
		std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsetscompanion))};
		// detect exceptions
		if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
			if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the main thread produced an exception
		}
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed);
			}while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == other);
			// detect exceptions
			if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
				if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the main thread produced an exception
			}
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
				reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		offsets = reinterpret_cast<X *>(other);// retrieve the pointer
	}

	// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
	unsigned allareidentical{generateoffsetssinglemtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, X>(count, offsets, offsetscompanion)};

	{// barrier and allareidentical value exchange with the main thread
		// no exception detection required here
		++allareidentical;// send over a 1 or a 2
		while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == atomiclightbarrier.load(std::memory_order_relaxed)){
			spinpause();// catch up
		}
		std::uintptr_t other{atomiclightbarrier.fetch_add(allareidentical)};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed) - allareidentical;
			}while(!other);
		}
		// only one of the two threads can set the all are identical state
		allareidentical -= static_cast<unsigned>(other);// codes:
		// 0: continue processing
		// -1: input from the main thread
		// 1: input from this thread
	}

	if(!allareidentical)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
		[[likely]]
#endif
	{// perform the bidirectional 8-bit sorting sequence
		radixsortnoallocsinglemainmtc<indirection1, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X>(count, input, output, offsetscompanion, varparameters...);
	}
}

// radixsortcopynoalloc() function implementation template for single-part types with indirection
template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename X
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	, bool ismultithreadcapable = true
#endif
	, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	radixsortcopynoallocsingle1thread
#else
	radixsortcopynoallocsingle2thread
#endif
	(std::size_t count, V *const input[], V *output[], vararguments... varparameters)	noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	static bool constexpr ismultithreadcapable{false};
#endif
	if constexpr(ismultithreadcapable){
		assert(1 < std::thread::hardware_concurrency());// only use multi-threading if there is more than one hardware thread
		assert(15 <= count);// a 0 or 1 count array is only allowed here in single-threaded function mode
	}
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);
	// All the code in this function is adapted for count to be one below its input value here.
	--count;
	if(ismultithreadcapable || 0 < static_cast<std::ptrdiff_t>(count)){// a 0 or 1 count array is only allowed here in single-threaded function mode
		static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
		// conditionally enable multi-threading here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t, std::nullptr_t> atomiclightbarrier{};
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::future<void>, std::nullptr_t> asynchandle;

		// count the 256 configurations, all in one go
		if constexpr(ismultithreadcapable){
			try{
				asynchandle = std::async(std::launch::async, radixsortcopynoallocsinglemtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X, vararguments...>, count, input, output, std::ref(atomiclightbarrier), varparameters...);
				usemultithread = 1;
			}catch(...){// std::async may fail gracefully here
				assert(false);
			}
		}
		X offsets[offsetsstride * (2 - ismultithreadcapable)];// a sizeable amount of indices, but it's worth it
		std::memset(offsets, 0, offsetsstride * sizeof(X));// zeroed in advance here
		{// scope atomicguard, so it's always destructed before asynchandle
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			std::conditional_t<ismultithreadcapable,
				std::conditional_t<std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>,
					std::atomic_uintptr_t &,// nothrow capable indirection1, let the compiler just discard this reference
					atomicvarwrapper>,// may throw, so set up the guard
				std::nullptr_t> atomicguard{atomiclightbarrier};
			std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
				if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
				do{
					V *pa{input[i]};
					V *pb{input[i - 1]};
					auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
					output[i] = pa;
					auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
					output[i - 1] = pb;
					U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
					U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
					if constexpr(isabsvalue || isfltpmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
					}
					++offsets[cura];
					++offsets[curb];
					i -= 2;
				}while(0 < i);
				if(!(1 & i)){// fill in the final item for odd counts
					V *p{input[0]};
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					output[0] = p;
					U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
					if constexpr(isabsvalue || isfltpmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
					}
					++offsets[cur];
				}
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 8) >> 4) * 8;
				i -= 7;
				if(0 <= i)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
					[[likely]]
#endif
					do{
					V *pa{input[i + 7]};
					V *pb{input[i + 6]};
					V *pc{input[i + 5]};
					V *pd{input[i + 4]};
					if constexpr(isabsvalue != isfltpmode){// two-register filters only
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						output[i + 7] = pa;
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						output[i + 6] = pb;
						auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
						output[i + 5] = pc;
						auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
						output[i + 4] = pd;
						U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
						U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
						// register pressure performance issue on several platforms: first do the high half here
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
						++offsets[cura];
						++offsets[curb];
						++offsets[curc];
						++offsets[curd];
					}
					V *pe{input[i + 3]};
					V *pf{input[i + 2]};
					V *pg{input[i + 1]};
					V *ph{input[i]};
					if constexpr(isabsvalue != isfltpmode){// two-register filters only
						auto ime{indirectinput1<indirection1, isindexed2, T, V>(pe, varparameters...)};
						output[i + 3] = pe;
						auto imf{indirectinput1<indirection1, isindexed2, T, V>(pf, varparameters...)};
						output[i + 2] = pf;
						auto img{indirectinput1<indirection1, isindexed2, T, V>(pg, varparameters...)};
						output[i + 1] = pg;
						auto imh{indirectinput1<indirection1, isindexed2, T, V>(ph, varparameters...)};
						output[i] = ph;
						U cure{indirectinput2<indirection1, indirection2, isindexed2, T>(ime, varparameters...)};
						U curf{indirectinput2<indirection1, indirection2, isindexed2, T>(imf, varparameters...)};
						U curg{indirectinput2<indirection1, indirection2, isindexed2, T>(img, varparameters...)};
						U curh{indirectinput2<indirection1, indirection2, isindexed2, T>(imh, varparameters...)};
						// register pressure performance issue on several platforms: do the low half here second
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cure, curf, curg, curh);
						++offsets[cure];
						++offsets[curf];
						++offsets[curg];
						++offsets[curh];
					}else{
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						output[i + 7] = pa;
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						output[i + 6] = pb;
						auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
						output[i + 5] = pc;
						auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
						output[i + 4] = pd;
						auto ime{indirectinput1<indirection1, isindexed2, T, V>(pe, varparameters...)};
						output[i + 3] = pe;
						auto imf{indirectinput1<indirection1, isindexed2, T, V>(pf, varparameters...)};
						output[i + 2] = pf;
						auto img{indirectinput1<indirection1, isindexed2, T, V>(pg, varparameters...)};
						output[i + 1] = pg;
						auto imh{indirectinput1<indirection1, isindexed2, T, V>(ph, varparameters...)};
						output[i] = ph;
						U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
						U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
						U cure{indirectinput2<indirection1, indirection2, isindexed2, T>(ime, varparameters...)};
						U curf{indirectinput2<indirection1, indirection2, isindexed2, T>(imf, varparameters...)};
						U curg{indirectinput2<indirection1, indirection2, isindexed2, T>(img, varparameters...)};
						U curh{indirectinput2<indirection1, indirection2, isindexed2, T>(imh, varparameters...)};
						if constexpr(isabsvalue && isfltpmode){// one-register filters only
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd, cure, curf, curg, curh);
						}
						++offsets[cura];
						++offsets[curb];
						++offsets[curc];
						++offsets[curd];
						++offsets[cure];
						++offsets[curf];
						++offsets[curg];
						++offsets[curh];
					}
					i -= 8;
				}while(0 <= i);
				if(4 & i){// fill in the final four items for a remainder of 4 to 7
					V *pa{input[i + 7]};
					V *pb{input[i + 6]};
					V *pc{input[i + 5]};
					V *pd{input[i + 4]};
					auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
					output[i + 7] = pa;
					auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
					output[i + 6] = pb;
					auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
					output[i + 5] = pc;
					auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
					output[i + 4] = pd;
					i -= 4;// required for the "if(2 & i){" part
					U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
					U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
					U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
					U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
					if constexpr(isabsvalue || isfltpmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
					}
					++offsets[cura];
					++offsets[curb];
					++offsets[curc];
					++offsets[curd];
				}
				if(2 & i){// fill in the final two items for a remainder of 2 or 3
					V *pa{input[i + 7]};
					V *pb{input[i + 6]};
					auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
					output[i + 7] = pa;
					auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
					output[i + 6] = pb;
					U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
					U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
					if constexpr(isabsvalue || isfltpmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
					}
					++offsets[cura];
					++offsets[curb];
				}
				if(1 & i){// fill in the final item for odd counts
					V *p{input[0]};
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					output[0] = p;
					U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
					if constexpr(isabsvalue || isfltpmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
					}
					++offsets[cur];
				}
			}

			// barrier and pointer exchange with the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			std::conditional_t<ismultithreadcapable, X *, std::nullptr_t> offsetscompanion;
			if constexpr(ismultithreadcapable){
				std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsets) & -static_cast<std::intptr_t>(usemultithread))};
				// detect exceptions
				if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
					if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the companion thread produced an exception
				}
				// simply do not spin if usemultithread is zero
				if(usemultithread > other){
					do{
						spinpause();
						other = atomiclightbarrier.load(std::memory_order_relaxed);
					}while(reinterpret_cast<std::uintptr_t>(offsets) == other);
					// detect exceptions
					if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
						if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the companion thread produced an exception
					}
					// reset the barrier after use, only one thread will do this
					// no busy-wait dependency on this store, hence relaxed memory order is fine
						reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
					// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
				}
				// this will just be zero if usemultithread is zero
				offsetscompanion = reinterpret_cast<X *>(other);// retrieve the pointer
			}else offsetscompanion = nullptr;

			// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
			unsigned allareidentical{generateoffsetssingle<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, std::nullptr_t, X>(count, offsets, offsetscompanion, usemultithread)};

			// barrier and allareidentical value exchange with the companion thread
			// no exception detection required here
			if constexpr(ismultithreadcapable){
				allareidentical += usemultithread;// send over a 1 or a 2 when multithreading
				while(reinterpret_cast<std::uintptr_t>(offsets) == atomiclightbarrier.load(std::memory_order_relaxed)){
					spinpause();// catch up
				}
				std::uintptr_t other{atomiclightbarrier.fetch_add(allareidentical)};
				// simply do not spin if usemultithread is zero
				if(usemultithread > other){
					do{
						spinpause();
						other = atomiclightbarrier.load(std::memory_order_relaxed) - allareidentical;
					}while(!other);
				}
				// only one of the two threads can set the all are identical state
				allareidentical -= static_cast<unsigned>(other);// codes:
				// 0: continue processing
				// -1: input from the companion thread
				// 1: input from this thread
			}

			if(!allareidentical)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
				[[likely]]
#endif
			{// perform the bidirectional 8-bit sorting sequence
				radixsortnoallocsinglemain<indirection1, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, ismultithreadcapable, V, X>(count, input, output, offsets, usemultithread, varparameters...);
			}
		}
	}else if(0 == static_cast<std::ptrdiff_t>(count)) *output = *input;// copy the single element if the count is 1
}

// multi-threading companion for the radixsortnoallocsingle() function implementation template for single-part types with indirection
// Do not use this function directly.
template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename X, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortnoallocsinglemtc(std::size_t count, V *input[], V *buffer[], std::atomic_uintptr_t &atomiclightbarrier, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	// do not pass a nullptr here
	assert(input);
	assert(buffer);
	static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
	X offsetscompanion[offsetsstride]{};// a sizeable amount of indices, but it's worth it, zeroed in advance here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
	[[maybe_unused]]
#endif
	std::conditional_t<std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>,
		std::atomic_uintptr_t &,// nothrow capable indirection1, let the compiler just discard this reference
		atomicvarwrapper> atomicguard{atomiclightbarrier};// may throw, so set up the guard
	radixsortnoallocsingleinitmtc<indirection1, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X>(count, input, buffer, offsetscompanion, varparameters...);

	X *offsets;
	{// barrier and pointer exchange with the main thread
		std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsetscompanion))};
		// detect exceptions
		if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
			if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the main thread produced an exception
		}
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed);
			}while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == other);
			// detect exceptions
			if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
				if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the main thread produced an exception
			}
			// reset the barrier after use, only one thread will do this
			// no busy-wait dependency on this store, hence relaxed memory order is fine
				reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
			// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
		}
		offsets = reinterpret_cast<X *>(other);// retrieve the pointer
	}

	// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
	unsigned allareidentical{generateoffsetssinglemtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, X>(count, offsets, offsetscompanion)};

	{// barrier and allareidentical value exchange with the main thread
		// no exception detection required here
		++allareidentical;// send over a 1 or a 2
		while(reinterpret_cast<std::uintptr_t>(offsetscompanion) == atomiclightbarrier.load(std::memory_order_relaxed)){
			spinpause();// catch up
		}
		std::uintptr_t other{atomiclightbarrier.fetch_add(allareidentical)};
		if(!other){
			do{
				spinpause();
				other = atomiclightbarrier.load(std::memory_order_relaxed) - allareidentical;
			}while(!other);
		}
		// only one of the two threads can set the all are identical state
		allareidentical -= static_cast<unsigned>(other);// codes:
		// 0: continue processing
		// -1: input from the main thread
		// 1: input from this thread
	}

	if(!allareidentical)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
		[[likely]]
#endif
	{// perform the bidirectional 8-bit sorting sequence
		radixsortnoallocsinglemainmtc<indirection1, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X>(count, buffer, input, offsetscompanion, varparameters...);
	}
}

// radixsortnoalloc() function implementation template for single-part types with indirection
template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename X
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	, bool ismultithreadcapable = true
#endif
	, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_unsigned_v<X> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	radixsortnoallocsingle1thread
#else
	radixsortnoallocsingle2thread
#endif
	(std::size_t count, V *input[], V *buffer[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	using U = std::conditional_t<sizeof(T) < sizeof(unsigned), unsigned, T>;// assume zero-extension to be basically free for U on basically all modern machines
#if defined(RSBD8_THREAD_MAXIMUM) && 1 >= (RSBD8_THREAD_MAXIMUM)
	static bool constexpr ismultithreadcapable{false};
#endif
	if constexpr(ismultithreadcapable){
		assert(1 < std::thread::hardware_concurrency());// only use multi-threading if there is more than one hardware thread
		assert(15 <= count);// a 0 or 1 count array is only allowed here in single-threaded function mode
	}
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(buffer);
	// All the code in this function is adapted for count to be one below its input value here.
	--count;
	if(ismultithreadcapable || 0 < static_cast<std::ptrdiff_t>(count)){// a 0 or 1 count array is only allowed here in single-threaded function mode
		static std::size_t constexpr offsetsstride{CHAR_BIT * sizeof(T) * 256 / 8 - (isabsvalue && issignmode) * (127 + isfltpmode)};// shrink the offsets size if possible
		// conditionally enable multi-threading here
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::atomic_uintptr_t, std::nullptr_t> atomiclightbarrier{};
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
		[[maybe_unused]]
#endif
		std::conditional_t<ismultithreadcapable, std::future<void>, std::nullptr_t> asynchandle;

		// count the 256 configurations, all in one go
		if constexpr(ismultithreadcapable){
			try{
				asynchandle = std::async(std::launch::async, radixsortnoallocsinglemtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X, vararguments...>, count, input, buffer, std::ref(atomiclightbarrier), varparameters...);
				usemultithread = 1;
			}catch(...){// std::async may fail gracefully here
				assert(false);
			}
		}
		X offsets[offsetsstride * (2 - ismultithreadcapable)];// a sizeable amount of indices, but it's worth it
		std::memset(offsets, 0, offsetsstride * sizeof(X));// zeroed in advance here
		{// scope atomicguard, so it's always destructed before asynchandle
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			std::conditional_t<ismultithreadcapable,
				std::conditional_t<std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>,
					std::atomic_uintptr_t &,// nothrow capable indirection1, let the compiler just discard this reference
					atomicvarwrapper>,// may throw, so set up the guard
				std::nullptr_t> atomicguard{atomiclightbarrier};
			std::ptrdiff_t i{static_cast<std::ptrdiff_t>(count)};// if mulitithreaded, the half count will be rounded up in the companion thread
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: limit to two at a time when there's few registers
				if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 2) >> 2) * 2;
				do{
					V *pa{input[i]};
					V *pb{input[i - 1]};
					auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
					buffer[i] = pa;
					auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
					buffer[i - 1] = pb;
					U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
					U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
					if constexpr(isabsvalue || isfltpmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
					}
					++offsets[cura];
					++offsets[curb];
					i -= 2;
				}while(0 < i);
				if(!(1 & i)){// fill in the final item for odd counts
					V *p{input[0]};
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					buffer[0] = p;
					U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
					if constexpr(isabsvalue || isfltpmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
					}
					++offsets[cur];
				}
			}else{// architecture: do not limit as much when there's a reasonable amount of registers
				if constexpr(ismultithreadcapable) i -= -static_cast<std::ptrdiff_t>(usemultithread) & static_cast<std::ptrdiff_t>((count + 1 + 8) >> 4) * 8;
				i -= 7;
				if(0 <= i)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
					[[likely]]
#endif
					do{
					V *pa{input[i + 7]};
					V *pb{input[i + 6]};
					V *pc{input[i + 5]};
					V *pd{input[i + 4]};
					if constexpr(isabsvalue != isfltpmode){// two-register filters only
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						buffer[i + 7] = pa;
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						buffer[i + 6] = pb;
						auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
						buffer[i + 5] = pc;
						auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
						buffer[i + 4] = pd;
						U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
						U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
						// register pressure performance issue on several platforms: first do the high half here
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
						++offsets[cura];
						++offsets[curb];
						++offsets[curc];
						++offsets[curd];
					}
					V *pe{input[i + 3]};
					V *pf{input[i + 2]};
					V *pg{input[i + 1]};
					V *ph{input[i]};
					if constexpr(isabsvalue != isfltpmode){// two-register filters only
						auto ime{indirectinput1<indirection1, isindexed2, T, V>(pe, varparameters...)};
						buffer[i + 3] = pe;
						auto imf{indirectinput1<indirection1, isindexed2, T, V>(pf, varparameters...)};
						buffer[i + 2] = pf;
						auto img{indirectinput1<indirection1, isindexed2, T, V>(pg, varparameters...)};
						buffer[i + 1] = pg;
						auto imh{indirectinput1<indirection1, isindexed2, T, V>(ph, varparameters...)};
						buffer[i] = ph;
						U cure{indirectinput2<indirection1, indirection2, isindexed2, T>(ime, varparameters...)};
						U curf{indirectinput2<indirection1, indirection2, isindexed2, T>(imf, varparameters...)};
						U curg{indirectinput2<indirection1, indirection2, isindexed2, T>(img, varparameters...)};
						U curh{indirectinput2<indirection1, indirection2, isindexed2, T>(imh, varparameters...)};
						// register pressure performance issue on several platforms: do the low half here second
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cure, curf, curg, curh);
						++offsets[cure];
						++offsets[curf];
						++offsets[curg];
						++offsets[curh];
					}else{
						auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
						buffer[i + 7] = pa;
						auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
						buffer[i + 6] = pb;
						auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
						buffer[i + 5] = pc;
						auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
						buffer[i + 4] = pd;
						auto ime{indirectinput1<indirection1, isindexed2, T, V>(pe, varparameters...)};
						buffer[i + 3] = pe;
						auto imf{indirectinput1<indirection1, isindexed2, T, V>(pf, varparameters...)};
						buffer[i + 2] = pf;
						auto img{indirectinput1<indirection1, isindexed2, T, V>(pg, varparameters...)};
						buffer[i + 1] = pg;
						auto imh{indirectinput1<indirection1, isindexed2, T, V>(ph, varparameters...)};
						buffer[i] = ph;
						U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
						U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
						U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
						U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
						U cure{indirectinput2<indirection1, indirection2, isindexed2, T>(ime, varparameters...)};
						U curf{indirectinput2<indirection1, indirection2, isindexed2, T>(imf, varparameters...)};
						U curg{indirectinput2<indirection1, indirection2, isindexed2, T>(img, varparameters...)};
						U curh{indirectinput2<indirection1, indirection2, isindexed2, T>(imh, varparameters...)};
						if constexpr(isabsvalue && isfltpmode){// one-register filters only
							filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd, cure, curf, curg, curh);
						}
						++offsets[cura];
						++offsets[curb];
						++offsets[curc];
						++offsets[curd];
						++offsets[cure];
						++offsets[curf];
						++offsets[curg];
						++offsets[curh];
					}
					i -= 8;
				}while(0 <= i);
				if(4 & i){// fill in the final four items for a remainder of 4 to 7
					V *pa{input[i + 7]};
					V *pb{input[i + 6]};
					V *pc{input[i + 5]};
					V *pd{input[i + 4]};
					auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
					buffer[i + 7] = pa;
					auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
					buffer[i + 6] = pb;
					auto imc{indirectinput1<indirection1, isindexed2, T, V>(pc, varparameters...)};
					buffer[i + 5] = pc;
					auto imd{indirectinput1<indirection1, isindexed2, T, V>(pd, varparameters...)};
					buffer[i + 4] = pd;
					i -= 4;// required for the "if(2 & i){" part
					U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
					U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
					U curc{indirectinput2<indirection1, indirection2, isindexed2, T>(imc, varparameters...)};
					U curd{indirectinput2<indirection1, indirection2, isindexed2, T>(imd, varparameters...)};
					if constexpr(isabsvalue || isfltpmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb, curc, curd);
					}
					++offsets[cura];
					++offsets[curb];
					++offsets[curc];
					++offsets[curd];
				}
				if(2 & i){// fill in the final two items for a remainder of 2 or 3
					V *pa{input[i + 7]};
					V *pb{input[i + 6]};
					auto ima{indirectinput1<indirection1, isindexed2, T, V>(pa, varparameters...)};
					buffer[i + 7] = pa;
					auto imb{indirectinput1<indirection1, isindexed2, T, V>(pb, varparameters...)};
					buffer[i + 6] = pb;
					U cura{indirectinput2<indirection1, indirection2, isindexed2, T>(ima, varparameters...)};
					U curb{indirectinput2<indirection1, indirection2, isindexed2, T>(imb, varparameters...)};
					if constexpr(isabsvalue || isfltpmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cura, curb);
					}
					++offsets[cura];
					++offsets[curb];
				}
				if(1 & i){// fill in the final item for odd counts
					V *p{input[0]};
					auto im{indirectinput1<indirection1, isindexed2, T, V>(p, varparameters...)};
					buffer[0] = p;
					U cur{indirectinput2<indirection1, indirection2, isindexed2, T>(im, varparameters...)};
					if constexpr(isabsvalue || isfltpmode){
						filterinput<isabsvalue, issignmode, isfltpmode, T>(cur);
					}
					++offsets[cur];
				}
			}

			// barrier and pointer exchange with the companion thread
#if defined(__has_cpp_attribute) && __has_cpp_attribute(maybe_unused)
			[[maybe_unused]]
#endif
			std::conditional_t<ismultithreadcapable, X *, std::nullptr_t> offsetscompanion;
			if constexpr(ismultithreadcapable){
				std::uintptr_t other{atomiclightbarrier.exchange(reinterpret_cast<std::uintptr_t>(offsets) & -static_cast<std::intptr_t>(usemultithread))};
				// detect exceptions
				if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
					if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the companion thread produced an exception
				}
				// simply do not spin if usemultithread is zero
				if(usemultithread > other){
					do{
						spinpause();
						other = atomiclightbarrier.load(std::memory_order_relaxed);
					}while(reinterpret_cast<std::uintptr_t>(offsets) == other);
					// detect exceptions
					if constexpr(!std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
						if(reinterpret_cast<std::uintptr_t>(&atomiclightbarrier) == other) return;// the companion thread produced an exception
					}
					// reset the barrier after use, only one thread will do this
					// no busy-wait dependency on this store, hence relaxed memory order is fine
						reinterpret_cast<std::uintptr_t &>(atomiclightbarrier) = 0;//atomiclightbarrier.store(0, std::memory_order_relaxed); TODO: fix this, as the original failed to inline anything in an early testing round
					// the next write to atomiclightbarrier will simply lock on and synchronise based on 0
				}
				// this will just be zero if usemultithread is zero
				offsetscompanion = reinterpret_cast<X *>(other);// retrieve the pointer
			}else offsetscompanion = nullptr;

			// transform counts into base offsets for each set of 256 items, both for the low and high half of offsets here
			unsigned allareidentical{generateoffsetssingle<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, std::nullptr_t, X>(count, offsets, offsetscompanion, usemultithread)};

			// barrier and allareidentical value exchange with the companion thread
			// no exception detection required here
			if constexpr(ismultithreadcapable){
				allareidentical += usemultithread;// send over a 1 or a 2 when multithreading
				while(reinterpret_cast<std::uintptr_t>(offsets) == atomiclightbarrier.load(std::memory_order_relaxed)){
					spinpause();// catch up
				}
				std::uintptr_t other{atomiclightbarrier.fetch_add(allareidentical)};
				// simply do not spin if usemultithread is zero
				if(usemultithread > other){
					do{
						spinpause();
						other = atomiclightbarrier.load(std::memory_order_relaxed) - allareidentical;
					}while(!other);
				}
				// only one of the two threads can set the all are identical state
				allareidentical -= static_cast<unsigned>(other);// codes:
				// 0: continue processing
				// -1: input from the companion thread
				// 1: input from this thread
			}

			if(!allareidentical)
#if defined(__has_cpp_attribute) && __has_cpp_attribute(likely)
				[[likely]]
#endif
			{// perform the bidirectional 8-bit sorting sequence
				radixsortnoallocsinglemain<indirection1, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, ismultithreadcapable, V, X>(count, buffer, input, offsets, usemultithread, varparameters...);
			}
		}
	}
}

// 1- to 16-way multithreading function reroutes

// Reroutes to the 1- or 2-thread functions for single-part types
// the single-part types do not benefit from more than two threads in practice

template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T),
	void> radixsortcopynoallocsingle(std::size_t count, T const input[], T output[])noexcept{
	// select the smallest unsigned type for the indices
	// architecture: this compiles into just a few conditional move instructions on most platforms
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortcopynoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>};
	if(0xFFu < count){
		if(1 < std::thread::hardware_concurrency()){
			pcall = radixsortcopynoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, true>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, true>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, true>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, true>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, true>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, true>;
			}
		}else{// single-threaded
			pcall = radixsortcopynoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, false>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, false>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, false>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, false>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, false>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>;
			}
		}
	}
#else// single-threaded only
	auto pcall{radixsortcopynoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t>};
	if constexpr(ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
		pcall = radixsortcopynoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long>;
	}
	if constexpr(ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
		pcall = radixsortcopynoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long>;
	}
	if constexpr(UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
		pcall = radixsortcopynoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned>;
	}
	if constexpr(USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
		pcall = radixsortcopynoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short>;
	}
	if constexpr(UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
		pcall = radixsortcopynoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char>;
	}
#endif
	pcall(count, input, output);// architecture: indirect calls only have a modest performance penalty on most platforms
}

template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T),
	void> radixsortnoallocsingle(std::size_t count, T input[], T buffer[])noexcept{
	// select the smallest unsigned type for the indices
	// architecture: this compiles into just a few conditional move instructions on most platforms
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>};
	if(0xFFu < count){
		if(1 < std::thread::hardware_concurrency()){
			pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, true>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, true>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, true>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, true>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, true>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, true>;
			}
		}else{// single-threaded
			pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, false>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, false>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, false>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, false>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, false>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>;
			}
		}
	}
#else// single-threaded only
	auto pcall{radixsortnoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t>};
	if constexpr(ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
		pcall = radixsortnoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long>;
	}
	if constexpr(ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
		pcall = radixsortnoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long>;
	}
	if constexpr(UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
		pcall = radixsortnoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned>;
	}
	if constexpr(USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
		pcall = radixsortnoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short>;
	}
	if constexpr(UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
		pcall = radixsortnoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char>;
	}
#endif
	if constexpr((isabsvalue && issignmode) ||// both regular absolute modes
		(!isabsvalue && issignmode && isfltpmode)){// regular floating-point mode
		pcall(count, input, buffer);// architecture: indirect calls only have a modest performance penalty on most platforms
	}else pcall(count, input);// architecture: indirect calls only have a modest performance penalty on most platforms
}

template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T) &&
	!(isabsvalue && issignmode) &&// both regular absolute modes
	!(!isabsvalue && issignmode && isfltpmode),// regular floating-point mode
	void> radixsortnoallocsingle(std::size_t count, T input[])noexcept{
	// select the smallest unsigned type for the indices
	// architecture: this compiles into just a few conditional move instructions on most platforms
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>};
	if(0xFFu < count){
		if(1 < std::thread::hardware_concurrency()){
			pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, true>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, true>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, true>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, true>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, true>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, true>;
			}
		}else{// single-threaded
			pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, false>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, false>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, false>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, false>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, false>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocsingle2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>;
			}
		}
	}
#else// single-threaded only
	auto pcall{radixsortnoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t>};
	if constexpr(ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
		pcall = radixsortnoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long>;
	}
	if constexpr(ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
		pcall = radixsortnoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long>;
	}
	if constexpr(UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
		pcall = radixsortnoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned>;
	}
	if constexpr(USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
		pcall = radixsortnoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short>;
	}
	if constexpr(UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
		pcall = radixsortnoallocsingle1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char>;
	}
#endif
	pcall(count, input);// architecture: indirect calls only have a modest performance penalty on most platforms
}

template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortcopynoallocsingle(std::size_t count, V *const input[], V *output[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	// select the smallest unsigned type for the indices
	// architecture: this compiles into just a few conditional move instructions on most platforms
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortcopynoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>};
	if(0xFFu < count){
		if(1 < std::thread::hardware_concurrency()){
			pcall = radixsortcopynoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, true, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, true, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, true, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, true, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, true, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, true, vararguments...>;
			}
		}else{// single-threaded
			pcall = radixsortcopynoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, false, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, false, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, false, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, false, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, false, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>;
			}
		}
	}
#else// single-threaded only
	auto pcall{radixsortcopynoallocsingle1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, vararguments...>};
	if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
		pcall = radixsortcopynoallocsingle1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, vararguments...>;
	}
	if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
		pcall = radixsortcopynoallocsingle1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, vararguments...>;
	}
	if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
		pcall = radixsortcopynoallocsingle1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, vararguments...>;
	}
	if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
		pcall = radixsortcopynoallocsingle1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, vararguments...>;
	}
	if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
		pcall = radixsortcopynoallocsingle1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, vararguments...>;
	}
#endif
	pcall(count, input, output, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
}

template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortnoallocsingle(std::size_t count, V *input[], V *buffer[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	// select the smallest unsigned type for the indices
	// architecture: this compiles into just a few conditional move instructions on most platforms
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortnoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>};
	if(0xFFu < count){
		if(1 < std::thread::hardware_concurrency()){
			pcall = radixsortnoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, true, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, true, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, true, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, true, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, true, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, true, vararguments...>;
			}
		}else{// single-threaded
			pcall = radixsortnoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, false, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, false, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, false, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, false, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, false, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocsingle2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>;
			}
		}
	}
#else// single-threaded only
	auto pcall{radixsortnoallocsingle1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, vararguments...>};
	if constexpr(ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
		pcall = radixsortnoallocsingle1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, vararguments...>;
	}
	if constexpr(ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
		pcall = radixsortnoallocsingle1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, vararguments...>;
	}
	if constexpr(UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
		pcall = radixsortnoallocsingle1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, vararguments...>;
	}
	if constexpr(USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
		pcall = radixsortnoallocsingle1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, vararguments...>;
	}
	if constexpr(UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
		pcall = radixsortnoallocsingle1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, vararguments...>;
	}
#endif
	pcall(count, input, buffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
}

#if defined(RSBD8_THREAD_MAXIMUM) && 4 > (RSBD8_THREAD_MAXIMUM)
// Reroutes to the 1- or 2-thread functions (variants without indirection)

template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void> radixsortcopynoallocmulti(std::size_t count, T const input[], T output[], T buffer[])noexcept{
	// select the smallest unsigned type for the indices
	// architecture: this compiles into just a few conditional move instructions on most platforms
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>};
	if(0xFFu < count){
		if(1 < std::thread::hardware_concurrency()){
			pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, true>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, true>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, true>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, true>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, true>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, true>;
			}
		}else{// single-threaded
			pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, false>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, false>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, false>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, false>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, false>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>;
			}
		}
	}
#else// single-threaded only
	auto pcall{radixsortcopynoallocmulti1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t>};
	if constexpr(ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
		pcall = radixsortcopynoallocmulti1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long>;
	}
	if constexpr(ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
		pcall = radixsortcopynoallocmulti1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long>;
	}
	if constexpr(UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
		pcall = radixsortcopynoallocmulti1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned>;
	}
	if constexpr(USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
		pcall = radixsortcopynoallocmulti1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short>;
	}
	if constexpr(UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
		pcall = radixsortcopynoallocmulti1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char>;
	}
#endif
	pcall(count, input, output, buffer);// architecture: indirect calls only have a modest performance penalty on most platforms
}

template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void> radixsortnoallocmulti(std::size_t count, T input[], T buffer[], bool movetobuffer = false)noexcept{
	// select the smallest unsigned type for the indices
	// architecture: this compiles into just a few conditional move instructions on most platforms
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>};
	if(0xFFu < count){
		if(1 < std::thread::hardware_concurrency()){
			pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, true>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, true>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, true>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, true>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, true>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, true>;
			}
		}else{// single-threaded
			pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, false>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, false>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, false>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, false>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, false>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>;
			}
		}
	}
#else// single-threaded only
	auto pcall{radixsortnoallocmulti1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t>};
	if constexpr(ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
		pcall = radixsortnoallocmulti1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long>;
	}
	if constexpr(ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
		pcall = radixsortnoallocmulti1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long>;
	}
	if constexpr(UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
		pcall = radixsortnoallocmulti1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned>;
	}
	if constexpr(USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
		pcall = radixsortnoallocmulti1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short>;
	}
	if constexpr(UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
		pcall = radixsortnoallocmulti1thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char>;
	}
#endif
	pcall(count, input, buffer, movetobuffer);// architecture: indirect calls only have a modest performance penalty on most platforms
}
#endif

#if defined(RSBD8_THREAD_MAXIMUM) && 6 > (RSBD8_THREAD_MAXIMUM)
// Reroutes to the 1- or 2-thread functions (variants with indirection)

template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortcopynoallocmulti(std::size_t count, V *const input[], V *output[], V *buffer[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	// select the smallest unsigned type for the indices
	// architecture: this compiles into just a few conditional move instructions on most platforms
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>};
	if(0xFFu < count){
		if(1 < std::thread::hardware_concurrency()){
			pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, true, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, true, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, true, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, true, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, true, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, true, vararguments...>;
			}
		}else{// single-threaded
			pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, false, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, false, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, false, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, false, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, false, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>;
			}
		}
	}
#else// single-threaded only
	auto pcall{radixsortcopynoallocmulti1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, vararguments...>};
	if constexpr(ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
		pcall = radixsortcopynoallocmulti1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, vararguments...>;
	}
	if constexpr(ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
		pcall = radixsortcopynoallocmulti1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, vararguments...>;
	}
	if constexpr(UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
		pcall = radixsortcopynoallocmulti1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, vararguments...>;
	}
	if constexpr(USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
		pcall = radixsortcopynoallocmulti1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, vararguments...>;
	}
	if constexpr(UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
		pcall = radixsortcopynoallocmulti1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, vararguments...>;
	}
#endif
	pcall(count, input, output, buffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
}

template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortnoallocmulti(std::size_t count, V *input[], V *buffer[], bool movetobuffer = false, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	// select the smallest unsigned type for the indices
	// architecture: this compiles into just a few conditional move instructions on most platforms
#if !defined(RSBD8_THREAD_MAXIMUM) || 1 < (RSBD8_THREAD_MAXIMUM)
	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>};
	if(0xFFu < count){
		if(1 < std::thread::hardware_concurrency()){
			pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, true, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, true, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, true, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, true, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, true, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, true, vararguments...>;
			}
		}else{// single-threaded
			pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, false, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, false, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, false, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, false, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, false, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>;
			}
		}
	}
#else// single-threaded only
	auto pcall{radixsortnoallocmulti1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, vararguments...>};
	if constexpr(ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
		pcall = radixsortnoallocmulti1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, vararguments...>;
	}
	if constexpr(ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
		pcall = radixsortnoallocmulti1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, vararguments...>;
	}
	if constexpr(UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
		pcall = radixsortnoallocmulti1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, vararguments...>;
	}
	if constexpr(USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
		pcall = radixsortnoallocmulti1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, vararguments...>;
	}
	if constexpr(UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
		pcall = radixsortnoallocmulti1thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, vararguments...>;
	}
#endif
	pcall(count, input, buffer, movetobuffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
}
#endif

#if !defined(RSBD8_THREAD_MAXIMUM) || 4 <= (RSBD8_THREAD_MAXIMUM)
// Functions to establish the initial treshold for beyond 2-way multithreading

// function to establish the initial treshold for 4-way multithreading
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
constexpr RSBD8_FUNC_INLINE std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	std::size_t> base4waythreshold()noexcept{
	// TODO: refine this formula further with more benchmarking data
	static std::size_t constexpr typebitsize{
		(std::is_same_v<longdoubletest128, T> ||
		std::is_same_v<longdoubletest96, T> ||
		std::is_same_v<longdoubletest80, T>)? 80 : CHAR_BIT * sizeof(T)};
	static std::size_t constexpr typebitsizesqr{typebitsize * typebitsize};
	// for unfiltered 16-bit it's 80 GiB, and for half-precision floating point it's 70 GiB
	// for unfiltered 32-bit it's 5 GiB, and for float it's 4.375 GiB
	// for unfiltered 64-bit it's 320 MiB, and for double it's 280 MiB
	// for unfiltered 80-bit it's 131.072 MiB, and for 80-bit floating point it's 114.688 MiB
	static double constexpr base{// inverse quintic exponential scaling
		0x5p43 / static_cast<double>(typebitsize * typebitsizesqr * typebitsizesqr)
		* (isdescsort? 15. / 16. : 1.)// descending sort requires slightly more work in the intermediate sorting phase
		* (isrevorder? 7. / 8. : 1.)// reverse ordering requires more memory work in the initial sorting phase
		* ((isabsvalue && isfltpmode)? 15. / 16. : 1.)// 2 modes with one extra filtering step per input value
		* ((isabsvalue != isfltpmode)? 7. / 8. : 1.)// 4 modes with around three extra filtering steps per input value
	};
	// apply clamping and rounding typecast
	// very inefficient rounding on a truncation cast, as the std namespace rounding typecast functions do not grant constexpr
	static double constexpr intermediate{base - (-static_cast<double>(PTRDIFF_MIN) + ((base < -static_cast<double>(PTRDIFF_MIN))? .5 : -.5))};
	// signed typecast on the intermediate, to avoid the issues in the standard with unsigned typecasts from floating point
	return{static_cast<std::size_t>(static_cast<std::ptrdiff_t>(std::min(intermediate, static_cast<double>(PTRDIFF_MAX)))) - static_cast<std::size_t>(PTRDIFF_MIN)};
}

// function to establish the initial treshold for 6-way multithreading
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
constexpr RSBD8_FUNC_INLINE std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	std::size_t> base6waythreshold()noexcept{
	// TODO: refine this formula further with more benchmarking data
	static std::size_t constexpr typebitsize{
		(std::is_same_v<longdoubletest128, T> ||
		std::is_same_v<longdoubletest96, T> ||
		std::is_same_v<longdoubletest80, T>)? 80 : CHAR_BIT * sizeof(T)};
	static std::size_t constexpr typebitsizecub{typebitsize * typebitsize * typebitsize};
	static std::size_t constexpr typebitsizeset{typebitsizecub * typebitsizecub};
	// for unfiltered 16-bit it's 32 TiB, and for half-precision floating point it's 28 TiB
	// for unfiltered 32-bit it's 16 GiB, and for float it's 14 GiB
	// for unfiltered 64-bit it's 8 MiB, and for double it's 7 MiB
	// for unfiltered 80-bit it's 703.687 KiB, and for 80-bit floating point it's 615.727 KiB
	static double constexpr base{// inverse duodecic exponential scaling
		0x1p92 / static_cast<double>(typebitsizeset * typebitsizeset)
		* (isdescsort? 15. / 16. : 1.)// descending sort requires slightly more work in the intermediate sorting phase
		* (isrevorder? 7. / 8. : 1.)// reverse ordering requires more memory work in the initial sorting phase
		* ((isabsvalue && isfltpmode)? 15. / 16. : 1.)// 2 modes with one extra filtering step per input value
		* ((isabsvalue != isfltpmode)? 7. / 8. : 1.)// 4 modes with around three extra filtering steps per input value
	};
	// apply clamping and rounding typecast
	// very inefficient rounding on a truncation cast, as the std namespace rounding typecast functions do not grant constexpr
	static double constexpr intermediate{base - (-static_cast<double>(PTRDIFF_MIN) + ((base < -static_cast<double>(PTRDIFF_MIN))? .5 : -.5))};
	// signed typecast on the intermediate, to avoid the issues in the standard with unsigned typecasts from floating point
	return{static_cast<std::size_t>(static_cast<std::ptrdiff_t>(std::min(intermediate, static_cast<double>(PTRDIFF_MAX)))) - static_cast<std::size_t>(PTRDIFF_MIN)};
}

// function to establish the initial treshold for 8-way multithreading
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
constexpr RSBD8_FUNC_INLINE std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	std::size_t> base8waythreshold()noexcept{
	// TODO: refine this formula further with more benchmarking data
	static std::size_t constexpr typebitsize{
		(std::is_same_v<longdoubletest128, T> ||
		std::is_same_v<longdoubletest96, T> ||
		std::is_same_v<longdoubletest80, T>)? 80 : CHAR_BIT * sizeof(T)};
	// for unfiltered 16-bit it's 128 GiB, and for half-precision floating point it's 112 GiB
	// for unfiltered 32-bit it's 32 GiB, and for float it's 28 GiB
	// for unfiltered 64-bit it's 8 GiB, and for double it's 7 GiB
	// for unfiltered 80-bit it's 5.12 GiB, and for 80-bit floating point it's 4.48 GiB
	static double constexpr base{// inverse cubic exponential scaling
		0x1p48 / static_cast<double>(typebitsize * typebitsize * typebitsize)
		* (isdescsort? 15. / 16. : 1.)// descending sort requires slightly more work in the intermediate sorting phase
		* (isrevorder? 7. / 8. : 1.)// reverse ordering requires more memory work in the initial sorting phase
		* ((isabsvalue && isfltpmode)? 15. / 16. : 1.)// 2 modes with one extra filtering step per input value
		* ((isabsvalue != isfltpmode)? 7. / 8. : 1.)// 4 modes with around three extra filtering steps per input value
	};
	// apply clamping and rounding typecast
	// very inefficient rounding on a truncation cast, as the std namespace rounding typecast functions do not grant constexpr
	static double constexpr intermediate{base - (-static_cast<double>(PTRDIFF_MIN) + ((base < -static_cast<double>(PTRDIFF_MIN))? .5 : -.5))};
	// signed typecast on the intermediate, to avoid the issues in the standard with unsigned typecasts from floating point
	return{static_cast<std::size_t>(static_cast<std::ptrdiff_t>(std::min(intermediate, static_cast<double>(PTRDIFF_MAX)))) - static_cast<std::size_t>(PTRDIFF_MIN)};
}

// function to establish the initial treshold for 16-way multithreading
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
constexpr RSBD8_FUNC_INLINE std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	std::size_t> base16waythreshold()noexcept{
	// TODO: refine this formula further with more benchmarking data
	static std::size_t constexpr typebitsize{
		(std::is_same_v<longdoubletest128, T> ||
		std::is_same_v<longdoubletest96, T> ||
		std::is_same_v<longdoubletest80, T>)? 80 : CHAR_BIT * sizeof(T)};
	// for unfiltered 16-bit it's 256 GiB, and for half-precision floating point it's 224 GiB
	// for unfiltered 32-bit it's 128 GiB, and for float it's 112 GiB
	// for unfiltered 64-bit it's 64 GiB, and for double it's 56 GiB
	// for unfiltered 80-bit it's 51.2 GiB, and for 80-bit floating point it's 44.8 GiB
	static double constexpr base{// inverse square scaling
		0x1p45 / static_cast<double>(typebitsize * typebitsize)
		* (isdescsort? 15. / 16. : 1.)// descending sort requires slightly more work in the intermediate sorting phase
		* (isrevorder? 7. / 8. : 1.)// reverse ordering requires more memory work in the initial sorting phase
		* ((isabsvalue && isfltpmode)? 15. / 16. : 1.)// 2 modes with one extra filtering step per input value
		* ((isabsvalue != isfltpmode)? 7. / 8. : 1.)// 4 modes with around three extra filtering steps per input value
	};
	// apply clamping and rounding typecast
	// very inefficient rounding on a truncation cast, as the std namespace rounding typecast functions do not grant constexpr
	static double constexpr intermediate{base - (-static_cast<double>(PTRDIFF_MIN) + ((base < -static_cast<double>(PTRDIFF_MIN))? .5 : -.5))};
	// signed typecast on the intermediate, to avoid the issues in the standard with unsigned typecasts from floating point
	return{static_cast<std::size_t>(static_cast<std::ptrdiff_t>(std::min(intermediate, static_cast<double>(PTRDIFF_MAX)))) - static_cast<std::size_t>(PTRDIFF_MIN)};
}

// Helper functions for converting inputs to perform unsigned comparisons in a final merging phase
// these are altered copies of the filterinput() functions to have an extra final filtering step, and skip processing for signed inputs
// nothing will be processed when using these on unfiltered integer inputs

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	std::conditional_t<std::is_same_v<longdoubletest128, T>, longdoubletest128,
#endif
	longdoubletest96
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	>
#endif
	> convertinput(std::uint_least64_t curm, U cure)noexcept{
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curp{static_cast<std::int_least16_t>(cure)};
		if constexpr(isfltpmode){
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
			curo += curo;
			cure = curo;
		}else if constexpr(!issignmode){
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carry;
			curm = __builtin_addcll(curm, curm, 0, &carry);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			curm = __builtin_addcl(curm, curm, 0, &carry);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymid, carry;
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo = __builtin_addcl(curmlo, curmlo, 0, &carrymid);
			curmhi = __builtin_addcl(curmhi, curmhi, carrymid, &carry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
			unsigned short checkcarry;
			curo = __builtin_addcs(curo, curo, static_cast<unsigned short>(carry), &checkcarry);
			static_cast<void>(checkcarry);
#elif defined(_M_X64)
			unsigned char checkcarry{_addcarry_u16(_addcarry_u64(0, curm, curm, &curm), curo, curo, &curo)};
			static_cast<void>(checkcarry);
#elif defined(_M_IX86)
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			unsigned char checkcarry{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlo, curmlo, &curmlo), curmhi, curmhi, &curmhi), curo, curo, &curo)};
			static_cast<void>(checkcarry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#else
			std::uint_least64_t curmtmp{curm};
			curm += curm;
			curo += static_cast<std::uint_least16_t>(curo);
			curo += curm < curmtmp;
#endif
			cure = curo;
		}
		curp >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curq{static_cast<std::uint_least64_t>(curp)};// sign-extend
#else
		std::uint_least32_t curq{static_cast<std::uint_least32_t>(curp)};// sign-extend
#endif
		if constexpr(isfltpmode) cure >>= 1;
		if constexpr(issignmode){
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carry;
			curm = __builtin_addcll(curm, curq, 0, &carry);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			curm = __builtin_addcl(curm, curq, 0, &carry);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymid, carry;
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo = __builtin_addcl(curmlo, curq, 0, &carrymid);
			curmhi = __builtin_addcl(curmhi, curq, carrymid, &carry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
			unsigned short checkcarry;
			curo = __builtin_addcs(curo, static_cast<unsigned short>(curq), static_cast<unsigned short>(carry), &checkcarry);
			static_cast<void>(checkcarry);
#elif defined(_M_X64)
			unsigned char checkcarry{_addcarry_u16(_addcarry_u64(0, curm, curq, &curm), curo, static_cast<std::uint_least16_t>(curq), &curo)};
			static_cast<void>(checkcarry);
#elif defined(_M_IX86)
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			unsigned char checkcarry{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlo, curq, &curmlo), curmhi, curq, &curmhi), curo, static_cast<std::uint_least16_t>(curq), &curo)};
			static_cast<void>(checkcarry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#elif 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
			curm += curq;
			curo += static_cast<std::uint_least16_t>(curq);
			curo += curm < curq;
#else
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo += curq;
			curmhi += curq;
			curmhi += curmlo < curq;
			curo += static_cast<std::uint_least16_t>(curq);
			curo += curmhi < curq;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
			cure = curo;
		}
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		curm ^= curq;
#else
		std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
		curmlo ^= curq;
		curmhi ^= curq;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
		curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
		cure ^= static_cast<U>(curq);
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		if constexpr(issignmode) cure &= 0xFFFFu >> 1;
		else{
			std::uint_least16_t curo{static_cast<std::uint_least16_t>(cure)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carry;
			curm = __builtin_addcll(curm, curm, 0, &carry);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carry;
			curm = __builtin_addcl(curm, curm, 0, &carry);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymid, carry;
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			curmlo = __builtin_addcl(curmlo, curmlo, 0, &carrymid);
			curmhi = __builtin_addcl(curmhi, curmhi, carrymid, &carry);
#endif
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
			unsigned short carrysign;
			curo = __builtin_addcs(curo, curo, static_cast<unsigned short>(carry), &carrysign);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long checkcarry;
			curm = __builtin_subcll(curm, 0xFFFFFFFFFFFFFFFFu, static_cast<unsigned long long>(carrysign), &checkcarry);// flip the least significant bit
#else
			unsigned long checkcarry;
			curm = __builtin_subcl(curm, 0xFFFFFFFFFFFFFFFFu, static_cast<unsigned long>(carrysign), &checkcarry);// flip the least significant bit
#endif
#else
			unsigned long checkcarry;
			curmlo = __builtin_subcl(curmlo, 0xFFFFFFFFu, static_cast<unsigned long>(carrysign), &checkcarry);// flip the least significant bit
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#endif
#elif defined(_M_X64)
			unsigned char carrysign{_addcarry_u16(_addcarry_u64(0, curm, curm, &curm), curo, curo, &curo)};
			unsigned char checkcarry{_subborrow_u64(carrysign, curm, 0xFFFFFFFFFFFFFFFFu, &curm)};// flip the least significant bit
			static_cast<void>(checkcarry);
#elif defined(_M_IX86)
			std::uint_least32_t curmlo{static_cast<std::uint_least32_t>(curm & 0xFFFFFFFFu)}, curmhi{static_cast<std::uint_least32_t>(curm >> 32)};// decompose
			unsigned char carrysign{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlo, curmlo, &curmlo), curmhi, curmhi, &curmhi), curo, curo, &curo)};
			unsigned char checkcarry{_subborrow_u32(carrysign, curmlo, 0xFFFFFFFFu, &curmlo)};// flip the least significant bit
			static_cast<void>(checkcarry);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurm[2]{curmlo, curmhi};
			curm = *reinterpret_cast<std::uint_least64_t *>(acurm);// recompose
#else
			std::uint_least64_t curmtmp{curm};
			curm += curm;
			std::uint_least16_t curotmp{curo};
			curo += curo;
			curo += curm < curmtmp;
			curm += curo >= curotmp;// flip the least significant bit
#endif
			cure = curo;
		}
	}
	if constexpr(!isabsvalue && issignmode) cure += static_cast<U>(1) << 15;// flip the sign bit
	assert(cure <= 0xFFFFu);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	return{curm, cure};
#else
	return{curm, static_cast<std::uint_least32_t>(cure)};
#endif
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>,
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	std::conditional_t<std::is_same_v<longdoubletest128, T>, longdoubletest128,
#endif
	longdoubletest96
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	>
#endif
	> convertinput(T cur)noexcept{
	using U =
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::conditional_t<128 == CHAR_BIT * sizeof(T), std::uint_least64_t,
#endif
		unsigned
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		>
#endif
		;// assume zero-extension to be basically free for U on basically all modern machines
	return{convertinput<isabsvalue, issignmode, isfltpmode, T>(cur.mantissa, static_cast<U>(cur.signexponent))};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	std::conditional_t<std::is_same_v<longdoubletest128, T>, std::pair<longdoubletest128, longdoubletest128>,
#endif
	std::pair<longdoubletest96, longdoubletest96>
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	>
#endif
	> convertinput(std::uint_least64_t curma, U curea, std::uint_least64_t curmb, U cureb)noexcept{
	using W = decltype(T::signexponent);
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curpa{static_cast<std::int_least16_t>(curea)};
		std::int_least16_t curpb{static_cast<std::int_least16_t>(cureb)};
		if constexpr(isfltpmode){
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			curoa += curoa;
			curea = curoa;
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
			curob += curob;
			cureb = curob;
		}else if constexpr(!issignmode){
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			curma = __builtin_addcll(curma, curma, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			curma = __builtin_addcl(curma, curma, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymida, carrya;
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa = __builtin_addcl(curmloa, curmloa, 0, &carrymida);
			curmhia = __builtin_addcl(curmhia, curmhia, carrymida, &carrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, curoa, static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			curmb = __builtin_addcll(curmb, curmb, 0, &carryb);
#else
			unsigned long carryb;
			curmb = __builtin_addcl(curmb, curmb, 0, &carryb);
#endif
#else
			unsigned long carrymidb, carryb;
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob = __builtin_addcl(curmlob, curmlob, 0, &carrymidb);
			curmhib = __builtin_addcl(curmhib, curmhib, carrymidb, &carryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, curob, static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curma, &curma), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curmb, &curmb), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmloa, curmloa, &curmloa), curmhia, curmhia, &curmhia), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlob, curmlob, &curmlob), curmhib, curmhib, &curmhib), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#else
			std::uint_least64_t curmtmpa{curma};
			curma += curma;
			curoa += static_cast<std::uint_least16_t>(curoa);
			curoa += curma < curmtmpa;
			std::uint_least64_t curmtmpb{curmb};
			curmb += curmb;
			curob += static_cast<std::uint_least16_t>(curob);
			curob += curmb < curmtmpb;
#endif
			curea = curoa;
			cureb = curob;
		}
		curpa >>= 16 - 1;
		curpb >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curqa{static_cast<std::uint_least64_t>(curpa)};// sign-extend
		std::uint_least64_t curqb{static_cast<std::uint_least64_t>(curpb)};
#else
		std::uint_least32_t curqa{static_cast<std::uint_least32_t>(curpa)};// sign-extend
		std::uint_least32_t curqb{static_cast<std::uint_least32_t>(curpb)};
#endif
		if constexpr(isfltpmode){
			curea >>= 1;
			cureb >>= 1;
		}
		if constexpr(issignmode){
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			curma = __builtin_addcll(curma, curqa, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			curma = __builtin_addcl(curma, curqa, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymida, carrya;
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa = __builtin_addcl(curmloa, curqa, 0, &carrymida);
			curmhia = __builtin_addcl(curmhia, curqa, carrymida, &carrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, static_cast<unsigned short>(curqa), static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			curmb = __builtin_addcll(curmb, curqb, 0, &carryb);
#else
			unsigned long carryb;
			curmb = __builtin_addcl(curmb, curqb, 0, &carryb);
#endif
#else
			unsigned long carrymidb, carryb;
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob = __builtin_addcl(curmlob, curqb, 0, &carrymidb);
			curmhib = __builtin_addcl(curmhib, curqb, carrymidb, &carryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, static_cast<unsigned short>(curqb), static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curqa, &curma), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curqb, &curmb), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmloa, curqa, &curmloa), curmhia, curqa, &curmhia), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlob, curqb, &curmlob), curmhib, curqb, &curmhib), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#elif 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
			curma += curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curma < curqa;
			curmb += curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmb < curqb;
#else
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa += curqa;
			curmhia += curqa;
			curmhia += curmloa < curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curmhia < curqa;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob += curqb;
			curmhib += curqb;
			curmhib += curmlob < curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmhib < curqb;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			curea = curoa;
			cureb = curob;
		}
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		curma ^= curqa;
		curmb ^= curqb;
#else
		std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		curmloa ^= curqa;
		curmhia ^= curqa;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
		curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
		std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		curmlob ^= curqb;
		curmhib ^= curqb;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
		curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
		curea ^= static_cast<U>(curqa);
		cureb ^= static_cast<U>(curqb);
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		if constexpr(issignmode){
			curea &= 0xFFFFu >> 1;
			cureb &= 0xFFFFu >> 1;
		}else{
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			curma = __builtin_addcll(curma, curma, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			curma = __builtin_addcl(curma, curma, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymida, carrya;
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa = __builtin_addcl(curmloa, curmloa, 0, &carrymida);
			curmhia = __builtin_addcl(curmhia, curmhia, carrymida, &carrya);
#endif
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
			unsigned short carrysigna;
			curoa = __builtin_addcs(curoa, curoa, static_cast<unsigned short>(carrya), &carrysigna);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long checkcarrya;
			curma = __builtin_subcll(curma, 0xFFFFFFFFFFFFFFFFu, static_cast<unsigned long long>(carrysigna), &checkcarrya);// flip the least significant bit
#else
			unsigned long checkcarrya;
			curma = __builtin_subcl(curma, 0xFFFFFFFFFFFFFFFFu, static_cast<unsigned long>(carrysigna), &checkcarrya);// flip the least significant bit
#endif
#else
			unsigned long checkcarrya;
			curmloa = __builtin_subcl(curmloa, 0xFFFFFFFFu, static_cast<unsigned long>(carrysigna), &checkcarrya);// flip the least significant bit
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
#endif
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			curmb = __builtin_addcll(curmb, curmb, 0, &carryb);
#else
			unsigned long carryb;
			curmb = __builtin_addcl(curmb, curmb, 0, &carryb);
#endif
#else
			unsigned long carrymidb, carryb;
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob = __builtin_addcl(curmlob, curmlob, 0, &carrymidb);
			curmhib = __builtin_addcl(curmhib, curmhib, carrymidb, &carryb);
#endif
			unsigned short carrysignb;
			curob = __builtin_addcs(curob, curob, static_cast<unsigned short>(carryb), &carrysignb);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long checkcarryb;
			curmb = __builtin_subcll(curmb, 0xFFFFFFFFFFFFFFFFu, static_cast<unsigned long long>(carrysignb), &checkcarryb);// flip the least significant bit
#else
			unsigned long checkcarryb;
			curmb = __builtin_subcl(curmb, 0xFFFFFFFFFFFFFFFFu, static_cast<unsigned long>(carrysignb), &checkcarryb);// flip the least significant bit
#endif
#else
			unsigned long checkcarryb;
			curmlob = __builtin_subcl(curmlob, 0xFFFFFFFFu, static_cast<unsigned long>(carrysignb), &checkcarryb);// flip the least significant bit
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
#elif defined(_M_X64)
			unsigned char carrysigna{_addcarry_u16(_addcarry_u64(0, curma, curma, &curma), curoa, curoa, &curoa)};
			unsigned char checkcarrya{_subborrow_u64(carrysigna, curma, 0xFFFFFFFFFFFFFFFFu, &curma)};// flip the least significant bit
			static_cast<void>(checkcarrya);
			unsigned char carrysignb{_addcarry_u16(_addcarry_u64(0, curmb, curmb, &curmb), curob, curob, &curob)};
			unsigned char checkcarryb{_subborrow_u64(carrysignb, curmb, 0xFFFFFFFFFFFFFFFFu, &curmb)};// flip the least significant bit
			static_cast<void>(checkcarryb);
#elif defined(_M_IX86)
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char carrysigna{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmloa, curmloa, &curmloa), curmhia, curmhia, &curmhia), curoa, curoa, &curoa)};
			unsigned char checkcarrya{_subborrow_u32(carrysigna, curmloa, 0xFFFFFFFFu, &curmloa)};// flip the least significant bit
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char carrysignb{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlob, curmlob, &curmlob), curmhib, curmhib, &curmhib), curob, curob, &curob)};
			unsigned char checkcarryb{_subborrow_u32(carrysignb, curmlob, 0xFFFFFFFFu, &curmlob)};// flip the least significant bit
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#else
			std::uint_least64_t curmtmpa{curma};
			curma += curma;
			std::uint_least16_t curotmpa{curoa};
			curoa += curoa;
			curoa += curma < curmtmpa;
			curma += curoa >= curotmpa;// flip the least significant bit
			std::uint_least64_t curmtmpb{curmb};
			curmb += curmb;
			std::uint_least16_t curotmpb{curob};
			curob += curob;
			curob += curmb < curmtmpb;
			curmb += curob >= curotmpb;// flip the least significant bit
#endif
			curea = curoa;
			cureb = curob;
		}
	}
	if constexpr(!isabsvalue && issignmode) curea += static_cast<U>(1) << 15, cureb += static_cast<U>(1) << 15;// flip the sign bit
	assert(curea <= 0xFFFFu);
	assert(cureb <= 0xFFFFu);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	return{{curma, curea}, {curmb, cureb}};
#else
	return{{curma, static_cast<std::uint_least32_t>(curea)}, {curmb, static_cast<std::uint_least32_t>(cureb)}};
#endif
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>),
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	std::conditional_t<std::is_same_v<longdoubletest128, T>, std::pair<longdoubletest128, longdoubletest128>,
#endif
	std::pair<longdoubletest96, longdoubletest96>
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	>
#endif
	> convertinput(T cura, T curb)noexcept{
	using U =
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::conditional_t<128 == CHAR_BIT * sizeof(T), std::uint_least64_t,
#endif
		unsigned
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		>
#endif
		;// assume zero-extension to be basically free for U on basically all modern machines
	return{convertinput<isabsvalue, issignmode, isfltpmode, T>(
		cura.mantissa, static_cast<U>(cura.signexponent),
		curb.mantissa, static_cast<U>(curb.signexponent))};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>) &&
	std::is_unsigned_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	std::conditional_t<std::is_same_v<longdoubletest128, T>, std::tuple<longdoubletest128, longdoubletest128, longdoubletest128>,
#endif
	std::tuple<longdoubletest96, longdoubletest96, longdoubletest96>
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	>
#endif
	> convertinput(std::uint_least64_t curma, U curea, std::uint_least64_t curmb, U cureb, std::uint_least64_t curmc, U curec)noexcept{
	using W = decltype(T::signexponent);
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::int_least16_t curpa{static_cast<std::int_least16_t>(curea)};
		std::int_least16_t curpb{static_cast<std::int_least16_t>(cureb)};
		std::int_least16_t curpc{static_cast<std::int_least16_t>(curec)};
		if constexpr(isfltpmode){
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			curoa += curoa;
			curea = curoa;
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
			curob += curob;
			cureb = curob;
			std::uint_least16_t curoc{static_cast<std::uint_least16_t>(curec)};
			curoc += curoc;
			curec = curoc;
		}else if constexpr(!issignmode){
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
			std::uint_least16_t curoc{static_cast<std::uint_least16_t>(curec)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			curma = __builtin_addcll(curma, curma, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			curma = __builtin_addcl(curma, curma, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymida, carrya;
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa = __builtin_addcl(curmloa, curmloa, 0, &carrymida);
			curmhia = __builtin_addcl(curmhia, curmhia, carrymida, &carrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, curoa, static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			curmb = __builtin_addcll(curmb, curmb, 0, &carryb);
#else
			unsigned long carryb;
			curmb = __builtin_addcl(curmb, curmb, 0, &carryb);
#endif
#else
			unsigned long carrymidb, carryb;
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob = __builtin_addcl(curmlob, curmlob, 0, &carrymidb);
			curmhib = __builtin_addcl(curmhib, curmhib, carrymidb, &carryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, curob, static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryc;
			curmc = __builtin_addcll(curmc, curmc, 0, &carryc);
#else
			unsigned long carryc;
			curmc = __builtin_addcl(curmc, curmc, 0, &carryc);
#endif
#else
			unsigned long carrymidc, carryc;
			std::uint_least32_t curmloc{static_cast<std::uint_least32_t>(curmc & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			curmloc = __builtin_addcl(curmloc, curmloc, 0, &carrymidc);
			curmhic = __builtin_addcl(curmhic, curmhic, carrymidc, &carryc);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmc[2]{curmloc, curmhic};
			curmc = *reinterpret_cast<std::uint_least64_t *>(acurmc);// recompose
#endif
			unsigned short checkcarryc;
			curoc = __builtin_addcs(curoc, curoc, static_cast<unsigned short>(carryc), &checkcarryc);
			static_cast<void>(checkcarryc);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curma, &curma), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curmb, &curmb), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
			unsigned char checkcarryc{_addcarry_u16(_addcarry_u64(0, curmc, curmc, &curmc), curoc, curoc, &curoc)};
			static_cast<void>(checkcarryc);
#elif defined(_M_IX86)
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmloa, curmloa, &curmloa), curmhia, curmhia, &curmhia), curoa, curoa, &curoa)};
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlob, curmlob, &curmlob), curmhib, curmhib, &curmhib), curob, curob, &curob)};
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
			std::uint_least32_t curmloc{static_cast<std::uint_least32_t>(curmc & 0xFFFFFFFFu)}, curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			unsigned char checkcarryc{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmloc, curmloc, &curmloc), curmhic, curmhic, &curmhic), curoc, curoc, &curoc)};
			static_cast<void>(checkcarryc);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmc[2]{curmloc, curmhic};
			curmc = *reinterpret_cast<std::uint_least64_t *>(acurmc);// recompose
#else
			std::uint_least64_t curmtmpa{curma};
			curma += curma;
			curoa += static_cast<std::uint_least16_t>(curoa);
			curoa += curma < curmtmpa;
			std::uint_least64_t curmtmpb{curmb};
			curmb += curmb;
			curob += static_cast<std::uint_least16_t>(curob);
			curob += curmb < curmtmpb;
			std::uint_least64_t curmtmpc{curmc};
			curmc += curmc;
			curoc += static_cast<std::uint_least16_t>(curoc);
			curoc += curmc < curmtmpc;
#endif
			curea = curoa;
			cureb = curob;
			curec = curoc;
		}
		curpa >>= 16 - 1;
		curpb >>= 16 - 1;
		curpc >>= 16 - 1;
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::uint_least64_t curqa{static_cast<std::uint_least64_t>(curpa)};// sign-extend
		std::uint_least64_t curqb{static_cast<std::uint_least64_t>(curpb)};
		std::uint_least64_t curqc{static_cast<std::uint_least64_t>(curpc)};
#else
		std::uint_least32_t curqa{static_cast<std::uint_least32_t>(curpa)};// sign-extend
		std::uint_least32_t curqb{static_cast<std::uint_least32_t>(curpb)};
		std::uint_least32_t curqc{static_cast<std::uint_least32_t>(curpc)};
#endif
		if constexpr(isfltpmode){
			curea >>= 1;
			cureb >>= 1;
			curec >>= 1;
		}
		if constexpr(issignmode){
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
			std::uint_least16_t curoc{static_cast<std::uint_least16_t>(curec)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			curma = __builtin_addcll(curma, curqa, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			curma = __builtin_addcl(curma, curqa, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymida, carrya;
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa = __builtin_addcl(curmloa, curqa, 0, &carrymida);
			curmhia = __builtin_addcl(curmhia, curqa, carrymida, &carrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
#endif
			unsigned short checkcarrya;
			curoa = __builtin_addcs(curoa, static_cast<unsigned short>(curqa), static_cast<unsigned short>(carrya), &checkcarrya);
			static_cast<void>(checkcarrya);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			curmb = __builtin_addcll(curmb, curqb, 0, &carryb);
#else
			unsigned long carryb;
			curmb = __builtin_addcl(curmb, curqb, 0, &carryb);
#endif
#else
			unsigned long carrymidb, carryb;
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob = __builtin_addcl(curmlob, curqb, 0, &carrymidb);
			curmhib = __builtin_addcl(curmhib, curqb, carrymidb, &carryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
			unsigned short checkcarryb;
			curob = __builtin_addcs(curob, static_cast<unsigned short>(curqb), static_cast<unsigned short>(carryb), &checkcarryb);
			static_cast<void>(checkcarryb);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryc;
			curmc = __builtin_addcll(curmc, curqc, 0, &carryc);
#else
			unsigned long carryc;
			curmc = __builtin_addcl(curmc, curqc, 0, &carryc);
#endif
#else
			unsigned long carrymidc, carryc;
			std::uint_least32_t curmloc{static_cast<std::uint_least32_t>(curmc & 0xFFFFFFFFu)}, curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			curmloc = __builtin_addcl(curmloc, curqc, 0, &carrymidc);
			curmhic = __builtin_addcl(curmhic, curqc, carrymidc, &carryc);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmc[2]{curmloc, curmhic};
			curmc = *reinterpret_cast<std::uint_least64_t *>(acurmc);// recompose
#endif
			unsigned short checkcarryc;
			curoc = __builtin_addcs(curoc, static_cast<unsigned short>(curqc), static_cast<unsigned short>(carryc), &checkcarryc);
			static_cast<void>(checkcarryc);
#elif defined(_M_X64)
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u64(0, curma, curqa, &curma), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u64(0, curmb, curqb, &curmb), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
			unsigned char checkcarryc{_addcarry_u16(_addcarry_u64(0, curmc, curqc, &curmc), curoc, static_cast<std::uint_least16_t>(curqc), &curoc)};
			static_cast<void>(checkcarryc);
#elif defined(_M_IX86)
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char checkcarrya{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmloa, curqa, &curmloa), curmhia, curqa, &curmhia), curoa, static_cast<std::uint_least16_t>(curqa), &curoa)};
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char checkcarryb{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlob, curqb, &curmlob), curmhib, curqb, &curmhib), curob, static_cast<std::uint_least16_t>(curqb), &curob)};
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
			std::uint_least32_t curmloc{static_cast<std::uint_least32_t>(curmc & 0xFFFFFFFFu)}, curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			unsigned char checkcarryc{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmloc, curqc, &curmloc), curmhic, curqc, &curmhic), curoc, static_cast<std::uint_least16_t>(curqc), &curoc)};
			static_cast<void>(checkcarryc);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmc[2]{curmloc, curmhic};
			curmc = *reinterpret_cast<std::uint_least64_t *>(acurmc);// recompose
#elif 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
			curma += curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curma < curqa;
			curmb += curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmb < curqb;
			curmc += curqc;
			curoc += static_cast<std::uint_least16_t>(curqc);
			curoc += curmc < curqc;
#else
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa += curqa;
			curmhia += curqa;
			curmhia += curmloa < curqa;
			curoa += static_cast<std::uint_least16_t>(curqa);
			curoa += curmhia < curqa;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob += curqb;
			curmhib += curqb;
			curmhib += curmlob < curqb;
			curob += static_cast<std::uint_least16_t>(curqb);
			curob += curmhib < curqb;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
			std::uint_least32_t curmloc{static_cast<std::uint_least32_t>(curmc & 0xFFFFFFFFu)}, curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			curmloc += curqc;
			curmhic += curqc;
			curmhic += curmloc < curqc;
			curoc += static_cast<std::uint_least16_t>(curqc);
			curoc += curmhic < curqc;
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmc[2]{curmloc, curmhic};
			curmc = *reinterpret_cast<std::uint_least64_t *>(acurmc);// recompose
#endif
			curea = curoa;
			cureb = curob;
			curec = curoc;
		}
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		curma ^= curqa;
		curmb ^= curqb;
		curmc ^= curqc;
#else
		std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
		curmloa ^= curqa;
		curmhia ^= curqa;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
		curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
		std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
		curmlob ^= curqb;
		curmhib ^= curqb;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
		curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
		std::uint_least32_t curmloc{static_cast<std::uint_least32_t>(curmc & 0xFFFFFFFFu)}, curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
		curmloc ^= curqc;
		curmhic ^= curqc;
		alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmc[2]{curmloc, curmhic};
		curmc = *reinterpret_cast<std::uint_least64_t *>(acurmc);// recompose
#endif
		curea ^= static_cast<U>(curqa);
		cureb ^= static_cast<U>(curqb);
		curec ^= static_cast<U>(curqc);
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		if constexpr(issignmode){
			curea &= 0xFFFFu >> 1;
			cureb &= 0xFFFFu >> 1;
			curec &= 0xFFFFu >> 1;
		}else{
			std::uint_least16_t curoa{static_cast<std::uint_least16_t>(curea)};
			std::uint_least16_t curob{static_cast<std::uint_least16_t>(cureb)};
			std::uint_least16_t curoc{static_cast<std::uint_least16_t>(curec)};
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc)
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			static_assert(64 == CHAR_BIT * sizeof(long long), "unexpected size of type long long");
			unsigned long long carrya;
			curma = __builtin_addcll(curma, curma, 0, &carrya);
#else
			static_assert(64 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrya;
			curma = __builtin_addcl(curma, curma, 0, &carrya);
#endif
#else
			static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
			unsigned long carrymida, carrya;
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			curmloa = __builtin_addcl(curmloa, curmloa, 0, &carrymida);
			curmhia = __builtin_addcl(curmhia, curmhia, carrymida, &carrya);
#endif
			static_assert(16 == CHAR_BIT * sizeof(short), "unexpected size of type short");
			unsigned short carrysigna;
			curoa = __builtin_addcs(curoa, curoa, static_cast<unsigned short>(carrya), &carrysigna);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long checkcarrya;
			curma = __builtin_subcll(curma, 0xFFFFFFFFFFFFFFFFu, static_cast<unsigned long long>(carrysigna), &checkcarrya);// flip the least significant bit
#else
			unsigned long checkcarrya;
			curma = __builtin_subcl(curma, 0xFFFFFFFFFFFFFFFFu, static_cast<unsigned long>(carrysigna), &checkcarrya);// flip the least significant bit
#endif
#else
			unsigned long checkcarrya;
			curmloa = __builtin_subcl(curmloa, 0xFFFFFFFFu, static_cast<unsigned long>(carrysigna), &checkcarrya);// flip the least significant bit
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
#endif
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryb;
			curmb = __builtin_addcll(curmb, curmb, 0, &carryb);
#else
			unsigned long carryb;
			curmb = __builtin_addcl(curmb, curmb, 0, &carryb);
#endif
#else
			unsigned long carrymidb, carryb;
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			curmlob = __builtin_addcl(curmlob, curmlob, 0, &carrymidb);
			curmhib = __builtin_addcl(curmhib, curmhib, carrymidb, &carryb);
#endif
			unsigned short carrysignb;
			curob = __builtin_addcs(curob, curob, static_cast<unsigned short>(carryb), &carrysignb);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long checkcarryb;
			curmb = __builtin_subcll(curmb, 0xFFFFFFFFFFFFFFFFu, static_cast<unsigned long long>(carrysignb), &checkcarryb);// flip the least significant bit
#else
			unsigned long checkcarryb;
			curmb = __builtin_subcl(curmb, 0xFFFFFFFFFFFFFFFFu, static_cast<unsigned long>(carrysignb), &checkcarryb);// flip the least significant bit
#endif
#else
			unsigned long checkcarryb;
			curmlob = __builtin_subcl(curmlob, 0xFFFFFFFFu, static_cast<unsigned long>(carrysignb), &checkcarryb);// flip the least significant bit
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
#endif
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long carryc;
			curmc = __builtin_addcll(curmc, curmc, 0, &carryc);
#else
			unsigned long carryc;
			curmc = __builtin_addcl(curmc, curmc, 0, &carryc);
#endif
#else
			unsigned long carrymidc, carryc;
			std::uint_least32_t curmloc{static_cast<std::uint_least32_t>(curmc & 0xFFFFFFFFu)}, curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			curmloc = __builtin_addcl(curmloc, curmloc, 0, &carrymidc);
			curmhic = __builtin_addcl(curmhic, curmhic, carrymidc, &carryc);
#endif
			unsigned short carrysignc;
			curoc = __builtin_addcs(curoc, curoc, static_cast<unsigned short>(carryc), &carrysignc);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			unsigned long long checkcarryc;
			curmc = __builtin_subcll(curmc, 0xFFFFFFFFFFFFFFFFu, static_cast<unsigned long long>(carrysignc), &checkcarryc);// flip the least significant bit
#else
			unsigned long checkcarryc;
			curmc = __builtin_subcl(curmc, 0xFFFFFFFFFFFFFFFFu, static_cast<unsigned long>(carrysignc), &checkcarryc);// flip the least significant bit
#endif
#else
			unsigned long checkcarryc;
			curmloc = __builtin_subcl(curmloc, 0xFFFFFFFFu, static_cast<unsigned long>(carrysignc), &checkcarryc);// flip the least significant bit
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmc[2]{curmloc, curmhic};
			curmc = *reinterpret_cast<std::uint_least64_t *>(acurmc);// recompose
#endif
#elif defined(_M_X64)
			unsigned char carrysigna{_addcarry_u16(_addcarry_u64(0, curma, curma, &curma), curoa, curoa, &curoa)};
			unsigned char checkcarrya{_subborrow_u64(carrysigna, curma, 0xFFFFFFFFFFFFFFFFu, &curma)};// flip the least significant bit
			static_cast<void>(checkcarrya);
			unsigned char carrysignb{_addcarry_u16(_addcarry_u64(0, curmb, curmb, &curmb), curob, curob, &curob)};
			unsigned char checkcarryb{_subborrow_u64(carrysignb, curmb, 0xFFFFFFFFFFFFFFFFu, &curmb)};// flip the least significant bit
			static_cast<void>(checkcarryb);
			unsigned char carrysignc{_addcarry_u16(_addcarry_u64(0, curmc, curmc, &curmc), curoc, curoc, &curoc)};
			unsigned char checkcarryc{_subborrow_u64(carrysignc, curmc, 0xFFFFFFFFFFFFFFFFu, &curmc)};// flip the least significant bit
			static_cast<void>(checkcarryc);
#elif defined(_M_IX86)
			std::uint_least32_t curmloa{static_cast<std::uint_least32_t>(curma & 0xFFFFFFFFu)}, curmhia{static_cast<std::uint_least32_t>(curma >> 32)};// decompose
			unsigned char carrysigna{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmloa, curmloa, &curmloa), curmhia, curmhia, &curmhia), curoa, curoa, &curoa)};
			unsigned char checkcarrya{_subborrow_u32(carrysigna, curmloa, 0xFFFFFFFFu, &curmloa)};// flip the least significant bit
			static_cast<void>(checkcarrya);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurma[2]{curmloa, curmhia};
			curma = *reinterpret_cast<std::uint_least64_t *>(acurma);// recompose
			std::uint_least32_t curmlob{static_cast<std::uint_least32_t>(curmb & 0xFFFFFFFFu)}, curmhib{static_cast<std::uint_least32_t>(curmb >> 32)};// decompose
			unsigned char carrysignb{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmlob, curmlob, &curmlob), curmhib, curmhib, &curmhib), curob, curob, &curob)};
			unsigned char checkcarryb{_subborrow_u32(carrysignb, curmlob, 0xFFFFFFFFu, &curmlob)};// flip the least significant bit
			static_cast<void>(checkcarryb);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmb[2]{curmlob, curmhib};
			curmb = *reinterpret_cast<std::uint_least64_t *>(acurmb);// recompose
			std::uint_least32_t curmloc{static_cast<std::uint_least32_t>(curmc & 0xFFFFFFFFu)}, curmhic{static_cast<std::uint_least32_t>(curmc >> 32)};// decompose
			unsigned char carrysignc{_addcarry_u16(_addcarry_u32(_addcarry_u32(0, curmloc, curmloc, &curmloc), curmhic, curmhic, &curmhic), curoc, curoc, &curoc)};
			unsigned char checkcarryc{_subborrow_u32(carrysignc, curmloc, 0xFFFFFFFFu, &curmloc)};// flip the least significant bit
			static_cast<void>(checkcarryc);
			alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurmc[2]{curmloc, curmhic};
			curmc = *reinterpret_cast<std::uint_least64_t *>(acurmc);// recompose
#else
			std::uint_least64_t curmtmpa{curma};
			curma += curma;
			std::uint_least16_t curotmpa{curoa};
			curoa += curoa;
			curoa += curma < curmtmpa;
			curma += curoa >= curotmpa;// flip the least significant bit
			std::uint_least64_t curmtmpb{curmb};
			curmb += curmb;
			std::uint_least16_t curotmpb{curob};
			curob += curob;
			curob += curmb < curmtmpb;
			curmb += curob >= curotmpb;// flip the least significant bit
			std::uint_least64_t curmtmpc{curmc};
			curmc += curmc;
			std::uint_least16_t curotmpc{curoc};
			curoc += curoc;
			curoc += curmc < curmtmpc;
			curmc += curoc >= curotmpc;// flip the least significant bit
#endif
			curea = curoa;
			cureb = curob;
			curec = curoc;
		}
	}
	if constexpr(!isabsvalue && issignmode) curea += static_cast<U>(1) << 15, cureb += static_cast<U>(1) << 15, curec += static_cast<U>(1) << 15;// flip the sign bit
	assert(curea <= 0xFFFFu);
	assert(cureb <= 0xFFFFu);
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	return{{curma, curea}, {curmb, cureb}, {curmc, curec}};
#else
	return{{curma, static_cast<std::uint_least32_t>(curea)}, {curmb, static_cast<std::uint_least32_t>(cureb)}, {curmc, static_cast<std::uint_least32_t>(curec)}};
#endif
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_same_v<longdoubletest128, T> ||
	std::is_same_v<longdoubletest96, T> ||
	std::is_same_v<longdoubletest80, T>),
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	std::conditional_t<std::is_same_v<longdoubletest128, T>, std::tuple<longdoubletest128, longdoubletest128, longdoubletest128>,
#endif
	std::tuple<longdoubletest96, longdoubletest96, longdoubletest96>
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	>
#endif
	> convertinput(T cura, T curb, T curc)noexcept{
	using U =
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		std::conditional_t<128 == CHAR_BIT * sizeof(T), std::uint_least64_t,
#endif
		unsigned
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		>
#endif
		;// assume zero-extension to be basically free for U on basically all modern machines
	return{convertinput<isabsvalue, issignmode, isfltpmode, T>(
		cura.mantissa, static_cast<U>(cura.signexponent),
		curb.mantissa, static_cast<U>(curb.signexponent),
		curc.mantissa, static_cast<U>(curc.signexponent))};
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_integral_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_integral_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
#if 0xFFFFFFFFFFFFFFFFu > UINTPTR_MAX
	std::conditional_t<64 == CHAR_BIT * sizeof(T), test64<isfltpmode>,
#endif
	std::conditional_t<!isabsvalue && issignmode && !isfltpmode, std::intptr_t, U>// handle simple signed types
#if 0xFFFFFFFFFFFFFFFFu > UINTPTR_MAX
	>
#endif
	> convertinput(U cur)noexcept{
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curp{static_cast<std::make_signed_t<T>>(cur)};
		if constexpr(!issignmode || isfltpmode){
			T curo{static_cast<T>(cur)};
			curo += curo;
			cur = curo;
		}
		curp >>= CHAR_BIT * sizeof(T) - 1;
		U curq{static_cast<T>(curp)};
		if constexpr(isfltpmode) cur >>= 1;
		if constexpr(issignmode){
			T curo{static_cast<T>(cur)};
			curo += static_cast<T>(curq);
			cur = curo;
		}
		curq >>= 1;// flip the sign bit
		cur ^= curq;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		if constexpr(issignmode) cur &= ~static_cast<T>(0) >> 1;
		else{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// no use for any tricks when the type is already small enough
			cur = rotateleftportable<1>(static_cast<T>(cur));
			cur ^= 1u;// flip the least significant bit
#else
			if constexpr(64 != CHAR_BIT * sizeof(T)){// again, no use for any tricks when the type is already small enough
				cur = rotateleftportable<1>(static_cast<T>(cur));
				cur ^= 1u;// flip the least significant bit
			}else{// try to split the sequence
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc) && __has_builtin(__builtin_subc)
				std::uint_least32_t curlo{static_cast<std::uint_least32_t>(cur & 0xFFFFFFFFu)}, curhi{static_cast<std::uint_least32_t>(cur >> 32)};// decompose
				static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
				unsigned long carrylo, carryhi, checkcarry;
				curlo = __builtin_addcl(curlo, curlo, 0, &carrylo);
				curhi = __builtin_addcl(curhi, curhi, carrylo, &carryhi);
				curlo = __builtin_subcl(curlo, 0xFFFFFFFFu, carryhi, &checkcarry);// flip the least significant bit
				static_cast<void>(checkcarry);
				alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acur[2]{curlo, curhi};
				cur = *reinterpret_cast<std::uint_least64_t *>(acur);// recompose
#elif defined(_M_IX86)
				std::uint_least32_t curlo{static_cast<std::uint_least32_t>(cur & 0xFFFFFFFFu)}, curhi{static_cast<std::uint_least32_t>(cur >> 32)};// decompose
				unsigned char checkcarry{_subborrow_u32(_addcarry_u32(_addcarry_u32(0, curlo, curlo, &curlo), curhi, curhi, &curhi), curlo, 0xFFFFFFFFu, &curlo)};// flip the least significant bit
				static_cast<void>(checkcarry);
				alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acur[2]{curlo, curhi};
				cur = *reinterpret_cast<std::uint_least64_t *>(acur);// recompose
#else
				cur = rotateleftportable<1>(static_cast<T>(cur));
				cur ^= 1u;// flip the least significant bit
#endif
			}
#endif
		}
	}
	if constexpr(sizeof(T) != sizeof(U)) assert(cur == static_cast<T>(cur));// only zero-extension is allowed
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	return{cur};
#else
	if constexpr(64 == CHAR_BIT * sizeof(T)){
		if constexpr(1 < sizeof(double)){
			// basic endianess detection, relies on proper inlining and compiler optimisation of that
			static auto constexpr highbit{generatehighbit<std::conditional_t<isfltpmode, double, std::uint_least64_t>>()};
			if(*reinterpret_cast<std::uint_least32_t const *>(&highbit)){// big and mixed-endian cases
				return{{static_cast<std::uint_least32_t>(cur >> 32), static_cast<std::uint_least32_t>(cur & 0xFFFFFFFFu)}};
			}
		}
		// little-endian case
		return{{static_cast<std::uint_least32_t>(cur & 0xFFFFFFFFu), static_cast<std::uint_least32_t>(cur >> 32)}};
	}else return{cur};
#endif
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_integral_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_integral_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
#if 0xFFFFFFFFFFFFFFFFu > UINTPTR_MAX
	std::conditional_t<64 == CHAR_BIT * sizeof(T), std::pair<test64<isfltpmode>, test64<isfltpmode>>,
#endif
	std::conditional_t<!isabsvalue && issignmode && !isfltpmode, std::pair<std::intptr_t, std::intptr_t>, std::pair<U, U>>// handle simple signed types
#if 0xFFFFFFFFFFFFFFFFu > UINTPTR_MAX
	>
#endif
	> convertinput(U cura, U curb)noexcept{
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		if constexpr(!issignmode || isfltpmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		if constexpr(!issignmode || isfltpmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		if constexpr(isfltpmode){
			cura >>= 1;
			curb >>= 1;
		}
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			cura = curoa;
			curb = curob;
		}
		curqa >>= 1;// flip the sign bit
		curqb >>= 1;
		cura ^= curqa;
		curb ^= curqb;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		if constexpr(issignmode){
			cura &= ~static_cast<T>(0) >> 1;
			curb &= ~static_cast<T>(0) >> 1;
		}else{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// no use for any tricks when the type is already small enough
			cura = rotateleftportable<1>(static_cast<T>(cura));
			curb = rotateleftportable<1>(static_cast<T>(curb));
			cura ^= 1u;// flip the least significant bit
			curb ^= 1u;
#else
			if constexpr(64 != CHAR_BIT * sizeof(T)){// again, no use for any tricks when the type is already small enough
				cura = rotateleftportable<1>(static_cast<T>(cura));
				curb = rotateleftportable<1>(static_cast<T>(curb));
				cura ^= 1u;// flip the least significant bit
				curb ^= 1u;
			}else{// try to split the sequence
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc) && __has_builtin(__builtin_subc)
				std::uint_least32_t curloa{static_cast<std::uint_least32_t>(cura & 0xFFFFFFFFu)}, curhia{static_cast<std::uint_least32_t>(cura >> 32)};// decompose
				static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
				unsigned long carryloa, carryhia, checkcarrya;
				curloa = __builtin_addcl(curloa, curloa, 0, &carryloa);
				curhia = __builtin_addcl(curhia, curhia, carryloa, &carryhia);
				curloa = __builtin_subcl(curloa, 0xFFFFFFFFu, carryhia, &checkcarrya);// flip the least significant bit
				static_cast<void>(checkcarrya);
				alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acura[2]{curloa, curhia};
				cura = *reinterpret_cast<std::uint_least64_t *>(acura);// recompose
				std::uint_least32_t curlob{static_cast<std::uint_least32_t>(curb & 0xFFFFFFFFu)}, curhib{static_cast<std::uint_least32_t>(curb >> 32)};// decompose
				unsigned long carrylob, carryhib, checkcarryb;
				curlob = __builtin_addcl(curlob, curlob, 0, &carrylob);
				curhib = __builtin_addcl(curhib, curhib, carrylob, &carryhib);
				curlob = __builtin_subcl(curlob, 0xFFFFFFFFu, carryhib, &checkcarryb);// flip the least significant bit
				static_cast<void>(checkcarryb);
				alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurb[2]{curlob, curhib};
				curb = *reinterpret_cast<std::uint_least64_t *>(acurb);// recompose
#elif defined(_M_IX86)
				std::uint_least32_t curloa{static_cast<std::uint_least32_t>(cura & 0xFFFFFFFFu)}, curhia{static_cast<std::uint_least32_t>(cura >> 32)};// decompose
				unsigned char checkcarrya{_subborrow_u32(_addcarry_u32(_addcarry_u32(0, curloa, curloa, &curloa), curhia, curhia, &curhia), curloa, 0xFFFFFFFFu, &curloa)};// flip the least significant bit
				static_cast<void>(checkcarrya);
				alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acura[2]{curloa, curhia};
				cura = *reinterpret_cast<std::uint_least64_t *>(acura);// recompose
				std::uint_least32_t curlob{static_cast<std::uint_least32_t>(curb & 0xFFFFFFFFu)}, curhib{static_cast<std::uint_least32_t>(curb >> 32)};// decompose
				unsigned char checkcarryb{_subborrow_u32(_addcarry_u32(_addcarry_u32(0, curlob, curlob, &curlob), curhib, curhib, &curhib), curlob, 0xFFFFFFFFu, &curlob)};// flip the least significant bit
				static_cast<void>(checkcarryb);
				alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurb[2]{curlob, curhib};
				curb = *reinterpret_cast<std::uint_least64_t *>(acurb);// recompose
#else
				cura = rotateleftportable<1>(static_cast<T>(cura));
				curb = rotateleftportable<1>(static_cast<T>(curb));
				cura ^= 1u;// flip the least significant bit
				curb ^= 1u;
#endif
			}
#endif
		}
	}
	if constexpr(sizeof(T) != sizeof(U)){// only zero-extension is allowed
		assert(cura == static_cast<T>(cura));
		assert(curb == static_cast<T>(curb));
	}
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	return{cura, curb};
#else
	if constexpr(64 == CHAR_BIT * sizeof(T)){
		if constexpr(1 < sizeof(double)){
			// basic endianess detection, relies on proper inlining and compiler optimisation of that
			static auto constexpr highbit{generatehighbit<std::conditional_t<isfltpmode, double, std::uint_least64_t>>()};
			if(*reinterpret_cast<std::uint_least32_t const *>(&highbit)){// big and mixed-endian cases
				return{{{static_cast<std::uint_least32_t>(cura >> 32), static_cast<std::uint_least32_t>(cura & 0xFFFFFFFFu)}},
					{{static_cast<std::uint_least32_t>(curb >> 32), static_cast<std::uint_least32_t>(curb & 0xFFFFFFFFu)}}};
			}
		}
		// little-endian case
		return{{{static_cast<std::uint_least32_t>(cura & 0xFFFFFFFFu), static_cast<std::uint_least32_t>(cura >> 32)}},
			{{static_cast<std::uint_least32_t>(curb & 0xFFFFFFFFu), static_cast<std::uint_least32_t>(curb >> 32)}}};
	}else return{cura, curb};
#endif
}

template<bool isabsvalue, bool issignmode, bool isfltpmode, typename T, typename U>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_integral_v<T> &&
	64 >= CHAR_BIT * sizeof(T) &&
	std::is_integral_v<U> &&
	64 >= CHAR_BIT * sizeof(U),
#if 0xFFFFFFFFFFFFFFFFu > UINTPTR_MAX
	std::conditional_t<64 == CHAR_BIT * sizeof(T), std::tuple<test64<isfltpmode>, test64<isfltpmode>, test64<isfltpmode>>,
#endif
	std::conditional_t<!isabsvalue && issignmode && !isfltpmode, std::tuple<std::intptr_t, std::intptr_t, std::intptr_t>, std::tuple<U, U, U>>// handle simple signed types
#if 0xFFFFFFFFFFFFFFFFu > UINTPTR_MAX
	>
#endif
	> convertinput(U cura, U curb, U curc)noexcept{
	if constexpr(isabsvalue != isfltpmode){// two-register filtering
		std::make_signed_t<T> curpa{static_cast<std::make_signed_t<T>>(cura)};
		if constexpr(!issignmode || isfltpmode){
			T curoa{static_cast<T>(cura)};
			curoa += curoa;
			cura = curoa;
		}
		curpa >>= CHAR_BIT * sizeof(T) - 1;
		U curqa{static_cast<T>(curpa)};
		std::make_signed_t<T> curpb{static_cast<std::make_signed_t<T>>(curb)};
		if constexpr(!issignmode || isfltpmode){
			T curob{static_cast<T>(curb)};
			curob += curob;
			curb = curob;
		}
		curpb >>= CHAR_BIT * sizeof(T) - 1;
		U curqb{static_cast<T>(curpb)};
		std::make_signed_t<T> curpc{static_cast<std::make_signed_t<T>>(curc)};
		if constexpr(!issignmode || isfltpmode){
			T curoc{static_cast<T>(curc)};
			curoc += curoc;
			curc = curoc;
		}
		curpc >>= CHAR_BIT * sizeof(T) - 1;
		U curqc{static_cast<T>(curpc)};
		if constexpr(isfltpmode){
			cura >>= 1;
			curb >>= 1;
			curc >>= 1;
		}
		if constexpr(issignmode){
			T curoa{static_cast<T>(cura)};
			T curob{static_cast<T>(curb)};
			T curoc{static_cast<T>(curc)};
			curoa += static_cast<T>(curqa);
			curob += static_cast<T>(curqb);
			curoc += static_cast<T>(curqc);
			cura = curoa;
			curb = curob;
			curc = curoc;
		}
		curqa >>= 1;// flip the sign bit
		curqb >>= 1;
		curqc >>= 1;
		cura ^= curqa;
		curb ^= curqb;
		curc ^= curqc;
	}else if constexpr(isabsvalue && isfltpmode){// one-register filtering
		if constexpr(issignmode){
			cura &= ~static_cast<T>(0) >> 1;
			curb &= ~static_cast<T>(0) >> 1;
			curc &= ~static_cast<T>(0) >> 1;
		}else{
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX// no use for any tricks when the type is already small enough
			cura = rotateleftportable<1>(static_cast<T>(cura));
			curb = rotateleftportable<1>(static_cast<T>(curb));
			curc = rotateleftportable<1>(static_cast<T>(curc));
			cura ^= 1u;// flip the least significant bit
			curb ^= 1u;
			curc ^= 1u;
#else
			if constexpr(64 != CHAR_BIT * sizeof(T)){// again, no use for any tricks when the type is already small enough
				cura = rotateleftportable<1>(static_cast<T>(cura));
				curb = rotateleftportable<1>(static_cast<T>(curb));
				curc = rotateleftportable<1>(static_cast<T>(curc));
				cura ^= 1u;// flip the least significant bit
				curb ^= 1u;
				curc ^= 1u;
			}else{// try to split the sequence
#if (defined(__GNUC__) || defined(__clang__) || defined(__xlC__) && (defined(__VEC__) || defined(__ALTIVEC__))) && defined(__has_builtin) && __has_builtin(__builtin_addc) && __has_builtin(__builtin_subc)
				std::uint_least32_t curloa{static_cast<std::uint_least32_t>(cura & 0xFFFFFFFFu)}, curhia{static_cast<std::uint_least32_t>(cura >> 32)};// decompose
				static_assert(32 == CHAR_BIT * sizeof(long), "unexpected size of type long");
				unsigned long carryloa, carryhia, checkcarrya;
				curloa = __builtin_addcl(curloa, curloa, 0, &carryloa);
				curhia = __builtin_addcl(curhia, curhia, carryloa, &carryhia);
				curloa = __builtin_subcl(curloa, 0xFFFFFFFFu, carryhia, &checkcarrya);// flip the least significant bit
				static_cast<void>(checkcarrya);
				alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acura[2]{curloa, curhia};
				cura = *reinterpret_cast<std::uint_least64_t *>(acura);// recompose
				std::uint_least32_t curlob{static_cast<std::uint_least32_t>(curb & 0xFFFFFFFFu)}, curhib{static_cast<std::uint_least32_t>(curb >> 32)};// decompose
				unsigned long carrylob, carryhib, checkcarryb;
				curlob = __builtin_addcl(curlob, curlob, 0, &carrylob);
				curhib = __builtin_addcl(curhib, curhib, carrylob, &carryhib);
				curlob = __builtin_subcl(curlob, 0xFFFFFFFFu, carryhib, &checkcarryb);// flip the least significant bit
				static_cast<void>(checkcarryb);
				alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurb[2]{curlob, curhib};
				curb = *reinterpret_cast<std::uint_least64_t *>(acurb);// recompose
				std::uint_least32_t curloc{static_cast<std::uint_least32_t>(curc & 0xFFFFFFFFu)}, curhic{static_cast<std::uint_least32_t>(curc >> 32)};// decompose
				unsigned long carryloc, carryhic, checkcarryc;
				curloc = __builtin_addcl(curloc, curloc, 0, &carryloc);
				curhic = __builtin_addcl(curhic, curhic, carryloc, &carryhic);
				curloc = __builtin_subcl(curloc, 0xFFFFFFFFu, carryhic, &checkcarryc);// flip the least significant bit
				static_cast<void>(checkcarryc);
				alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurc[2]{curloc, curhic};
				curc = *reinterpret_cast<std::uint_least64_t *>(acurc);// recompose
#elif defined(_M_IX86)
				std::uint_least32_t curloa{static_cast<std::uint_least32_t>(cura & 0xFFFFFFFFu)}, curhia{static_cast<std::uint_least32_t>(cura >> 32)};// decompose
				unsigned char checkcarrya{_subborrow_u32(_addcarry_u32(_addcarry_u32(0, curloa, curloa, &curloa), curhia, curhia, &curhia), curloa, 0xFFFFFFFFu, &curloa)};// flip the least significant bit
				static_cast<void>(checkcarrya);
				alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acura[2]{curloa, curhia};
				cura = *reinterpret_cast<std::uint_least64_t *>(acura);// recompose
				std::uint_least32_t curlob{static_cast<std::uint_least32_t>(curb & 0xFFFFFFFFu)}, curhib{static_cast<std::uint_least32_t>(curb >> 32)};// decompose
				unsigned char checkcarryb{_subborrow_u32(_addcarry_u32(_addcarry_u32(0, curlob, curlob, &curlob), curhib, curhib, &curhib), curlob, 0xFFFFFFFFu, &curlob)};// flip the least significant bit
				static_cast<void>(checkcarryb);
				alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurb[2]{curlob, curhib};
				curb = *reinterpret_cast<std::uint_least64_t *>(acurb);// recompose
				std::uint_least32_t curloc{static_cast<std::uint_least32_t>(curc & 0xFFFFFFFFu)}, curhic{static_cast<std::uint_least32_t>(curc >> 32)};// decompose
				unsigned char checkcarryc{_subborrow_u32(_addcarry_u32(_addcarry_u32(0, curloc, curloc, &curloc), curhic, curhic, &curhic), curloc, 0xFFFFFFFFu, &curloc)};// flip the least significant bit
				static_cast<void>(checkcarryc);
				alignas(alignof(std::uint_least32_t) * 2) std::uint_least32_t acurc[2]{curloc, curhic};
				curc = *reinterpret_cast<std::uint_least64_t *>(acurc);// recompose
#else
				cura = rotateleftportable<1>(static_cast<T>(cura));
				curb = rotateleftportable<1>(static_cast<T>(curb));
				curc = rotateleftportable<1>(static_cast<T>(curc));
				cura ^= 1u;// flip the least significant bit
				curb ^= 1u;
				curc ^= 1u;
#endif
			}
#endif
		}
	}
	if constexpr(sizeof(T) != sizeof(U)){// only zero-extension is allowed
		assert(cura == static_cast<T>(cura));
		assert(curb == static_cast<T>(curb));
		assert(curc == static_cast<T>(curc));
	}
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
	return{cura, curb, curc};
#else
	if constexpr(64 == CHAR_BIT * sizeof(T)){
		if constexpr(1 < sizeof(double)){
			// basic endianess detection, relies on proper inlining and compiler optimisation of that
			static auto constexpr highbit{generatehighbit<std::conditional_t<isfltpmode, double, std::uint_least64_t>>()};
			if(*reinterpret_cast<std::uint_least32_t const *>(&highbit)){// big and mixed-endian cases
				return{{{static_cast<std::uint_least32_t>(cura >> 32), static_cast<std::uint_least32_t>(cura & 0xFFFFFFFFu)}},
					{{static_cast<std::uint_least32_t>(curb >> 32), static_cast<std::uint_least32_t>(curb & 0xFFFFFFFFu)}},
					{{static_cast<std::uint_least32_t>(curc >> 32), static_cast<std::uint_least32_t>(curc & 0xFFFFFFFFu)}}};
			}
		}
		// little-endian case
		return{{{static_cast<std::uint_least32_t>(cura & 0xFFFFFFFFu), static_cast<std::uint_least32_t>(cura >> 32)}},
			{{static_cast<std::uint_least32_t>(curb & 0xFFFFFFFFu), static_cast<std::uint_least32_t>(curb >> 32)}},
			{{static_cast<std::uint_least32_t>(curc & 0xFFFFFFFFu), static_cast<std::uint_least32_t>(curc >> 32)}}};
	}else return{cura, curb, curc};
#endif
}

// Helper functions for merging the halves from multithreading inputs without indirection

// multithreading companion function for radixsortcopynoallocmulti() and radixsortnoallocmulti()
// standalone function, reused in the same template form (hence the RSBD8_FUNC_NORMAL) in the 4-, 8- and then 16-way multithreading parts
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
RSBD8_FUNC_NORMAL std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void> mergehalvesmtc(std::size_t count, T const input[], T output[])noexcept{
	using W = typename std::conditional_t<std::is_class_v<T> || std::is_union_v<T> || isabsvalue || !issignmode || isfltpmode, std::enable_if<true, T>, std::make_signed<T>>::type;// for simple signed comparisons, use signed W
	using U = std::conditional_t<std::is_signed_v<W> && sizeof(W) < sizeof(std::intptr_t), std::intptr_t,// sign-extend signed types for masking operations
		std::conditional_t<std::is_unsigned_v<W> && sizeof(W) < sizeof(unsigned), unsigned, W>>;// assume zero-extension to be basically free for U on basically all modern machines
	using M = std::conditional_t<std::is_integral_v<U> &&
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		128 != CHAR_BIT * sizeof(T)// test128 and longdoubletest128 cases
#else
		64 != CHAR_BIT * sizeof(T)// test64 case
#endif
		, U, std::intptr_t>;// used for masking operations
	assert(2 < count);
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);

	// process the high half here (rounded up)
	std::size_t halfcount{(count >> 1) - 1};// rounded down and one less, as the odd count and final items are handled outside of the loop
	W *pout{reinterpret_cast<W *>(output) + (count - 1)};
	W const *pdatahi{reinterpret_cast<W const *>(input) + (!isrevorder? (count - 1) : halfcount)};
	W const *pdatalo{reinterpret_cast<W const *>(input) + (isrevorder? (count - 1) : halfcount)};
	U curhi{*pdatahi}, curlo{*pdatalo};
	if constexpr(isabsvalue || isfltpmode){// filtered input, convert everything for unsigned comparisons
		auto[comphi, complo]{convertinput<isabsvalue, issignmode, isfltpmode, W>(curhi, curlo)};
		do{
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
				U out;
				if(!isdescsort? comphi < complo : complo < comphi){
					--pdatalo;
					out = curlo;
					curlo = *pdatalo;
					complo = convertinput<isabsvalue, issignmode, isfltpmode, W>(curlo);// convert the value for integer comparison
				}else{
					--pdatahi;
					out = curhi;
					curhi = *pdatahi;
					comphi = convertinput<isabsvalue, issignmode, isfltpmode, W>(curhi);// convert the value for integer comparison
				}
				*pout-- = static_cast<W>(out);
			}else{// architecture: flatten the branch, at a higher register pressure cost
				std::intptr_t mask{-static_cast<std::intptr_t>(!isdescsort? comphi < complo : complo < comphi)};
				std::intptr_t notmask{~mask};

				// line breaks are placed for clarity, based on the dependency sequences
				pdatalo += mask;
				pdatahi += notmask;

				std::intptr_t platestlo{reinterpret_cast<std::intptr_t>(pdatalo) & mask};
				std::intptr_t platesthi{reinterpret_cast<std::intptr_t>(pdatahi) & notmask};
				U outlo{curlo & static_cast<M>(mask)};
				U outhi{curhi & static_cast<M>(notmask)};

				platestlo |= platesthi;
				outlo |= outhi;
				curlo &= static_cast<M>(notmask);
				complo &= static_cast<M>(notmask);

				U latestlo{*reinterpret_cast<W *>(platestlo)};
				*pout-- = static_cast<W>(outlo);
				curhi &= static_cast<M>(mask);

				auto complatestlo{convertinput<isabsvalue, issignmode, isfltpmode, W>(latestlo)};// convert the value for integer comparison
				U latesthi{latestlo};
				latestlo &= static_cast<M>(mask);
				comphi &= static_cast<M>(mask);

				auto complatesthi{complatestlo};
				complatestlo &= static_cast<M>(mask);
				curlo |= latestlo;
				latesthi &= static_cast<M>(notmask);

				complatesthi &= static_cast<M>(notmask);
				complo |= complatestlo;
				curhi |= latesthi;

				comphi |= complatesthi;
			}
		}while(--halfcount);
		if(1 & count){// odd counts will be handled here
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
				U out;
				// the only modification here is this part
				// never sample beyond the lower division (half of count, rounded down) of the array
				// this doesn't happen to the upper half, as it has 1 more item to process in odd-count cases
				if(!isdescsort? comphi < complo : complo < comphi){
					--pdatalo;
					if constexpr(!isrevorder) if(pdatalo < reinterpret_cast<W const *>(input)) pdatalo = pdatahi;
					out = curlo;
					curlo = *pdatalo;
					complo = convertinput<isabsvalue, issignmode, isfltpmode, W>(curlo);// convert the value for integer comparison
				}else{
					--pdatahi;
					if constexpr(isrevorder) if(pdatahi < reinterpret_cast<W const *>(input)) pdatahi = pdatalo;
					out = curhi;
					curhi = *pdatahi;
					comphi = convertinput<isabsvalue, issignmode, isfltpmode, W>(curhi);// convert the value for integer comparison
				}
				*pout-- = static_cast<W>(out);
			}else{// architecture: flatten the branch, at a higher register pressure cost
				// line breaks are placed for clarity, based on the dependency sequences
				std::intptr_t mask{-static_cast<std::intptr_t>(!isdescsort? comphi < complo : complo < comphi)};
				std::intptr_t notmask{~mask};

				pdatalo += mask;
				U outlo{curlo & static_cast<M>(mask)};
				pdatahi += notmask;
				U outhi{curhi & static_cast<M>(notmask)};

				// the only modification here is this part
				// never sample beyond the lower division (half of count, rounded down) of the array
				// this doesn't happen to the upper half, as it has 1 more item to process in odd-count cases
				if constexpr(!isrevorder){
					if(pdatalo < reinterpret_cast<W const *>(input)) pdatalo = pdatahi;
				}else if(pdatahi < reinterpret_cast<W const *>(input)) pdatahi = pdatalo;
				outlo |= outhi;
				curlo &= static_cast<M>(notmask);

				std::intptr_t platestlo{reinterpret_cast<std::intptr_t>(pdatalo) & mask};
				std::intptr_t platesthi{reinterpret_cast<std::intptr_t>(pdatahi) & notmask};
				*pout-- = static_cast<W>(outlo);

				platestlo |= platesthi;
				comphi &= static_cast<M>(mask);
				complo &= static_cast<M>(notmask);

				U latestlo{*reinterpret_cast<W *>(platestlo)};
				curhi &= static_cast<M>(mask);

				auto complatestlo{convertinput<isabsvalue, issignmode, isfltpmode, W>(latestlo)};// convert the value for integer comparison
				U latesthi{latestlo};
				latestlo &= static_cast<M>(mask);

				auto complatesthi{complatestlo};
				complatestlo &= static_cast<M>(mask);
				latesthi &= static_cast<M>(notmask);
				curlo |= latestlo;

				complatesthi &= static_cast<M>(notmask);
				complo |= complatestlo;
				curhi |= latesthi;

				comphi |= complatesthi;
			}
		}
		// finalise
		if(!isdescsort? comphi < complo : complo < comphi){
			curhi = curlo;
		}
	}else{// unfiltered input, uses direct integer comparisons
		do{
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
				U out;
				if(!isdescsort? curhi < curlo : curlo < curhi){
					--pdatalo;
					out = curlo;
					curlo = *pdatalo;
				}else{
					--pdatahi;
					out = curhi;
					curhi = *pdatahi;
				}
				*pout-- = static_cast<W>(out);
			}else{// architecture: flatten the branch, at a higher register pressure cost
				std::intptr_t mask;
				if constexpr(std::is_signed_v<W>){// signed comparison optimisation
					mask = !isdescsort? curhi - curlo : curlo - curhi;
					mask >>= CHAR_BIT * sizeof(std::intptr_t) - 1;
				}else mask = -static_cast<std::intptr_t>(!isdescsort? curhi < curlo : curlo < curhi);
				std::intptr_t notmask{~mask};

				// line breaks are placed for clarity, based on the dependency sequences
				pdatalo += mask;
				pdatahi += notmask;

				std::intptr_t platestlo{reinterpret_cast<std::intptr_t>(pdatalo) & mask};
				std::intptr_t platesthi{reinterpret_cast<std::intptr_t>(pdatahi) & notmask};
				U outlo{curlo & static_cast<M>(mask)};
				U outhi{curhi & static_cast<M>(notmask)};

				platestlo |= platesthi;
				outlo |= outhi;
				curlo &= static_cast<M>(notmask);

				U latestlo{*reinterpret_cast<W *>(platestlo)};
				*pout-- = static_cast<W>(outlo);

				U latesthi{latestlo};
				curhi &= static_cast<M>(mask);
				latestlo &= static_cast<M>(mask);

				latesthi &= static_cast<M>(notmask);
				curlo |= latestlo;

				curhi |= latesthi;
			}
		}while(--halfcount);
		if(1 & count){// odd counts will be handled here
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
				U out;
				// the only modification here is this part
				// never sample beyond the lower division (half of count, rounded down) of the array
				// this doesn't happen to the upper half, as it has 1 more item to process in odd-count cases
				if(!isdescsort? curhi < curlo : curlo < curhi){
					--pdatalo;
					if constexpr(!isrevorder) if(pdatalo < reinterpret_cast<W const *>(input)) pdatalo = pdatahi;
					out = curlo;
					curlo = *pdatalo;
				}else{
					--pdatahi;
					if constexpr(isrevorder) if(pdatahi < reinterpret_cast<W const *>(input)) pdatahi = pdatalo;
					out = curhi;
					curhi = *pdatahi;
				}
				*pout-- = static_cast<W>(out);
			}else{// architecture: flatten the branch, at a higher register pressure cost
				std::intptr_t mask;
				if constexpr(std::is_signed_v<W>){// signed comparison optimisation
					mask = !isdescsort? curhi - curlo : curlo - curhi;
					mask >>= CHAR_BIT * sizeof(std::intptr_t) - 1;
				}else mask = -static_cast<std::intptr_t>(!isdescsort? curhi < curlo : curlo < curhi);
				std::intptr_t notmask{~mask};

				// line breaks are placed for clarity, based on the dependency sequences
				pdatalo += mask;
				U outlo{curlo & static_cast<M>(mask)};
				pdatahi += notmask;
				U outhi{curhi & static_cast<M>(notmask)};

				// the only modification here is this part
				// never sample beyond the lower division (half of count, rounded down) of the array
				// this doesn't happen to the upper half, as it has 1 more item to process in odd-count cases
				if constexpr(!isrevorder){
					if(pdatalo < reinterpret_cast<W const *>(input)) pdatalo = pdatahi;
				}else if(pdatahi < reinterpret_cast<W const *>(input)) pdatahi = pdatalo;
				outlo |= outhi;

				std::intptr_t platestlo{reinterpret_cast<std::intptr_t>(pdatalo) & mask};
				std::intptr_t platesthi{reinterpret_cast<std::intptr_t>(pdatahi) & notmask};
				*pout-- = static_cast<W>(outlo);

				platestlo |= platesthi;
				curlo &= static_cast<M>(notmask);

				U latestlo{*reinterpret_cast<W *>(platestlo)};
				curhi &= static_cast<M>(mask);

				U latesthi{latestlo};
				latestlo &= static_cast<M>(mask);

				latesthi &= static_cast<M>(notmask);
				curlo |= latestlo;

				curhi |= latesthi;
			}
		}
		// finalise
		if(!isdescsort? curhi < curlo : curlo < curhi){
			curhi = curlo;
		}
	}
	*pout = static_cast<W>(curhi);
}

// multithreading main function for radixsortcopynoallocmulti() and radixsortnoallocmulti()
// standalone function, reused in the same template form (hence the RSBD8_FUNC_NORMAL) in the 4-, 8- and then 16-way multithreading parts
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
RSBD8_FUNC_NORMAL std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void> mergehalvesmain(std::size_t count, T const input[], T output[])noexcept{
	using W = typename std::conditional_t<std::is_class_v<T> || std::is_union_v<T> || isabsvalue || !issignmode || isfltpmode, std::enable_if<true, T>, std::make_signed<T>>::type;// for simple signed comparisons, use signed W
	using U = std::conditional_t<std::is_signed_v<W> && sizeof(W) < sizeof(std::intptr_t), std::intptr_t,// sign-extend signed types for masking operations
		std::conditional_t<std::is_unsigned_v<W> && sizeof(W) < sizeof(unsigned), unsigned, W>>;// assume zero-extension to be basically free for U on basically all modern machines
	using M = std::conditional_t<std::is_integral_v<U> &&
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		128 != CHAR_BIT * sizeof(T)// test128 and longdoubletest128 cases
#else
		64 != CHAR_BIT * sizeof(T)// test64 case
#endif
		, U, std::intptr_t>;// used for masking operations
	assert(2 < count);
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);

	// process the low half here (rounded down)
	std::size_t halfcount{count >> 1};
	W *pout{reinterpret_cast<W *>(output)};
	W const *pdatalo{reinterpret_cast<W const *>(input) + isrevorder * halfcount};
	W const *pdatahi{reinterpret_cast<W const *>(input) + !isrevorder * halfcount};
	U curlo{*pdatalo}, curhi{*pdatahi};
	--halfcount;// rounded down and one less, as the final item is handled outside of the loop
	if constexpr(isabsvalue || isfltpmode){// filtered input, convert everything for unsigned comparisons
		auto[complo, comphi]{convertinput<isabsvalue, issignmode, isfltpmode, W>(curlo, curhi)};
		do{
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
				U out;
				if(!isdescsort? comphi < complo : complo < comphi){
					++pdatahi;
					out = curhi;
					curhi = *pdatahi;
					comphi = convertinput<isabsvalue, issignmode, isfltpmode, W>(curhi);// convert the value for integer comparison
				}else{
					++pdatalo;
					out = curlo;
					curlo = *pdatalo;
					complo = convertinput<isabsvalue, issignmode, isfltpmode, W>(curlo);// convert the value for integer comparison
				}
				*pout++ = static_cast<W>(out);
			}else{// architecture: flatten the branch, at a higher register pressure cost
				// line breaks are placed for clarity, based on the dependency sequences
				std::intptr_t mask{-static_cast<std::intptr_t>(!isdescsort? comphi < complo : complo < comphi)};
				std::intptr_t notmask{~mask};

				pdatahi -= mask;
				U outhi{curhi & static_cast<M>(mask)};
				pdatalo -= notmask;
				U outlo{curlo & static_cast<M>(notmask)};

				std::intptr_t platesthi{reinterpret_cast<std::intptr_t>(pdatahi) & mask};
				std::intptr_t platestlo{reinterpret_cast<std::intptr_t>(pdatalo) & notmask};
				outhi |= outlo;

				platesthi |= platestlo;
				*pout++ = static_cast<W>(outhi);
				curhi &= static_cast<M>(notmask);

				U latesthi{*reinterpret_cast<W *>(platesthi)};
				comphi &= static_cast<M>(notmask);
				curlo &= static_cast<M>(mask);

				auto complatesthi{convertinput<isabsvalue, issignmode, isfltpmode, W>(latesthi)};// convert the value for integer comparison
				U latestlo{latesthi};
				latesthi &= static_cast<M>(mask);
				complo &= static_cast<M>(mask);

				auto complatestlo{complatesthi};
				complatesthi &= static_cast<M>(mask);
				latestlo &= static_cast<M>(notmask);

				complatestlo &= static_cast<M>(notmask);
				comphi |= complatesthi;
				curhi |= latesthi;
				curlo |= latestlo;

				complo |= complatestlo;
			}
		}while(--halfcount);
		// finalise
		if(!isdescsort? comphi < complo : complo < comphi){
			curlo = curhi;
		}
	}else{// unfiltered input
		do{
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
				U out;
				if(!isdescsort? curhi < curlo : curlo < curhi){
					++pdatahi;
					out = curhi;
					curhi = *pdatahi;
				}else{
					++pdatalo;
					out = curlo;
					curlo = *pdatalo;
				}
				*pout++ = static_cast<W>(out);
			}else{// architecture: flatten the branch, at a higher register pressure cost
				std::intptr_t mask;
				if constexpr(std::is_signed_v<W>){// signed comparison optimisation
					mask = !isdescsort? curhi - curlo : curlo - curhi;
					mask >>= CHAR_BIT * sizeof(std::intptr_t) - 1;
				}else mask = -static_cast<std::intptr_t>(!isdescsort? curhi < curlo : curlo < curhi);
				std::intptr_t notmask{~mask};

				// line breaks are placed for clarity, based on the dependency sequences
				pdatahi -= mask;
				U outhi{curhi & static_cast<M>(mask)};
				pdatalo -= notmask;
				U outlo{curlo & static_cast<M>(notmask)};

				std::intptr_t platesthi{reinterpret_cast<std::intptr_t>(pdatahi) & mask};
				std::intptr_t platestlo{reinterpret_cast<std::intptr_t>(pdatalo) & notmask};
				outhi |= outlo;

				platesthi |= platestlo;
				*pout++ = static_cast<W>(outhi);

				U latesthi{*reinterpret_cast<W *>(platesthi)};
				curhi &= static_cast<M>(notmask);
				curlo &= static_cast<M>(mask);

				U latestlo{latesthi};
				latesthi &= static_cast<M>(mask);

				latestlo &= static_cast<M>(notmask);
				curhi |= latesthi;

				curlo |= latestlo;
			}
		}while(--halfcount);
		// finalise
		if(!isdescsort? curhi < curlo : curlo < curhi){
			curlo = curhi;
		}
	}
	*pout = static_cast<W>(curlo);
}

// Up to 4-way multithreading functions without indirection

template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T
#if !defined(RSBD8_THREAD_MAXIMUM) || 8 <= (RSBD8_THREAD_MAXIMUM)
	, typename X
#endif
	>
RSBD8_FUNC_NORMAL std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
	radixsortcopynoallocmulti
#else
	radixsortcopynoallocmulti4thread
#endif
	(std::size_t count, T const input[], T output[], T buffer[])noexcept{
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);
	assert(buffer);

#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>};
	if(0xFFu < count){
		unsigned reportedcores{std::thread::hardware_concurrency()};// when this is 0, assume single-core
		if(1 < reportedcores){// 2-way limit
			// initial phase with regular sorting of both halves
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, true>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, true>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, true>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, true>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, true>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, true>;
			}
#else// no indirect secondary call
			static auto constexpr pcall{radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, X, true>};
#endif
			unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
			{
				std::future<void> asynchandle;
#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
				static std::size_t constexpr limit4way{base4waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
				if(3 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 4 > (RSBD8_THREAD_MINIMUM)
					&& limit4way < count
#endif
					){// 4-way limit
#endif
					std::size_t const halfcount{count >> 1};// rounded down
					try{
						// process the upper half (rounded up) separately if possible
						asynchandle = std::async(std::launch::async, pcall, (count + 1) >> 1, input + halfcount, buffer + halfcount, output + halfcount);
						usemultithread = 1;
						std::swap(output, buffer);// swap the buffer pointers for the lower half processing
					}catch(...){// std::async may fail gracefully here
						assert(false);
					}
#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
				}
#endif
				// process the lower half (rounded down) here
				pcall(count >> usemultithread, input, output, buffer);// architecture: indirect calls only have a modest performance penalty on most platforms
			}

			// merging phase
			if(usemultithread){// conditionally enable multi-threading here
				// This cannot be synchronised by a simple spinlock, as the processing above will most likely involve waiting on two other threads to finish.
				// note that output and buffer were swapped in the initial phase
				std::future<void> asynchandle;
				try{
					// process the upper half separately if possible
					asynchandle = std::async(std::launch::async, mergehalvesmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>, count, output, buffer);
				}catch(...){// std::async may fail gracefully here
					assert(false);
					// given the absolute rarity of this case, simply process this part in the current thread
					mergehalvesmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>(count, output, buffer);
				}
				mergehalvesmain<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>(count, output, buffer);
			}
#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
			return;
		}else{// single-threaded
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, false>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, false>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, false>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, false>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, false>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>;
			}
		}
	}
	pcall(count, input, output, buffer);// architecture: indirect calls only have a modest performance penalty on most platforms
#endif
}

template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T
#if !defined(RSBD8_THREAD_MAXIMUM) || 8 <= (RSBD8_THREAD_MAXIMUM)
	, typename X
#endif
	>
RSBD8_FUNC_NORMAL std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
	radixsortnoallocmulti
#else
	radixsortnoallocmulti4thread
#endif
	(std::size_t count, T input[], T buffer[], bool movetobuffer = false)noexcept{
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(buffer);

#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>};
	if(0xFFu < count){
		unsigned reportedcores{std::thread::hardware_concurrency()};// when this is 0, assume single-core
		if(1 < reportedcores){// 2-way limit
			// initial phase with regular sorting of both halves
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, true>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, true>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, true>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, true>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, true>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, true>;
			}
#else// no indirect secondary call
			static auto constexpr pcall{radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, X, true>};
#endif
			unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
			{
				std::future<void> asynchandle;
#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
				static std::size_t constexpr limit4way{base4waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
				if(3 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 4 > (RSBD8_THREAD_MINIMUM)
					&& limit4way < count
#endif
					){// 4-way limit
#endif
					std::size_t const halfcount{count >> 1};// rounded down
					try{
						// process the upper half (rounded up) separately if possible
						asynchandle = std::async(std::launch::async, pcall, (count + 1) >> 1, input + halfcount, buffer + halfcount, !movetobuffer);
						usemultithread = 1;
						movetobuffer = !movetobuffer;// swap the buffer pointers for the lower half processing
					}catch(...){// std::async may fail gracefully here
						assert(false);
					}
#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
				}
#endif
				// process the lower half (rounded down) here
				pcall(count >> usemultithread, input, buffer, movetobuffer);// architecture: indirect calls only have a modest performance penalty on most platforms
			}

			// merging phase
			if(usemultithread){// conditionally enable multi-threading here
				// This cannot be synchronised by a simple spinlock, as the processing above will most likely involve waiting on two other threads to finish.
				// note that input and buffer were swapped in the initial phase
				T *tmp{input};
				if(movetobuffer){
					input = buffer;
					buffer = tmp;
				}
				std::future<void> asynchandle;
				try{
					// process the upper half separately if possible
					asynchandle = std::async(std::launch::async, mergehalvesmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>, count, input, buffer);
				}catch(...){// std::async may fail gracefully here
					assert(false);
					// given the absolute rarity of this case, simply process this part in the current thread
					mergehalvesmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>(count, input, buffer);
				}
				mergehalvesmain<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>(count, input, buffer);
			}
#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
			return;
		}else{// single-threaded
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, false>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, false>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, false>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, false>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, false>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>;
			}
		}
	}
	pcall(count, input, buffer, movetobuffer);// architecture: indirect calls only have a modest performance penalty on most platforms
#endif
}
#endif// !defined(RSBD8_THREAD_MAXIMUM) || 4 <= (RSBD8_THREAD_MAXIMUM)

#if !defined(RSBD8_THREAD_MAXIMUM) || 6 <= (RSBD8_THREAD_MAXIMUM)
// Helper functions for merging the thirds from multithreading inputs without indirection

// multithreading companion function for radixsortcopynoallocmulti() and radixsortnoallocmulti()
// standalone function, reused in the same template form (hence the RSBD8_FUNC_NORMAL) in the 6-way multithreading parts
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
RSBD8_FUNC_NORMAL std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void> mergethirdsmtc(std::size_t count, T const input[], T output[])noexcept{
	using W = typename std::conditional_t<std::is_class_v<T> || std::is_union_v<T> || isabsvalue || !issignmode || isfltpmode, std::enable_if<true, T>, std::make_signed<T>>::type;// for simple signed comparisons, use signed W
	using U = std::conditional_t<std::is_signed_v<W> && sizeof(W) < sizeof(std::intptr_t), std::intptr_t,// sign-extend signed types for masking operations
		std::conditional_t<std::is_unsigned_v<W> && sizeof(W) < sizeof(unsigned), unsigned, W>>;// assume zero-extension to be basically free for U on basically all modern machines
	using M = std::conditional_t<std::is_integral_v<U> &&
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		128 != CHAR_BIT * sizeof(T)// test128 and longdoubletest128 cases
#else
		64 != CHAR_BIT * sizeof(T)// test64 case
#endif
		, U, std::intptr_t>;// used for masking operations
	assert(2 < count);
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);

	// process the high half here (rounded up)
	std::size_t thirdcount{count / 3};
	std::size_t thirdcountmid{(count + 1) / 3};
	std::size_t finalcount{(count >> 1) - thirdcount};// half of count (rounded down) minus thirdcount, used for finalisation
	--thirdcount;// rounded down and one less, as the final item is handled outside of the loop
	W *pout{reinterpret_cast<W *>(output) + count - 1};
	W const *pdata2{reinterpret_cast<W const *>(input) + (!isrevorder? count - 1 : thirdcount)};
	W const *pdata1{reinterpret_cast<W const *>(input) + (thirdcount + thirdcountmid)};
	W const *pdata0{reinterpret_cast<W const *>(input) + (isrevorder? count - 1 : thirdcount)};
	U cur2{*pdata2}, cur1{*pdata1}, cur0{*pdata0};
	W const *pdata2stop{!isrevorder? pdata1 : reinterpret_cast<W const *>(input) - 1};
	W const *pdata1stop{!isrevorder? pdata0 : pdata2};
	W const *pdata0stop{isrevorder? pdata1 : reinterpret_cast<W const *>(input) - 1};
	if constexpr(isabsvalue || isfltpmode){// filtered input, convert everything for unsigned comparisons
		auto[comp2, comp1, comp0]{convertinput<isabsvalue, issignmode, isfltpmode, W>(cur2, cur1, cur0)};
		U out;
		do{
			if(!isdescsort? comp2 < comp1 : comp1 < comp2){
				if(!isdescsort? comp1 < comp0 : comp0 < comp1) goto handle0filtered;
				--pdata1;
				out = cur1;
				cur1 = *pdata1;
				comp1 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur1);// convert the value for integer comparison
			}else if(!(!isdescsort? comp2 < comp0 : comp0 < comp2)){
				--pdata2;
				out = cur2;
				cur2 = *pdata2;
				comp2 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur2);// convert the value for integer comparison
			}else{
handle0filtered:
				--pdata0;
				out = cur0;
				cur0 = *pdata0;
				comp0 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur0);// convert the value for integer comparison
			}
			*pout-- = static_cast<W>(out);
		}while(--thirdcount);
		// after one third it's possble that one of the three parts has exhausted its items, check for that here
		do{// the only modification here is this part
			// never sample beyond the three divisions (the start, one third and two thirds) of the array
			if(!isdescsort? comp2 < comp1 : comp1 < comp2){
				if(!isdescsort? comp1 < comp0 : comp0 < comp1) goto handle0finalfiltered;
				--pdata1;
				out = cur1;
				if(pdata1stop < pdata1){
					cur1 = *pdata1;
					comp1 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur1);// convert the value for integer comparison
				}else{
					pdata1 = pdata0;
					pdata1stop = pdata0stop;
					goto lastloopfiltered;
				}
			}else if(!(!isdescsort? comp2 < comp0 : comp0 < comp2)){
				--pdata2;
				out = cur2;
				if(pdata2stop < pdata2){
					cur2 = *pdata2;
					comp2 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur2);// convert the value for integer comparison
				}else{
					pdata2 = pdata1;
					pdata1 = pdata0;
					pdata2stop = pdata1stop;
					pdata1stop = pdata0stop;
					goto lastloopfiltered;
				}
			}else{
handle0finalfiltered:// architecture: jump label reuse (from the else branch, including possible nop padding instructions)
				--pdata0;
				out = cur0;
				if(pdata0stop >= pdata0) goto lastloopfiltered;
				cur0 = *pdata0;
				comp0 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur0);// convert the value for integer comparison
			}
			*pout-- = static_cast<W>(out);
		}while(--finalcount);
		if(1 & count){// odd counts will be handled here
			// the only modification here is this part
			// never sample beyond the three divisions (the start, one third and two thirds) of the array
			if(!isdescsort? comp2 < comp1 : comp1 < comp2){
				if(!isdescsort? comp1 < comp0 : comp0 < comp1) goto handle0oddfiltered;
				--pdata1;
				if(pdata1stop >= pdata1) pdata1 = pdata2;
				out = cur1;
				cur1 = *pdata1;
				comp1 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur1);// convert the value for integer comparison
			}else if(!(!isdescsort? comp2 < comp0 : comp0 < comp2)){
				--pdata2;
				if(pdata2stop >= pdata2) pdata2 = pdata1;
				out = cur2;
				cur2 = *pdata2;
				comp2 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur2);// convert the value for integer comparison
			}else{
handle0oddfiltered:
				--pdata0;
				if(pdata0stop >= pdata0) pdata0 = pdata1;
				out = cur0;
				cur0 = *pdata0;
				comp0 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur0);// convert the value for integer comparison
			}
			*pout-- = static_cast<W>(out);
		}
		// finalise using all three parts
		if(!isdescsort? comp1 < comp0 : comp0 < comp1){
			comp1 = comp0;
			cur1 = cur0;
		}
		goto exitfiltered;
lastloopfiltered:
		*pout-- = static_cast<W>(out);
		while(--finalcount){
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
				if(!isdescsort? comp2 < comp1 : comp1 < comp2){
					--pdata1;
					out = cur1;
					cur1 = *pdata1;
					comp1 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur1);// convert the value for integer comparison
				}else{
					--pdata2;
					out = cur2;
					cur2 = *pdata2;
					comp2 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur2);// convert the value for integer comparison
				}
				*pout-- = static_cast<W>(out);
			}else{// architecture: flatten the branch, at a higher register pressure cost
				// line breaks are placed for clarity, based on the dependency sequences
				std::intptr_t mask{-static_cast<std::intptr_t>(!isdescsort? comp2 < comp1 : comp1 < comp2)};
				std::intptr_t notmask{~mask};

				pdata1 += mask;
				pdata2 += notmask;

				std::intptr_t platest1{reinterpret_cast<std::intptr_t>(pdata1) & mask};
				std::intptr_t platest2{reinterpret_cast<std::intptr_t>(pdata2) & notmask};
				U out1{cur1 & static_cast<M>(mask)};
				U out2{cur2 & static_cast<M>(notmask)};

				platest1 |= platest2;
				out1 |= out2;
				cur1 &= static_cast<M>(notmask);
				comp1 &= static_cast<M>(notmask);

				U latest1{*reinterpret_cast<W *>(platest1)};
				*pout-- = static_cast<W>(out1);
				cur2 &= static_cast<M>(mask);

				auto complatest1{convertinput<isabsvalue, issignmode, isfltpmode, W>(latest1)};// convert the value for integer comparison
				U latest2{latest1};
				latest1 &= static_cast<M>(mask);
				comp2 &= static_cast<M>(mask);

				auto complatest2{complatest1};
				complatest1 &= static_cast<M>(mask);
				cur1 |= latest1;
				latest2 &= static_cast<M>(notmask);

				complatest2 &= static_cast<M>(notmask);
				comp1 |= complatest1;
				cur2 |= latest2;

				comp2 |= complatest2;
			}
		}
		if(1 & count){// odd counts will be handled here
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
				// the only modification here is this part
				// never sample beyond the three divisions (the start, one third and two thirds) of the array
				if(!isdescsort? comp2 < comp1 : comp1 < comp2){
					--pdata1;
					if(pdata1stop >= pdata1) pdata1 = pdata2;
					out = cur1;
					cur1 = *pdata1;
					comp1 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur1);// convert the value for integer comparison
				}else{
					--pdata2;
					if(pdata2stop >= pdata2) pdata2 = pdata1;
					out = cur2;
					cur2 = *pdata2;
					comp2 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur2);// convert the value for integer comparison
				}
				*pout-- = static_cast<W>(out);
			}else{// architecture: flatten the branch, at a higher register pressure cost
				// line breaks are placed for clarity, based on the dependency sequences
				std::intptr_t mask{-static_cast<std::intptr_t>(!isdescsort? comp2 < comp1 : comp1 < comp2)};
				std::intptr_t notmask{~mask};

				pdata1 += mask;
				U out1{cur1 & static_cast<M>(mask)};
				pdata2 += notmask;
				U out2{cur2 & static_cast<M>(notmask)};

				// the only modification here is this part
				// never sample beyond the three divisions (the start, one third and two thirds) of the array
				if(pdata1stop >= pdata1) pdata1 = pdata2;
				if(pdata2stop >= pdata2) pdata2 = pdata1;
				out1 |= out2;
				cur1 &= static_cast<M>(notmask);

				std::intptr_t platest1{reinterpret_cast<std::intptr_t>(pdata1) & mask};
				std::intptr_t platest2{reinterpret_cast<std::intptr_t>(pdata2) & notmask};
				*pout-- = static_cast<W>(out1);

				platest1 |= platest2;
				comp2 &= static_cast<M>(mask);
				comp1 &= static_cast<M>(notmask);

				U latest1{*reinterpret_cast<W *>(platest1)};
				cur2 &= static_cast<M>(mask);

				auto complatest1{convertinput<isabsvalue, issignmode, isfltpmode, W>(latest1)};// convert the value for integer comparison
				U latest2{latest1};
				latest1 &= static_cast<M>(mask);

				auto complatest2{complatest1};
				complatest1 &= static_cast<M>(mask);
				latest2 &= static_cast<M>(notmask);
				cur1 |= latest1;

				complatest2 &= static_cast<M>(notmask);
				comp1 |= complatest1;
				cur2 |= latest2;

				comp2 |= complatest2;
			}
		}
		// finalise using only two parts
exitfiltered:
		if(!isdescsort? comp2 < comp1 : comp1 < comp2){
			cur2 = cur1;
		}
	}else{// unfiltered input
		do{
			U out;
			if(!isdescsort? cur2 < cur1 : cur1 < cur2){
				if(!isdescsort? cur1 < cur0 : cur0 < cur1) goto handle0unfiltered;
				--pdata1;
				out = cur1;
				cur1 = *pdata1;
			}else if(!(!isdescsort? cur2 < cur0 : cur0 < cur2)){
				--pdata2;
				out = cur2;
				cur2 = *pdata2;
			}else{
handle0unfiltered:
				--pdata0;
				out = cur0;
				cur0 = *pdata0;
			}
			*pout-- = static_cast<W>(out);
		}while(--thirdcount);
		// after one third it's possble that one of the three parts has exhausted its items, check for that here
		U out;
		do{// the only modification here is this part
			// never sample beyond the three divisions (the start, one third and two thirds) of the array
			if(!isdescsort? cur2 < cur1 : cur1 < cur2){
				if(!isdescsort? cur1 < cur0 : cur0 < cur1) goto handle0finalunfiltered;
				--pdata1;
				out = cur1;
				if(pdata1stop < pdata1){
					cur1 = *pdata1;
				}else{
					pdata1 = pdata0;
					pdata1stop = pdata0stop;
					goto lastloopunfiltered;
				}
			}else if(!(!isdescsort? cur2 < cur0 : cur0 < cur2)){
				--pdata2;
				out = cur2;
				if(pdata2stop < pdata2){
					cur2 = *pdata2;
				}else{
					pdata2 = pdata1;
					pdata1 = pdata0;
					pdata2stop = pdata1stop;
					pdata1stop = pdata0stop;
					goto lastloopunfiltered;
				}
			}else{
handle0finalunfiltered:// architecture: jump label reuse (from the else branch, including possible nop padding instructions)
				--pdata0;
				out = cur0;
				if(pdata0stop >= pdata0) goto lastloopunfiltered;
				cur0 = *pdata0;
			}
			*pout-- = static_cast<W>(out);
		}while(--finalcount);
		if(1 & count){// odd counts will be handled here
			// the only modification here is this part
			// never sample beyond the three divisions (the start, one third and two thirds) of the array
			if(!isdescsort? cur2 < cur1 : cur1 < cur2){
				if(!isdescsort? cur1 < cur0 : cur0 < cur1) goto handle0oddunfiltered;
				--pdata1;
				if(pdata1stop >= pdata1) pdata1 = pdata2;
				out = cur1;
				cur1 = *pdata1;
			}else if(!(!isdescsort? cur2 < cur0 : cur0 < cur2)){
				--pdata2;
				if(pdata2stop >= pdata2) pdata2 = pdata1;
				out = cur2;
				cur2 = *pdata2;
			}else{
handle0oddunfiltered:
				--pdata0;
				if(pdata0stop >= pdata0) pdata0 = pdata1;
				out = cur0;
				cur0 = *pdata0;
			}
			*pout-- = static_cast<W>(out);
		}
		// finalise using all three parts
		if(!isdescsort? cur1 < cur0 : cur0 < cur1){
			cur1 = cur0;
		}
		goto exitunfiltered;
lastloopunfiltered:
		*pout-- = static_cast<W>(out);
		while(--finalcount){
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
				if(!isdescsort? cur2 < cur1 : cur1 < cur2){
					--pdata1;
					out = cur1;
					cur1 = *pdata1;
				}else{
					--pdata2;
					out = cur2;
					cur2 = *pdata2;
				}
				*pout-- = static_cast<W>(out);
			}else{// architecture: flatten the branch, at a higher register pressure cost
				std::intptr_t mask;
				if constexpr(std::is_signed_v<W>){// signed comparison optimisation
					mask = !isdescsort? cur2 - cur1 : cur1 - cur2;
					mask >>= CHAR_BIT * sizeof(std::intptr_t) - 1;
				}else mask = -static_cast<std::intptr_t>(!isdescsort? cur2 < cur1 : cur1 < cur2);
				std::intptr_t notmask{~mask};

				// line breaks are placed for clarity, based on the dependency sequences
				pdata1 += mask;
				pdata2 += notmask;

				std::intptr_t platest1{reinterpret_cast<std::intptr_t>(pdata1) & mask};
				std::intptr_t platest2{reinterpret_cast<std::intptr_t>(pdata2) & notmask};
				U out1{cur1 & static_cast<M>(mask)};
				U out2{cur2 & static_cast<M>(notmask)};

				platest1 |= platest2;
				out1 |= out2;
				cur1 &= static_cast<M>(notmask);

				U latest1{*reinterpret_cast<W *>(platest1)};
				*pout-- = static_cast<W>(out1);

				U latest2{latest1};
				cur2 &= static_cast<M>(mask);
				latest1 &= static_cast<M>(mask);

				latest2 &= static_cast<M>(notmask);
				cur1 |= latest1;

				cur2 |= latest2;
			}
		}
		if(1 & count){// odd counts will be handled here
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
				// the only modification here is this part
				// never sample beyond the three divisions (the start, one third and two thirds) of the array
				if(!isdescsort? cur2 < cur1 : cur1 < cur2){
					--pdata1;
					if(pdata1stop >= pdata1) pdata1 = pdata2;
					out = cur1;
					cur1 = *pdata1;
				}else{
					--pdata2;
					if(pdata2stop >= pdata2) pdata2 = pdata1;
					out = cur2;
					cur2 = *pdata2;
				}
				*pout-- = static_cast<W>(out);
			}else{// flatten the branch, at a higher register pressure cost
				std::intptr_t mask;
				if constexpr(std::is_signed_v<W>){// signed comparison optimisation
					mask = !isdescsort? cur2 - cur1 : cur1 - cur2;
					mask >>= CHAR_BIT * sizeof(std::intptr_t) - 1;
				}else mask = -static_cast<std::intptr_t>(!isdescsort? cur2 < cur1 : cur1 < cur2);
				std::intptr_t notmask{~mask};

				// line breaks are placed for clarity, based on the dependency sequences
				pdata1 += mask;
				U out1{cur1 & static_cast<M>(mask)};
				pdata2 += notmask;
				U out2{cur2 & static_cast<M>(notmask)};

				// the only modification here is this part
				// never sample beyond the three divisions (the start, one third and two thirds) of the array
				if constexpr(!isrevorder){
					if(pdata1 < reinterpret_cast<W const *>(input)) pdata1 = pdata2;
				}else if(pdata2 < reinterpret_cast<W const *>(input)) pdata2 = pdata1;
				out1 |= out2;

				std::intptr_t platest1{reinterpret_cast<std::intptr_t>(pdata1) & mask};
				std::intptr_t platest2{reinterpret_cast<std::intptr_t>(pdata2) & notmask};
				*pout-- = static_cast<W>(out1);

				platest1 |= platest2;
				cur1 &= static_cast<M>(notmask);

				U latest1{*reinterpret_cast<W *>(platest1)};
				cur2 &= static_cast<M>(mask);

				U latest2{latest1};
				latest1 &= static_cast<M>(mask);

				latest2 &= static_cast<M>(notmask);
				cur1 |= latest1;

				cur2 |= latest2;
			}
		}
		// finalise using only two parts
exitunfiltered:
		if(!isdescsort? cur2 < cur1 : cur1 < cur2){
			cur2 = cur1;
		}
	}
	*pout = static_cast<W>(cur2);
}

// multithreading main function for radixsortcopynoallocmulti() and radixsortnoallocmulti()
// standalone function, reused in the same template form (hence the RSBD8_FUNC_NORMAL) in the 6-way multithreading parts
template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
RSBD8_FUNC_NORMAL std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void> mergethirdsmain(std::size_t count, T const input[], T output[])noexcept{
	using W = typename std::conditional_t<std::is_class_v<T> || std::is_union_v<T> || isabsvalue || !issignmode || isfltpmode, std::enable_if<true, T>, std::make_signed<T>>::type;// for simple signed comparisons, use signed W
	using U = std::conditional_t<std::is_signed_v<W> && sizeof(W) < sizeof(std::intptr_t), std::intptr_t,// sign-extend signed types for masking operations
		std::conditional_t<std::is_unsigned_v<W> && sizeof(W) < sizeof(unsigned), unsigned, W>>;// assume zero-extension to be basically free for U on basically all modern machines
	using M = std::conditional_t<std::is_integral_v<U> &&
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		128 != CHAR_BIT * sizeof(T)// test128 and longdoubletest128 cases
#else
		64 != CHAR_BIT * sizeof(T)// test64 case
#endif
		, U, std::intptr_t>;// used for masking operations
	assert(2 < count);
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);

	// process the low half here (rounded down)
	std::size_t thirdcount{count / 3};
	std::size_t const thirdcountmid{(count + 1) / 3};
	W *pout{reinterpret_cast<W *>(output)};
	W const *pdata0{reinterpret_cast<W const *>(input) + isrevorder * (thirdcount + thirdcountmid)};
	W const *pdata1{reinterpret_cast<W const *>(input) + thirdcount};
	W const *pdata2{reinterpret_cast<W const *>(input) + !isrevorder * (thirdcount + thirdcountmid)};
	U cur0{*pdata0}, cur1{*pdata1}, cur2{*pdata2};
	std::size_t finalcount{(count >> 1) - thirdcount};// half of count (rounded down) minus thirdcount, used for finalisation
	--thirdcount;// rounded down and one less, as the final item is handled outside of the loop
	W const *const pdata0stop{!isrevorder? pdata1 : reinterpret_cast<W const *>(input) + count};
	W const *const pdata1stop{!isrevorder? pdata2 : pdata0};
	W const *const pdata2stop{isrevorder? pdata1 : reinterpret_cast<W const *>(input) + count};
	if constexpr(isabsvalue || isfltpmode){// filtered input, convert everything for unsigned comparisons
		auto[comp0, comp1, comp2]{convertinput<isabsvalue, issignmode, isfltpmode, W>(cur0, cur1, cur2)};
		U out;
		do{
			if(!isdescsort? comp1 < comp0 : comp0 < comp1){
				if(!isdescsort? comp2 < comp1 : comp1 < comp2) goto handle2filtered;
				++pdata1;
				out = cur1;
				cur1 = *pdata1;
				comp1 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur1);// convert the value for integer comparison
			}else if(!(!isdescsort? comp2 < comp0 : comp0 < comp2)){
				++pdata0;
				out = cur0;
				cur0 = *pdata0;
				comp0 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur0);// convert the value for integer comparison
			}else{
handle2filtered:// architecture: jump label reuse (from the else branch, including possible nop padding instructions)
				++pdata2;
				out = cur2;
				cur2 = *pdata2;
				comp2 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur2);// convert the value for integer comparison
			}
			*pout++ = static_cast<W>(out);
		}while(--thirdcount);
		// after one third it's possble that one of the three parts has exhausted its items, check for that here
		do{// the only modification here is this part
			// never sample beyond the three divisions (one third, two thirds and the end) of the array
			if(!isdescsort? comp1 < comp0 : comp0 < comp1){
				if(!isdescsort? comp2 < comp1 : comp1 < comp2) goto handle2finalfiltered;
				++pdata1;
				out = cur1;
				if(pdata1stop > pdata1){
					cur1 = *pdata1;
					comp1 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur1);// convert the value for integer comparison
				}else{
					pdata1 = pdata2;
					goto lastloopfiltered;
				}
			}else if(!(!isdescsort? comp2 < comp0 : comp0 < comp2)){
				++pdata0;
				out = cur0;
				if(pdata0stop > pdata0){
					cur0 = *pdata0;
					comp0 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur0);// convert the value for integer comparison
				}else{
					pdata0 = pdata1;
					pdata1 = pdata2;
					goto lastloopfiltered;
				}
			}else{
handle2finalfiltered:// architecture: jump label reuse (from the else branch, including possible nop padding instructions)
				++pdata2;
				out = cur2;
				if(pdata2stop <= pdata2) goto lastloopfiltered;
				cur2 = *pdata2;
				comp2 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur2);// convert the value for integer comparison
			}
			*pout++ = static_cast<W>(out);
		}while(--finalcount);
		// finalise using all three parts
		if(!isdescsort? comp2 < comp1 : comp1 < comp2){
			comp1 = comp2;
			cur1 = cur2;
		}
		goto exitfiltered;
lastloopfiltered:
		*pout++ = static_cast<W>(out);
		while(--finalcount){
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
				if(!isdescsort? comp1 < comp0 : comp0 < comp1){
					++pdata1;
					out = cur1;
					cur1 = *pdata1;
					comp1 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur1);// convert the value for integer comparison
				}else{
					++pdata0;
					out = cur0;
					cur0 = *pdata0;
					comp0 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur0);// convert the value for integer comparison
				}
				*pout++ = static_cast<W>(out);
			}else{// architecture: flatten the branch, at a higher register pressure cost
				// line breaks are placed for clarity, based on the dependency sequences
				std::intptr_t mask{-static_cast<std::intptr_t>(!isdescsort? comp1 < comp0 : comp0 < comp1)};
				std::intptr_t notmask{~mask};

				pdata1 -= mask;
				U out1{cur1 & static_cast<M>(mask)};
				pdata0 -= notmask;
				U out0{cur0 & static_cast<M>(notmask)};

				std::intptr_t platest1{reinterpret_cast<std::intptr_t>(pdata1) & mask};
				std::intptr_t platest0{reinterpret_cast<std::intptr_t>(pdata0) & notmask};
				out1 |= out0;

				platest1 |= platest0;
				*pout++ = static_cast<W>(out1);
				cur1 &= static_cast<M>(notmask);

				U latest1{*reinterpret_cast<W *>(platest1)};
				comp1 &= static_cast<M>(notmask);
				cur0 &= static_cast<M>(mask);

				auto complatest1{convertinput<isabsvalue, issignmode, isfltpmode, W>(latest1)};// convert the value for integer comparison
				U latest0{latest1};
				latest1 &= static_cast<M>(mask);
				comp0 &= static_cast<M>(mask);

				auto complatest0{complatest1};
				complatest1 &= static_cast<M>(mask);
				latest0 &= static_cast<M>(notmask);

				complatest0 &= static_cast<M>(notmask);
				comp1 |= complatest1;
				cur1 |= latest1;
				cur0 |= latest0;

				comp0 |= complatest0;
			}
		}
		// finalise using only two parts
exitfiltered:
		if(!isdescsort? comp1 < comp0 : comp0 < comp1){
			cur0 = cur1;
		}
	}else{// unfiltered input
		do{
			U out;
			if(!isdescsort? cur1 < cur0 : cur0 < cur1){
				if(!isdescsort? cur2 < cur1 : cur1 < cur2) goto handle2unfiltered;
				++pdata1;
				out = cur1;
				cur1 = *pdata1;
			}else if(!(!isdescsort? cur2 < cur0 : cur0 < cur2)){
				++pdata0;
				out = cur0;
				cur0 = *pdata0;
			}else{
handle2unfiltered:// architecture: jump label reuse (from the else branch, including possible nop padding instructions)
				++pdata2;
				out = cur2;
				cur2 = *pdata2;
			}
			*pout++ = static_cast<W>(out);
		}while(--thirdcount);
		// after one third it's possble that one of the three parts has exhausted its items, check for that here
		U out;
		do{// the only modification here is this part
			// never sample beyond the three divisions (one third, two thirds and the end) of the array
			if(!isdescsort? cur1 < cur0 : cur0 < cur1){
				if(!isdescsort? cur2 < cur1 : cur1 < cur2) goto handle2finalunfiltered;
				++pdata1;
				out = cur1;
				if(pdata1stop > pdata1){
					cur1 = *pdata1;
				}else{
					pdata1 = pdata2;
					goto lastloopunfiltered;
				}
			}else if(!(!isdescsort? cur2 < cur0 : cur0 < cur2)){
				++pdata0;
				out = cur0;
				if(pdata0stop > pdata0){
					cur0 = *pdata0;
				}else{
					pdata0 = pdata1;
					pdata1 = pdata2;
					goto lastloopunfiltered;
				}
			}else{
handle2finalunfiltered:// architecture: jump label reuse (from the else branch, including possible nop padding instructions)
				++pdata2;
				out = cur2;
				if(pdata2stop <= pdata2) goto lastloopunfiltered;
				cur2 = *pdata2;
			}
			*pout++ = static_cast<W>(out);
		}while(--finalcount);
		// finalise using all three parts
		if(!isdescsort? cur2 < cur1 : cur1 < cur2){
			cur1 = cur2;
		}
		goto exitunfiltered;
lastloopunfiltered:
		*pout++ = static_cast<W>(out);
		while(--finalcount){
			if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
				if(!isdescsort? cur1 < cur0 : cur0 < cur1){
					++pdata1;
					out = cur1;
					cur1 = *pdata1;
				}else{
					++pdata0;
					out = cur0;
					cur0 = *pdata0;
				}
				*pout++ = static_cast<W>(out);
			}else{// architecture: flatten the branch, at a higher register pressure cost
				std::intptr_t mask;
				if constexpr(std::is_signed_v<W>){// signed comparison optimisation
					mask = !isdescsort? cur1 - cur0 : cur0 - cur1;
					mask >>= CHAR_BIT * sizeof(std::intptr_t) - 1;
				}else mask = -static_cast<std::intptr_t>(!isdescsort? cur1 < cur0 : cur0 < cur1);
				std::intptr_t notmask{~mask};

				// line breaks are placed for clarity, based on the dependency sequences
				pdata1 -= mask;
				U out1{cur1 & static_cast<M>(mask)};
				pdata0 -= notmask;
				U out0{cur0 & static_cast<M>(notmask)};

				std::intptr_t platest1{reinterpret_cast<std::intptr_t>(pdata1) & mask};
				std::intptr_t platest0{reinterpret_cast<std::intptr_t>(pdata0) & notmask};
				out1 |= out0;

				platest1 |= platest0;
				*pout++ = static_cast<W>(out1);

				U latest1{*reinterpret_cast<W *>(platest1)};
				cur1 &= static_cast<M>(notmask);
				cur0 &= static_cast<M>(mask);

				U latest0{latest1};
				latest1 &= static_cast<M>(mask);

				latest0 &= static_cast<M>(notmask);
				cur1 |= latest1;

				cur0 |= latest0;
			}
		}
		// finalise using only two parts
exitunfiltered:
		if(!isdescsort? cur1 < cur0 : cur0 < cur1){
			cur0 = cur1;
		}
	}
	*pout++ = static_cast<W>(cur0);
}

// Up to 6-way multithreading functions without indirection

template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
RSBD8_FUNC_NORMAL std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void>
#if false// disabled in favour of other versions
	radixsortcopynoallocmulti
#else
	radixsortcopynoallocmulti6thread
#endif
	(std::size_t count, T const input[], T output[], T buffer[])noexcept{
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);
	assert(buffer);

	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>};
	if(0xFFu < count){
		unsigned reportedcores{std::thread::hardware_concurrency()};// when this is 0, assume single-core
		if(1 < reportedcores){// 2-way limit
			// initial phase with regular sorting of both halves
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char>;
			}
			std::size_t finalcount{count};// depending on multithreading, this will be either count or one third of count (rounded down)
			{
				std::future<void> asynchandle;
				static std::size_t constexpr limit6way{base6waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
				if(5 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 6 > (RSBD8_THREAD_MINIMUM)
					&& limit6way < count
#endif
					){// 6-way limit
					std::size_t const thirdcount{count / 3};// rounded down
					std::size_t const thirdcountmid{(count + 1) / 3};
					try{
						// process the middle third (rounded in between) separately if possible
						asynchandle = std::async(std::launch::async, pcall, thirdcountmid, input + thirdcount, buffer + thirdcount, output + thirdcount);
						std::size_t const twothirdscount{thirdcount + thirdcountmid};
						std::swap(output, buffer);// swap the buffer pointers for the lower half processing
						std::size_t const thirdcounttop{count - twothirdscount};
						finalcount = thirdcount;
						try{
							// process the top third (rounded up) separately if possible
							asynchandle = std::async(std::launch::async, pcall, thirdcounttop, input + twothirdscount, output + twothirdscount, buffer + twothirdscount);
						}catch(...){// std::async may fail gracefully here
							// given the absolute rarity of this case, simply process this part in the current thread
							assert(false);
							pcall(thirdcounttop, input + twothirdscount, output + twothirdscount, buffer + twothirdscount);
						}
					}catch(...){// std::async may fail gracefully here
						assert(false);
					}
				}
				// process the lower third (rounded down) here
				pcall(finalcount, input, output, buffer);// architecture: indirect calls only have a modest performance penalty on most platforms
			}

			// merging phase
			if(finalcount != count){// conditionally enable multi-threading here
				// This cannot be synchronised by a simple spinlock, as the processing above will most likely involve waiting on two other threads to finish.
				// note that output and buffer were swapped in the initial phase
				std::future<void> asynchandle;
				try{
					// process the upper half separately if possible
					asynchandle = std::async(std::launch::async, mergethirdsmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>, count, output, buffer);
				}catch(...){// std::async may fail gracefully here
					assert(false);
					// given the absolute rarity of this case, simply process this part in the current thread
					mergethirdsmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>(count, output, buffer);
				}
				mergethirdsmain<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>(count, output, buffer);
			}
			return;
		}else{// single-threaded
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, false>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, false>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, false>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, false>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, false>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>;
			}
		}
	}
	pcall(count, input, output, buffer);// architecture: indirect calls only have a modest performance penalty on most platforms
}

template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
RSBD8_FUNC_NORMAL std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void>
#if false// disabled in favour of other versions
	radixsortnoallocmulti
#else
	radixsortnoallocmulti6thread
#endif
	(std::size_t count, T input[], T buffer[], bool movetobuffer = false)noexcept{
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(buffer);

	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>};
	if(0xFFu < count){
		unsigned reportedcores{std::thread::hardware_concurrency()};// when this is 0, assume single-core
		if(1 < reportedcores){// 2-way limit
			// initial phase with regular sorting of both halves
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char>;
			}
			std::size_t finalcount{count};// depending on multithreading, this will be either count or one third of count (rounded down)
			{
				std::future<void> asynchandle;
				static std::size_t constexpr limit6way{base6waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
				if(5 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 6 > (RSBD8_THREAD_MINIMUM)
					&& limit6way < count
#endif
					){// 6-way limit
					std::size_t const thirdcount{count / 3};// rounded down
					std::size_t const thirdcountmid{(count + 1) / 3};
					try{
						// process the middle third (rounded in between) separately if possible
						asynchandle = std::async(std::launch::async, pcall, thirdcountmid, input + thirdcount, buffer + thirdcount, !movetobuffer);
						std::size_t const twothirdscount{thirdcount + thirdcountmid};
						movetobuffer = !movetobuffer;// swap the buffer pointers for the lower half processing
						std::size_t const thirdcounttop{count - twothirdscount};
						finalcount = thirdcount;
						try{
							// process the top third (rounded up) separately if possible
							asynchandle = std::async(std::launch::async, pcall, thirdcounttop, input + twothirdscount, buffer + twothirdscount, movetobuffer);
						}catch(...){// std::async may fail gracefully here
							// given the absolute rarity of this case, simply process this part in the current thread
							assert(false);
							pcall(thirdcounttop, input + twothirdscount, buffer + twothirdscount, movetobuffer);
						}
					}catch(...){// std::async may fail gracefully here
						assert(false);
					}
				}
				// process the lower half (rounded down) here
				pcall(finalcount, input, buffer, movetobuffer);// architecture: indirect calls only have a modest performance penalty on most platforms
			}

			// merging phase
			if(finalcount != count){// conditionally enable multi-threading here
				// This cannot be synchronised by a simple spinlock, as the processing above will most likely involve waiting on two other threads to finish.
				// note that input and buffer were swapped in the initial phase
				T *tmp{input};
				if(movetobuffer){
					input = buffer;
					buffer = tmp;
				}
				std::future<void> asynchandle;
				try{
					// process the upper half separately if possible
					asynchandle = std::async(std::launch::async, mergethirdsmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>, count, input, buffer);
				}catch(...){// std::async may fail gracefully here
					assert(false);
					// given the absolute rarity of this case, simply process this part in the current thread
					mergethirdsmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>(count, input, buffer);
				}
				mergethirdsmain<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>(count, input, buffer);
			}
			return;
		}else{// single-threaded
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, false>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, false>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, false>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, false>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, false>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>;
			}
		}
	}
	pcall(count, input, buffer, movetobuffer);// architecture: indirect calls only have a modest performance penalty on most platforms
}
#endif// !defined(RSBD8_THREAD_MAXIMUM) || 6 <= (RSBD8_THREAD_MAXIMUM)

#if !defined(RSBD8_THREAD_MAXIMUM) || 8 <= (RSBD8_THREAD_MAXIMUM)
// Up to 8-way multithreading functions without indirection

template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T
#if !defined(RSBD8_THREAD_MAXIMUM) || 16 <= (RSBD8_THREAD_MAXIMUM)
	, typename X
#endif
	>
RSBD8_FUNC_NORMAL std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
	radixsortcopynoallocmulti
#else
	radixsortcopynoallocmulti8thread
#endif
	(std::size_t count, T const input[], T output[], T buffer[])noexcept{
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);
	assert(buffer);

#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>};
	if(0xFFu < count){
		unsigned reportedcores{std::thread::hardware_concurrency()};// when this is 0, assume single-core
		if(1 < reportedcores){// 2-way limit
			static std::size_t constexpr limit4way{base4waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
			if(3 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 4 > (RSBD8_THREAD_MINIMUM)
				&& limit4way < count
#endif
				){// 4-way limit
				// initial phase with regular sorting of both halves
				// select the smallest unsigned type for the indices
				// architecture: this compiles into just a few conditional move instructions on most platforms
				pcall = radixsortcopynoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t>;
				if constexpr(ULLONG_MAX > limit4way && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
					pcall = radixsortcopynoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long>;
				}
				if constexpr(ULONG_MAX > limit4way && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
					pcall = radixsortcopynoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long>;
				}
				if constexpr(UINT_MAX > limit4way && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
					pcall = radixsortcopynoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned>;
				}
				if constexpr(USHRT_MAX > limit4way && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
					pcall = radixsortcopynoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short>;
				}
				if constexpr(UCHAR_MAX > limit4way && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
					pcall = radixsortcopynoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char>;
				}
#else// no indirect secondary call
				static constexpr auto pcall{radixsortcopynoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, X>};
#endif
				unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
				{
					std::future<void> asynchandle;
#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
					static std::size_t constexpr limit8way{base8waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
					if(7 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 8 > (RSBD8_THREAD_MINIMUM)
						&& limit8way < count
#endif
						){// 8-way limit
#endif
						std::size_t const halfcount{count >> 1};// rounded down
						try{
							// process the upper half (rounded up) separately if possible
							asynchandle = std::async(std::launch::async, pcall, (count + 1) >> 1, input + halfcount, buffer + halfcount, output + halfcount);
							usemultithread = 1;
							std::swap(output, buffer);// swap the buffer pointers for the lower half processing
						}catch(...){// std::async may fail gracefully here
							assert(false);
						}
#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
					}
#endif
					// process the lower half (rounded down) here
					pcall(count >> usemultithread, input, output, buffer);// architecture: indirect calls only have a modest performance penalty on most platforms
				}

				// merging phase
				if(usemultithread){// conditionally enable multi-threading here
					// This cannot be synchronised by a simple spinlock, as the processing above will most likely involve waiting on two other threads to finish.
					// note that output and buffer were swapped in the initial phase
					std::future<void> asynchandle;
					try{
						// process the upper half separately if possible
						asynchandle = std::async(std::launch::async, mergehalvesmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>, count, output, buffer);
					}catch(...){// std::async may fail gracefully here
						assert(false);
						// given the absolute rarity of this case, simply process this part in the current thread
						mergehalvesmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>(count, output, buffer);
					}
					mergehalvesmain<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>(count, output, buffer);
				}
#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
				return;
			}else{// dual-threaded
				// select the smallest unsigned type for the indices
				// architecture: this compiles into just a few conditional move instructions on most platforms
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, true>;
				if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, true>;
				}
				if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, true>;
				}
				if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, true>;
				}
				if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, true>;
				}
				if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, true>;
				}
			}
		}else{// single-threaded
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, false>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, false>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, false>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, false>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, false>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>;
			}
		}
	}
	pcall(count, input, output, buffer);// architecture: indirect calls only have a modest performance penalty on most platforms
#endif
}

template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T
#if !defined(RSBD8_THREAD_MAXIMUM) || 16 <= (RSBD8_THREAD_MAXIMUM)
	, typename X
#endif
	>
RSBD8_FUNC_NORMAL std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void>
#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
	radixsortnoallocmulti
#else
	radixsortnoallocmulti8thread
#endif
	(std::size_t count, T input[], T buffer[], bool movetobuffer = false)noexcept{
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(buffer);

#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>};
	if(0xFFu < count){
		unsigned reportedcores{std::thread::hardware_concurrency()};// when this is 0, assume single-core
		if(1 < reportedcores){// 2-way limit
			static std::size_t constexpr limit4way{base4waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
			if(3 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 4 > (RSBD8_THREAD_MINIMUM)
				&& limit4way < count
#endif
				){// 4-way limit
				// initial phase with regular sorting of both halves
				// select the smallest unsigned type for the indices
				// architecture: this compiles into just a few conditional move instructions on most platforms
				pcall = radixsortnoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t>;
				if constexpr(ULLONG_MAX > limit4way && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
					pcall = radixsortnoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long>;
				}
				if constexpr(ULONG_MAX > limit4way && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
					pcall = radixsortnoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long>;
				}
				if constexpr(UINT_MAX > limit4way && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
					pcall = radixsortnoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned>;
				}
				if constexpr(USHRT_MAX > limit4way && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
					pcall = radixsortnoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short>;
				}
				if constexpr(UCHAR_MAX > limit4way && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
					pcall = radixsortnoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char>;
				}
#else// no indirect secondary call
				static constexpr auto pcall{radixsortnoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, X>};
#endif
				unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
				{
					std::future<void> asynchandle;
#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
					static std::size_t constexpr limit8way{base8waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
					if(7 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 8 > (RSBD8_THREAD_MINIMUM)
						&& limit8way < count
#endif
						){// 8-way limit
#endif
						std::size_t const halfcount{count >> 1};// rounded down
						try{
							// process the upper half (rounded up) separately if possible
							asynchandle = std::async(std::launch::async, pcall, (count + 1) >> 1, input + halfcount, buffer + halfcount, !movetobuffer);
							usemultithread = 1;
							movetobuffer = !movetobuffer;// swap the buffer pointers for the lower half processing
						}catch(...){// std::async may fail gracefully here
							assert(false);
						}
#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
					}
#endif
					// process the lower half (rounded down) here
					pcall(count >> usemultithread, input, buffer, movetobuffer);// architecture: indirect calls only have a modest performance penalty on most platforms
				}

				// merging phase
				if(usemultithread){// conditionally enable multi-threading here
					// This cannot be synchronised by a simple spinlock, as the processing above will most likely involve waiting on two other threads to finish.
					// note that input and buffer were swapped in the initial phase
					T *tmp{input};
					if(movetobuffer){
						input = buffer;
						buffer = tmp;
					}
					std::future<void> asynchandle;
					try{
						// process the upper half separately if possible
						asynchandle = std::async(std::launch::async, mergehalvesmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>, count, input, buffer);
					}catch(...){// std::async may fail gracefully here
						assert(false);
						// given the absolute rarity of this case, simply process this part in the current thread
						mergehalvesmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>(count, input, buffer);
					}
					mergehalvesmain<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>(count, input, buffer);
				}
				return;
#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
			}else{// dual-threaded
				// select the smallest unsigned type for the indices
				// architecture: this compiles into just a few conditional move instructions on most platforms
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, true>;
				if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
					pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, true>;
				}
				if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
					pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, true>;
				}
				if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
					pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, true>;
				}
				if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
					pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, true>;
				}
				if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
					pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, true>;
				}
			}
		}else{// single-threaded
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, false>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, false>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, false>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, false>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, false>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>;
			}
		}
	}
	pcall(count, input, buffer, movetobuffer);// architecture: indirect calls only have a modest performance penalty on most platforms
#endif
}
#endif// !defined(RSBD8_THREAD_MAXIMUM) || 8 <= (RSBD8_THREAD_MAXIMUM)

#if !defined(RSBD8_THREAD_MAXIMUM) || 16 <= (RSBD8_THREAD_MAXIMUM)
// Up to 16-way multithreading functions without indirection

template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
RSBD8_FUNC_NORMAL std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void> radixsortcopynoallocmulti(std::size_t count, T const input[], T output[], T buffer[])noexcept{
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);
	assert(buffer);

	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>};
	if(0xFFu < count){
		unsigned reportedcores{std::thread::hardware_concurrency()};// when this is 0, assume single-core
		if(1 < reportedcores){// 2-way limit
			static std::size_t constexpr limit4way{base4waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
			if(3 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 4 > (RSBD8_THREAD_MINIMUM)
				&& limit4way < count
#endif
				){// 4-way limit
				static std::size_t constexpr limit8way{base8waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
				if(7 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 8 > (RSBD8_THREAD_MINIMUM)
					&& limit8way < count
#endif
					){// 8-way limit
					// initial phase with regular sorting of both halves
					// select the smallest unsigned type for the indices
					// architecture: this compiles into just a few conditional move instructions on most platforms
					pcall = radixsortcopynoallocmulti8thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t>;
					if constexpr(ULLONG_MAX > limit8way && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
						pcall = radixsortcopynoallocmulti8thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long>;
					}
					if constexpr(ULONG_MAX > limit8way && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
						pcall = radixsortcopynoallocmulti8thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long>;
					}
					if constexpr(UINT_MAX > limit8way && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
						pcall = radixsortcopynoallocmulti8thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned>;
					}
					if constexpr(USHRT_MAX > limit8way && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
						pcall = radixsortcopynoallocmulti8thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short>;
					}
					if constexpr(UCHAR_MAX > limit8way && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
						pcall = radixsortcopynoallocmulti8thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char>;
					}
					unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
					{
						std::future<void> asynchandle;
						static std::size_t constexpr limit16way{base16waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
						if(15 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 16 > (RSBD8_THREAD_MINIMUM)
							&& limit16way < count
#endif
							){// 16-way limit
							std::size_t const halfcount{count >> 1};// rounded down
							try{
								// process the upper half (rounded up) separately if possible
								asynchandle = std::async(std::launch::async, pcall, (count + 1) >> 1, input + halfcount, buffer + halfcount, output + halfcount);
								usemultithread = 1;
								std::swap(output, buffer);// swap the buffer pointers for the lower half processing
							}catch(...){// std::async may fail gracefully here
								assert(false);
							}
						}
						// process the lower half (rounded down) here
						pcall(count >> usemultithread, input, output, buffer);// architecture: indirect calls only have a modest performance penalty on most platforms
					}

					// merging phase
					if(usemultithread){// conditionally enable multi-threading here
						// This cannot be synchronised by a simple spinlock, as the processing above will most likely involve waiting on two other threads to finish.
						// note that output and buffer were swapped in the initial phase
						std::future<void> asynchandle;
						try{
							// process the upper half separately if possible
							asynchandle = std::async(std::launch::async, mergehalvesmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>, count, output, buffer);
						}catch(...){// std::async may fail gracefully here
							assert(false);
							// given the absolute rarity of this case, simply process this part in the current thread
							mergehalvesmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>(count, output, buffer);
						}
						mergehalvesmain<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>(count, output, buffer);
					}
					return;
				}else{// quad-threaded
					// select the smallest unsigned type for the indices
					// architecture: this compiles into just a few conditional move instructions on most platforms
					pcall = radixsortcopynoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t>;
					if constexpr(ULLONG_MAX > limit4way && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
						pcall = radixsortcopynoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long>;
					}
					if constexpr(ULONG_MAX > limit4way && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
						pcall = radixsortcopynoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long>;
					}
					if constexpr(UINT_MAX > limit4way && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
						pcall = radixsortcopynoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned>;
					}
					if constexpr(USHRT_MAX > limit4way && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
						pcall = radixsortcopynoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short>;
					}
					if constexpr(UCHAR_MAX > limit4way && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
						pcall = radixsortcopynoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char>;
					}
				}
			}else{// dual-threaded
				// select the smallest unsigned type for the indices
				// architecture: this compiles into just a few conditional move instructions on most platforms
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, true>;
				if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, true>;
				}
				if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, true>;
				}
				if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, true>;
				}
				if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, true>;
				}
				if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, true>;
				}
			}
		}else{// single-threaded
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, false>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, false>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, false>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, false>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, false>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>;
			}
		}
	}
	pcall(count, input, output, buffer);// architecture: indirect calls only have a modest performance penalty on most platforms
}

template<bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, typename T>
RSBD8_FUNC_NORMAL std::enable_if_t<
	!std::is_same_v<bool, T> &&
	(std::is_unsigned_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void> radixsortnoallocmulti(std::size_t count, T input[], T buffer[], bool movetobuffer = false)noexcept{
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(buffer);

	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>};
	if(0xFFu < count){
		unsigned reportedcores{std::thread::hardware_concurrency()};// when this is 0, assume single-core
		if(1 < reportedcores){// 2-way limit
			static std::size_t constexpr limit4way{base4waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
			if(3 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 4 > (RSBD8_THREAD_MINIMUM)
				&& limit4way < count
#endif
				){// 4-way limit
				static std::size_t constexpr limit8way{base8waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
				if(7 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 8 > (RSBD8_THREAD_MINIMUM)
					&& limit8way < count
#endif
					){// 8-way limit
					// initial phase with regular sorting of both halves
					// select the smallest unsigned type for the indices
					// architecture: this compiles into just a few conditional move instructions on most platforms
					pcall = radixsortnoallocmulti8thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t>;
					if constexpr(ULLONG_MAX > limit8way && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
						pcall = radixsortnoallocmulti8thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long>;
					}
					if constexpr(ULONG_MAX > limit8way && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
						pcall = radixsortnoallocmulti8thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long>;
					}
					if constexpr(UINT_MAX > limit8way && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
						pcall = radixsortnoallocmulti8thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned>;
					}
					if constexpr(USHRT_MAX > limit8way && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
						pcall = radixsortnoallocmulti8thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short>;
					}
					if constexpr(UCHAR_MAX > limit8way && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
						pcall = radixsortnoallocmulti8thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char>;
					}
					unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
					{
						std::future<void> asynchandle;
						static std::size_t constexpr limit16way{base16waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
						if(15 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 16 > (RSBD8_THREAD_MINIMUM)
							&& limit16way < count
#endif
							){// 16-way limit
							std::size_t const halfcount{count >> 1};// rounded down
							try{
								// process the upper half (rounded up) separately if possible
								asynchandle = std::async(std::launch::async, pcall, (count + 1) >> 1, input + halfcount, buffer + halfcount, !movetobuffer);
								usemultithread = 1;
								movetobuffer = !movetobuffer;// swap the buffer pointers for the lower half processing
							}catch(...){// std::async may fail gracefully here
								assert(false);
							}
						}
						// process the lower half (rounded down) here
						pcall(count >> usemultithread, input, buffer, movetobuffer);// architecture: indirect calls only have a modest performance penalty on most platforms
					}

					// merging phase
					if(usemultithread){// conditionally enable multi-threading here
						// This cannot be synchronised by a simple spinlock, as the processing above will most likely involve waiting on two other threads to finish.
						// note that input and buffer were swapped in the initial phase
						T *tmp{input};
						if(movetobuffer){
							input = buffer;
							buffer = tmp;
						}
						std::future<void> asynchandle;
						try{
							// process the upper half separately if possible
							asynchandle = std::async(std::launch::async, mergehalvesmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>, count, input, buffer);
						}catch(...){// std::async may fail gracefully here
							assert(false);
							// given the absolute rarity of this case, simply process this part in the current thread
							mergehalvesmtc<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>(count, input, buffer);
						}
						mergehalvesmain<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>(count, input, buffer);
					}
					return;
				}else{// quad-threaded
					// select the smallest unsigned type for the indices
					// architecture: this compiles into just a few conditional move instructions on most platforms
					pcall = radixsortnoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t>;
					if constexpr(ULLONG_MAX > limit4way && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
						pcall = radixsortnoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long>;
					}
					if constexpr(ULONG_MAX > limit4way && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
						pcall = radixsortnoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long>;
					}
					if constexpr(UINT_MAX > limit4way && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
						pcall = radixsortnoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned>;
					}
					if constexpr(USHRT_MAX > limit4way && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
						pcall = radixsortnoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short>;
					}
					if constexpr(UCHAR_MAX > limit4way && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
						pcall = radixsortnoallocmulti4thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char>;
					}
				}
			}else{// dual-threaded
				// select the smallest unsigned type for the indices
				// architecture: this compiles into just a few conditional move instructions on most platforms
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, true>;
				if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
					pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, true>;
				}
				if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
					pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, true>;
				}
				if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
					pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, true>;
				}
				if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
					pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, true>;
				}
				if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
					pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, true>;
				}
			}
		}else{// single-threaded
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, std::size_t, false>;
			if constexpr(ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long long, false>;
			}
			if constexpr(ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned long, false>;
			}
			if constexpr(UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned, false>;
			}
			if constexpr(USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned short, false>;
			}
			if constexpr(UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocmulti2thread<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T, unsigned char, false>;
			}
		}
	}
	pcall(count, input, buffer, movetobuffer);// architecture: indirect calls only have a modest performance penalty on most platforms
}
#endif// !defined(RSBD8_THREAD_MAXIMUM) || 16 <= (RSBD8_THREAD_MAXIMUM)

#if !defined(RSBD8_THREAD_MAXIMUM) || 4 <= (RSBD8_THREAD_MAXIMUM)
// Helper functions for merging the halves from multithreading inputs with indirection

// multithreading companion function for radixsortcopynoallocmulti() and radixsortnoallocmulti()
// standalone function, reused in the same template form (hence the RSBD8_FUNC_NORMAL) in the 4-, 8- and then 16-way multithreading parts
template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> mergehalvesmtc(std::size_t count, V *const input[], V *output[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	using W = typename std::conditional_t<std::is_class_v<T> || std::is_union_v<T> || isabsvalue || !issignmode || isfltpmode, std::enable_if<true, T>, std::make_signed<T>>::type;// for simple signed comparisons, use signed W
	assert(2 < count);
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);

	// process the high half here (rounded up)
	std::size_t halfcount{count >> 1};
	std::intptr_t *pout{reinterpret_cast<std::intptr_t *>(output) + (count - 1)};
	std::intptr_t const *pdatahi{reinterpret_cast<std::intptr_t const *>(input) + (!isrevorder? (count - 1) : halfcount)};
	std::intptr_t const *pdatalo{reinterpret_cast<std::intptr_t const *>(input) + (isrevorder? (count - 1) : halfcount)};
	std::intptr_t phi{*pdatahi}, plo{*pdatalo};
	--halfcount;// rounded down and one less, as the final item is handled outside of the loop
	auto imhi{indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(phi), varparameters...)};
	auto imlo{indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(plo), varparameters...)};
	auto curhi{indirectinput2<indirection1, indirection2, isindexed2, W>(imhi, varparameters...)};
	auto curlo{indirectinput2<indirection1, indirection2, isindexed2, W>(imlo, varparameters...)};
	auto[comphi, complo]{convertinput<isabsvalue, issignmode, isfltpmode, W>(curhi, curlo)};
	using M = std::conditional_t<std::is_integral_v<decltype(comphi)> &&
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		128 != CHAR_BIT * sizeof(T)// test128 and longdoubletest128 cases
#else
		64 != CHAR_BIT * sizeof(T)// test64 case
#endif
		, decltype(comphi), std::intptr_t>;// used for masking operations
	do{
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
			std::intptr_t out;
			if(!isdescsort? comphi < complo : complo < comphi){
				--pdatalo;
				out = plo;
				plo = *pdatalo;
				imlo = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(plo), varparameters...);
				curlo = indirectinput2<indirection1, indirection2, isindexed2, W>(imlo, varparameters...);
				complo = convertinput<isabsvalue, issignmode, isfltpmode, W>(curlo);// convert the value for integer comparison
			}else{
				--pdatahi;
				out = phi;
				phi = *pdatahi;
				imhi = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(phi), varparameters...);
				curhi = indirectinput2<indirection1, indirection2, isindexed2, W>(imhi, varparameters...);
				comphi = convertinput<isabsvalue, issignmode, isfltpmode, W>(curhi);// convert the value for integer comparison
			}
			*pout-- = out;
		}else{// architecture: flatten the branch, at a higher register pressure cost
			std::intptr_t mask;
			if constexpr(std::is_signed_v<W>){// signed comparison optimisation
				mask = !isdescsort? comphi - complo : complo - comphi;
				mask >>= CHAR_BIT * sizeof(std::intptr_t) - 1;
			}else mask = -static_cast<std::intptr_t>(!isdescsort? comphi < complo : complo < comphi);
			std::intptr_t notmask{~mask};

			// line breaks are placed for clarity, based on the dependency sequences
			pdatalo += mask;
			pdatahi += notmask;

			std::intptr_t platestlo{reinterpret_cast<std::intptr_t>(pdatalo) & mask};
			std::intptr_t platesthi{reinterpret_cast<std::intptr_t>(pdatahi) & notmask};
			std::intptr_t outlo{plo & mask};
			std::intptr_t outhi{phi & notmask};

			platestlo |= platesthi;
			outlo |= outhi;
			plo &= notmask;
			complo &= static_cast<M>(notmask);

			std::intptr_t latestlo{*reinterpret_cast<std::intptr_t const *>(platestlo)};
			*pout-- = outlo;
			phi &= mask;

			auto im{indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(latestlo), varparameters...)};
			auto cur{indirectinput2<indirection1, indirection2, isindexed2, W>(im, varparameters...)};
			auto complatestlo{convertinput<isabsvalue, issignmode, isfltpmode, W>(cur)};// convert the value for integer comparison
			std::intptr_t latesthi{latestlo};
			latestlo &= mask;
			comphi &= static_cast<M>(mask);

			auto complatesthi{complatestlo};
			complatestlo &= static_cast<M>(mask);
			plo |= latestlo;
			latesthi &= notmask;

			complatesthi &= static_cast<M>(notmask);
			complo |= complatestlo;
			phi |= latesthi;

			comphi |= complatesthi;
		}
	}while(--halfcount);
	if(1 & count){// odd counts will be handled here
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
			std::intptr_t out;
			// the only modification here is this part
			// never sample beyond the lower division (half of count, rounded down) of the array
			// this doesn't happen to the upper half, as it has 1 more item to process in odd-count cases
			if(!isdescsort? comphi < complo : complo < comphi){
				--pdatalo;
				if constexpr(!isrevorder) if(pdatalo < reinterpret_cast<std::intptr_t const *>(input)) pdatalo = pdatahi;
				out = plo;
				plo = *pdatalo;
				imlo = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(plo), varparameters...);
				curlo = indirectinput2<indirection1, indirection2, isindexed2, W>(imlo, varparameters...);
				complo = convertinput<isabsvalue, issignmode, isfltpmode, W>(curlo);// convert the value for integer comparison
			}else{
				--pdatahi;
				if constexpr(isrevorder) if(pdatahi < reinterpret_cast<std::intptr_t const *>(input)) pdatahi = pdatalo;
				out = phi;
				phi = *pdatahi;
				imhi = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(phi), varparameters...);
				curhi = indirectinput2<indirection1, indirection2, isindexed2, W>(imhi, varparameters...);
				comphi = convertinput<isabsvalue, issignmode, isfltpmode, W>(curhi);// convert the value for integer comparison
			}
			*pout-- = out;
		}else{// architecture: flatten the branch, at a higher register pressure cost
			std::intptr_t mask;
			if constexpr(std::is_signed_v<W>){// signed comparison optimisation
				mask = !isdescsort? comphi - complo : complo - comphi;
				mask >>= CHAR_BIT * sizeof(std::intptr_t) - 1;
			}else mask = -static_cast<std::intptr_t>(!isdescsort? comphi < complo : complo < comphi);
			std::intptr_t notmask{~mask};

			// line breaks are placed for clarity, based on the dependency sequences
			pdatalo += mask;
			std::intptr_t outlo{plo & mask};
			pdatahi += notmask;
			std::intptr_t outhi{phi & notmask};

			// the only modification here is this part
			// never sample beyond the lower division (half of count, rounded down) of the array
			// this doesn't happen to the upper half, as it has 1 more item to process in odd-count cases
			if constexpr(!isrevorder){
				if(pdatalo < reinterpret_cast<std::intptr_t const *>(input)) pdatalo = pdatahi;
			}else if(pdatahi < reinterpret_cast<std::intptr_t const *>(input)) pdatahi = pdatalo;
			outlo |= outhi;
			plo &= notmask;

			std::intptr_t platestlo{reinterpret_cast<std::intptr_t>(pdatalo) & mask};
			std::intptr_t platesthi{reinterpret_cast<std::intptr_t>(pdatahi) & notmask};
			*pout-- = outlo;

			platestlo |= platesthi;
			phi &= mask;
			complo &= static_cast<M>(notmask);

			std::intptr_t latestlo{*reinterpret_cast<std::intptr_t const *>(platestlo)};
			comphi &= static_cast<M>(mask);

			auto im{indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(latestlo), varparameters...)};
			auto cur{indirectinput2<indirection1, indirection2, isindexed2, W>(im, varparameters...)};
			auto complatestlo{convertinput<isabsvalue, issignmode, isfltpmode, W>(cur)};// convert the value for integer comparison
			std::intptr_t latesthi{latestlo};
			latestlo &= mask;

			auto complatesthi{complatestlo};
			complatestlo &= static_cast<M>(mask);
			latesthi &= notmask;
			plo |= latestlo;

			complatesthi &= static_cast<M>(notmask);
			complo |= complatestlo;
			phi |= latesthi;

			comphi |= complatesthi;
		}
	}
	// finalise
	if(!isdescsort? comphi < complo : complo < comphi){
		phi = plo;
	}
	*pout = phi;
}

// multithreading main function for radixsortcopynoallocmulti() and radixsortnoallocmulti()
// standalone function, reused in the same template form (hence the RSBD8_FUNC_NORMAL) in the 4-, 8- and then 16-way multithreading parts
template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> mergehalvesmain(std::size_t count, V *const input[], V *output[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	using W = typename std::conditional_t<std::is_class_v<T> || std::is_union_v<T> || isabsvalue || !issignmode || isfltpmode, std::enable_if<true, T>, std::make_signed<T>>::type;// for simple signed comparisons, use signed W
	assert(2 < count);
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);

	// process the low half here (rounded down)
	std::size_t halfcount{count >> 1};
	std::intptr_t *pout{reinterpret_cast<std::intptr_t *>(output)};
	std::intptr_t const *pdatalo{reinterpret_cast<std::intptr_t const *>(input) + !isrevorder * halfcount};
	std::intptr_t const *pdatahi{reinterpret_cast<std::intptr_t const *>(input) + isrevorder * halfcount};
	std::intptr_t plo{*pdatalo}, phi{*pdatahi};
	--halfcount;// rounded down and one less, as the final item is handled outside of the loop
	auto imlo{indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(plo), varparameters...)};
	auto imhi{indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(phi), varparameters...)};
	auto curlo{indirectinput2<indirection1, indirection2, isindexed2, W>(imlo, varparameters...)};
	auto curhi{indirectinput2<indirection1, indirection2, isindexed2, W>(imhi, varparameters...)};
	auto[complo, comphi]{convertinput<isabsvalue, issignmode, isfltpmode, W>(curlo, curhi)};
	using M = std::conditional_t<std::is_integral_v<decltype(complo)> &&
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		128 != CHAR_BIT * sizeof(T)// test128 and longdoubletest128 cases
#else
		64 != CHAR_BIT * sizeof(T)// test64 case
#endif
		, decltype(complo), std::intptr_t>;// used for masking operations
	do{
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
			std::intptr_t out;
			if(!isdescsort? comphi < complo : complo < comphi){
				++pdatahi;
				out = phi;
				phi = *pdatahi;
				imhi = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(phi), varparameters...);
				curhi = indirectinput2<indirection1, indirection2, isindexed2, W>(imhi, varparameters...);
				comphi = convertinput<isabsvalue, issignmode, isfltpmode, W>(curhi);// convert the value for integer comparison
			}else{
				++pdatalo;
				out = plo;
				plo = *pdatalo;
				imlo = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(plo), varparameters...);
				curlo = indirectinput2<indirection1, indirection2, isindexed2, W>(imlo, varparameters...);
				complo = convertinput<isabsvalue, issignmode, isfltpmode, W>(curlo);// convert the value for integer comparison
			}
			*pout++ = out;
		}else{// architecture: flatten the branch, at a higher register pressure cost
			std::intptr_t mask;
			if constexpr(std::is_signed_v<W>){// signed comparison optimisation
				mask = !isdescsort? comphi - complo : complo - comphi;
				mask >>= CHAR_BIT * sizeof(std::intptr_t) - 1;
			}else mask = -static_cast<std::intptr_t>(!isdescsort? comphi < complo : complo < comphi);
			std::intptr_t notmask{~mask};

			// line breaks are placed for clarity, based on the dependency sequences
			pdatahi -= mask;
			std::intptr_t outhi{phi & mask};
			pdatalo -= notmask;
			std::intptr_t outlo{plo & notmask};

			std::intptr_t platesthi{reinterpret_cast<std::intptr_t>(pdatahi) & mask};
			std::intptr_t platestlo{reinterpret_cast<std::intptr_t>(pdatalo) & notmask};
			outhi |= outlo;

			platesthi |= platestlo;
			phi &= notmask;
			plo &= mask;

			std::intptr_t latesthi{*reinterpret_cast<std::intptr_t const *>(platesthi)};
			comphi &= static_cast<M>(notmask);
			*pout++ = outhi;

			auto im{indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(latesthi), varparameters...)};
			auto cur{indirectinput2<indirection1, indirection2, isindexed2, W>(im, varparameters...)};
			auto complatesthi{convertinput<isabsvalue, issignmode, isfltpmode, W>(cur)};// convert the value for integer comparison
			complo &= static_cast<M>(mask);
			std::intptr_t latestlo{latesthi};
			latesthi &= mask;

			auto complatestlo{complatesthi};
			complatesthi &= static_cast<M>(mask);
			latestlo &= notmask;
			phi |= latesthi;

			complatestlo &= static_cast<M>(notmask);
			comphi |= complatesthi;
			plo |= latestlo;

			complo |= complatestlo;
		}
	}while(--halfcount);
	// finalise
	if(!isdescsort? comphi < complo : complo < comphi){
		plo = phi;
	}
	*pout = plo;
}

// Up to 4-way multithreading functions with indirection

template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V
#if !defined(RSBD8_THREAD_MAXIMUM) || 8 <= (RSBD8_THREAD_MAXIMUM)
	, typename X
#endif
	, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void>
#if false//defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM) disabed in favour of 6-thread version
	radixsortcopynoallocmulti
#else
	radixsortcopynoallocmulti4thread
#endif
	(std::size_t count, V *const input[], V *output[], V *buffer[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);
	assert(buffer);

#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>};
	if(0xFFu < count){
		unsigned reportedcores{std::thread::hardware_concurrency()};// when this is 0, assume single-core
		if(1 < reportedcores){// 2-way limit
			// initial phase with regular sorting of both halves
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, true, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, true, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, true, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, true, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, true, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, true, vararguments...>;
			}
#else// no indirect secondary call
			static auto constexpr pcall{radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X, true, vararguments...>};
#endif
			unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
			{
				std::future<void> asynchandle;
#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
				static std::size_t constexpr limit4way{base4waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
				if(3 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 4 > (RSBD8_THREAD_MINIMUM)
					&& limit4way < count
#endif
					){// 4-way limit
#endif
					std::size_t const halfcount{count >> 1};// rounded down
					try{
						// process the upper half (rounded up) separately if possible
						asynchandle = std::async(std::launch::async, pcall, (count + 1) >> 1, input + halfcount, buffer + halfcount, output + halfcount, varparameters...);
						usemultithread = 1;
						std::swap(output, buffer);// swap the buffer pointers for the lower half processing
					}catch(...){// std::async may fail gracefully here
						assert(false);
					}
#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
				}
#endif
				// process the lower half (rounded down) here
				pcall(count >> usemultithread, input, output, buffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
			}

			// merging phase
			if(usemultithread){// conditionally enable multi-threading here
				// This cannot be synchronised by a simple spinlock, as the processing above will most likely involve waiting on two other threads to finish.
				// note that output and buffer were swapped in the initial phase
				std::future<void> asynchandle;
				try{
					// process the upper half separately if possible
					asynchandle = std::async(std::launch::async, mergehalvesmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>, count, output, buffer, varparameters...);
				}catch(...){// std::async may fail gracefully here
					assert(false);
					// given the absolute rarity of this case, simply process this part in the current thread
					mergehalvesmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>(count, output, buffer, varparameters...);
				}
				mergehalvesmain<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>(count, output, buffer, varparameters...);
			}
			return;
#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
		}else{// single-threaded
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, false, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, false, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, false, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, false, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, false, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>;
			}
		}
	}
	pcall(count, input, output, buffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
#endif
}

template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V
#if !defined(RSBD8_THREAD_MAXIMUM) || 8 <= (RSBD8_THREAD_MAXIMUM)
	, typename X
#endif
	, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void>
#if false//defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM) disabed in favour of 6-thread version
	radixsortnoallocmulti
#else
	radixsortnoallocmulti4thread
#endif
	(std::size_t count, V *input[], V *buffer[], bool movetobuffer = false, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(buffer);

#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>};
	if(0xFFu < count){
		unsigned reportedcores{std::thread::hardware_concurrency()};// when this is 0, assume single-core
		if(1 < reportedcores){// 2-way limit
			// initial phase with regular sorting of both halves
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, true, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, true, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, true, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, true, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, true, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, true, vararguments...>;
			}
#else// no indirect secondary call
			static auto constexpr pcall{radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X, true, vararguments...>};
#endif
			unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
			{
				std::future<void> asynchandle;
#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
				static std::size_t constexpr limit4way{base4waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
				if(3 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 4 > (RSBD8_THREAD_MINIMUM)
					&& limit4way < count
#endif
					){// 4-way limit
#endif
					std::size_t const halfcount{count >> 1};// rounded down
					try{
						// process the upper half (rounded up) separately if possible
						asynchandle = std::async(std::launch::async, pcall, (count + 1) >> 1, input + halfcount, buffer + halfcount, !movetobuffer, varparameters...);
						usemultithread = 1;
						movetobuffer = !movetobuffer;// swap the buffer pointers for the lower half processing
					}catch(...){// std::async may fail gracefully here
						assert(false);
					}
#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
				}
#endif
				// process the lower half (rounded down) here
				pcall(count >> usemultithread, input, buffer, movetobuffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
			}

			// merging phase
			if(usemultithread){// conditionally enable multi-threading here
				// This cannot be synchronised by a simple spinlock, as the processing above will most likely involve waiting on two other threads to finish.
				// note that input and buffer were swapped in the initial phase
				V **tmp{input};
				if(movetobuffer){
					input = buffer;
					buffer = tmp;
				}
				std::future<void> asynchandle;
				try{
					// process the upper half separately if possible
					asynchandle = std::async(std::launch::async, mergehalvesmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>, count, input, buffer, varparameters...);
				}catch(...){// std::async may fail gracefully here
					assert(false);
					// given the absolute rarity of this case, simply process this part in the current thread
					mergehalvesmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>(count, input, buffer, varparameters...);
				}
				mergehalvesmain<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>(count, input, buffer, varparameters...);
			}
			return;
#if defined(RSBD8_THREAD_MAXIMUM) && 8 > (RSBD8_THREAD_MAXIMUM)
		}else{// single-threaded
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, false, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, false, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, false, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, false, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, false, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>;
			}
		}
	}
	pcall(count, input, buffer, movetobuffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
#endif
}
#endif// !defined(RSBD8_THREAD_MAXIMUM) || 4 <= (RSBD8_THREAD_MAXIMUM)

#if !defined(RSBD8_THREAD_MAXIMUM) || 6 <= (RSBD8_THREAD_MAXIMUM)
// Helper functions for merging the thirds from multithreading inputs with indirection

// multithreading companion function for radixsortcopynoallocmulti() and radixsortnoallocmulti()
// standalone function, reused in the same template form (hence the RSBD8_FUNC_NORMAL) in the 6-way multithreading parts
template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> mergethirdsmtc(std::size_t count, V *const input[], V *output[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	using W = typename std::conditional_t<std::is_class_v<T> || std::is_union_v<T> || isabsvalue || !issignmode || isfltpmode, std::enable_if<true, T>, std::make_signed<T>>::type;// for simple signed comparisons, use signed W
	assert(2 < count);
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);

	// process the high half here (rounded up)
	std::size_t thirdcount{count / 3};
	std::size_t thirdcountmid{(count + 1) / 3};
	std::size_t finalcount{(count >> 1) - thirdcount};// half of count (rounded down) minus thirdcount, used for finalisation
	--thirdcount;// rounded down and one less, as the final item is handled outside of the loop
	std::intptr_t *pout{reinterpret_cast<std::intptr_t *>(output) + count - 1};
	std::intptr_t const *pdata2{reinterpret_cast<std::intptr_t const *>(input) + (!isrevorder? count - 1 : thirdcount)};
	std::intptr_t const *pdata1{reinterpret_cast<std::intptr_t const *>(input) + (thirdcount + thirdcountmid)};
	std::intptr_t const *pdata0{reinterpret_cast<std::intptr_t const *>(input) + (isrevorder? count - 1 : thirdcount)};
	std::intptr_t p2{*pdata2}, p1{*pdata1}, p0{*pdata0};
	auto im2{indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p2), varparameters...)};
	auto im1{indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p1), varparameters...)};
	auto im0{indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p0), varparameters...)};
	auto cur2{indirectinput2<indirection1, indirection2, isindexed2, W>(im2, varparameters...)};
	auto cur1{indirectinput2<indirection1, indirection2, isindexed2, W>(im1, varparameters...)};
	auto cur0{indirectinput2<indirection1, indirection2, isindexed2, W>(im0, varparameters...)};
	std::intptr_t const *pdata2stop{!isrevorder? pdata1 : reinterpret_cast<std::intptr_t const *>(input) - 1};
	std::intptr_t const *pdata1stop{!isrevorder? pdata0 : pdata2};
	std::intptr_t const *pdata0stop{isrevorder? pdata1 : reinterpret_cast<std::intptr_t const *>(input) - 1};
	auto[comp2, comp1, comp0]{convertinput<isabsvalue, issignmode, isfltpmode, W>(cur2, cur1, cur0)};
	using M = std::conditional_t<std::is_integral_v<decltype(comp2)> &&
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		128 != CHAR_BIT * sizeof(T)// test128 and longdoubletest128 cases
#else
		64 != CHAR_BIT * sizeof(T)// test64 case
#endif
		, decltype(comp2), std::intptr_t>;// used for masking operations
	std::intptr_t out;
	do{
		if(!isdescsort? comp2 < comp1 : comp1 < comp2){
			if(!isdescsort? comp1 < comp0 : comp0 < comp1) goto handle0;
			--pdata1;
			out = p1;
			p1 = *pdata1;
			im1 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p1), varparameters...);
			cur1 = indirectinput2<indirection1, indirection2, isindexed2, W>(im1, varparameters...);
			comp1 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur1);// convert the value for integer comparison
		}else if(!(!isdescsort? comp2 < comp0 : comp0 < comp2)){
			--pdata2;
			out = p2;
			p2 = *pdata2;
			im2 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p2), varparameters...);
			cur2 = indirectinput2<indirection1, indirection2, isindexed2, W>(im2, varparameters...);
			comp2 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur2);// convert the value for integer comparison
		}else{
handle0:
			--pdata0;
			out = p0;
			p0 = *pdata0;
			im0 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p0), varparameters...);
			cur0 = indirectinput2<indirection1, indirection2, isindexed2, W>(im0, varparameters...);
			comp0 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur0);// convert the value for integer comparison
		}
		*pout-- = out;
	}while(--thirdcount);
	// after one third it's possble that one of the three parts has exhausted its items, check for that here
	do{// the only modification here is this part
		// never sample beyond the three divisions (the start, one third and two thirds) of the array
		if(!isdescsort? comp2 < comp1 : comp1 < comp2){
			if(!isdescsort? comp1 < comp0 : comp0 < comp1) goto handle0final;
			--pdata1;
			out = p1;
			if(pdata1stop < pdata1){
				p1 = *pdata1;
				im1 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p1), varparameters...);
				cur1 = indirectinput2<indirection1, indirection2, isindexed2, W>(im1, varparameters...);
				comp1 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur1);// convert the value for integer comparison
			}else{
				pdata1 = pdata0;
				pdata1stop = pdata0stop;
				goto lastloop;
			}
		}else if(!(!isdescsort? comp2 < comp0 : comp0 < comp2)){
			--pdata2;
			out = p2;
			if(pdata2stop < pdata2){
				p2 = *pdata2;
				im2 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p2), varparameters...);
				cur2 = indirectinput2<indirection1, indirection2, isindexed2, W>(im2, varparameters...);
				comp2 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur2);// convert the value for integer comparison
			}else{
				pdata2 = pdata1;
				pdata1 = pdata0;
				pdata2stop = pdata1stop;
				pdata1stop = pdata0stop;
				goto lastloop;
			}
		}else{
handle0final:// architecture: jump label reuse (from the else branch, including possible nop padding instructions)
			--pdata0;
			out = p0;
			if(pdata0stop >= pdata0) goto lastloop;
			p0 = *pdata0;
			im0 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p0), varparameters...);
			cur0 = indirectinput2<indirection1, indirection2, isindexed2, W>(im0, varparameters...);
			comp0 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur0);// convert the value for integer comparison
		}
		*pout-- = out;
	}while(--finalcount);
	if(1 & count){// odd counts will be handled here
		// the only modification here is this part
		// never sample beyond the three divisions (the start, one third and two thirds) of the array
		if(!isdescsort? comp2 < comp1 : comp1 < comp2){
			if(!isdescsort? comp1 < comp0 : comp0 < comp1) goto handle0odd;
			--pdata1;
			if(pdata1stop >= pdata1) pdata1 = pdata2;
			out = p1;
			p1 = *pdata1;
			im1 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p1), varparameters...);
			cur1 = indirectinput2<indirection1, indirection2, isindexed2, W>(im1, varparameters...);
			comp1 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur1);// convert the value for integer comparison
		}else if(!(!isdescsort? comp2 < comp0 : comp0 < comp2)){
			--pdata2;
			if(pdata2stop >= pdata2) pdata2 = pdata1;
			out = p2;
			p2 = *pdata2;
			im2 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p2), varparameters...);
			cur2 = indirectinput2<indirection1, indirection2, isindexed2, W>(im2, varparameters...);
			comp2 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur2);// convert the value for integer comparison
		}else{
handle0odd:
			--pdata0;
			if(pdata0stop >= pdata0) pdata0 = pdata1;
			out = p0;
			p0 = *pdata0;
			im0 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p0), varparameters...);
			cur0 = indirectinput2<indirection1, indirection2, isindexed2, W>(im0, varparameters...);
			comp0 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur0);// convert the value for integer comparison
		}
		*pout-- = out;
	}
	// finalise using all three parts
	if(!isdescsort? comp2 < comp1 : comp1 < comp2){
		comp2 = comp1;
		p2 = p1;
	}
	goto exit;
lastloop:
	*pout-- = out;
	while(--finalcount){
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
			if(!isdescsort? comp2 < comp1 : comp1 < comp2){
				--pdata1;
				out = p1;
				p1 = *pdata1;
				im1 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p1), varparameters...);
				cur1 = indirectinput2<indirection1, indirection2, isindexed2, W>(im1, varparameters...);
				comp1 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur1);// convert the value for integer comparison
			}else{
				--pdata2;
				out = p2;
				p2 = *pdata2;
				im2 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p2), varparameters...);
				cur2 = indirectinput2<indirection1, indirection2, isindexed2, W>(im2, varparameters...);
				comp2 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur2);// convert the value for integer comparison
			}
			*pout-- = out;
		}else{// architecture: flatten the branch, at a higher register pressure cost
			std::intptr_t mask;
			if constexpr(std::is_signed_v<W>){// signed comparison optimisation
				mask = !isdescsort? comp2 - comp1 : comp1 - comp2;
				mask >>= CHAR_BIT * sizeof(std::intptr_t) - 1;
			}else mask = -static_cast<std::intptr_t>(!isdescsort? comp2 < comp1 : comp1 < comp2);
			std::intptr_t notmask{~mask};

			// line breaks are placed for clarity, based on the dependency sequences
			pdata1 += mask;
			pdata2 += notmask;

			std::intptr_t platest1{reinterpret_cast<std::intptr_t>(pdata1) & mask};
			std::intptr_t platest2{reinterpret_cast<std::intptr_t>(pdata2) & notmask};
			std::intptr_t out1{p1 & mask};
			std::intptr_t out2{p2 & notmask};

			platest1 |= platest2;
			out1 |= out2;
			p1 &= notmask;
			comp1 &= static_cast<M>(notmask);

			std::intptr_t latest1{*reinterpret_cast<std::intptr_t const *>(platest1)};
			*pout-- = out1;
			p2 &= mask;

			auto im{indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(latest1), varparameters...)};
			auto cur{indirectinput2<indirection1, indirection2, isindexed2, W>(im, varparameters...)};
			auto complatest1{convertinput<isabsvalue, issignmode, isfltpmode, W>(cur)};// convert the value for integer comparison
			std::intptr_t latest2{latest1};
			latest1 &= mask;
			comp2 &= static_cast<M>(mask);

			auto complatest2{complatest1};
			complatest1 &= static_cast<M>(mask);
			p1 |= latest1;
			latest2 &= notmask;

			complatest2 &= static_cast<M>(notmask);
			comp1 |= complatest1;
			p2 |= latest2;

			comp2 |= complatest2;
		}
	}
	if(1 & count){// odd counts will be handled here
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
			// the only modification here is this part
			// never sample beyond the three divisions (the start, one third and two thirds) of the array
			if(!isdescsort? comp2 < comp1 : comp1 < comp2){
				--pdata1;
				if(pdata1stop >= pdata1) pdata1 = pdata2;
				out = p1;
				p1 = *pdata1;
				im1 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p1), varparameters...);
				cur1 = indirectinput2<indirection1, indirection2, isindexed2, W>(im1, varparameters...);
				comp1 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur1);// convert the value for integer comparison
			}else{
				--pdata2;
				if(pdata2stop >= pdata2) pdata2 = pdata1;
				out = p2;
				p2 = *pdata2;
				im2 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p2), varparameters...);
				cur2 = indirectinput2<indirection1, indirection2, isindexed2, W>(im2, varparameters...);
				comp2 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur2);// convert the value for integer comparison
			}
			*pout-- = out;
		}else{// architecture: flatten the branch, at a higher register pressure cost
			std::intptr_t mask;
			if constexpr(std::is_signed_v<W>){// signed comparison optimisation
				mask = !isdescsort? comp2 - comp1 : comp1 - comp2;
				mask >>= CHAR_BIT * sizeof(std::intptr_t) - 1;
			}else mask = -static_cast<std::intptr_t>(!isdescsort? comp2 < comp1 : comp1 < comp2);
			std::intptr_t notmask{~mask};

			// line breaks are placed for clarity, based on the dependency sequences
			pdata1 += mask;
			std::intptr_t out1{p1 & mask};
			pdata2 += notmask;
			std::intptr_t out2{p2 & notmask};

			// the only modification here is this part
			// never sample beyond the three divisions (the start, one third and two thirds) of the array
			if(pdata1stop >= pdata1) pdata1 = pdata2;
			if(pdata2stop >= pdata2) pdata2 = pdata1;
			out1 |= out2;
			p1 &= notmask;

			std::intptr_t platest1{reinterpret_cast<std::intptr_t>(pdata1) & mask};
			std::intptr_t platest2{reinterpret_cast<std::intptr_t>(pdata2) & notmask};
			*pout-- = out1;

			platest1 |= platest2;
			p2 &= mask;
			comp1 &= static_cast<M>(notmask);

			std::intptr_t latest1{*reinterpret_cast<std::intptr_t const *>(platest1)};
			comp2 &= static_cast<M>(mask);

			auto im{indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(latest1), varparameters...)};
			auto cur{indirectinput2<indirection1, indirection2, isindexed2, W>(im, varparameters...)};
			auto complatest1{convertinput<isabsvalue, issignmode, isfltpmode, W>(cur)};// convert the value for integer comparison
			std::intptr_t latest2{latest1};
			latest1 &= mask;

			auto complatest2{complatest1};
			complatest1 &= static_cast<M>(mask);
			latest2 &= notmask;
			p1 |= latest1;

			complatest2 &= static_cast<M>(notmask);
			comp1 |= complatest1;
			p2 |= latest2;

			comp2 |= complatest2;
		}
	}
	// finalise using only two parts
exit:
	if(!isdescsort? comp2 < comp1 : comp1 < comp2){
		p2 = p1;
	}
	*pout = p2;
}

// multithreading main function for radixsortcopynoallocmulti() and radixsortnoallocmulti()
// standalone function, reused in the same template form (hence the RSBD8_FUNC_NORMAL) in the 6-way multithreading parts
template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> mergethirdsmain(std::size_t count, V *const input[], V *output[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	using W = typename std::conditional_t<std::is_class_v<T> || std::is_union_v<T> || isabsvalue || !issignmode || isfltpmode, std::enable_if<true, T>, std::make_signed<T>>::type;// for simple signed comparisons, use signed W
	assert(2 < count);
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);

	// process the low half here (rounded down)
	std::size_t thirdcount{count / 3};
	std::size_t const thirdcountmid{(count + 1) / 3};
	std::intptr_t *pout{reinterpret_cast<std::intptr_t *>(output)};
	std::intptr_t const *pdata0{reinterpret_cast<std::intptr_t const *>(input) + isrevorder * (thirdcount + thirdcountmid)};
	std::intptr_t const *pdata1{reinterpret_cast<std::intptr_t const *>(input) + thirdcount};
	std::intptr_t const *pdata2{reinterpret_cast<std::intptr_t const *>(input) + !isrevorder * (thirdcount + thirdcountmid)};
	std::intptr_t p0{*pdata0}, p1{*pdata1}, p2{*pdata2};
	std::size_t finalcount{(count >> 1) - thirdcount};// half of count (rounded down) minus thirdcount, used for finalisation
	--thirdcount;// rounded down and one less, as the final item is handled outside of the loop
	auto im0{indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p0), varparameters...)};
	auto im1{indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p1), varparameters...)};
	auto im2{indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p2), varparameters...)};
	auto cur0{indirectinput2<indirection1, indirection2, isindexed2, W>(im0, varparameters...)};
	auto cur1{indirectinput2<indirection1, indirection2, isindexed2, W>(im1, varparameters...)};
	auto cur2{indirectinput2<indirection1, indirection2, isindexed2, W>(im2, varparameters...)};
	std::intptr_t const *const pdata0stop{!isrevorder? pdata1 : reinterpret_cast<std::intptr_t const *>(input) + count};
	std::intptr_t const *const pdata1stop{!isrevorder? pdata2 : pdata0};
	std::intptr_t const *const pdata2stop{isrevorder? pdata1 : reinterpret_cast<std::intptr_t const *>(input) + count};
	auto[comp0, comp1, comp2]{convertinput<isabsvalue, issignmode, isfltpmode, W>(cur0, cur1, cur2)};
	using M = std::conditional_t<std::is_integral_v<decltype(comp0)> &&
#if 0xFFFFFFFFFFFFFFFFu <= UINTPTR_MAX
		128 != CHAR_BIT * sizeof(T)// test128 and longdoubletest128 cases
#else
		64 != CHAR_BIT * sizeof(T)// test64 case
#endif
		, decltype(comp0), std::intptr_t>;// used for masking operations
	std::intptr_t out;
	do{
		if(!isdescsort? comp1 < comp0 : comp0 < comp1){
			if(!isdescsort? comp2 < comp1 : comp1 < comp2) goto handle2;
			++pdata1;
			out = p1;
			p1 = *pdata1;
			im1 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p1), varparameters...);
			cur1 = indirectinput2<indirection1, indirection2, isindexed2, W>(im1, varparameters...);
			comp1 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur1);// convert the value for integer comparison
		}else if(!(!isdescsort? comp2 < comp0 : comp0 < comp2)){
			++pdata0;
			out = p0;
			p0 = *pdata0;
			im0 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p0), varparameters...);
			cur0 = indirectinput2<indirection1, indirection2, isindexed2, W>(im0, varparameters...);
			comp0 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur0);// convert the value for integer comparison
		}else{
handle2:// architecture: jump label reuse (from the else branch, including possible nop padding instructions)
			++pdata2;
			out = p2;
			p2 = *pdata2;
			im2 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p2), varparameters...);
			cur2 = indirectinput2<indirection1, indirection2, isindexed2, W>(im2, varparameters...);
			comp2 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur2);// convert the value for integer comparison
		}
		*pout++ = out;
	}while(--thirdcount);
	// after one third it's possble that one of the three parts has exhausted its items, check for that here
	do{// the only modification here is this part
		// never sample beyond the three divisions (one third, two thirds and the end) of the array
		if(!isdescsort? comp1 < comp0 : comp0 < comp1){
			if(!isdescsort? comp2 < comp1 : comp1 < comp2) goto handle2final;
			++pdata1;
			out = p1;
			if(pdata1stop > pdata1){
				p1 = *pdata1;
				im1 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p1), varparameters...);
				cur1 = indirectinput2<indirection1, indirection2, isindexed2, W>(im1, varparameters...);
				comp1 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur1);// convert the value for integer comparison
			}else{
				pdata1 = pdata2;
				goto lastloop;
			}
		}else if(!(!isdescsort? comp2 < comp0 : comp0 < comp2)){
			++pdata0;
			out = p0;
			if(pdata0stop > pdata0){
				p0 = *pdata0;
				im0 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p0), varparameters...);
				cur0 = indirectinput2<indirection1, indirection2, isindexed2, W>(im0, varparameters...);
				comp0 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur0);// convert the value for integer comparison
			}else{
				pdata0 = pdata1;
				pdata1 = pdata2;
				goto lastloop;
			}
		}else{
handle2final:// architecture: jump label reuse (from the else branch, including possible nop padding instructions)
			++pdata2;
			out = p2;
			if(pdata2stop <= pdata2) goto lastloop;
			p2 = *pdata2;
			im2 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p2), varparameters...);
			cur2 = indirectinput2<indirection1, indirection2, isindexed2, W>(im2, varparameters...);
			comp2 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur2);// convert the value for integer comparison
		}
		*pout++ = out;
	}while(--finalcount);
	// finalise using all three parts
	if(!isdescsort? comp2 < comp1 : comp1 < comp2){
		comp1 = comp2;
		p1 = p2;
	}
	goto exit;
lastloop:
	*pout++ = out;
	while(--finalcount){
		if constexpr(defaultgprfilesize < gprfilesize::large){// architecture: don't flatten the branch when there's few registers
			if(!isdescsort? comp1 < comp0 : comp0 < comp1){
				++pdata1;
				out = p1;
				p1 = *pdata1;
				im1 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p1), varparameters...);
				cur1 = indirectinput2<indirection1, indirection2, isindexed2, W>(im1, varparameters...);
				comp1 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur1);// convert the value for integer comparison
			}else{
				++pdata0;
				out = p0;
				p0 = *pdata0;
				im0 = indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(p0), varparameters...);
				cur0 = indirectinput2<indirection1, indirection2, isindexed2, W>(im0, varparameters...);
				comp0 = convertinput<isabsvalue, issignmode, isfltpmode, W>(cur0);// convert the value for integer comparison
			}
			*pout++ = out;
		}else{// flatten the branch, at a higher register pressure cost
			std::intptr_t mask;
			if constexpr(std::is_signed_v<W>){// signed comparison optimisation
				mask = !isdescsort? comp1 - comp0 : comp0 - comp1;
				mask >>= CHAR_BIT * sizeof(std::intptr_t) - 1;
			}else mask = -static_cast<std::intptr_t>(!isdescsort? comp1 < comp0 : comp0 < comp1);
			std::intptr_t notmask{~mask};

			// line breaks are placed for clarity, based on the dependency sequences
			pdata1 -= mask;
			std::intptr_t out1{p1 & mask};
			pdata0 -= notmask;
			std::intptr_t out0{p0 & notmask};

			std::intptr_t platest1{reinterpret_cast<std::intptr_t>(pdata1) & mask};
			std::intptr_t platest0{reinterpret_cast<std::intptr_t>(pdata0) & notmask};
			out1 |= out0;

			platest1 |= platest0;
			p1 &= notmask;
			p0 &= mask;

			std::intptr_t latest1{*reinterpret_cast<std::intptr_t const *>(platest1)};
			comp1 &= static_cast<M>(notmask);
			*pout++ = out1;

			auto im{indirectinput1<indirection1, isindexed2, W, V>(reinterpret_cast<V *>(latest1), varparameters...)};
			auto cur{indirectinput2<indirection1, indirection2, isindexed2, W>(im, varparameters...)};
			auto complatest1{convertinput<isabsvalue, issignmode, isfltpmode, W>(cur)};// convert the value for integer comparison
			comp0 &= static_cast<M>(mask);
			std::intptr_t latest0{latest1};
			latest1 &= mask;

			auto complatest0{complatest1};
			complatest1 &= static_cast<M>(mask);
			latest0 &= notmask;
			p1 |= latest1;

			complatest0 &= static_cast<M>(notmask);
			comp1 |= complatest1;
			p0 |= latest0;

			comp0 |= complatest0;
		}
	}
	// finalise using only two parts
exit:
	if(!isdescsort? comp1 < comp0 : comp0 < comp1){
		p0 = p1;
	}
	*pout++ = p0;
}

// Up to 6-way multithreading functions with indirection

template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void>
#if true// set the 6-thread version as default
	radixsortcopynoallocmulti
#else
	radixsortcopynoallocmulti6thread
#endif
	(std::size_t count, V *const input[], V *output[], V *buffer[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);
	assert(buffer);

	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>};
	if(0xFFu < count){
		unsigned reportedcores{std::thread::hardware_concurrency()};// when this is 0, assume single-core
		if(1 < reportedcores){// 2-way limit
			// initial phase with regular sorting of both halves
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, true, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, true, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, true, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, true, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, true, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, true, vararguments...>;
			}
			std::size_t finalcount{count};// depending on multithreading, this will be either count or one third of count (rounded down)
			{
				std::future<void> asynchandle;
				static std::size_t constexpr limit6way{base6waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
				if(5 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 6 > (RSBD8_THREAD_MINIMUM)
					&& limit6way < count
#endif
					){// 6-way limit
					std::size_t const thirdcount{count / 3};// rounded down
					std::size_t const thirdcountmid{(count + 1) / 3};
					try{
						// process the middle third (rounded in between) separately if possible
						asynchandle = std::async(std::launch::async, pcall, thirdcountmid, input + thirdcount, buffer + thirdcount, output + thirdcount, varparameters...);
						std::size_t const twothirdscount{thirdcount + thirdcountmid};
						std::swap(output, buffer);// swap the buffer pointers for the lower half processing
						std::size_t const thirdcounttop{count - twothirdscount};
						finalcount = thirdcount;
						try{
							// process the top third (rounded up) separately if possible
							asynchandle = std::async(std::launch::async, pcall, thirdcounttop, input + twothirdscount, output + twothirdscount, buffer + twothirdscount, varparameters...);
						}catch(...){// std::async may fail gracefully here
							// given the absolute rarity of this case, simply process this part in the current thread
							assert(false);
							pcall(thirdcounttop, input + twothirdscount, output + twothirdscount, buffer + twothirdscount, varparameters...);
						}
					}catch(...){// std::async may fail gracefully here
						assert(false);
					}
				}
				// process the lower third (rounded down) here
				pcall(finalcount, input, output, buffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
			}

			// merging phase
			if(finalcount != count){// conditionally enable multi-threading here
				// This cannot be synchronised by a simple spinlock, as the processing above will most likely involve waiting on two other threads to finish.
				// note that output and buffer were swapped in the initial phase
				std::future<void> asynchandle;
				try{
					// process the upper half separately if possible
					asynchandle = std::async(std::launch::async, mergethirdsmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>, count, output, buffer, varparameters...);
				}catch(...){// std::async may fail gracefully here
					assert(false);
					// given the absolute rarity of this case, simply process this part in the current thread
					mergethirdsmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>(count, output, buffer, varparameters...);
				}
				mergethirdsmain<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>(count, output, buffer, varparameters...);
			}
			return;
		}else{// single-threaded
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, false, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, false, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, false, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, false, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, false, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>;
			}
		}
	}
	pcall(count, input, output, buffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
}

template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void>
#if true// set the 6-thread version as default
	radixsortnoallocmulti
#else
	radixsortnoallocmulti6thread
#endif
	(std::size_t count, V *input[], V *buffer[], bool movetobuffer = false, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(buffer);

	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>};
	if(0xFFu < count){
		unsigned reportedcores{std::thread::hardware_concurrency()};// when this is 0, assume single-core
		if(1 < reportedcores){// 2-way limit
			// initial phase with regular sorting of both halves
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, true, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, true, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, true, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, true, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, true, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, true, vararguments...>;
			}
			std::size_t finalcount{count};// depending on multithreading, this will be either count or one third of count (rounded down)
			{
				std::future<void> asynchandle;
				static std::size_t constexpr limit6way{base6waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
				if(5 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 6 > (RSBD8_THREAD_MINIMUM)
					&& limit6way < count
#endif
					){// 6-way limit
					std::size_t const thirdcount{count / 3};// rounded down
					std::size_t const thirdcountmid{(count + 1) / 3};
					try{
						// process the middle third (rounded in between) separately if possible
						asynchandle = std::async(std::launch::async, pcall, thirdcountmid, input + thirdcount, buffer + thirdcount, !movetobuffer, varparameters...);
						std::size_t const twothirdscount{thirdcount + thirdcountmid};
						movetobuffer = !movetobuffer;// swap the buffer pointers for the lower half processing
						std::size_t const thirdcounttop{count - twothirdscount};
						finalcount = thirdcount;
						try{
							// process the top third (rounded up) separately if possible
							asynchandle = std::async(std::launch::async, pcall, thirdcounttop, input + twothirdscount, buffer + twothirdscount, movetobuffer, varparameters...);
						}catch(...){// std::async may fail gracefully here
							// given the absolute rarity of this case, simply process this part in the current thread
							assert(false);
							pcall(thirdcounttop, input + twothirdscount, buffer + twothirdscount, movetobuffer, varparameters...);
						}
					}catch(...){// std::async may fail gracefully here
						assert(false);
					}
				}
				// process the lower half (rounded down) here
				pcall(finalcount, input, buffer, movetobuffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
			}

			// merging phase
			if(finalcount != count){// conditionally enable multi-threading here
				// This cannot be synchronised by a simple spinlock, as the processing above will most likely involve waiting on two other threads to finish.
				// note that input and buffer were swapped in the initial phase
				V **tmp{input};
				if(movetobuffer){
					input = buffer;
					buffer = tmp;
				}
				std::future<void> asynchandle;
				try{
					// process the upper half separately if possible
					asynchandle = std::async(std::launch::async, mergethirdsmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>, count, input, buffer, varparameters...);
				}catch(...){// std::async may fail gracefully here
					assert(false);
					// given the absolute rarity of this case, simply process this part in the current thread
					mergethirdsmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>(count, input, buffer, varparameters...);
				}
				mergethirdsmain<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>(count, input, buffer, varparameters...);
			}
			return;
		}else{// single-threaded
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, false, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, false, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, false, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, false, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, false, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>;
			}
		}
	}
	pcall(count, input, buffer, movetobuffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
}
#endif// !defined(RSBD8_THREAD_MAXIMUM) || 6 <= (RSBD8_THREAD_MAXIMUM)

#if !defined(RSBD8_THREAD_MAXIMUM) || 8 <= (RSBD8_THREAD_MAXIMUM)
// Up to 8-way multithreading functions with indirection

template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V
#if !defined(RSBD8_THREAD_MAXIMUM) || 16 <= (RSBD8_THREAD_MAXIMUM)
	, typename X
#endif
	, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void>
#if false//defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM) disabled in favour of 6-thread version
	radixsortcopynoallocmulti
#else
	radixsortcopynoallocmulti8thread
#endif
	(std::size_t count, V *const input[], V *output[], V *buffer[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);
	assert(buffer);

#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>};
	if(0xFFu < count){
		unsigned reportedcores{std::thread::hardware_concurrency()};// when this is 0, assume single-core
		if(1 < reportedcores){// 2-way limit
			static std::size_t constexpr limit4way{base4waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
			if(3 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 4 > (RSBD8_THREAD_MINIMUM)
				&& limit4way < count
#endif
				){// 4-way limit
				// initial phase with regular sorting of both halves
				// select the smallest unsigned type for the indices
				// architecture: this compiles into just a few conditional move instructions on most platforms
				pcall = radixsortcopynoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, vararguments...>;
				if constexpr(ULLONG_MAX > limit4way && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
					pcall = radixsortcopynoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, vararguments...>;
				}
				if constexpr(ULONG_MAX > limit4way && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
					pcall = radixsortcopynoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, vararguments...>;
				}
				if constexpr(UINT_MAX > limit4way && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
					pcall = radixsortcopynoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, vararguments...>;
				}
				if constexpr(USHRT_MAX > limit4way && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
					pcall = radixsortcopynoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, vararguments...>;
				}
				if constexpr(UCHAR_MAX > limit4way && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
					pcall = radixsortcopynoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, vararguments...>;
				}
#else// no indirect secondary call
				static constexpr auto pcall{radixsortcopynoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X, vararguments...>};
#endif
				unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
				{
					std::future<void> asynchandle;
#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
					static std::size_t constexpr limit8way{base8waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
					if(7 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 8 > (RSBD8_THREAD_MINIMUM)
						&& limit8way < count
#endif
						){// 8-way limit
#endif
						std::size_t const halfcount{count >> 1};// rounded down
						try{
							// process the upper half (rounded up) separately if possible
							asynchandle = std::async(std::launch::async, pcall, (count + 1) >> 1, input + halfcount, buffer + halfcount, output + halfcount, varparameters...);
							usemultithread = 1;
							std::swap(output, buffer);// swap the buffer pointers for the lower half processing
						}catch(...){// std::async may fail gracefully here
							assert(false);
						}
#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
					}
#endif
					// process the lower half (rounded down) here
					pcall(count >> usemultithread, input, output, buffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
				}

				// merging phase
				if(usemultithread){// conditionally enable multi-threading here
					// This cannot be synchronised by a simple spinlock, as the processing above will most likely involve waiting on two other threads to finish.
					// note that output and buffer were swapped in the initial phase
					std::future<void> asynchandle;
					try{
						// process the upper half separately if possible
						asynchandle = std::async(std::launch::async, mergehalvesmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>, count, output, buffer, varparameters...);
					}catch(...){// std::async may fail gracefully here
						assert(false);
						// given the absolute rarity of this case, simply process this part in the current thread
						mergehalvesmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>(count, output, buffer, varparameters...);
					}
					mergehalvesmain<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>(count, output, buffer, varparameters...);
				}
				return;
#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
			}else{// dual-threaded
				// select the smallest unsigned type for the indices
				// architecture: this compiles into just a few conditional move instructions on most platforms
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, true, vararguments...>;
				if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, true, vararguments...>;
				}
				if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, true, vararguments...>;
				}
				if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, true, vararguments...>;
				}
				if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, true, vararguments...>;
				}
				if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, true, vararguments...>;
				}
			}
		}else{// single-threaded
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, false, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, false, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, false, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, false, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, false, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>;
			}
		}
	}
	pcall(count, input, output, buffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
#endif
}

template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V
#if !defined(RSBD8_THREAD_MAXIMUM) || 16 <= (RSBD8_THREAD_MAXIMUM)
	, typename X
#endif
	, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void>
#if false//defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM) disabled in favour of 6-thread version
	radixsortnoallocmulti
#else
	radixsortnoallocmulti8thread
#endif
	(std::size_t count, V *input[], V *buffer[], bool movetobuffer = false, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(buffer);

#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>};
	if(0xFFu < count){
		unsigned reportedcores{std::thread::hardware_concurrency()};// when this is 0, assume single-core
		if(1 < reportedcores){// 2-way limit
			static std::size_t constexpr limit4way{base4waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
			if(3 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 4 > (RSBD8_THREAD_MINIMUM)
				&& limit4way < count
#endif
				){// 4-way limit
				// initial phase with regular sorting of both halves
				// select the smallest unsigned type for the indices
				// architecture: this compiles into just a few conditional move instructions on most platforms
				pcall = radixsortnoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, vararguments...>;
				if constexpr(ULLONG_MAX > limit4way && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
					pcall = radixsortnoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, vararguments...>;
				}
				if constexpr(ULONG_MAX > limit4way && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
					pcall = radixsortnoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, vararguments...>;
				}
				if constexpr(UINT_MAX > limit4way && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
					pcall = radixsortnoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, vararguments...>;
				}
				if constexpr(USHRT_MAX > limit4way && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
					pcall = radixsortnoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, vararguments...>;
				}
				if constexpr(UCHAR_MAX > limit4way && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
					pcall = radixsortnoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, vararguments...>;
				}
#else// no indirect secondary call
				static auto constexpr pcall{radixsortnoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, X, vararguments...>};
#endif
				unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
				{
					std::future<void> asynchandle;
#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
					static std::size_t constexpr limit8way{base8waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
					if(7 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 8 > (RSBD8_THREAD_MINIMUM)
						&& limit8way < count
#endif
						){// 8-way limit
#endif
						std::size_t const halfcount{count >> 1};// rounded down
						try{
							// process the upper half (rounded up) separately if possible
							asynchandle = std::async(std::launch::async, pcall, (count + 1) >> 1, input + halfcount, buffer + halfcount, !movetobuffer, varparameters...);
							usemultithread = 1;
							movetobuffer = !movetobuffer;// swap the buffer pointers for the lower half processing
						}catch(...){// std::async may fail gracefully here
							assert(false);
						}
#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
					}
#endif
					// process the lower half (rounded down) here
					pcall(count >> usemultithread, input, buffer, movetobuffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
				}

				// merging phase
				if(usemultithread){// conditionally enable multi-threading here
					// This cannot be synchronised by a simple spinlock, as the processing above will most likely involve waiting on two other threads to finish.
					// note that input and buffer were swapped in the initial phase
					V **tmp{input};
					if(movetobuffer){
						input = buffer;
						buffer = tmp;
					}
					std::future<void> asynchandle;
					try{
						// process the upper half separately if possible
						asynchandle = std::async(std::launch::async, mergehalvesmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>, count, input, buffer, varparameters...);
					}catch(...){// std::async may fail gracefully here
						assert(false);
						// given the absolute rarity of this case, simply process this part in the current thread
						mergehalvesmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>(count, input, buffer, varparameters...);
					}
					mergehalvesmain<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>(count, input, buffer, varparameters...);
				}
				return;
#if defined(RSBD8_THREAD_MAXIMUM) && 16 > (RSBD8_THREAD_MAXIMUM)
			}else{// dual-threaded
				// select the smallest unsigned type for the indices
				// architecture: this compiles into just a few conditional move instructions on most platforms
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, true, vararguments...>;
				if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
					pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, true, vararguments...>;
				}
				if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
					pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, true, vararguments...>;
				}
				if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
					pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, true, vararguments...>;
				}
				if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
					pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, true, vararguments...>;
				}
				if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
					pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, true, vararguments...>;
				}
			}
		}else{// single-threaded
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, false, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, false, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, false, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, false, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, false, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>;
			}
		}
	}
	pcall(count, input, buffer, movetobuffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
#endif
}
#endif// !defined(RSBD8_THREAD_MAXIMUM) || 8 <= (RSBD8_THREAD_MAXIMUM)

#if !defined(RSBD8_THREAD_MAXIMUM) || 16 <= (RSBD8_THREAD_MAXIMUM)
// Up to 16-way multithreading functions with indirection

template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void>
#if false// disabled in favour of 6-thread version
	radixsortcopynoallocmulti
#else
	radixsortcopynoallocmulti16thread
#endif
	(std::size_t count, V *const input[], V *output[], V *buffer[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(output);
	assert(buffer);

	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>};
	if(0xFFu < count){
		unsigned reportedcores{std::thread::hardware_concurrency()};// when this is 0, assume single-core
		if(1 < reportedcores){// 2-way limit
			static std::size_t constexpr limit4way{base4waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
			if(3 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 4 > (RSBD8_THREAD_MINIMUM)
				&& limit4way < count
#endif
				){// 4-way limit
				static std::size_t constexpr limit8way{base8waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
				if(7 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 8 > (RSBD8_THREAD_MINIMUM)
					&& limit8way < count
#endif
					){// 8-way limit
					// initial phase with regular sorting of both halves
					// select the smallest unsigned type for the indices
					// architecture: this compiles into just a few conditional move instructions on most platforms
					pcall = radixsortcopynoallocmulti8thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, vararguments...>;
					if constexpr(ULLONG_MAX > limit8way && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
						pcall = radixsortcopynoallocmulti8thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, vararguments...>;
					}
					if constexpr(ULONG_MAX > limit8way && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
						pcall = radixsortcopynoallocmulti8thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, vararguments...>;
					}
					if constexpr(UINT_MAX > limit8way && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
						pcall = radixsortcopynoallocmulti8thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, vararguments...>;
					}
					if constexpr(USHRT_MAX > limit8way && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
						pcall = radixsortcopynoallocmulti8thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, vararguments...>;
					}
					if constexpr(UCHAR_MAX > limit8way && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
						pcall = radixsortcopynoallocmulti8thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, vararguments...>;
					}
					unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
					{
						std::future<void> asynchandle;
						static std::size_t constexpr limit16way{base16waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
						if(15 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 16 > (RSBD8_THREAD_MINIMUM)
							&& limit16way < count
#endif
							){// 16-way limit
							std::size_t const halfcount{count >> 1};// rounded down
							try{
								// process the upper half (rounded up) separately if possible
								asynchandle = std::async(std::launch::async, pcall, (count + 1) >> 1, input + halfcount, buffer + halfcount, output + halfcount, varparameters...);
								usemultithread = 1;
								std::swap(output, buffer);// swap the buffer pointers for the lower half processing
							}catch(...){// std::async may fail gracefully here
								assert(false);
							}
						}
						// process the lower half (rounded down) here
						pcall(count >> usemultithread, input, output, buffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
					}

					// merging phase
					if(usemultithread){// conditionally enable multi-threading here
						// This cannot be synchronised by a simple spinlock, as the processing above will most likely involve waiting on two other threads to finish.
						// note that output and buffer were swapped in the initial phase
						std::future<void> asynchandle;
						try{
							// process the upper half separately if possible
							asynchandle = std::async(std::launch::async, mergehalvesmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>, count, output, buffer, varparameters...);
						}catch(...){// std::async may fail gracefully here
							assert(false);
							// given the absolute rarity of this case, simply process this part in the current thread
							mergehalvesmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>(count, output, buffer, varparameters...);
						}
						mergehalvesmain<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>(count, output, buffer, varparameters...);
					}
					return;
				}else{// quad-threaded
					// select the smallest unsigned type for the indices
					// architecture: this compiles into just a few conditional move instructions on most platforms
					pcall = radixsortcopynoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, vararguments...>;
					if constexpr(ULLONG_MAX > limit4way && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
						pcall = radixsortcopynoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, vararguments...>;
					}
					if constexpr(ULONG_MAX > limit4way && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
						pcall = radixsortcopynoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, vararguments...>;
					}
					if constexpr(UINT_MAX > limit4way && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
						pcall = radixsortcopynoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, vararguments...>;
					}
					if constexpr(USHRT_MAX > limit4way && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
						pcall = radixsortcopynoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, vararguments...>;
					}
					if constexpr(UCHAR_MAX > limit4way && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
						pcall = radixsortcopynoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, vararguments...>;
					}
				}
			}else{// dual-threaded
				// select the smallest unsigned type for the indices
				// architecture: this compiles into just a few conditional move instructions on most platforms
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, true, vararguments...>;
				if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, true, vararguments...>;
				}
				if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, true, vararguments...>;
				}
				if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, true, vararguments...>;
				}
				if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, true, vararguments...>;
				}
				if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
					pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, true, vararguments...>;
				}
			}
		}else{// single-threaded
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, false, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, false, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, false, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, false, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, false, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortcopynoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>;
			}
		}
	}
	pcall(count, input, output, buffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
}

template<auto indirection1, bool isdescsort, bool isrevorder, bool isabsvalue, bool issignmode, bool isfltpmode, std::ptrdiff_t indirection2, bool isindexed2, typename V, typename... vararguments>
RSBD8_FUNC_NORMAL std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void>
#if false// disabled in favour of 6-thread version
	radixsortnoallocmulti
#else
	radixsortnoallocmulti16thread
#endif
	(std::size_t count, V *input[], V *buffer[], bool movetobuffer = false, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using T = tounifunsigned<std::remove_pointer_t<std::decay_t<memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>>;
	// do not pass a nullptr here, even though it's safe if count is 0
	assert(input);
	assert(buffer);

	// TODO: fine-tune, right now the threshold is set to the 8-bit limit (the minimum for an 8-bit type is 15)
	auto pcall{radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>};
	if(0xFFu < count){
		unsigned reportedcores{std::thread::hardware_concurrency()};// when this is 0, assume single-core
		if(1 < reportedcores){// 2-way limit
			static std::size_t constexpr limit4way{base4waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
			if(3 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 4 > (RSBD8_THREAD_MINIMUM)
				&& limit4way < count
#endif
				){// 4-way limit
				static std::size_t constexpr limit8way{base8waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
				if(7 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 8 > (RSBD8_THREAD_MINIMUM)
					&& limit8way < count
#endif
					){// 8-way limit
					// initial phase with regular sorting of both halves
					// select the smallest unsigned type for the indices
					// architecture: this compiles into just a few conditional move instructions on most platforms
					pcall = radixsortnoallocmulti8thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, vararguments...>;
					if constexpr(ULLONG_MAX > limit8way && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
						pcall = radixsortnoallocmulti8thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, vararguments...>;
					}
					if constexpr(ULONG_MAX > limit8way && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
						pcall = radixsortnoallocmulti8thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, vararguments...>;
					}
					if constexpr(UINT_MAX > limit8way && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
						pcall = radixsortnoallocmulti8thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, vararguments...>;
					}
					if constexpr(USHRT_MAX > limit8way && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
						pcall = radixsortnoallocmulti8thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, vararguments...>;
					}
					if constexpr(UCHAR_MAX > limit8way && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
						pcall = radixsortnoallocmulti8thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, vararguments...>;
					}
					unsigned usemultithread{};// filled in as a boolean 0 or 1, used as unsigned input later on
					{
						std::future<void> asynchandle;
						static std::size_t constexpr limit16way{base16waythreshold<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, T>()};
						if(15 < reportedcores
#if !defined(RSBD8_THREAD_MINIMUM) || 16 > (RSBD8_THREAD_MINIMUM)
							&& limit16way < count
#endif
							){// 16-way limit
							std::size_t const halfcount{count >> 1};// rounded down
							try{
								// process the upper half (rounded up) separately if possible
								asynchandle = std::async(std::launch::async, pcall, (count + 1) >> 1, input + halfcount, buffer + halfcount, !movetobuffer, varparameters...);
								usemultithread = 1;
								movetobuffer = !movetobuffer;// swap the buffer pointers for the lower half processing
							}catch(...){// std::async may fail gracefully here
								assert(false);
							}
						}
						// process the lower half (rounded down) here
						pcall(count >> usemultithread, input, buffer, movetobuffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
					}

					// merging phase
					if(usemultithread){// conditionally enable multi-threading here
						// This cannot be synchronised by a simple spinlock, as the processing above will most likely involve waiting on two other threads to finish.
						// note that input and buffer were swapped in the initial phase
						V **tmp{input};
						if(movetobuffer){
							input = buffer;
							buffer = tmp;
						}
						std::future<void> asynchandle;
						try{
							// process the upper half separately if possible
							asynchandle = std::async(std::launch::async, mergehalvesmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>, count, input, buffer, varparameters...);
						}catch(...){// std::async may fail gracefully here
							assert(false);
							// given the absolute rarity of this case, simply process this part in the current thread
							mergehalvesmtc<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>(count, input, buffer, varparameters...);
						}
						mergehalvesmain<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, vararguments...>(count, input, buffer, varparameters...);
					}
					return;
				}else{// quad-threaded
					// select the smallest unsigned type for the indices
					// architecture: this compiles into just a few conditional move instructions on most platforms
					pcall = radixsortnoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, vararguments...>;
					if constexpr(ULLONG_MAX > limit4way && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
						pcall = radixsortnoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, vararguments...>;
					}
					if constexpr(ULONG_MAX > limit4way && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
						pcall = radixsortnoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, vararguments...>;
					}
					if constexpr(UINT_MAX > limit4way && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
						pcall = radixsortnoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, vararguments...>;
					}
					if constexpr(USHRT_MAX > limit4way && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
						pcall = radixsortnoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, vararguments...>;
					}
					if constexpr(UCHAR_MAX > limit4way && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
						pcall = radixsortnoallocmulti4thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, vararguments...>;
					}
				}
			}else{// dual-threaded
				// select the smallest unsigned type for the indices
				// architecture: this compiles into just a few conditional move instructions on most platforms
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, true, vararguments...>;
				if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
					pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, true, vararguments...>;
				}
				if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
					pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, true, vararguments...>;
				}
				if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
					pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, true, vararguments...>;
				}
				if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
					pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, true, vararguments...>;
				}
				if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
					pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, true, vararguments...>;
				}
			}
		}else{// single-threaded
			// select the smallest unsigned type for the indices
			// architecture: this compiles into just a few conditional move instructions on most platforms
			pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, std::size_t, false, vararguments...>;
			if constexpr(ULLONG_MAX > 0xFFu && ULLONG_MAX < SIZE_MAX && ULLONG_MAX != ULONG_MAX) if(ULLONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long long, false, vararguments...>;
			}
			if constexpr(ULONG_MAX > 0xFFu && ULONG_MAX < SIZE_MAX && ULONG_MAX != UINT_MAX) if(ULONG_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned long, false, vararguments...>;
			}
			if constexpr(UINT_MAX > 0xFFu && UINT_MAX < SIZE_MAX && UINT_MAX != USHRT_MAX) if(UINT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned, false, vararguments...>;
			}
			if constexpr(USHRT_MAX > 0xFFu && USHRT_MAX < SIZE_MAX && USHRT_MAX != UCHAR_MAX) if(USHRT_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned short, false, vararguments...>;
			}
			if constexpr(UCHAR_MAX > 0xFFu && UCHAR_MAX < SIZE_MAX) if(UCHAR_MAX >= count){
				pcall = radixsortnoallocmulti2thread<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V, unsigned char, false, vararguments...>;
			}
		}
	}
	pcall(count, input, buffer, movetobuffer, varparameters...);// architecture: indirect calls only have a modest performance penalty on most platforms
}
#endif// !defined(RSBD8_THREAD_MAXIMUM) || 16 <= (RSBD8_THREAD_MAXIMUM)
}// namespace helper

// Definition of the GetOffsetOf and getoffsetof templates

// Altered, to gain C++17 compatibility and make the simpler getoffsetof template with only one input.
// Temporary, until a revision of "offsetof" is standardized in C++ with constexpr.
// This part isn't used internally, but serves as a tool to the user for calculating compile-time offsets.
// Section start of all rights reserved for the respective author (Sulley, 2024-06-15):
// https://sulley.cc/2024/06/15/16/18/

template<typename B, typename M, std::size_t Offset>
union PaddedUnion
{
	char c;
	B base;
	helper::memberobjectgenerator<M, static_cast<std::ptrdiff_t>(Offset)> member;
};

// ~~~~~ Begin core modification ~~~~~
template<
	auto MemberPtr,
	typename B,
	std::size_t Low,
	std::size_t High,
	std::size_t Mid = (Low + High) / 2>
struct OffsetHelper{
	using M = std::remove_reference_t<decltype(std::declval<B>().*MemberPtr)>;

	static constexpr PaddedUnion<B, M, Mid> dummy{};
	static constexpr std::size_t GetOffsetOf()noexcept{
		if constexpr(&(dummy.base.*MemberPtr) > &dummy.member.object){
			return{OffsetHelper<MemberPtr, B, Mid + 1, High>::GetOffsetOf()};
		}else if constexpr(&(dummy.base.*MemberPtr) < &dummy.member.object){
			return{OffsetHelper<MemberPtr, B, Low, Mid>::GetOffsetOf()};
		}else return{Mid};
	}
};
// ~~~~~ End core modification ~~~~~

template<auto MemberPtr, typename B>
constexpr std::size_t GetOffsetOf = OffsetHelper<MemberPtr, B, 0, sizeof(B)>::GetOffsetOf();
// Section end

template<auto memberptr>
struct memberptrsplitter{
	template<typename C, typename M>
	static constexpr C *classgrabber(M C:: *in)noexcept{static_cast<void>(in); return{};}
	static constexpr auto classptr{classgrabber(memberptr)};
	using classtype = std::remove_pointer_t<decltype(classptr)>;
};

template<auto memberptr>
constexpr std::size_t getoffsetof{OffsetHelper<memberptr, typename memberptrsplitter<memberptr>::classtype, 0, sizeof(typename memberptrsplitter<memberptr>::classtype)>::GetOffsetOf()};

// Generic large array allocation and deallocation functions

template<typename T>
#if defined(__has_cpp_attribute) && __has_cpp_attribute(nodiscard)
[[nodiscard]]
#endif
#if !defined(_WIN32) && defined(_POSIX_C_SOURCE)// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
RSBD8_FUNC_INLINE std::pair<T *, std::size_t>
#else
RSBD8_FUNC_INLINE T *
#endif
	allocatearray(std::size_t count
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
	, std::size_t largepagesize = 0
#elif defined(_POSIX_C_SOURCE)
	, int mmapflags = MAP_ANONYMOUS | MAP_PRIVATE
#endif
	)noexcept{
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
	assert(!(largepagesize - 1 & largepagesize));// a maximum of one bit should be set in the value of largepagesize
	std::size_t allocsize{count * sizeof(T)};
	std::size_t largeallocsize{(largepagesize - 1 & -static_cast<std::ptrdiff_t>(allocsize)) + allocsize};// round up to the nearest multiple of largepagesize
	DWORD alloctype{MEM_RESERVE | MEM_COMMIT};
	DWORD largealloctype{MEM_LARGE_PAGES | MEM_RESERVE | MEM_COMMIT};
	if(largepagesize) allocsize = largeallocsize, alloctype = largealloctype;
	T *buffer{reinterpret_cast<T *>(VirtualAlloc(nullptr, allocsize, alloctype, PAGE_READWRITE))};
	return{buffer};
#elif defined(_POSIX_C_SOURCE)
	std::size_t allocsize{count * sizeof(T)};
	void *pempty{};
#ifdef MAP_HUGETLB
	if(MAP_HUGETLB & mmapflags){// use the 6 bits associated with the huge TLB functionality
		std::size_t pagesize{static_cast<std::size_t>(1) << (static_cast<unsigned>(mmapflags) >> MAP_HUGE_SHIFT & ((1 << 6) - 1))};
		allocsize = (pagesize - 1 & -static_cast<std::ptrdiff_t>(allocsize)) + allocsize};// round up to the nearest multiple of pagesize
#ifdef __ia64__// Only IA64 requires this part for this type of allocation
		pempty = reinterpret_cast<void *>(0x8000000000000000UL);
#endif
	}
#endif
	T *buffer{reinterpret_cast<T *>(mmap(pempty, allocsize, PROT_READ | PROT_WRITE, mmapflags, -1, 0))};
	return{buffer, allocsize};
#else
	T *buffer{new(std::nothrow) T[count]};
	return{buffer};
#endif
}

template<typename T>
RSBD8_FUNC_INLINE void deallocatearray(T *buffer
#if !defined(_WIN32) && defined(_POSIX_C_SOURCE)// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
	, std::size_t allocsize
#endif
	)noexcept{
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
	BOOL boVirtualFree{VirtualFree(buffer, 0, MEM_RELEASE)};
	static_cast<void>(boVirtualFree);
	assert(boVirtualFree);
#elif defined(_POSIX_C_SOURCE)
	int imunmap{munmap(buffer, allocsize);
	static_cast<void>(imunmap);
	assert(!imunmap);
#else
	delete[] buffer;
#endif
}

// This class is a simple RAII wrapper for the buffer memory allocated with allocatearray().
template<typename T>
struct buffermemorywrapper{
	T *ptr;
#if defined(_POSIX_C_SOURCE)
	std::size_t size;
#endif
	RSBD8_FUNC_INLINE ~buffermemorywrapper()noexcept{
		deallocatearray(ptr
#if defined(_POSIX_C_SOURCE)
			, size
#endif
		);}
	// disable copy and move mechanisms
	buffermemorywrapper(buffermemorywrapper const &) = delete;
	buffermemorywrapper &operator=(buffermemorywrapper const &) = delete;
	RSBD8_FUNC_INLINE buffermemorywrapper(T *ptrmem
#if defined(_POSIX_C_SOURCE)
		, sizemem
#endif
		)noexcept : ptr(ptrmem)
#if defined(_POSIX_C_SOURCE)
		, size(sizemem)
#endif
	{}
};

// Wrapper template functions for the main sorting functions in this library

// Wrapper for the multi-part radixsortcopynoalloc() function without indirection
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void> radixsortcopynoalloc(std::size_t count, T const input[], T output[], T buffer[])noexcept{
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = helper::tounifunsigned<T>;
	helper::radixsortcopynoallocmulti<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, U>(count, reinterpret_cast<U const *>(input), reinterpret_cast<U *>(output), reinterpret_cast<U *>(buffer));
}

// Wrapper for the multi-part radixsortnoalloc() function without indirection
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void> radixsortnoalloc(std::size_t count, T input[], T buffer[], bool movetobuffer = false)noexcept{
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = helper::tounifunsigned<T>;
	helper::radixsortnoallocmulti<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, U>(count, reinterpret_cast<U *>(input), reinterpret_cast<U *>(buffer), movetobuffer);
}

// Wrapper for the single-part radixsortcopynoalloc() function without indirection
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T),
	void> radixsortcopynoalloc(std::size_t count, T const input[], T output[])noexcept{
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = helper::tounifunsigned<T>;
	helper::radixsortcopynoallocsingle<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, U>(count, reinterpret_cast<U const *>(input), reinterpret_cast<U *>(output));
}

// Wrapper for the single-part radixsortcopynoalloc() function without indirection with a dummy buffer argument
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T),
	void> radixsortcopynoalloc(std::size_t count, T const input[], T output[], T buffer[])noexcept{
	static_cast<void>(buffer);// the single-part version never needs an extra buffer
	radixsortcopynoalloc<direction, mode, T>(count, input, output);
}

// Wrapper for the single-part radixsortnoalloc() function without indirection
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T),
	void> radixsortnoalloc(std::size_t count, T input[], T buffer[])noexcept{
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = helper::tounifunsigned<T>;
	if constexpr((isabsvalue && issignmode) ||// both regular absolute modes
		(!isabsvalue && issignmode && isfltpmode)){// regular floating-point mode
		helper::radixsortnoallocsingle<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, U>(count, reinterpret_cast<U *>(input), reinterpret_cast<U *>(buffer));
	}else helper::radixsortnoallocsingle<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, U>(count, reinterpret_cast<U *>(input));
}

// Wrapper for the single-part radixsortnoalloc() function without indirection
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T),
	void> radixsortnoalloc(std::size_t count, T input[])noexcept{
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = helper::tounifunsigned<T>;
	if constexpr((isabsvalue && issignmode) ||// both regular absolute modes
		(!isabsvalue && issignmode && isfltpmode)){// regular floating-point mode
		static_assert(false, "Unsupported combination of sorting modes.");
	}else helper::radixsortnoallocsingle<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, U>(count, reinterpret_cast<U *>(input));
}

// Wrapper for the single-part radixsortnoalloc() and radixsortcopynoalloc() functions without indirection
// This variant does not set the default "false" for the "movetobuffer" parameter.
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T),
	void> radixsortnoalloc(std::size_t count, T input[], T buffer[], bool movetobuffer)noexcept{
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = helper::tounifunsigned<T>;
	if constexpr((isabsvalue && issignmode) ||// both regular absolute modes
		(!isabsvalue && issignmode && isfltpmode)){// regular floating-point mode
		if(!movetobuffer) helper::radixsortnoallocsingle<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, U>(count, reinterpret_cast<U *>(input), reinterpret_cast<U *>(buffer));
		else helper::radixsortcopynoallocsingle<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, U>(count, reinterpret_cast<U *>(input), reinterpret_cast<U *>(buffer));
	}else if(!movetobuffer) helper::radixsortnoallocsingle<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, U>(count, reinterpret_cast<U *>(input));
	else helper::radixsortcopynoallocsingle<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, U>(count, reinterpret_cast<U *>(input));
}

// Wrapper for the single-part radixsortnoalloc() and radixsortcopynoalloc() functions without indirection
// This variant does not set the default "false" for the "movetobuffer" parameter.
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, typename T>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T),
	void> radixsortnoalloc(std::size_t count, T input[], bool movetobuffer)noexcept{
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = helper::tounifunsigned<T>;

	if constexpr((isabsvalue && issignmode) ||// both regular absolute modes
		(!isabsvalue && issignmode && isfltpmode)){// regular floating-point mode
		static_assert(false, "Unsupported combination of sorting modes.");
	}else if(!movetobuffer) helper::radixsortnoallocsingle<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, U>(count, reinterpret_cast<U *>(input));
	else helper::radixsortcopynoallocsingle<isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, U>(count, reinterpret_cast<U *>(input));
}

// Wrapper to implement the radixsort() function without indirection, which only allocates some memory prior to sorting arrays
// This requires no specialisation for handling the single-part types.
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, typename T>
#if defined(__has_cpp_attribute) && __has_cpp_attribute(nodiscard)
[[nodiscard]]
#endif
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T),
	bool> radixsort(std::size_t count, T input[]
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		, std::size_t largepagesize = 0
#elif defined(_POSIX_C_SOURCE)
		, int mmapflags = MAP_ANONYMOUS | MAP_PRIVATE
#endif
		)noexcept{
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	if constexpr(8 >= CHAR_BIT * sizeof(T) &&
		!(isabsvalue && issignmode) &&// both regular absolute modes
		!(!isabsvalue && issignmode && isfltpmode)){// regular floating-point mode
		radixsortnoalloc<direction, mode, T>(count, input);// skip buffer allocation for these single-part types
	}else if(1 < count){// do not attempt to allocate memory if the array is already considered sorted
		auto
#if defined(_POSIX_C_SOURCE)
			[buffer, allocsize]
#else
			buffer
#endif
			{allocatearray<T>(count
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			, largepagesize
#elif defined(_POSIX_C_SOURCE)
			, mmapflags
#endif
			)};
		if(buffer){
			radixsortnoalloc<direction, mode, T>(count, input, buffer);// last parameter not filled in on purpose
			deallocatearray(buffer
#if defined(_POSIX_C_SOURCE)
				, allocsize
#endif
				);
			return{true};
		}
		return{false};
	}
	return{true};// the array is already considered sorted if the count is 0 or 1
}

// Wrapper to implement the multi-part radixsortcopy() function without indirection, which only allocates some memory prior to sorting arrays
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, typename T>
#if defined(__has_cpp_attribute) && __has_cpp_attribute(nodiscard)
[[nodiscard]]
#endif
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	bool> radixsortcopy(std::size_t count, T const input[], T output[]
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		, std::size_t largepagesize = 0
#elif defined(_POSIX_C_SOURCE)
		, int mmapflags = MAP_ANONYMOUS | MAP_PRIVATE
#endif
		)noexcept{
	if(1 < count){// do not attempt to allocate memory if the array is already considered sorted
		auto
#if defined(_POSIX_C_SOURCE)
			[buffer, allocsize]
#else
			buffer
#endif
			{allocatearray<T>(count
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			, largepagesize
#elif defined(_POSIX_C_SOURCE)
			, mmapflags
#endif
			)};
		if(buffer){
			radixsortcopynoalloc<direction, mode, T>(count, input, output, buffer);
			deallocatearray(buffer
#if defined(_POSIX_C_SOURCE)
				, allocsize
#endif
				);
			return{true};
		}
		return{false};
	}else if(1 == count) *output = *input;// copy the single element if the count is 1
	return{true};// the array is already considered sorted if the count is 0 or 1
}

// Wrapper to implement the single-part radixsortcopy() function without indirection, which only allocates some memory prior to sorting arrays
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, typename T>
#if defined(__has_cpp_attribute) && __has_cpp_attribute(nodiscard)
[[nodiscard]]
#endif
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T),
	bool> radixsortcopy(std::size_t count, T const input[], T output[]
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		, std::size_t largepagesize = 0
#elif defined(_POSIX_C_SOURCE)
		, int mmapflags = MAP_ANONYMOUS | MAP_PRIVATE
#endif
		)noexcept{
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
	assert(!(largepagesize - 1 & largepagesize));// a maximum of one bit should be set in the value of largepagesize
	static_cast<void>(largepagesize);
#elif defined(_POSIX_C_SOURCE)
	static_cast<void>(mmapflags);
#endif
	// the single-part version never needs an extra buffer
	radixsortcopynoalloc<direction, mode, T>(count, input, output);
	return{true};
}

// Wrapper for the multi-part radixsortcopynoalloc() function with simple second-level indirection
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename T, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void> radixsortcopynoalloc(std::size_t count, T *const input[], T *output[], T *buffer[], vararguments... varparameters)noexcept{
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = helper::tounifunsigned<T>;
	using V = std::conditional_t<std::is_const_v<T> && std::is_volatile_v<T>, const volatile helper::memberobjectgenerator<U, 0>,
		std::conditional_t<std::is_const_v<T>, const helper::memberobjectgenerator<U, 0>,
		std::conditional_t<std::is_volatile_v<T>, volatile helper::memberobjectgenerator<U, 0>,
		helper::memberobjectgenerator<U, 0>>>>;
	helper::radixsortcopynoallocmulti<&V::object, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2>(count, reinterpret_cast<V *const *>(input), reinterpret_cast<V **>(output), reinterpret_cast<V **>(buffer), varparameters...);
}

// Wrapper for the multi-part radixsortnoalloc() function with simple second-level indirection
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename T, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	void> radixsortnoalloc(std::size_t count, T *input[], T *buffer[], bool movetobuffer = false, vararguments... varparameters)noexcept{
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = helper::tounifunsigned<T>;
	using V = std::conditional_t<std::is_const_v<T> && std::is_volatile_v<T>, const volatile helper::memberobjectgenerator<U, 0>,
		std::conditional_t<std::is_const_v<T>, const helper::memberobjectgenerator<U, 0>,
		std::conditional_t<std::is_volatile_v<T>, volatile helper::memberobjectgenerator<U, 0>,
		helper::memberobjectgenerator<U, 0>>>>;
	helper::radixsortnoallocmulti<&V::object, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2>(count, reinterpret_cast<V **>(input), reinterpret_cast<V **>(buffer), movetobuffer, varparameters...);
}

// Wrapper for the single-part radixsortcopynoalloc() function with simple second-level indirection
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename T, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T),
	void> radixsortcopynoalloc(std::size_t count, T *const input[], T *output[], vararguments... varparameters)noexcept{
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = helper::tounifunsigned<T>;
	using V = std::conditional_t<std::is_const_v<T> && std::is_volatile_v<T>, const volatile helper::memberobjectgenerator<U, 0>,
		std::conditional_t<std::is_const_v<T>, const helper::memberobjectgenerator<U, 0>,
		std::conditional_t<std::is_volatile_v<T>, volatile helper::memberobjectgenerator<U, 0>,
		helper::memberobjectgenerator<U, 0>>>>;
	helper::radixsortcopynoallocsingle<&V::object, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2>(count, reinterpret_cast<V *const *>(input), reinterpret_cast<V **>(output), varparameters...);
}

// Wrapper for the single-part radixsortcopynoalloc() function with simple second-level indirection with a dummy buffer argument
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename T, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T),
	void> radixsortcopynoalloc(std::size_t count, T *const input[], T *output[], T *buffer[], vararguments... varparameters)noexcept{
	static_cast<void>(buffer);// the single-part version never needs an extra buffer
	radixsortcopynoalloc<direction, mode, indirection2, isindexed2, T>(count, input, output, varparameters...);
}

// Wrapper for the single-part radixsortnoalloc() function with simple second-level indirection
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename T, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T),
	void> radixsortnoalloc(std::size_t count, T *input[], T *buffer[], vararguments... varparameters)noexcept{
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = helper::tounifunsigned<T>;
	using V = std::conditional_t<std::is_const_v<T> && std::is_volatile_v<T>, const volatile helper::memberobjectgenerator<U, 0>,
		std::conditional_t<std::is_const_v<T>, const helper::memberobjectgenerator<U, 0>,
		std::conditional_t<std::is_volatile_v<T>, volatile helper::memberobjectgenerator<U, 0>,
		helper::memberobjectgenerator<U, 0>>>>;
	helper::radixsortnoallocsingle<&V::object, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2>(count, reinterpret_cast<V **>(input), reinterpret_cast<V **>(buffer), varparameters...);
}

// Wrapper for the single-part radixsortnoalloc() and radixsortcopynoalloc() functions with simple second-level indirection
// This variant does not set the default "false" for the "movetobuffer" parameter.
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename T, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T),
	void> radixsortnoalloc(std::size_t count, T *input[], T *buffer[], bool movetobuffer, vararguments... varparameters)noexcept{
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = helper::tounifunsigned<T>;
	using V = std::conditional_t<std::is_const_v<T> && std::is_volatile_v<T>, const volatile helper::memberobjectgenerator<U, 0>,
		std::conditional_t<std::is_const_v<T>, const helper::memberobjectgenerator<U, 0>,
		std::conditional_t<std::is_volatile_v<T>, volatile helper::memberobjectgenerator<U, 0>,
		helper::memberobjectgenerator<U, 0>>>>;
	if(!movetobuffer) helper::radixsortnoallocsingle<&V::object, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2>(count, reinterpret_cast<V **>(input), reinterpret_cast<V **>(buffer), varparameters...);
	else helper::radixsortcopynoallocsingle<&V::object, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2>(count, reinterpret_cast<V **>(input), reinterpret_cast<V **>(buffer), varparameters...);
}

// Wrapper to implement the radixsort() function with simple second-level indirection, which only allocates some memory prior to sorting arrays
// This requires no specialisation for handling the single-part types.
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename T, typename... vararguments>
#if defined(__has_cpp_attribute) && __has_cpp_attribute(nodiscard)
[[nodiscard]]
#endif
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T),
	bool> radixsort(std::size_t count, T *input[]
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		, std::size_t largepagesize = 0
#elif defined(_POSIX_C_SOURCE)
		, int mmapflags = MAP_ANONYMOUS | MAP_PRIVATE
#endif
		, vararguments... varparameters)noexcept{
	if(1 < count){// do not attempt to allocate memory if the array is already considered sorted
		auto
#if defined(_POSIX_C_SOURCE)
			[buffer, allocsize]
#else
			buffer
#endif
			{allocatearray<T *>(count
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			, largepagesize
#elif defined(_POSIX_C_SOURCE)
			, mmapflags
#endif
			)};
		if(buffer){
			radixsortnoalloc<direction, mode, indirection2, isindexed2, T>(count, input, buffer, false, varparameters...);
			deallocatearray(buffer
#if defined(_POSIX_C_SOURCE)
				, allocsize
#endif
				);
			return{true};
		}
		return{false};
	}
	return{true};// the array is already considered sorted if the count is 0 or 1
}

// Wrapper to implement the multi-part radixsortcopy() function with simple second-level indirection, which only allocates some memory prior to sorting arrays
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename T, typename... vararguments>
#if defined(__has_cpp_attribute) && __has_cpp_attribute(nodiscard)
[[nodiscard]]
#endif
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	128 >= CHAR_BIT * sizeof(T) &&
	8 < CHAR_BIT * sizeof(T),
	bool> radixsortcopy(std::size_t count, T *const input[], T *output[]
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		, std::size_t largepagesize = 0
#elif defined(_POSIX_C_SOURCE)
		, int mmapflags = MAP_ANONYMOUS | MAP_PRIVATE
#endif
		, vararguments... varparameters)noexcept{
	if(1 < count){// do not attempt to allocate memory if the array is already considered sorted
		auto
#if defined(_POSIX_C_SOURCE)
			[buffer, allocsize]
#else
			buffer
#endif
			{allocatearray<T *>(count
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			, largepagesize
#elif defined(_POSIX_C_SOURCE)
			, mmapflags
#endif
			)};
		if(buffer){
			radixsortcopynoalloc<direction, mode, indirection2, isindexed2, T>(count, input, output, buffer, varparameters...);
			deallocatearray(buffer
#if defined(_POSIX_C_SOURCE)
				, allocsize
#endif
				);
			return{true};
		}
		return{false};
	}else if(1 == count) *output = *input;// copy the single element if the count is 1
	return{true};// the array is already considered sorted if the count is 0 or 1
}

// Wrapper to implement the single-part radixsortcopy() function with simple second-level indirection, which only allocates some memory prior to sorting arrays
template<sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename T, typename... vararguments>
#if defined(__has_cpp_attribute) && __has_cpp_attribute(nodiscard)
[[nodiscard]]
#endif
RSBD8_FUNC_INLINE std::enable_if_t<
	(std::is_arithmetic_v<T> ||
	std::is_enum_v<T> ||
	std::is_class_v<T> || std::is_union_v<T>) &&
	8 >= CHAR_BIT * sizeof(T),
	bool> radixsortcopy(std::size_t count, T *const input[], T *output[]
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		, std::size_t largepagesize = 0
#elif defined(_POSIX_C_SOURCE)
		, int mmapflags = MAP_ANONYMOUS | MAP_PRIVATE
#endif
		, vararguments... varparameters)noexcept{
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
	assert(!(largepagesize - 1 & largepagesize));// a maximum of one bit should be set in the value of largepagesize
	static_cast<void>(largepagesize);
#elif defined(_POSIX_C_SOURCE)
	static_cast<void>(mmapflags);
#endif
	// the single-part version never needs an extra buffer
	radixsortcopynoalloc<direction, mode, indirection2, isindexed2, T>(count, input, output, varparameters...);
	return{true};
}

// Wrapper for the multi-part radixsortcopynoalloc() function with indirection
template<auto indirection1, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<helper::memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<helper::memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortcopynoalloc(std::size_t count, V *const input[], V *output[], V *buffer[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(helper::splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using W = std::decay_t<helper::memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>;
	using T = helper::tounifunsigned<std::remove_pointer_t<W>>;
	static_assert(!std::is_pointer_v<T>, "third level indirection is not supported");
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	helper::radixsortcopynoallocmulti<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V>(count, input, output, buffer, varparameters...);
}

// Wrapper for the multi-part radixsortnoalloc() function with indirection
template<auto indirection1, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<helper::memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<helper::memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortnoalloc(std::size_t count, V *input[], V *buffer[], bool movetobuffer = false, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(helper::splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using W = std::decay_t<helper::memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>;
	using T = helper::tounifunsigned<std::remove_pointer_t<W>>;
	static_assert(!std::is_pointer_v<T>, "third level indirection is not supported");
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	helper::radixsortnoallocmulti<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V>(count, input, buffer, movetobuffer, varparameters...);
}

// Wrapper for the single-part radixsortcopynoalloc() function with indirection
template<auto indirection1, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<// disable the option for with the V *buffer[] argument here, and do not allow active compile-time template evaluation with it
	!std::is_same_v<V **, std::conditional_t<0 < sizeof...(vararguments),
		std::invoke_result_t<decltype(helper::splitparameter<vararguments...>), vararguments...>, void>> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<
		typename std::enable_if<!std::is_same_v<V **, std::conditional_t<0 < sizeof...(vararguments),
			std::invoke_result_t<decltype(helper::splitparameter<vararguments...>), vararguments...>, void>>,
			helper::memberpointerdeducebody<indirection1, isindexed2, V, vararguments...>>::type>>),
	void> radixsortcopynoalloc(std::size_t count, V *const input[], V *output[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(helper::splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using W = std::decay_t<helper::memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>;
	using T = helper::tounifunsigned<std::remove_pointer_t<W>>;
	static_assert(!std::is_pointer_v<T>, "third level indirection is not supported");
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	helper::radixsortcopynoallocsingle<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V>(count, input, output, varparameters...);
}

// Wrapper for the single-part radixsortcopynoalloc() function with indirection with a dummy buffer argument
template<auto indirection1, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<helper::memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortcopynoalloc(std::size_t count, V *const input[], V *output[], V *buffer[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(helper::splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	static_cast<void>(buffer);// the single-part version never needs an extra buffer
	helper::radixsortcopynoallocsingle<indirection1, direction, mode, indirection2, isindexed2, V>(count, input, output, varparameters...);
}

// Wrapper for the single-part radixsortnoalloc() function with indirection
template<auto indirection1, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<// disable the option for with the bool movetobuffer argument here, and do not allow active compile-time template evaluation with it
	!std::is_same_v<bool, std::conditional_t<0 < sizeof...(vararguments),
		std::invoke_result_t<decltype(helper::splitparameter<vararguments...>), vararguments...>, void>> &&
	std::is_member_pointer_v<decltype(indirection1)> &&
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<
		typename std::enable_if<!std::is_same_v<bool, std::conditional_t<0 < sizeof...(vararguments),
			std::invoke_result_t<decltype(helper::splitparameter<vararguments...>), vararguments...>, void>>,
			helper::memberpointerdeducebody<indirection1, isindexed2, V, vararguments...>>::type>>),
	void> radixsortnoalloc(std::size_t count, V *input[], V *buffer[], vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(helper::splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using W = std::decay_t<helper::memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>;
	using T = helper::tounifunsigned<std::remove_pointer_t<W>>;
	static_assert(!std::is_pointer_v<T>, "third level indirection is not supported");
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	helper::radixsortnoallocsingle<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V>(count, input, buffer, varparameters...);
}

// Wrapper for the single-part radixsortnoalloc() and radixsortcopynoalloc() functions with indirection
// This variant does not set the default "false" for the "movetobuffer" parameter.
template<auto indirection1, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<helper::memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	void> radixsortnoalloc(std::size_t count, V *input[], V *buffer[], bool movetobuffer, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(helper::splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	using W = std::decay_t<helper::memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>;
	using T = helper::tounifunsigned<std::remove_pointer_t<W>>;
	static_assert(!std::is_pointer_v<T>, "third level indirection is not supported");
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && (std::is_signed_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && (std::is_floating_point_v<T> || std::is_same_v<helper::longdoubletest128, T> || std::is_same_v<helper::longdoubletest96, T> || std::is_same_v<helper::longdoubletest80, T>)) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = helper::tounifunsigned<T>;
	if(!movetobuffer){
		helper::radixsortnoallocsingle<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V>(count, input, buffer, varparameters...);
	}else{
		helper::radixsortcopynoallocsingle<indirection1, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, V>(count, input, buffer, varparameters...);
	}
}

// Wrapper to implement the radixsort() function with indirection, which only allocates some memory prior to sorting arrays
// This requires no specialisation for handling the single-part types.
template<auto indirection1, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
#if defined(__has_cpp_attribute) && __has_cpp_attribute(nodiscard)
[[nodiscard]]
#endif
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<helper::memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	bool> radixsort(std::size_t count, V *input[]
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		, std::size_t largepagesize = 0
#elif defined(_POSIX_C_SOURCE)
		, int mmapflags = MAP_ANONYMOUS | MAP_PRIVATE
#endif
		, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(helper::splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	if(1 < count){// do not attempt to allocate memory if the array is already considered sorted
		auto
#if defined(_POSIX_C_SOURCE)
			[buffer, allocsize]
#else
			buffer
#endif
			{allocatearray<V *>(count
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
				, largepagesize
#elif defined(_POSIX_C_SOURCE)
				, mmapflags
#endif
			)};
		if(buffer){
			buffermemorywrapper<V *> guard{buffer
#if defined(_POSIX_C_SOURCE)
				, allocsize
#endif
			};// ensure the buffer is deallocated, even if an exception is thrown by the getter function here
			radixsortnoalloc<indirection1, direction, mode, indirection2, isindexed2, V>(count, input, buffer, false, varparameters...);
			return{true};
		}
		return{false};
	}
	return{true};// the array is already considered sorted if the count is 0 or 1
}

// Wrapper to implement the multi-part radixsortcopy() function with indirection, which only allocates some memory prior to sorting arrays
template<auto indirection1, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
#if defined(__has_cpp_attribute) && __has_cpp_attribute(nodiscard)
[[nodiscard]]
#endif
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<helper::memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<helper::memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	bool> radixsortcopy(std::size_t count, V *const input[], V output[]
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		, std::size_t largepagesize = 0
#elif defined(_POSIX_C_SOURCE)
		, int mmapflags = MAP_ANONYMOUS | MAP_PRIVATE
#endif
		, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(helper::splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
	if(1 < count){// do not attempt to allocate memory if the array is already considered sorted
		auto
#if defined(_POSIX_C_SOURCE)
			[buffer, allocsize]
#else
			buffer
#endif
			{allocatearray<V *>(count
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			, largepagesize
#elif defined(_POSIX_C_SOURCE)
			, mmapflags
#endif
			)};
		if(buffer){
			buffermemorywrapper<V *> guard{buffer
#if defined(_POSIX_C_SOURCE)
				, allocsize
#endif
			};// ensure the buffer is deallocated, even if an exception is thrown by the getter function here
			radixsortcopynoalloc<indirection1, direction, mode, indirection2, isindexed2, V>(count, input, output, buffer, varparameters...);
			return{true};
		}
		return{false};
	}else if(1 == count) *output = *input;// copy the single element if the count is 1
	return{true};// the array is already considered sorted if the count is 0 or 1
}

// Wrapper to implement the single-part radixsortcopy() function with indirection, which only allocates some memory prior to sorting arrays
template<auto indirection1, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
#if defined(__has_cpp_attribute) && __has_cpp_attribute(nodiscard)
[[nodiscard]]
#endif
RSBD8_FUNC_INLINE std::enable_if_t<
	std::is_member_pointer_v<decltype(indirection1)> &&
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<helper::memberpointerdeduce<indirection1, isindexed2, V, vararguments...>>>),
	bool> radixsortcopy(std::size_t count, V *const input[], V *output[]
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		, std::size_t largepagesize = 0
#elif defined(_POSIX_C_SOURCE)
		, int mmapflags = MAP_ANONYMOUS | MAP_PRIVATE
#endif
		, vararguments... varparameters)noexcept(std::is_nothrow_invocable_v<decltype(helper::splitget<indirection1, isindexed2, V, vararguments...>), V *, vararguments...>){
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
	assert(!(largepagesize - 1 & largepagesize));// a maximum of one bit should be set in the value of largepagesize
	static_cast<void>(largepagesize);
#elif defined(_POSIX_C_SOURCE)
	static_cast<void>(mmapflags);
#endif
	// the single-part version never needs an extra buffer
	radixsortcopynoalloc<indirection1, direction, mode, indirection2, isindexed2, V>(count, input, output, varparameters...);
	return{true};
}

// Wrapper for the multi-part radixsortcopynoalloc() function with type and offset pointer indirection
template<typename T, std::ptrdiff_t indirection1 = 0, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<T>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<T>),
	void> radixsortcopynoalloc(std::size_t count, V *const input[], V *output[], V *buffer[], vararguments... varparameters)noexcept{
	using W = helper::tounifunsigned<std::remove_pointer_t<T>>;
	static_assert(!std::is_pointer_v<W>, "third level indirection is not supported");
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && std::is_signed_v<W>) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && std::is_signed_v<W>) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && std::is_floating_point_v<W>) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = std::conditional_t<std::is_const_v<V> && std::is_volatile_v<V>, const volatile helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>,
		std::conditional_t<std::is_const_v<V>, const helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>,
		std::conditional_t<std::is_volatile_v<V>, volatile helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>,
		helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>>>>;
	helper::radixsortcopynoallocmulti<&U::object, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, U>(count, reinterpret_cast<U *const *>(input), reinterpret_cast<U **>(output), reinterpret_cast<U **>(buffer), varparameters...);
}

// Wrapper for the multi-part radixsortnoalloc() function with type and offset pointer indirection
template<typename T, std::ptrdiff_t indirection1 = 0, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<T>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<T>),
	void> radixsortnoalloc(std::size_t count, V *input[], V *buffer[], bool movetobuffer = false, vararguments... varparameters)noexcept{
	using W = helper::tounifunsigned<std::remove_pointer_t<T>>;
	static_assert(!std::is_pointer_v<W>, "third level indirection is not supported");
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && std::is_signed_v<W>) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && std::is_signed_v<W>) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && std::is_floating_point_v<W>) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = std::conditional_t<std::is_const_v<V> && std::is_volatile_v<V>, const volatile helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>,
		std::conditional_t<std::is_const_v<V>, const helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>,
		std::conditional_t<std::is_volatile_v<V>, volatile helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>,
		helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>>>>;
	helper::radixsortnoallocmulti<&U::object, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, U>(count, reinterpret_cast<U **>(input), reinterpret_cast<U **>(buffer), movetobuffer, varparameters...);
}

// Wrapper for the single-part radixsortcopynoalloc() function with type and offset pointer indirection
template<typename T, std::ptrdiff_t indirection1 = 0, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<// disable the option for with the V *buffer[] argument here, and do not allow active compile-time template evaluation with it
	!std::is_same_v<V **, std::conditional_t<0 < sizeof...(vararguments),
		std::invoke_result_t<decltype(helper::splitparameter<vararguments...>), vararguments...>, void>> &&
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<
		typename std::enable_if<!std::is_same_v<V **, std::conditional_t<0 < sizeof...(vararguments),
			std::invoke_result_t<decltype(helper::splitparameter<vararguments...>), vararguments...>, void>>,
			helper::memberpointerdeducebody<indirection1, isindexed2, V, vararguments...>>::type>>),
	void> radixsortcopynoalloc(std::size_t count, V *const input[], V *output[], vararguments... varparameters)noexcept{
	using W = helper::tounifunsigned<std::remove_pointer_t<T>>;
	static_assert(!std::is_pointer_v<W>, "third level indirection is not supported");
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && std::is_signed_v<W>) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && std::is_signed_v<W>) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && std::is_floating_point_v<W>) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = std::conditional_t<std::is_const_v<V> && std::is_volatile_v<V>, const volatile helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>,
		std::conditional_t<std::is_const_v<V>, const helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>,
		std::conditional_t<std::is_volatile_v<V>, volatile helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>,
		helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>>>>;
	helper::radixsortcopynoallocsingle<&U::object, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, U>(count, reinterpret_cast<U *const *>(input), reinterpret_cast<U **>(output), varparameters...);
}

// Wrapper for the single-part radixsortcopynoalloc() function with type and offset pointer indirection with a dummy buffer argument
template<typename T, std::ptrdiff_t indirection1 = 0, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<T>),
	void> radixsortcopynoalloc(std::size_t count, V *const input[], V *output[], V *buffer[], vararguments... varparameters)noexcept{
	static_cast<void>(buffer);// the single-part version never needs an extra buffer
	helper::radixsortcopynoallocsingle<T, indirection1, direction, mode, indirection2, isindexed2, V>(count, input, output, varparameters...);
}

// Wrapper for the single-part radixsortnoalloc() function with type and offset pointer indirection
template<typename T, std::ptrdiff_t indirection1 = 0, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<// disable the option for with the bool movetobuffer argument here, and do not allow active compile-time template evaluation with it
	!std::is_same_v<bool, std::conditional_t<0 < sizeof...(vararguments),
		std::invoke_result_t<decltype(helper::splitparameter<vararguments...>), vararguments...>, void>> &&
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<std::decay_t<
		typename std::enable_if<!std::is_same_v<bool, std::conditional_t<0 < sizeof...(vararguments),
			std::invoke_result_t<decltype(helper::splitparameter<vararguments...>), vararguments...>, void>>,
			helper::memberpointerdeducebody<indirection1, isindexed2, V, vararguments...>>::type>>),
	void> radixsortnoalloc(std::size_t count, V *input[], V *buffer[], vararguments... varparameters)noexcept{
	using W = helper::tounifunsigned<std::remove_pointer_t<T>>;
	static_assert(!std::is_pointer_v<W>, "third level indirection is not supported");
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && std::is_signed_v<W>) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && std::is_signed_v<W>) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && std::is_floating_point_v<W>) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = std::conditional_t<std::is_const_v<V> && std::is_volatile_v<V>, const volatile helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>,
		std::conditional_t<std::is_const_v<V>, const helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>,
		std::conditional_t<std::is_volatile_v<V>, volatile helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>,
		helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>>>>;
	helper::radixsortnoallocsingle<&U::object, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, U>(count, reinterpret_cast<U **>(input), reinterpret_cast<U **>(buffer), varparameters...);
}

// Wrapper for the single-part radixsortnoalloc() and radixsortcopynoalloc() functions with with type and offset pointer indirection
// This variant does not set the default "false" for the "movetobuffer" parameter.
template<typename T, std::ptrdiff_t indirection1 = 0, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
RSBD8_FUNC_INLINE std::enable_if_t<
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<T>),
	void> radixsortnoalloc(std::size_t count, V *input[], V *buffer[], bool movetobuffer, vararguments... varparameters)noexcept{
	using W = helper::tounifunsigned<std::remove_pointer_t<T>>;
	static_assert(!std::is_pointer_v<W>, "third level indirection is not supported");
	static bool constexpr isdescsort{static_cast<bool>(1 & static_cast<unsigned char>(direction))};
	static bool constexpr isrevorder{static_cast<bool>(1 << 1 & static_cast<unsigned char>(direction))};
	static bool constexpr isabsvalue{
		(sortingmode::nativeabs <= mode && std::is_signed_v<W>) ||
		(sortingmode::native > mode && static_cast<bool>(1 & static_cast<unsigned char>(mode)))};
	static bool constexpr issignmode{
		(sortingmode::native <= mode && sortingmode::nativeabs >= mode && std::is_signed_v<W>) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 1 & static_cast<unsigned char>(mode)))};
	static bool constexpr isfltpmode{
		(sortingmode::native <= mode && std::is_floating_point_v<W>) ||
		(sortingmode::native > mode && static_cast<bool>(1 << 2 & static_cast<unsigned char>(mode)))};
	using U = std::conditional_t<std::is_const_v<V> && std::is_volatile_v<V>, const volatile helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>,
		std::conditional_t<std::is_const_v<V>, const helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>,
		std::conditional_t<std::is_volatile_v<V>, volatile helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>,
		helper::memberobjectgenerator<std::conditional_t<std::is_pointer_v<T>, helper::tounifunsigned<W> const *, helper::tounifunsigned<W>>, indirection1>>>>;
	if(!movetobuffer){
		helper::radixsortnoallocsingle<&U::object, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, U>(count, reinterpret_cast<U **>(input), reinterpret_cast<U **>(buffer), varparameters...);
	}else{
		helper::radixsortcopynoallocsingle<&U::object, isdescsort, isrevorder, isabsvalue, issignmode, isfltpmode, indirection2, isindexed2, U>(count, reinterpret_cast<U **>(input), reinterpret_cast<U **>(buffer), varparameters...);
	}
}

// Wrapper to implement the radixsort() function with with type and offset pointer indirection, which only allocates some memory prior to sorting arrays with indirection
// This requires no specialisation for handling the single-part types.
template<typename T, std::ptrdiff_t indirection1 = 0, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
#if defined(__has_cpp_attribute) && __has_cpp_attribute(nodiscard)
[[nodiscard]]
#endif
RSBD8_FUNC_INLINE std::enable_if_t<
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<T>),
	bool> radixsort(std::size_t count, V *input[]
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		, std::size_t largepagesize = 0
#elif defined(_POSIX_C_SOURCE)
		, int mmapflags = MAP_ANONYMOUS | MAP_PRIVATE
#endif
		, vararguments... varparameters)noexcept{
	if(1 < count){// do not attempt to allocate memory if the array is already considered sorted
		auto
#if defined(_POSIX_C_SOURCE)
			[buffer, allocsize]
#else
			buffer
#endif
			{allocatearray<V *>(count
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			, largepagesize
#elif defined(_POSIX_C_SOURCE)
			, mmapflags
#endif
			)};
		if(buffer){
			radixsortnoalloc<T, indirection1, direction, mode, indirection2, isindexed2, V>(count, input, buffer, false, varparameters...);
			deallocatearray(buffer
#if defined(_POSIX_C_SOURCE)
				, allocsize
#endif
				);
			return{true};
		}
		return{false};
	}
	return{true};// the array is already considered sorted if the count is 0 or 1
}

// Wrapper to implement the multi-part radixsortcopy() function with with type and offset pointer indirection, which only allocates some memory prior to sorting arrays with indirection
template<typename T, std::ptrdiff_t indirection1 = 0, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
#if defined(__has_cpp_attribute) && __has_cpp_attribute(nodiscard)
[[nodiscard]]
#endif
RSBD8_FUNC_INLINE std::enable_if_t<
	128 >= CHAR_BIT * sizeof(std::remove_pointer_t<T>) &&
	8 < CHAR_BIT * sizeof(std::remove_pointer_t<T>),
	bool> radixsortcopy(std::size_t count, V *const input[], V output[]
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		, std::size_t largepagesize = 0
#elif defined(_POSIX_C_SOURCE)
		, int mmapflags = MAP_ANONYMOUS | MAP_PRIVATE
#endif
		, vararguments... varparameters)noexcept{
	if(1 < count){// do not attempt to allocate memory if the array is already considered sorted
		auto
#if defined(_POSIX_C_SOURCE)
			[buffer, allocsize]
#else
			buffer
#endif
			{allocatearray<V *>(count
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
			, largepagesize
#elif defined(_POSIX_C_SOURCE)
			, mmapflags
#endif
			)};
		if(buffer){
			radixsortcopynoalloc<T, indirection1, direction, mode, indirection2, isindexed2, V>(count, input, output, buffer, varparameters...);
			deallocatearray(buffer
#if defined(_POSIX_C_SOURCE)
				, allocsize
#endif
				);
			return{true};
		}
		return{false};
	}else if(1 == count) *output = *input;// copy the single element if the count is 1
	return{true};// the array is already considered sorted if the count is 0 or 1
}

// Wrapper to implement the single-part radixsortcopy() function with with type and offset pointer indirection, which only allocates some memory prior to sorting arrays with indirection
template<typename T, std::ptrdiff_t indirection1 = 0, sortingdirection direction = sortingdirection::ascfwdorder, sortingmode mode = sortingmode::native, std::ptrdiff_t indirection2 = 0, bool isindexed2 = false, typename V, typename... vararguments>
#if defined(__has_cpp_attribute) && __has_cpp_attribute(nodiscard)
[[nodiscard]]
#endif
RSBD8_FUNC_INLINE std::enable_if_t<
	8 >= CHAR_BIT * sizeof(std::remove_pointer_t<T>),
	bool> radixsortcopy(std::size_t count, V *const input[], V *output[]
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
		, std::size_t largepagesize = 0
#elif defined(_POSIX_C_SOURCE)
		, int mmapflags = MAP_ANONYMOUS | MAP_PRIVATE
#endif
		, vararguments... varparameters)noexcept{
#ifdef _WIN32// _WIN32 will remain defined for Windows versions past the legacy 32-bit original.
	assert(!(largepagesize - 1 & largepagesize));// a maximum of one bit should be set in the value of largepagesize
	static_cast<void>(largepagesize);
#elif defined(_POSIX_C_SOURCE)
	static_cast<void>(mmapflags);
#endif
	// the single-part version never needs an extra buffer
	radixsortcopynoalloc<T, indirection1, direction, mode, indirection2, isindexed2, V>(count, input, output, varparameters...);
	return{true};
}

// Library finalisation
// It's a good practice to not propagate private macro definitions when compiling the next files.
// There are no more than these two items from #define statements in this library.
#undef RSBD8_FUNC_INLINE
#undef RSBD8_FUNC_NORMAL
}// namespace rsbd8